[
{
"commit_sha":"232f8275ec00767d1f100cacae4823e6f77e04ef",
"commit_node_id":"C_kwDOAAwOD9oAKDIzMmY4Mjc1ZWMwMDc2N2QxZjEwMGNhY2FlNDgyM2U2Zjc3ZTA0ZWY",
"commit_html_url":"https://github.com/openstack/nova/commit/232f8275ec00767d1f100cacae4823e6f77e04ef",
"commit_date":"2022-02-10T19:43:54Z",
"files":[
{
"sha":"b3f461cca42b3bc413767649e7284db3c7332f42",
"filename":"nova/api/openstack/compute/deferred_delete.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/deferred_delete.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/deferred_delete.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/deferred_delete.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -40,7 +40,7 @@ def _restore(self, req, id, body):\n                     target={'project_id': instance.project_id})\n         try:\n             self.compute_api.restore(context, instance)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise webob.exc.HTTPForbidden(explanation=error.format_message())\n         except exception.InstanceInvalidState as state_error:\n             common.raise_http_conflict_for_instance_invalid_state(state_error,"
},
{
"sha":"59b9c384df60d670f526f91ffb10fa09d12ab7ba",
"filename":"nova/api/openstack/compute/migrate_server.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/migrate_server.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/migrate_server.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/migrate_server.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -57,7 +57,7 @@ def _migrate(self, req, id, body):\n         try:\n             self.compute_api.resize(req.environ['nova.context'], instance,\n                                     host_name=host_name)\n-        except (exception.TooManyInstances, exception.QuotaError) as e:\n+        except exception.OverQuota as e:\n             raise exc.HTTPForbidden(explanation=e.format_message())\n         except (\n             exception.InstanceIsLocked,"
},
{
"sha":"e92becb582ad1b9ac5f044f7e4b312cf76806cc0",
"filename":"nova/api/openstack/compute/server_metadata.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/server_metadata.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/server_metadata.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/server_metadata.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -114,7 +114,7 @@ def _update_instance_metadata(self, context, server, metadata,\n                                                              server,\n                                                              metadata,\n                                                              delete)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(explanation=error.format_message())\n         except exception.InstanceIsLocked as e:\n             raise exc.HTTPConflict(explanation=e.format_message())"
},
{
"sha":"68d4ef0eeb0d71e78ff64174b477f9558bd4810f",
"filename":"nova/api/openstack/compute/servers.py",
"status":"modified",
"additions":3,
"deletions":4,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/servers.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/api/openstack/compute/servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/servers.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -797,8 +797,7 @@ def create(self, req, body):\n                 supports_multiattach=supports_multiattach,\n                 supports_port_resource_request=supports_port_resource_request,\n                 **create_kwargs)\n-        except (exception.QuotaError,\n-                exception.PortLimitExceeded) as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(\n                 explanation=error.format_message())\n         except exception.ImageNotFound:\n@@ -1054,7 +1053,7 @@ def _resize(self, req, instance_id, flavor_id, auto_disk_config=None):\n         try:\n             self.compute_api.resize(context, instance, flavor_id,\n                                     auto_disk_config=auto_disk_config)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(\n                 explanation=error.format_message())\n         except (\n@@ -1238,7 +1237,7 @@ def _action_rebuild(self, req, id, body):\n         except exception.KeypairNotFound:\n             msg = _(\"Invalid key_name provided.\")\n             raise exc.HTTPBadRequest(explanation=msg)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(explanation=error.format_message())\n         except (exception.AutoDiskConfigDisabledByImage,\n                 exception.CertificateValidationFailed,"
},
{
"sha":"a35889b9131c7c3ffe0dc06eef88ede96827c83c",
"filename":"nova/compute/api.py",
"status":"modified",
"additions":3,
"deletions":3,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/compute/api.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/compute/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/api.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -400,7 +400,7 @@ def _record_action_start(self, context, instance, action):\n     def _check_injected_file_quota(self, context, injected_files):\n         \"\"\"Enforce quota limits on injected files.\n \n-        Raises a QuotaError if any limit is exceeded.\n+        Raises a OverQuota if any limit is exceeded.\n         \"\"\"\n         if not injected_files:\n             return\n@@ -1474,7 +1474,7 @@ def _provision_instances(\n                         except exception.OverQuota:\n                             msg = _(\"Quota exceeded, too many servers in \"\n                                     \"group\")\n-                            raise exception.QuotaError(msg)\n+                            raise exception.OverQuota(msg)\n \n                     members = objects.InstanceGroup.add_members(\n                         context, instance_group.uuid, [instance.uuid])\n@@ -1494,7 +1494,7 @@ def _provision_instances(\n                                 context, instance_group.id, [instance.uuid])\n                             msg = _(\"Quota exceeded, too many servers in \"\n                                     \"group\")\n-                            raise exception.QuotaError(msg)\n+                            raise exception.OverQuota(msg)\n                     # list of members added to servers group in this iteration\n                     # is needed to check quota of server group during add next\n                     # instance"
},
{
"sha":"27405aea671abc234dc159a0033b62359007615b",
"filename":"nova/exception.py",
"status":"modified",
"additions":9,
"deletions":16,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -998,10 +998,6 @@ class QuotaClassExists(NovaException):\n     msg_fmt = _(\"Quota class %(class_name)s exists for resource %(resource)s\")\n \n \n-class OverQuota(NovaException):\n-    msg_fmt = _(\"Quota exceeded for resources: %(overs)s\")\n-\n-\n class SecurityGroupNotFound(NotFound):\n     msg_fmt = _(\"Security group %(security_group_id)s not found.\")\n \n@@ -1238,29 +1234,26 @@ class MaxRetriesExceeded(NoValidHost):\n     msg_fmt = _(\"Exceeded maximum number of retries. %(reason)s\")\n \n \n-class QuotaError(NovaException):\n-    msg_fmt = _(\"Quota exceeded: code=%(code)s\")\n-    # NOTE(cyeoh): 413 should only be used for the ec2 API\n-    # The error status code for out of quota for the nova api should be\n-    # 403 Forbidden.\n+class OverQuota(NovaException):\n+    msg_fmt = _(\"Quota exceeded for resources: %(overs)s\")\n     code = 413\n     safe = True\n \n \n-class TooManyInstances(QuotaError):\n+class TooManyInstances(OverQuota):\n     msg_fmt = _(\"Quota exceeded for %(overs)s: Requested %(req)s,\"\n                 \" but already used %(used)s of %(allowed)s %(overs)s\")\n \n \n-class FloatingIpLimitExceeded(QuotaError):\n+class FloatingIpLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of floating IPs exceeded\")\n \n \n-class MetadataLimitExceeded(QuotaError):\n+class MetadataLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of metadata items exceeds %(allowed)d\")\n \n \n-class OnsetFileLimitExceeded(QuotaError):\n+class OnsetFileLimitExceeded(OverQuota):\n     msg_fmt = _(\"Personality file limit exceeded\")\n \n \n@@ -1272,15 +1265,15 @@ class OnsetFileContentLimitExceeded(OnsetFileLimitExceeded):\n     msg_fmt = _(\"Personality file content exceeds maximum %(allowed)s\")\n \n \n-class KeypairLimitExceeded(QuotaError):\n+class KeypairLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of key pairs exceeded\")\n \n \n-class SecurityGroupLimitExceeded(QuotaError):\n+class SecurityGroupLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of security groups or rules exceeded\")\n \n \n-class PortLimitExceeded(QuotaError):\n+class PortLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of ports exceeded\")\n \n "
},
{
"sha":"d1bb6babb779b2053d7ea801cbd2beea7a0705dc",
"filename":"nova/tests/unit/api/openstack/compute/test_api.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/api/openstack/compute/test_api.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/api/openstack/compute/test_api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/api/openstack/compute/test_api.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -143,7 +143,7 @@ def fail(req):\n                 self.assertEqual(resp.headers[key], str(value))\n \n     def test_quota_error_mapping(self):\n-        self._do_test_exception_mapping(exception.QuotaError, 'too many used')\n+        self._do_test_exception_mapping(exception.OverQuota, 'too many used')\n \n     def test_non_nova_notfound_exception_mapping(self):\n         class ExceptionWithCode(Exception):"
},
{
"sha":"d8f443843f3778942292c2b3a81c73bb163e3171",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -8859,7 +8859,7 @@ def test_create_instance_group_members_over_quota_during_recheck(\n         group.create()\n         get_group_mock.return_value = group\n \n-        self.assertRaises(exception.QuotaError, self.compute_api.create,\n+        self.assertRaises(exception.OverQuota, self.compute_api.create,\n             self.context, self.default_flavor, self.fake_image['id'],\n             scheduler_hints={'group': group.uuid},\n             check_server_group_quota=True)"
},
{
"sha":"48910cf75cb862f122c6a53e26bcf9875f605395",
"filename":"nova/tests/unit/test_quota.py",
"status":"modified",
"additions":11,
"deletions":11,
"changes":22,
"blob_url":"https://github.com/openstack/nova/blob/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/test_quota.py",
"raw_url":"https://github.com/openstack/nova/raw/232f8275ec00767d1f100cacae4823e6f77e04ef/nova/tests/unit/test_quota.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/test_quota.py?ref=232f8275ec00767d1f100cacae4823e6f77e04ef",
"patch":"@@ -109,15 +109,15 @@ def test_too_many_instances(self):\n             self.compute_api.create(\n                 self.context, min_count=1, max_count=1,\n                 flavor=self.flavor, image_href=image_uuid)\n-        except exception.QuotaError as e:\n+        except exception.OverQuota as e:\n             expected_kwargs = {'code': 413,\n                                'req': '1, 1',\n                                'used': '8, 2',\n                                'allowed': '4, 2',\n                                'overs': 'cores, instances'}\n             self.assertEqual(expected_kwargs, e.kwargs)\n         else:\n-            self.fail('Expected QuotaError exception')\n+            self.fail('Expected OverQuota exception')\n \n     def test_too_many_cores(self):\n         self._create_instance()\n@@ -126,15 +126,15 @@ def test_too_many_cores(self):\n             self.compute_api.create(\n                 self.context, min_count=1, max_count=1, flavor=self.flavor,\n                 image_href=image_uuid)\n-        except exception.QuotaError as e:\n+        except exception.OverQuota as e:\n             expected_kwargs = {'code': 413,\n                                'req': '1',\n                                'used': '4',\n                                'allowed': '4',\n                                'overs': 'cores'}\n             self.assertEqual(expected_kwargs, e.kwargs)\n         else:\n-            self.fail('Expected QuotaError exception')\n+            self.fail('Expected OverQuota exception')\n \n     def test_many_cores_with_unlimited_quota(self):\n         # Setting cores quota to unlimited:\n@@ -150,7 +150,7 @@ def test_too_many_metadata_items(self):\n             metadata['key%s' % i] = 'value%s' % i\n         image_uuid = 'cedef40a-ed67-4d10-800e-17455edce175'\n         self.assertRaises(\n-            exception.QuotaError, self.compute_api.create,\n+            exception.OverQuota, self.compute_api.create,\n             self.context, min_count=1, max_count=1, flavor=self.flavor,\n             image_href=image_uuid, metadata=metadata)\n \n@@ -170,39 +170,39 @@ def test_max_injected_files(self):\n         files = []\n         for i in range(CONF.quota.injected_files):\n             files.append(('/my/path%d' % i, 'config = test\\n'))\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_files(self):\n         files = []\n         for i in range(CONF.quota.injected_files + 1):\n             files.append(('/my/path%d' % i, 'my\\ncontent%d\\n' % i))\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n     def test_max_injected_file_content_bytes(self):\n         max = CONF.quota.injected_file_content_bytes\n         content = ''.join(['a' for i in range(max)])\n         files = [('/test/path', content)]\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_file_content_bytes(self):\n         max = CONF.quota.injected_file_content_bytes\n         content = ''.join(['a' for i in range(max + 1)])\n         files = [('/test/path', content)]\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n     def test_max_injected_file_path_bytes(self):\n         max = CONF.quota.injected_file_path_length\n         path = ''.join(['a' for i in range(max)])\n         files = [(path, 'config = quotatest')]\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_file_path_bytes(self):\n         max = CONF.quota.injected_file_path_length\n         path = ''.join(['a' for i in range(max + 1)])\n         files = [(path, 'config = quotatest')]\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n "
}
]
},
{
"commit_sha":"db15cb9513dbf12e173a66ab87e9638dcc08f4f0",
"commit_node_id":"C_kwDOAAwOD9oAKGRiMTVjYjk1MTNkYmYxMmUxNzNhNjZhYjg3ZTk2MzhkY2MwOGY0ZjA",
"commit_html_url":"https://github.com/openstack/nova/commit/db15cb9513dbf12e173a66ab87e9638dcc08f4f0",
"commit_date":"2022-02-09T21:32:35Z",
"files":[
{
"sha":"61f23f9804cc81ec27db8616863af6eb1c283487",
"filename":"doc/source/admin/networking.rst",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/db15cb9513dbf12e173a66ab87e9638dcc08f4f0/doc/source/admin/networking.rst",
"raw_url":"https://github.com/openstack/nova/raw/db15cb9513dbf12e173a66ab87e9638dcc08f4f0/doc/source/admin/networking.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/networking.rst?ref=db15cb9513dbf12e173a66ab87e9638dcc08f4f0",
"patch":"@@ -206,10 +206,10 @@ virtio-net Multiqueue\n \n .. versionadded:: 12.0.0 (Liberty)\n \n-.. versionchanged:: 24.0.0 (Xena)\n+.. versionchanged:: 25.0.0 (Yoga)\n \n    Support for configuring multiqueue via the ``hw:vif_multiqueue_enabled``\n-   flavor extra spec was introduced in the Xena (24.0.0) release.\n+   flavor extra spec was introduced in the Yoga (25.0.0) release.\n \n .. important::\n "
}
]
},
{
"commit_sha":"861341aa758bbeb6c3a5b784f5682ccaec3f2519",
"commit_node_id":"C_kwDOAAwOD9oAKDg2MTM0MWFhNzU4YmJlYjZjM2E1Yjc4NGY1NjgyY2NhZWMzZjI1MTk",
"commit_html_url":"https://github.com/openstack/nova/commit/861341aa758bbeb6c3a5b784f5682ccaec3f2519",
"commit_date":"2022-02-09T21:32:28Z",
"files":[
{
"sha":"af7174a8acc7a650e39c936732f21927894724b5",
"filename":"doc/source/admin/networking.rst",
"status":"modified",
"additions":90,
"deletions":0,
"changes":90,
"blob_url":"https://github.com/openstack/nova/blob/861341aa758bbeb6c3a5b784f5682ccaec3f2519/doc/source/admin/networking.rst",
"raw_url":"https://github.com/openstack/nova/raw/861341aa758bbeb6c3a5b784f5682ccaec3f2519/doc/source/admin/networking.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/networking.rst?ref=861341aa758bbeb6c3a5b784f5682ccaec3f2519",
"patch":"@@ -199,3 +199,93 @@ As with the L2-type networks, this configuration will ensure instances using\n one or more L3-type networks must be scheduled on host cores from NUMA node 0.\n It is also possible to define more than one NUMA node, in which case the\n instance must be split across these nodes.\n+\n+\n+virtio-net Multiqueue\n+---------------------\n+\n+.. versionadded:: 12.0.0 (Liberty)\n+\n+.. versionchanged:: 24.0.0 (Xena)\n+\n+   Support for configuring multiqueue via the ``hw:vif_multiqueue_enabled``\n+   flavor extra spec was introduced in the Xena (24.0.0) release.\n+\n+.. important::\n+\n+   The functionality described below is currently only supported by the\n+   libvirt/KVM driver.\n+\n+Virtual NICs using the virtio-net driver support the multiqueue feature. By\n+default, these vNICs will only use a single virtio-net TX/RX queue pair,\n+meaning guests will not transmit or receive packets in parallel. As a result,\n+the scale of the protocol stack in a guest may be restricted as the network\n+performance will not scale as the number of vCPUs increases and per-queue data\n+processing limits in the underlying vSwitch are encountered. The solution to\n+this issue is to enable virtio-net multiqueue, which can allow the guest\n+instances to increase the total network throughput by scaling the number of\n+receive and transmit queue pairs with CPU count.\n+\n+Multiqueue virtio-net isn't always necessary, but it can provide a significant\n+performance benefit when:\n+\n+- Traffic packets are relatively large.\n+- The guest is active on many connections at the same time, with traffic\n+  running between guests, guest to host, or guest to an external system.\n+- The number of queues is equal to the number of vCPUs. This is because\n+  multi-queue support optimizes RX interrupt affinity and TX queue selection in\n+  order to make a specific queue private to a specific vCPU.\n+\n+However, while the virtio-net multiqueue feature will often provide a welcome\n+performance benefit, it has some limitations and therefore should not be\n+unconditionally enabled:\n+\n+- Enabling virtio-net multiqueue increases the total network throughput, but in\n+  parallel it also increases the CPU consumption.\n+- Enabling virtio-net multiqueue in the host QEMU config does not enable the\n+  functionality in the guest OS. The guest OS administrator needs to manually\n+  turn it on for each guest NIC that requires this feature, using\n+  :command:`ethtool`.\n+- In case the number of vNICs in a guest instance is proportional to the number\n+  of vCPUs, enabling the multiqueue feature is less important.\n+\n+Having considered these points, multiqueue can be enabled or explicitly\n+disabled using either the :nova:extra-spec:`hw:vif_multiqueue_enabled` flavor\n+extra spec or equivalent ``hw_vif_multiqueue_enabled`` image metadata property.\n+For example, to enable virtio-net multiqueue for a chosen flavor:\n+\n+.. code-block:: bash\n+\n+    $ openstack flavor set --property hw:vif_multiqueue_enabled=true $FLAVOR\n+\n+Alternatively, to explicitly disable multiqueue for a chosen image:\n+\n+.. code-block:: bash\n+\n+    $ openstack image set --property hw_vif_multiqueue_enabled=false $IMAGE\n+\n+.. note::\n+\n+    If both the flavor extra spec and image metadata property are provided,\n+    their values must match or an error will be raised.\n+\n+Once the guest has started, you must enable multiqueue using\n+:command:`ethtool`. For example:\n+\n+.. code-block:: bash\n+\n+    $ ethtool -L $devname combined $N\n+\n+where ``$devname`` is the name of the network device, and ``$N`` is the number\n+of TX/RX queue pairs to configure corresponding to the number of instance\n+vCPUs. Alternatively, you can configure this persistently using udev. For\n+example, to configure four TX/RX queue pairs for network device ``eth0``:\n+\n+.. code-block:: bash\n+\n+    # cat /etc/udev/rules.d/50-ethtool.rules\n+    ACTION==\"add\", SUBSYSTEM==\"net\", NAME==\"eth0\", RUN+=\"/sbin/ethtool -L eth0 combined 4\"\n+\n+For more information on this feature, refer to the `original spec`__.\n+\n+.. __: https://specs.openstack.org/openstack/nova-specs/specs/liberty/implemented/libvirt-virtiomq.html"
}
]
},
{
"commit_sha":"b47f35636576bda389f6b7afe4b4a6510db1b2b0",
"commit_node_id":"C_kwDOAAwOD9oAKGI0N2YzNTYzNjU3NmJkYTM4OWY2YjdhZmU0YjRhNjUxMGRiMWIyYjA",
"commit_html_url":"https://github.com/openstack/nova/commit/b47f35636576bda389f6b7afe4b4a6510db1b2b0",
"commit_date":"2022-02-09T21:09:26Z",
"files":[
{
"sha":"2875f3374adb04f9d628104eaa4afdc3563610c5",
"filename":"tox.ini",
"status":"modified",
"additions":30,
"deletions":1,
"changes":31,
"blob_url":"https://github.com/openstack/nova/blob/b47f35636576bda389f6b7afe4b4a6510db1b2b0/tox.ini",
"raw_url":"https://github.com/openstack/nova/raw/b47f35636576bda389f6b7afe4b4a6510db1b2b0/tox.ini",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/tox.ini?ref=b47f35636576bda389f6b7afe4b4a6510db1b2b0",
"patch":"@@ -29,6 +29,11 @@ deps =\n   -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}\n   -r{toxinidir}/requirements.txt\n   -r{toxinidir}/test-requirements.txt\n+extras =\n+  powervm\n+  zvm\n+  hyperv\n+  vmware\n passenv =\n   OS_DEBUG GENERATE_HASHES\n # there is also secret magic in subunit-trace which lets you run in a fail only\n@@ -42,16 +47,17 @@ commands =\n description =\n   Run type checks.\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   bash tools/mypywrap.sh {posargs}\n \n [testenv:pep8]\n description =\n   Run style checks.\n-envdir = {toxworkdir}/shared\n deps =\n   {[testenv]deps}\n   autopep8\n+extras =\n commands =\n   {[testenv:mypy]commands}\n   # check if autopep8 would alter the formatting but don't actually change it\n@@ -68,6 +74,7 @@ commands =\n   bash -c '! find doc/ -type f -name *.json | xargs -t -n1 python -m json.tool 2>&1 > /dev/null | grep -B1 -v ^python'\n \n [testenv:autopep8]\n+extras =\n deps = autopep8\n commands =\n   autopep8 --exit-code --max-line-length=79 --in-place -r nova doc setup.py\n@@ -76,6 +83,7 @@ commands =\n description =\n   Run style checks on the changes made since HEAD~. For a full run including docs, use 'pep8'\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   bash tools/flake8wrap.sh -HEAD\n \n@@ -84,6 +92,7 @@ description =\n   Determine whether a backport is ready to be merged by checking whether it has\n   already been merged to master or more recent stable branches.\n deps =\n+extras =\n skipsdist = true\n commands =\n   bash tools/check-cherry-picks.sh\n@@ -108,6 +117,7 @@ description =\n deps =\n   {[testenv]deps}\n   openstack-placement>=1.0.0\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional run {posargs}\n   stestr slowest\n@@ -116,20 +126,23 @@ commands =\n description =\n   Run functional tests using python3.6.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n [testenv:functional-py37]\n description =\n   Run functional tests using python3.7.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n [testenv:functional-py38]\n description =\n   Run functional tests using python3.8.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n@@ -140,13 +153,15 @@ description =\n   placement-nova-tox-functional-py38 job which is defined and\n   run in placement.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional run --exclude-regex '((?:api|notification)_sample_tests|functional\\.db\\.)' {posargs}\n \n [testenv:functional-py39]\n description =\n   Run functional tests using python3.9.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n@@ -157,17 +172,20 @@ setenv =\n   GENERATE_SAMPLES=True\n   PYTHONHASHSEED=0\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional/api_sample_tests run {posargs}\n   stestr slowest\n \n [testenv:genconfig]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslo-config-generator --config-file=etc/nova/nova-config-generator.conf\n \n [testenv:genpolicy]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslopolicy-sample-generator --config-file=etc/nova/nova-policy-generator.conf\n \n@@ -180,6 +198,7 @@ envdir = {toxworkdir}/shared\n setenv =\n   {[testenv]setenv}\n   PYTHON=coverage run --source nova --parallel-mode\n+extras =\n commands =\n   coverage erase\n   stestr run {posargs}\n@@ -190,13 +209,15 @@ commands =\n \n [testenv:debug]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslo_debug_helper {posargs}\n \n [testenv:venv]\n deps =\n   {[testenv]deps}\n   -r{toxinidir}/doc/requirements.txt\n+extras =\n commands =\n   {posargs}\n \n@@ -208,6 +229,7 @@ description =\n deps =\n   -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}\n   -r{toxinidir}/doc/requirements.txt\n+extras =\n commands =\n   rm -rf doc/build/html doc/build/doctrees\n   sphinx-build -W --keep-going -b html -j auto doc/source doc/build/html\n@@ -219,6 +241,7 @@ description =\n   Build PDF documentation.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf doc/build/pdf\n   sphinx-build -W --keep-going -b latex -j auto doc/source doc/build/pdf\n@@ -229,6 +252,7 @@ description =\n   Generate the API guide. Called from CI scripts to test and publish to docs.openstack.org.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf api-guide/build\n   sphinx-build -W --keep-going -b html -j auto api-guide/source api-guide/build/html\n@@ -238,6 +262,7 @@ description =\n   Generate the API ref. Called from CI scripts to test and publish to docs.openstack.org.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf api-ref/build\n   sphinx-build -W --keep-going -b html -j auto api-ref/source api-ref/build/html\n@@ -247,6 +272,7 @@ description =\n   Generate release notes.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf releasenotes/build\n   sphinx-build -W --keep-going -b html -j auto releasenotes/source releasenotes/build/html\n@@ -256,6 +282,7 @@ description =\n   Build all documentation including API guides and refs.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   {[testenv:docs]commands}\n   {[testenv:api-guide]commands}\n@@ -266,6 +293,7 @@ commands =\n # NOTE(browne): This is required for the integration test job of the bandit\n # project. Please do not remove.\n envdir = {toxworkdir}/shared\n+extras =\n commands = bandit -r nova -x tests -n 5 -ll\n \n [flake8]\n@@ -358,6 +386,7 @@ paths =\n # explicitly to avoid unnecessarily installing the checked-out repo too\n usedevelop = False\n deps = bindep\n+extras =\n commands =\n   bindep test\n "
}
]
},
{
"commit_sha":"b6f8af052dc10689a6b0847b7db9c6653e68035c",
"commit_node_id":"C_kwDOAAwOD9oAKGI2ZjhhZjA1MmRjMTA2ODlhNmIwODQ3YjdkYjljNjY1M2U2ODAzNWM",
"commit_html_url":"https://github.com/openstack/nova/commit/b6f8af052dc10689a6b0847b7db9c6653e68035c",
"commit_date":"2022-02-09T21:09:19Z",
"files":[
{
"sha":"2190f0570ff8974ef7bb3bc582f72743d98f809b",
"filename":"nova/tests/unit/virt/hyperv/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/hyperv/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/hyperv/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/hyperv/__init__.py?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import os_win  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'os-win' dependency is not installed.\"\n+    )"
},
{
"sha":"3f8ef7b1671790fb92010ac7f089bb1b44b4fc25",
"filename":"nova/tests/unit/virt/powervm/__init__.py",
"status":"modified",
"additions":10,
"deletions":1,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/powervm/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/powervm/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/powervm/__init__.py?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -11,13 +11,22 @@\n #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n #    License for the specific language governing permissions and limitations\n #    under the License.\n-#\n+\n+import unittest\n+\n from oslo_utils.fixture import uuidsentinel\n \n from nova.compute import power_state\n from nova.compute import vm_states\n from nova import objects\n \n+try:\n+    import powervm  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'pypowervm' dependency is not installed.\"\n+    )\n+\n \n TEST_FLAVOR = objects.flavor.Flavor(\n     memory_mb=2048,"
},
{
"sha":"206b60cb8fedb175233c423089f0d45d1e7c4d8c",
"filename":"nova/tests/unit/virt/vmwareapi/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/vmwareapi/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/vmwareapi/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/vmwareapi/__init__.py?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import oslo_vmware  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'oslo.vmware' dependency is not installed.\"\n+    )"
},
{
"sha":"a93e19e1be56ea0e5b494376d9b8ee1cacbdec19",
"filename":"nova/tests/unit/virt/zvm/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/zvm/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/nova/tests/unit/virt/zvm/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/zvm/__init__.py?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import zvmconnector  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'zVMCloudConnector' dependency is not installed.\"\n+    )"
},
{
"sha":"c83d6e38fa0a6f9c882c4c8d6e78a094a3780f49",
"filename":"requirements.txt",
"status":"modified",
"additions":0,
"deletions":5,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -8,8 +8,6 @@ lxml>=4.5.0 # BSD\n Routes>=2.3.1 # MIT\n cryptography>=2.7 # BSD/Apache-2.0\n WebOb>=1.8.2 # MIT\n-# NOTE(mriedem): greenlet 0.4.14 does not work with older versions of gcc on\n-# ppc64le systems, see https://github.com/python-greenlet/greenlet/issues/136.\n greenlet>=0.4.15 # MIT\n PasteDeploy>=1.5.0 # MIT\n Paste>=2.0.2 # MIT\n@@ -52,17 +50,14 @@ os-brick>=4.3.1 # Apache-2.0\n os-resource-classes>=1.1.0 # Apache-2.0\n os-traits>=2.7.0 # Apache-2.0\n os-vif>=1.15.2 # Apache-2.0\n-os-win>=5.4.0 # Apache-2.0\n castellan>=0.16.0 # Apache-2.0\n microversion-parse>=0.2.1 # Apache-2.0\n tooz>=1.58.0 # Apache-2.0\n cursive>=0.2.1 # Apache-2.0\n-pypowervm>=1.1.15 # Apache-2.0\n retrying>=1.3.3,!=1.3.0 # Apache-2.0\n os-service-types>=1.7.0 # Apache-2.0\n taskflow>=3.8.0 # Apache-2.0\n python-dateutil>=2.7.0 # BSD\n-zVMCloudConnector>=1.3.0;sys_platform!='win32'  # Apache 2.0 License\n futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License"
},
{
"sha":"99d7cdaf104dad07bd7e6c2c1a7409f59eaa7b6a",
"filename":"setup.cfg",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/setup.cfg",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/setup.cfg",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/setup.cfg?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -30,6 +30,14 @@ classifiers =\n [extras]\n osprofiler =\n     osprofiler>=1.4.0 # Apache-2.0\n+powervm =\n+    pypowervm>=1.1.15 # Apache-2.0\n+zvm =\n+    zVMCloudConnector>=1.3.0;sys_platform!='win32'  # Apache 2.0 License\n+hyperv =\n+    os-win>=5.4.0 # Apache-2.0\n+vmware =\n+    oslo.vmware>=3.6.0 # Apache-2.0\n \n [files]\n data_files ="
},
{
"sha":"3194e9dd66376277760c1404b32c48c281ffa3eb",
"filename":"test-requirements.txt",
"status":"modified",
"additions":0,
"deletions":3,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/b6f8af052dc10689a6b0847b7db9c6653e68035c/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/b6f8af052dc10689a6b0847b7db9c6653e68035c/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=b6f8af052dc10689a6b0847b7db9c6653e68035c",
"patch":"@@ -23,6 +23,3 @@ testtools>=2.5.0 # MIT\n bandit>=1.1.0 # Apache-2.0\n gabbi>=1.35.0 # Apache-2.0\n wsgi-intercept>=1.7.0 # MIT License\n-\n-# vmwareapi driver specific dependencies\n-oslo.vmware>=3.6.0 # Apache-2.0"
}
]
},
{
"commit_sha":"bacbf7a49379cf271c8059a316fd6a85733dae41",
"commit_node_id":"C_kwDOAAwOD9oAKGJhY2JmN2E0OTM3OWNmMjcxYzgwNTlhMzE2ZmQ2YTg1NzMzZGFlNDE",
"commit_html_url":"https://github.com/openstack/nova/commit/bacbf7a49379cf271c8059a316fd6a85733dae41",
"commit_date":"2022-02-09T21:09:12Z",
"files":[
{
"sha":"fc397161cbaa8c6096b444154547fcb97ecc9dde",
"filename":"lower-constraints.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/bacbf7a49379cf271c8059a316fd6a85733dae41/lower-constraints.txt",
"raw_url":"https://github.com/openstack/nova/raw/bacbf7a49379cf271c8059a316fd6a85733dae41/lower-constraints.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/lower-constraints.txt?ref=bacbf7a49379cf271c8059a316fd6a85733dae41",
"patch":"@@ -149,7 +149,7 @@ tenacity==6.3.1\n testrepository==0.0.20\n testresources==2.0.0\n testscenarios==0.4\n-testtools==2.2.0\n+testtools==2.5.0\n tooz==1.58.0\n traceback2==1.4.0\n types-paramiko==0.1.3"
},
{
"sha":"3f3c1c0cb5e6e104fb13494ccd7cf6317aebf17a",
"filename":"test-requirements.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/bacbf7a49379cf271c8059a316fd6a85733dae41/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/bacbf7a49379cf271c8059a316fd6a85733dae41/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=bacbf7a49379cf271c8059a316fd6a85733dae41",
"patch":"@@ -19,7 +19,7 @@ stestr>=2.0.0 # Apache-2.0\n osprofiler>=1.4.0 # Apache-2.0\n testresources>=2.0.0 # Apache-2.0/BSD\n testscenarios>=0.4 # Apache-2.0/BSD\n-testtools>=2.2.0 # MIT\n+testtools>=2.5.0 # MIT\n bandit>=1.1.0 # Apache-2.0\n gabbi>=1.35.0 # Apache-2.0\n wsgi-intercept>=1.7.0 # MIT License"
}
]
},
{
"commit_sha":"ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"commit_node_id":"C_kwDOAAwOD9oAKGZmYjgxMGUyYmEyZmRlYzliMmE4ODFhODhmYTZkNjVjZDMyZjhmYTM",
"commit_html_url":"https://github.com/openstack/nova/commit/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"commit_date":"2022-02-09T21:00:40Z",
"files":[
{
"sha":"34edf30cb680f560be574038a86d65ecb7206397",
"filename":"nova/api/openstack/compute/attach_interfaces.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/api/openstack/compute/attach_interfaces.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/api/openstack/compute/attach_interfaces.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/attach_interfaces.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -178,6 +178,7 @@ def create(self, req, server_id, body):\n                 exception.InterfaceAttachPciClaimFailed,\n                 exception.InterfaceAttachResourceAllocationFailed,\n                 exception.ForbiddenPortsWithAccelerator,\n+                exception.ForbiddenWithRemoteManagedPorts,\n                 exception.ExtendedResourceRequestOldCompute,\n                 ) as e:\n             raise exc.HTTPBadRequest(explanation=e.format_message())"
},
{
"sha":"1bfb3db698e5a36a3b31266777adda207b023983",
"filename":"nova/api/openstack/compute/servers.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/api/openstack/compute/servers.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/api/openstack/compute/servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/servers.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -862,6 +862,7 @@ def create(self, req, body):\n                 exception.DeviceProfileError,\n                 exception.ComputeHostNotFound,\n                 exception.ForbiddenPortsWithAccelerator,\n+                exception.ForbiddenWithRemoteManagedPorts,\n                 exception.ExtendedResourceRequestOldCompute,\n                 ) as error:\n             raise exc.HTTPBadRequest(explanation=error.format_message())"
},
{
"sha":"20c7ee7959175c16d2b35047c4fdbb825a01410a",
"filename":"nova/compute/api.py",
"status":"modified",
"additions":23,
"deletions":0,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/compute/api.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/compute/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/api.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -115,6 +115,8 @@\n MIN_COMPUTE_MOVE_WITH_EXTENDED_RESOURCE_REQUEST = 59\n MIN_COMPUTE_INT_ATTACH_WITH_EXTENDED_RES_REQ = 60\n \n+SUPPORT_VNIC_TYPE_REMOTE_MANAGED = 61\n+\n # FIXME(danms): Keep a global cache of the cells we find the\n # first time we look. This needs to be refreshed on a timer or\n # trigger.\n@@ -1017,6 +1019,22 @@ def _check_support_vnic_accelerator(self, context, requested_networks):\n                             \" until upgrade finished.\")\n                         raise exception.ForbiddenPortsWithAccelerator(msg)\n \n+    def _check_vnic_remote_managed_min_version(self, context):\n+        min_version = (objects.service.get_minimum_version_all_cells(\n+            context, ['nova-compute']))\n+        if min_version < SUPPORT_VNIC_TYPE_REMOTE_MANAGED:\n+            msg = (\"Remote-managed ports are not supported\"\n+                   \" until an upgrade is fully finished.\")\n+            raise exception.ForbiddenWithRemoteManagedPorts(msg)\n+\n+    def _check_support_vnic_remote_managed(self, context, requested_networks):\n+        if requested_networks:\n+            for request_net in requested_networks:\n+                if (request_net.port_id and\n+                        self.network_api.is_remote_managed_port(\n+                            context, request_net.port_id)):\n+                    self._check_vnic_remote_managed_min_version(context)\n+\n     def _validate_and_build_base_options(\n         self, context, flavor, boot_meta, image_href, image_id, kernel_id,\n         ramdisk_id, display_name, display_description, hostname, key_name,\n@@ -1087,6 +1105,7 @@ def _validate_and_build_base_options(\n         network_metadata, port_resource_requests, req_lvl_params = result\n \n         self._check_support_vnic_accelerator(context, requested_networks)\n+        self._check_support_vnic_remote_managed(context, requested_networks)\n \n         # Creating servers with ports that have resource requests, like QoS\n         # minimum bandwidth rules, is only supported in a requested minimum\n@@ -5161,6 +5180,10 @@ def attach_interface(self, context, instance, network_id, port_id,\n                 network_model.VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL):\n                 raise exception.ForbiddenPortsWithAccelerator()\n \n+            if port.get('binding:vnic_type',\n+                        'normal') == network_model.VNIC_TYPE_REMOTE_MANAGED:\n+                self._check_vnic_remote_managed_min_version(context)\n+\n             self.ensure_compute_version_for_resource_request(\n                 context, instance, port)\n "
},
{
"sha":"f0473c49023b31f49f66896914ec8d39ca7c4c45",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -313,6 +313,7 @@\n                         \"vdpa\",\n                         \"accelerator-direct\",\n                         \"accelerator-direct-physical\",\n+                        \"remote-managed\",\n                     ]),\n                 default=[],\n                 help=\"\"\"\n@@ -336,6 +337,7 @@\n * vdpa\n * accelerator-direct\n * accelerator-direct-physical\n+* remote-managed\n \n Adding a ``vnic_type`` to this configuration makes Nova wait for a\n network-vif-plugged event for each of the instance's vifs having the specific"
},
{
"sha":"e898ab3786e5f44c64a105badd517dd5c9fdc957",
"filename":"nova/exception.py",
"status":"modified",
"additions":5,
"deletions":0,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -175,6 +175,11 @@ class ForbiddenPortsWithAccelerator(NotSupported):\n     msg_fmt = _(\"Feature not supported with Ports that have accelerators.\")\n \n \n+class ForbiddenWithRemoteManagedPorts(NotSupported):\n+    msg_fmt = _(\"This feature is not supported when remote-managed ports\"\n+                \" are in use.\")\n+\n+\n class AdminRequired(Forbidden):\n     msg_fmt = _(\"User does not have admin privileges\")\n "
},
{
"sha":"b40c71166769ece74fe337bd0ab9fb2193b3744e",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -2375,7 +2375,13 @@ def create_resource_requests(\n                 # libvirt to expose the nic feature. At the moment\n                 # there is a limitation that deployers cannot use both\n                 # SR-IOV modes (legacy and ovs) in the same deployment.\n-                spec = {pci_request.PCI_NET_TAG: physnet}\n+                spec = {\n+                    pci_request.PCI_NET_TAG: physnet,\n+                    # Convert the value to string since tags are compared as\n+                    # string values case-insensitively.\n+                    pci_request.PCI_REMOTE_MANAGED_TAG:\n+                    str(self._is_remote_managed(vnic_type)),\n+                }\n                 dev_type = pci_request.DEVICE_TYPE_FOR_VNIC_TYPE.get(vnic_type)\n                 if dev_type:\n                     spec[pci_request.PCI_DEVICE_TYPE_TAG] = dev_type"
},
{
"sha":"21d6f66b79210343df9011a5ffabe6aa9d278f2b",
"filename":"nova/network/os_vif_util.py",
"status":"modified",
"additions":9,
"deletions":0,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/network/os_vif_util.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/network/os_vif_util.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/os_vif_util.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -338,6 +338,15 @@ def _nova_to_osvif_vif_ovs(vif):\n             port_profile=_get_ovs_representor_port_profile(vif),\n             plugin=\"ovs\")\n         _set_representor_datapath_offload_settings(vif, obj)\n+    elif vnic_type == model.VNIC_TYPE_REMOTE_MANAGED:\n+        # A networking backend is responsible for setting up a\n+        # representor in this case so the driver is noop.\n+        obj = _get_vif_instance(\n+            vif, objects.vif.VIFHostDevice,\n+            plugin=\"noop\",\n+            vif_name=vif_name,\n+            dev_address=vif[\"profile\"][\"pci_slot\"],\n+            dev_type=objects.fields.VIFHostDeviceDevType.ETHERNET)\n     elif vif.is_hybrid_plug_enabled():\n         obj = _get_vif_instance(\n             vif,"
},
{
"sha":"7d34204b0e54c36fd9bfa88707bb076d79f2ee35",
"filename":"nova/objects/service.py",
"status":"modified",
"additions":4,
"deletions":1,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/objects/service.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/objects/service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/service.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -31,7 +31,7 @@\n \n \n # NOTE(danms): This is the global service version counter\n-SERVICE_VERSION = 60\n+SERVICE_VERSION = 61\n \n \n # NOTE(danms): This is our SERVICE_VERSION history. The idea is that any\n@@ -213,6 +213,9 @@\n     # Add support for interface attach operation with neutron extended resource\n     # request\n     {'compute_rpc': '6.0'},\n+    # Version 61: Compute RPC v6.0:\n+    # Add support for remotely-managed ports (vnic-type 'remote-managed')\n+    {'compute_rpc': '6.0'},\n )\n \n # This is used to raise an error at service startup if older than N-1 computes"
},
{
"sha":"0932b07ce404eced709f5785c188fc27158e899f",
"filename":"nova/tests/unit/compute/test_api.py",
"status":"modified",
"additions":35,
"deletions":0,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/compute/test_api.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/compute/test_api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_api.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -206,6 +206,10 @@ def _obj_to_list_obj(self, list_obj, obj):\n         list_obj.obj_reset_changes()\n         return list_obj\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     @mock.patch('nova.objects.Quotas.check_deltas')\n     @mock.patch('nova.conductor.conductor_api.ComputeTaskAPI.build_instances')\n     @mock.patch('nova.compute.api.API._record_action_start')\n@@ -7243,6 +7247,37 @@ def test_check_support_vnic_accelerator_version_after_57(self, mock_get):\n             requested_networks)\n         mock_get.assert_called_once_with(self.context, ['nova-compute'])\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=True),\n+    )\n+    @mock.patch('nova.objects.service.get_minimum_version_all_cells',\n+                return_value=60)\n+    def test_check_support_vnic_remote_managed_version_before_61(\n+            self, mock_get):\n+        requested_networks = objects.NetworkRequestList(\n+            objects=[objects.NetworkRequest(port_id=uuids.port)])\n+        self.assertRaisesRegex(exception.ForbiddenWithRemoteManagedPorts,\n+            'Remote-managed ports are not supported until an upgrade is fully'\n+            ' finished.',\n+            self.compute_api._check_support_vnic_remote_managed,\n+            self.context,\n+            requested_networks)\n+        mock_get.assert_called_once_with(self.context, ['nova-compute'])\n+\n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=True),\n+    )\n+    @mock.patch('nova.objects.service.get_minimum_version_all_cells',\n+                return_value=61)\n+    def test_check_support_vnic_remote_managed_version_61(self, mock_get):\n+        requested_networks = objects.NetworkRequestList(\n+            objects=[objects.NetworkRequest(port_id=uuids.port)])\n+        self.compute_api._check_support_vnic_remote_managed(self.context,\n+            requested_networks)\n+        mock_get.assert_called_once_with(self.context, ['nova-compute'])\n+\n     def test_validate_and_build_base_options_translate_neutron_secgroup(self):\n         \"\"\"Tests that _check_requested_secgroups will return a uuid for a\n         requested Neutron security group and that will be returned from"
},
{
"sha":"b0f9832716f131e88aaa5257db6a2d4f54b5e8d0",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -8691,6 +8691,10 @@ def test_create_instance_with_invalid_security_group_raises(self):\n                          len(db.instance_get_all(self.context)))\n         mock_secgroups.assert_called_once_with(mock.ANY, 'invalid_sec_group')\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     def test_create_instance_associates_requested_networks(self):\n         # Make sure create adds the requested networks to the RequestSpec\n \n@@ -9826,6 +9830,10 @@ def test_multi_instance_display_name(self):\n             self.assertEqual(refs[i]['display_name'], name)\n             self.assertEqual(refs[i]['hostname'], name)\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     @mock.patch(\"nova.objects.service.get_minimum_version_all_cells\")\n     @mock.patch(\n         \"nova.network.neutron.API.has_extended_resource_request_extension\")"
},
{
"sha":"9b03dff761db03276d416a8aac6d9e897a4b74a1",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":22,
"deletions":5,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -6197,7 +6197,8 @@ def test_create_resource_requests(\n                 objects.NetworkRequest(port_id=uuids.portid_4),\n                 objects.NetworkRequest(port_id=uuids.portid_5),\n                 objects.NetworkRequest(port_id=uuids.trusted_port),\n-                objects.NetworkRequest(port_id=uuids.portid_vdpa)])\n+                objects.NetworkRequest(port_id=uuids.portid_vdpa),\n+                objects.NetworkRequest(port_id=uuids.portid_remote_managed)])\n         pci_requests = objects.InstancePCIRequests(requests=[])\n         # _get_port_vnic_info should be called for every NetworkRequest with a\n         # port_id attribute (so six times)\n@@ -6211,13 +6212,14 @@ def test_create_resource_requests(\n             (model.VNIC_TYPE_DIRECT, True, 'netN',\n              mock.sentinel.resource_request2, None, None),\n             (model.VNIC_TYPE_VDPA, None, 'netN', None, None, None),\n+            (model.VNIC_TYPE_REMOTE_MANAGED, None, 'netN', None, None, None),\n         ]\n         # _get_physnet_tunneled_info should be called for every NetworkRequest\n         # (so seven times)\n         mock_get_physnet_tunneled_info.side_effect = [\n             ('physnet1', False), ('physnet1', False), ('', True),\n             ('physnet1', False), ('physnet2', False), ('physnet3', False),\n-            ('physnet4', False), ('physnet1', False)\n+            ('physnet4', False), ('physnet1', False), ('physnet1', False),\n         ]\n         api = neutronapi.API()\n \n@@ -6234,13 +6236,16 @@ def test_create_resource_requests(\n                 mock.sentinel.request_group1,\n                 mock.sentinel.request_group2],\n             port_resource_requests)\n-        self.assertEqual(6, len(pci_requests.requests))\n+        self.assertEqual(7, len(pci_requests.requests))\n         has_pci_request_id = [net.pci_request_id is not None for net in\n                               requested_networks.objects]\n         self.assertEqual(pci_requests.requests[3].spec[0][\"dev_type\"],\n                          \"type-PF\")\n         self.assertEqual(pci_requests.requests[5].spec[0][\"dev_type\"], \"vdpa\")\n-        expected_results = [True, False, False, True, True, True, True, True]\n+        self.assertEqual(pci_requests.requests[6].spec[0][\"remote_managed\"],\n+                         'True')\n+        expected_results = [True, False, False, True, True, True, True, True,\n+                            True]\n         self.assertEqual(expected_results, has_pci_request_id)\n         # Make sure only the trusted VF has the 'trusted' tag set in the spec.\n         for pci_req in pci_requests.requests:\n@@ -6252,11 +6257,23 @@ def test_create_resource_requests(\n             else:\n                 self.assertNotIn(pci_request.PCI_TRUSTED_TAG, spec)\n \n+        # Only remote-managed ports must have the remote_managed tag set\n+        # to True.\n+        for pci_req in pci_requests.requests:\n+            spec = pci_req.spec[0]\n+            if pci_req.requester_id == uuids.portid_remote_managed:\n+                self.assertEqual('True',\n+                                 spec[pci_request.PCI_REMOTE_MANAGED_TAG])\n+            else:\n+                self.assertEqual('False',\n+                                 spec[pci_request.PCI_REMOTE_MANAGED_TAG])\n+\n         # Only SRIOV ports and those with a resource_request will have\n         # pci_req.requester_id.\n         self.assertEqual(\n             [uuids.portid_1, uuids.portid_3, uuids.portid_4, uuids.portid_5,\n-             uuids.trusted_port, uuids.portid_vdpa],\n+             uuids.trusted_port, uuids.portid_vdpa,\n+             uuids.portid_remote_managed],\n             [pci_req.requester_id for pci_req in pci_requests.requests])\n \n         self.assertCountEqual("
},
{
"sha":"338492aef0d24c08277351c33d8db630366d295d",
"filename":"nova/tests/unit/network/test_os_vif_util.py",
"status":"modified",
"additions":33,
"deletions":0,
"changes":33,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/network/test_os_vif_util.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/network/test_os_vif_util.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_os_vif_util.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -696,6 +696,39 @@ def test_nova_to_osvif_ovs_with_vnic_direct(self):\n \n         self.assertObjEqual(expect, actual)\n \n+    def test_nova_to_osvif_ovs_with_vnic_remote_managed(self):\n+        vif = model.VIF(\n+            id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\",\n+            type=model.VIF_TYPE_OVS,\n+            address=\"22:52:25:62:e2:aa\",\n+            vnic_type=model.VNIC_TYPE_REMOTE_MANAGED,\n+            network=model.Network(\n+                id=\"b82c1929-051e-481d-8110-4669916c7915\",\n+                label=\"Demo Net\",\n+                subnets=[]),\n+            profile={'pci_slot': '0000:0a:00.1'}\n+        )\n+\n+        actual = os_vif_util.nova_to_osvif_vif(vif)\n+\n+        expect = osv_objects.vif.VIFHostDevice(\n+            id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\",\n+            active=False,\n+            address=\"22:52:25:62:e2:aa\",\n+            dev_address='0000:0a:00.1',\n+            dev_type=os_vif_fields.VIFHostDeviceDevType.ETHERNET,\n+            plugin=\"noop\",\n+            has_traffic_filtering=False,\n+            preserve_on_delete=False,\n+            network=osv_objects.network.Network(\n+                id=\"b82c1929-051e-481d-8110-4669916c7915\",\n+                bridge_interface=None,\n+                label=\"Demo Net\",\n+                subnets=osv_objects.subnet.SubnetList(\n+                    objects=[])))\n+\n+        self.assertObjEqual(expect, actual)\n+\n     def test_nova_to_osvif_ovs_with_vnic_vdpa(self):\n         vif = model.VIF(\n             id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\","
},
{
"sha":"293f36bf8a9e83465ae388d2a5cfd12d173d6d26",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":21,
"deletions":2,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -19214,8 +19214,10 @@ def fake_prepare(instance, name, tag):\n \n         instance = objects.Instance(**self.test_instance)\n         instance.vm_state = vm_states.BUILDING\n-        vifs = [{'id': uuids.vif_1, 'active': False},\n-                {'id': uuids.vif_2, 'active': False}]\n+        vifs = [\n+            network_model.VIF(id=uuids.vif_1, active=False),\n+            network_model.VIF(id=uuids.vif_2, active=False)\n+        ]\n \n         @mock.patch.object(drvr, 'plug_vifs')\n         @mock.patch.object(drvr, '_create_guest')\n@@ -19412,6 +19414,23 @@ def test_get_neutron_events(self):\n         events = drvr._get_neutron_events(network_info)\n         self.assertEqual([('network-vif-plugged', '1')], events)\n \n+    def test_get_neutron_events_remote_managed(self):\n+        drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)\n+        network_info = [\n+            network_model.VIF(\n+                id=uuids.vif_1,\n+                vnic_type=network_model.VNIC_TYPE_REMOTE_MANAGED),\n+            network_model.VIF(\n+                id=uuids.vif_2,\n+                vnic_type=network_model.VNIC_TYPE_REMOTE_MANAGED,\n+                active=True),\n+        ]\n+        events = drvr._get_neutron_events(network_info)\n+        # For VNIC_TYPE_REMOTE_MANAGED events are only bind-time currently.\n+        # Until this changes, they need to be filtered out to avoid waiting\n+        # for them unnecessarily.\n+        self.assertEqual([], events)\n+\n     def test_unplug_vifs_ignores_errors(self):\n         drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI())\n         with mock.patch.object(drvr, 'vif_driver') as vif_driver:"
},
{
"sha":"8c7af49e667f64f9314a82a55ee11eb21e4a7a05",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":2,
"deletions":1,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -7232,7 +7232,8 @@ def _get_neutron_events(self, network_info):\n         # anything that might be stale (cache-wise) assume it's\n         # already up so we don't block on it.\n         return [('network-vif-plugged', vif['id'])\n-                for vif in network_info if vif.get('active', True) is False]\n+                for vif in network_info if vif.get('active', True) is False and\n+                vif['vnic_type'] != network_model.VNIC_TYPE_REMOTE_MANAGED]\n \n     def _create_guest_with_network(\n         self,"
},
{
"sha":"826729f378d9849dfe045cd7c0d17d64d7771f6f",
"filename":"releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"status":"added",
"additions":27,
"deletions":0,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"raw_url":"https://github.com/openstack/nova/raw/ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml?ref=ffb810e2ba2fdec9b2a881a88fa6d65cd32f8fa3",
"patch":"@@ -0,0 +1,27 @@\n+---\n+features:\n+  - |\n+    Added support for off-path networking backends where devices exposed to the\n+    hypervisor host are managed remotely (which is the case, for example, with\n+    various SmartNIC DPU devices). ``VNIC_TYPE_REMOTE_MANAGED`` ports can now\n+    be added to Nova instances as soon as all compute nodes are upgraded to\n+    the new compute service version. In order to use this feature, VF PCI/PCIe\n+    devices need to be tagged as ``remote_managed: \"true\"` in the Nova config\n+    in the ``passthrough_whitelist`` option.\n+\n+    This feature relies on Neutron being upgraded to the corresponding release\n+    of OpenStack and having an appropriate backend capable of binding\n+    ``VNIC_TYPE_REMOTE_MANAGED`` ports (at the time of writing, ML2 with the OVN\n+    ML2 mechanism driver is the only supported backend, see the Neutron\n+    documentation for more details).\n+\n+    Note that the PCI devices (VFs or, alternatively, their PF) must have a\n+    valid PCI Vital Product Data (VPD) with a serial number present in it for\n+    this feature to work properly. Also note that only VFs can be tagged as\n+    ``remote_managed: \"true\"`` and they cannot be used for legacy SR-IOV\n+    use-cases.\n+\n+    Nova operations on instances with ``VNIC_TYPE_REMOTE_MANAGED`` ports\n+    follow the same logic as the operations on direct SR-IOV ports.\n+\n+    This feature is only supported with the Libvirt driver."
}
]
},
{
"commit_sha":"8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"commit_node_id":"C_kwDOAAwOD9oAKDhiYzc2YjNjYzdjZTQ1NTdmNGJkYWI5OWI4MTUyOTU4NzhlODg5MWU",
"commit_html_url":"https://github.com/openstack/nova/commit/8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"commit_date":"2022-02-09T21:00:32Z",
"files":[
{
"sha":"e92874c7f9a54c1e301a3081260e09db80bbd35e",
"filename":"nova/compute/resource_tracker.py",
"status":"modified",
"additions":27,
"deletions":1,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/compute/resource_tracker.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/compute/resource_tracker.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/resource_tracker.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -1126,6 +1126,28 @@ def _sync_compute_service_disabled_trait(self, context, traits):\n             LOG.error('Unable to find services table record for nova-compute '\n                       'host %s', self.host)\n \n+    def _should_expose_remote_managed_ports_trait(self,\n+                                                  is_supported: bool):\n+        \"\"\"Determine whether COMPUTE_REMOTE_MANAGED_PORTS should be exposed.\n+\n+        Determines if the COMPUTE_REMOTE_MANAGED_PORTS trait needs to be\n+        exposed based on the respective compute driver capability and\n+        the presence of remote managed devices on a given host. Whether such\n+        devices are present or not depends on the Whitelist configuration\n+        (presence of a remote_managed tag association with some PCI devices)\n+        and their physical presence (plugged in, enumerated by the OS).\n+\n+        The aim of having this check is to optimize host lookup by prefiltering\n+        hosts that have compute driver support but no hardware. The check\n+        does not consider free device count - just the presence of device\n+        pools since device availability may change between a prefilter check\n+        and a later check in PciPassthroughFilter.\n+\n+        :param bool is_supported: Is the trait supported by the compute driver\n+        \"\"\"\n+        return (is_supported and\n+            self.pci_tracker.pci_stats.has_remote_managed_device_pools())\n+\n     def _get_traits(self, context, nodename, provider_tree):\n         \"\"\"Synchronizes internal and external traits for the node provider.\n \n@@ -1149,7 +1171,11 @@ def _get_traits(self, context, nodename, provider_tree):\n         # traits that are missing, and remove any existing set traits\n         # that are not currently supported.\n         for trait, supported in self.driver.capabilities_as_traits().items():\n-            if supported:\n+            add_trait = supported\n+            if trait == os_traits.COMPUTE_REMOTE_MANAGED_PORTS:\n+                add_trait &= self._should_expose_remote_managed_ports_trait(\n+                    supported)\n+            if add_trait:\n                 traits.add(trait)\n             elif trait in traits:\n                 traits.remove(trait)"
},
{
"sha":"5bd70837db55d48ac16468ef44a42dc64206fe03",
"filename":"nova/network/model.py",
"status":"modified",
"additions":4,
"deletions":2,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/network/model.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/network/model.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/model.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -106,6 +106,7 @@\n VNIC_TYPE_VDPA = 'vdpa'\n VNIC_TYPE_ACCELERATOR_DIRECT = 'accelerator-direct'\n VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL = 'accelerator-direct-physical'\n+VNIC_TYPE_REMOTE_MANAGED = \"remote-managed\"\n \n # Define list of ports which needs pci request.\n # Note: The macvtap port needs a PCI request as it is a tap interface\n@@ -121,14 +122,15 @@\n # selected compute node.\n VNIC_TYPES_SRIOV = (\n     VNIC_TYPE_DIRECT, VNIC_TYPE_MACVTAP, VNIC_TYPE_DIRECT_PHYSICAL,\n-    VNIC_TYPE_VIRTIO_FORWARDER, VNIC_TYPE_VDPA)\n+    VNIC_TYPE_VIRTIO_FORWARDER, VNIC_TYPE_VDPA, VNIC_TYPE_REMOTE_MANAGED)\n \n # Define list of ports which are passthrough to the guest\n # and need a special treatment on snapshot and suspend/resume\n VNIC_TYPES_DIRECT_PASSTHROUGH = (VNIC_TYPE_DIRECT,\n                                  VNIC_TYPE_DIRECT_PHYSICAL,\n                                  VNIC_TYPE_ACCELERATOR_DIRECT,\n-                                 VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL)\n+                                 VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL,\n+                                 VNIC_TYPE_REMOTE_MANAGED)\n \n # Define list of ports which contains devices managed by cyborg.\n VNIC_TYPES_ACCELERATOR = ("
},
{
"sha":"aa3c2b00b0cc1cb005e8baf5439119c1198e2102",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":21,
"deletions":0,
"changes":21,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -2183,6 +2183,27 @@ def _get_trusted_mode_from_port(port):\n             # the port binding profile and we can handle it as a boolean.\n             return strutils.bool_from_string(value)\n \n+    @staticmethod\n+    def _is_remote_managed(vnic_type):\n+        \"\"\"Determine if the port is remote_managed or not by VNIC type.\n+\n+        :param str vnic_type: The VNIC type to assess.\n+        :return: A boolean indicator whether the NIC is remote managed or not.\n+        :rtype: bool\n+        \"\"\"\n+        return vnic_type == network_model.VNIC_TYPE_REMOTE_MANAGED\n+\n+    def is_remote_managed_port(self, context, port_id):\n+        \"\"\"Determine if a port has a REMOTE_MANAGED VNIC type.\n+\n+        :param context: The request context\n+        :param port_id: The id of the Neutron port\n+        \"\"\"\n+        port = self.show_port(context, port_id)['port']\n+        return self._is_remote_managed(\n+            port.get('binding:vnic_type', network_model.VNIC_TYPE_NORMAL)\n+        )\n+\n     # NOTE(sean-k-mooney): we might want to have this return a\n     # nova.network.model.VIF object instead in the future.\n     def _get_port_vnic_info(self, context, neutron, port_id):"
},
{
"sha":"c8dda84d4bfbdca32a1ef05a87a9febbc62f427a",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":13,
"deletions":0,
"changes":13,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -729,3 +729,16 @@ def to_device_pools_obj(self) -> 'objects.PciDevicePoolList':\n         \"\"\"Return the contents of the pools as a PciDevicePoolList object.\"\"\"\n         stats = [x for x in self]\n         return pci_device_pool.from_pci_stats(stats)\n+\n+    def has_remote_managed_device_pools(self) -> bool:\n+        \"\"\"Determine whether remote managed device pools are present on a host.\n+\n+        The check is pool-based, not free device-based and is NUMA cell\n+        agnostic.\n+        \"\"\"\n+        dummy_req = objects.InstancePCIRequest(\n+            count=0,\n+            spec=[{'remote_managed': True}]\n+        )\n+        pools = self._filter_pools_for_spec(self.pools, dummy_req)\n+        return bool(pools)"
},
{
"sha":"be1455df888566a3409ee91570ea709bbf08dcb1",
"filename":"nova/scheduler/request_filter.py",
"status":"modified",
"additions":28,
"deletions":0,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/scheduler/request_filter.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/scheduler/request_filter.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/scheduler/request_filter.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -365,6 +365,33 @@ def routed_networks_filter(\n     return True\n \n \n+@trace_request_filter\n+def remote_managed_ports_filter(\n+    context: nova_context.RequestContext,\n+    request_spec: 'objects.RequestSpec',\n+) -> bool:\n+    \"\"\"Filter out hosts without remote managed port support (driver or hw).\n+\n+    If a request spec contains VNIC_TYPE_REMOTE_MANAGED ports then a\n+    remote-managed port trait (COMPUTE_REMOTE_MANAGED_PORTS) is added to\n+    the request in order to pre-filter hosts that do not use compute\n+    drivers supporting remote managed ports and the ones that do not have\n+    the device pools providing remote-managed ports (actual device\n+    availability besides a pool presence check is done at the time of\n+    PciPassthroughFilter execution).\n+    \"\"\"\n+    if request_spec.requested_networks:\n+        network_api = neutron.API()\n+        for request_net in request_spec.requested_networks:\n+            if request_net.port_id and network_api.is_remote_managed_port(\n+                context, request_net.port_id):\n+                request_spec.root_required.add(\n+                    os_traits.COMPUTE_REMOTE_MANAGED_PORTS)\n+                LOG.debug('remote_managed_ports_filter request filter added '\n+                          f'trait {os_traits.COMPUTE_REMOTE_MANAGED_PORTS}')\n+    return True\n+\n+\n ALL_REQUEST_FILTERS = [\n     require_tenant_aggregate,\n     map_az_to_placement_aggregate,\n@@ -374,6 +401,7 @@ def routed_networks_filter(\n     transform_image_metadata,\n     accelerators_filter,\n     routed_networks_filter,\n+    remote_managed_ports_filter,\n ]\n \n "
},
{
"sha":"0eff6c6bda06315328aa0b6799e9c356d5cc63ab",
"filename":"nova/tests/functional/test_servers_provider_tree.py",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/functional/test_servers_provider_tree.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/functional/test_servers_provider_tree.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_servers_provider_tree.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -45,7 +45,6 @@ class ProviderTreeTests(integrated_helpers.ProviderUsageBaseTestCase):\n             os_traits.COMPUTE_VOLUME_EXTEND,\n             os_traits.COMPUTE_VOLUME_MULTI_ATTACH,\n             os_traits.COMPUTE_TRUSTED_CERTS,\n-            os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n         ]\n     ])\n "
},
{
"sha":"36236d58dedea41461838d046d2c9e61e82c94de",
"filename":"nova/tests/unit/compute/test_resource_tracker.py",
"status":"modified",
"additions":14,
"deletions":1,
"changes":15,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/unit/compute/test_resource_tracker.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/unit/compute/test_resource_tracker.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_resource_tracker.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -1577,16 +1577,29 @@ def test_existing_compute_node_updated_new_resources(self, save_mock):\n         self.rt._update(mock.sentinel.ctx, new_compute)\n         save_mock.assert_called_once_with()\n \n+    @mock.patch(\n+        'nova.pci.stats.PciDeviceStats.has_remote_managed_device_pools',\n+        return_value=True)\n     @mock.patch('nova.compute.resource_tracker.ResourceTracker.'\n                 '_sync_compute_service_disabled_trait')\n-    def test_existing_node_capabilities_as_traits(self, mock_sync_disabled):\n+    def test_existing_node_capabilities_as_traits(\n+        self, mock_sync_disabled, mock_has_remote_managed_device_pools):\n         \"\"\"The capabilities_as_traits() driver method returns traits\n         information for a node/provider.\n         \"\"\"\n         self._setup_rt()\n         rc = self.rt.reportclient\n         rc.set_traits_for_provider = mock.MagicMock()\n \n+        # TODO(dmitriis): Remove once the PCI tracker is always created\n+        # upon the resource tracker initialization.\n+        with mock.patch.object(\n+            objects.PciDeviceList, 'get_by_compute_node',\n+            return_value=objects.PciDeviceList()\n+        ):\n+            self.rt.pci_tracker = pci_manager.PciDevTracker(\n+                mock.sentinel.ctx, _COMPUTE_NODE_FIXTURES[0])\n+\n         # Emulate a driver that has implemented the update_from_provider_tree()\n         # virt driver method\n         self.driver_mock.update_provider_tree = mock.Mock()"
},
{
"sha":"8ca5a985114a57d8d2266931ad5185b318004747",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/8bc76b3cc7ce4557f4bdab99b815295878e8891e/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=8bc76b3cc7ce4557f4bdab99b815295878e8891e",
"patch":"@@ -3575,6 +3575,23 @@ def test_get_phynet_tunneled_info_non_tunneled(\n         self.assertFalse(tunneled)\n         self.assertIsNone(physnet_name)\n \n+    def test_is_remote_managed(self):\n+        cases = {\n+            (model.VNIC_TYPE_NORMAL, False),\n+            (model.VNIC_TYPE_DIRECT, False),\n+            (model.VNIC_TYPE_MACVTAP, False),\n+            (model.VNIC_TYPE_DIRECT_PHYSICAL, False),\n+            (model.VNIC_TYPE_BAREMETAL, False),\n+            (model.VNIC_TYPE_VIRTIO_FORWARDER, False),\n+            (model.VNIC_TYPE_VDPA, False),\n+            (model.VNIC_TYPE_ACCELERATOR_DIRECT, False),\n+            (model.VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL, False),\n+            (model.VNIC_TYPE_REMOTE_MANAGED, True),\n+        }\n+\n+        for vnic_type, expected in cases:\n+            self.assertEqual(self.api._is_remote_managed(vnic_type), expected)\n+\n     def _test_get_port_vnic_info(\n         self, mock_get_client, binding_vnic_type, expected_vnic_type,\n         port_resource_request=None, numa_policy=None"
}
]
},
{
"commit_sha":"d99c15f4f12d713d47f54626769477c4129fec5b",
"commit_node_id":"C_kwDOAAwOD9oAKGQ5OWMxNWY0ZjEyZDcxM2Q0N2Y1NDYyNjc2OTQ3N2M0MTI5ZmVjNWI",
"commit_html_url":"https://github.com/openstack/nova/commit/d99c15f4f12d713d47f54626769477c4129fec5b",
"commit_date":"2022-02-09T21:00:10Z",
"files":[
{
"sha":"0ec49b5d71965b2677f51b3fb173c737900c23f2",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":4,
"deletions":0,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -110,6 +110,10 @@ def _ensure_remote_managed_tag(\n                                 fields.PciDeviceType.SRIOV_PF,\n                                 fields.PciDeviceType.VDPA):\n             return\n+\n+        # A tag is added here rather than at the client side to avoid an\n+        # issue with having objects without this tag specified during an\n+        # upgrade to the first version that supports handling this tag.\n         if pool.get(PCI_REMOTE_MANAGED_TAG) is None:\n             # NOTE: tags are compared as strings case-insensitively, see\n             # pci_device_prop_match in nova/pci/utils.py."
},
{
"sha":"334c4f329bebf0ba1488d861ec26119b9d7cb9fd",
"filename":"nova/tests/functional/test_servers_provider_tree.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/functional/test_servers_provider_tree.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/functional/test_servers_provider_tree.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_servers_provider_tree.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -45,6 +45,7 @@ class ProviderTreeTests(integrated_helpers.ProviderUsageBaseTestCase):\n             os_traits.COMPUTE_VOLUME_EXTEND,\n             os_traits.COMPUTE_VOLUME_MULTI_ATTACH,\n             os_traits.COMPUTE_TRUSTED_CERTS,\n+            os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n         ]\n     ])\n "
},
{
"sha":"cd1a083d058e689cca073960f0c175a8db7edbe5",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":16,
"deletions":0,
"changes":16,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -885,6 +885,22 @@ def test_driver_capabilities_secure_boot(self, mock_supports):\n         )\n         mock_supports.assert_called_once_with()\n \n+    @mock.patch.object(\n+        libvirt_driver.LibvirtDriver, '_register_instance_machine_type',\n+        new=mock.Mock())\n+    @mock.patch.object(\n+        host.Host, 'supports_remote_managed_ports',\n+        new_callable=mock.PropertyMock)\n+    def test_driver_capabilities_remote_managed_ports(self, mock_supports):\n+        drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)\n+        drvr.init_host(\"dummyhost\")\n+        self.assertTrue(\n+            drvr.capabilities['supports_remote_managed_ports'],\n+            \"Driver capabilities for 'supports_remote_managed_ports' \"\n+            \"is invalid when host should support this feature\"\n+        )\n+        mock_supports.assert_called_once_with()\n+\n     def test_driver_raises_on_non_linux_platform(self):\n         with utils.temporary_mutation(sys, platform='darwin'):\n             self.assertRaises("
},
{
"sha":"3aba6b35ee8d667658fc2ab3840cbe73be290c84",
"filename":"nova/tests/unit/virt/libvirt/test_host.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/unit/virt/libvirt/test_host.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/tests/unit/virt/libvirt/test_host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_host.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -1816,6 +1816,16 @@ def test_supports_secure_boot__true(self, mock_caps, mock_domcaps):\n         \"\"\"\n         self.assertTrue(self.host.supports_secure_boot)\n \n+    @mock.patch.object(fakelibvirt.virConnect, \"getLibVersion\")\n+    def test_supports_remote_managed_ports__true(self, mock_libversion):\n+        mock_libversion.return_value = 7009000\n+        self.assertTrue(self.host.supports_remote_managed_ports)\n+\n+    @mock.patch.object(fakelibvirt.virConnect, \"getLibVersion\")\n+    def test_supports_remote_managed_ports__false(self, mock_libversion):\n+        mock_libversion.return_value = 7008000\n+        self.assertFalse(self.host.supports_remote_managed_ports)\n+\n     @mock.patch.object(host.Host, 'loaders', new_callable=mock.PropertyMock)\n     @mock.patch.object(host.Host, 'get_canonical_machine_type')\n     def test_get_loader(self, mock_get_mtype, mock_loaders):"
},
{
"sha":"dfe97938eb2434dca191756915b3325c368adc6c",
"filename":"nova/virt/driver.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -126,6 +126,7 @@ def block_device_info_get_mapping(block_device_info):\n     \"supports_secure_boot\": os_traits.COMPUTE_SECURITY_UEFI_SECURE_BOOT,\n     \"supports_socket_pci_numa_affinity\":\n         os_traits.COMPUTE_SOCKET_PCI_NUMA_AFFINITY,\n+    \"supports_remote_managed_ports\": os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n }\n \n \n@@ -194,6 +195,7 @@ class ComputeDriver(object):\n         \"supports_vtpm\": False,\n         \"supports_secure_boot\": False,\n         \"supports_socket_pci_numa_affinity\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"5aab8ce300786ec33d6b2e8a8a213292e739e9c9",
"filename":"nova/virt/fake.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/fake.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/fake.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/fake.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -116,6 +116,7 @@ class FakeDriver(driver.ComputeDriver):\n         \"supports_trusted_certs\": True,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": True,\n+        \"supports_remote_managed_ports\": True,\n \n         # Supported image types\n         \"supports_image_type_raw\": True,"
},
{
"sha":"1291f975add266be0e8b971f6c4b8ad35f99ef0b",
"filename":"nova/virt/hyperv/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/hyperv/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/hyperv/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/hyperv/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -103,6 +103,7 @@ class HyperVDriver(driver.ComputeDriver):\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n         \"supports_secure_boot\": True,\n+        \"supports_remote_managed_ports\": False,\n \n         # Supported image types\n         \"supports_image_type_vhd\": True,"
},
{
"sha":"7970f185412b6e418f514c7c2b938d7e0660fcbe",
"filename":"nova/virt/ironic/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/ironic/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/ironic/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/ironic/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -164,6 +164,7 @@ class IronicDriver(virt_driver.ComputeDriver):\n         \"supports_trusted_certs\": False,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"410e87b82675bddd6e67630f7eb6bd1c84534b86",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -812,6 +812,8 @@ def _update_host_specific_capabilities(self) -> None:\n         # or UEFI bootloader support in this manner\n         self.capabilities.update({\n             'supports_secure_boot': self._host.supports_secure_boot,\n+            'supports_remote_managed_ports':\n+            self._host.supports_remote_managed_ports\n         })\n \n     def _register_instance_machine_type(self):"
},
{
"sha":"f37ebba473e1caafed1e96d0bb070d631b932cc6",
"filename":"nova/virt/libvirt/host.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/libvirt/host.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/libvirt/host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/host.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -1701,6 +1701,23 @@ def supports_amd_sev(self) -> bool:\n         LOG.debug(\"No AMD SEV support detected for any (arch, machine_type)\")\n         return self._supports_amd_sev\n \n+    @property\n+    def supports_remote_managed_ports(self) -> bool:\n+        \"\"\"Determine if the host supports remote managed ports.\n+\n+        Returns a boolean indicating whether remote managed ports are\n+        possible to use on this host.\n+\n+        The check is based on a Libvirt version which added support for\n+        parsing and exposing PCI VPD since a card serial number (if present in\n+        the VPD) since the use of remote managed ports depends on this.\n+        https://libvirt.org/news.html#v7-9-0-2021-11-01\n+\n+        The actual presence of a card serial number for a particular device\n+        is meant to be checked elsewhere.\n+        \"\"\"\n+        return self.has_min_version(lv_ver=(7, 9, 0))\n+\n     @property\n     def loaders(self) -> ty.List[dict]:\n         \"\"\"Retrieve details of loader configuration for the host."
},
{
"sha":"d3eb9fc7706ad39f3841063117bdeb42535bf39d",
"filename":"nova/virt/powervm/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/powervm/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/powervm/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/powervm/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -82,6 +82,7 @@ def __init__(self, virtapi):\n             'supports_vtpm': False,\n             'supports_secure_boot': False,\n             'supports_socket_pci_numa_affinity': False,\n+            'supports_remote_managed_ports': False,\n \n             # Supported image types\n             \"supports_image_type_aki\": False,"
},
{
"sha":"cc80ca775efcd0a2d8c58a18a8985a09f394fba7",
"filename":"nova/virt/vmwareapi/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/vmwareapi/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/vmwareapi/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/vmwareapi/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -72,6 +72,7 @@ class VMwareVCDriver(driver.ComputeDriver):\n         \"supports_trusted_certs\": False,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"a1fa721515c39e579c15cb2f28fb68881a88b45b",
"filename":"nova/virt/zvm/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/zvm/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d99c15f4f12d713d47f54626769477c4129fec5b/nova/virt/zvm/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/zvm/driver.py?ref=d99c15f4f12d713d47f54626769477c4129fec5b",
"patch":"@@ -46,6 +46,7 @@ class ZVMDriver(driver.ComputeDriver):\n     \"\"\"z/VM implementation of ComputeDriver.\"\"\"\n     capabilities = {\n         \"supports_pcpus\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
}
]
},
{
"commit_sha":"6674f7668c212dbc95d2606805c4fe2c07e94cf3",
"commit_node_id":"C_kwDOAAwOD9oAKDY2NzRmNzY2OGMyMTJkYmM5NWQyNjA2ODA1YzRmZTJjMDdlOTRjZjM",
"commit_html_url":"https://github.com/openstack/nova/commit/6674f7668c212dbc95d2606805c4fe2c07e94cf3",
"commit_date":"2022-02-09T21:00:03Z",
"files":[
{
"sha":"4e4b1cca9a5f7ff37c98d42c7a3da489367fd682",
"filename":"lower-constraints.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/6674f7668c212dbc95d2606805c4fe2c07e94cf3/lower-constraints.txt",
"raw_url":"https://github.com/openstack/nova/raw/6674f7668c212dbc95d2606805c4fe2c07e94cf3/lower-constraints.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/lower-constraints.txt?ref=6674f7668c212dbc95d2606805c4fe2c07e94cf3",
"patch":"@@ -62,7 +62,7 @@ os-brick==4.3.1\n os-client-config==1.29.0\n os-resource-classes==1.1.0\n os-service-types==1.7.0\n-os-traits==2.5.0\n+os-traits==2.7.0\n os-vif==1.15.2\n os-win==5.4.0\n osc-lib==1.10.0"
},
{
"sha":"6b47321b4c736bdcaaf5e39a05badb8eaaa23ff8",
"filename":"requirements.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/6674f7668c212dbc95d2606805c4fe2c07e94cf3/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/6674f7668c212dbc95d2606805c4fe2c07e94cf3/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=6674f7668c212dbc95d2606805c4fe2c07e94cf3",
"patch":"@@ -50,7 +50,7 @@ psutil>=3.2.2 # BSD\n oslo.versionedobjects>=1.35.0 # Apache-2.0\n os-brick>=4.3.1 # Apache-2.0\n os-resource-classes>=1.1.0 # Apache-2.0\n-os-traits>=2.5.0 # Apache-2.0\n+os-traits>=2.7.0 # Apache-2.0\n os-vif>=1.15.2 # Apache-2.0\n os-win>=5.4.0 # Apache-2.0\n castellan>=0.16.0 # Apache-2.0"
}
]
},
{
"commit_sha":"1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"commit_node_id":"C_kwDOAAwOD9oAKDFhYWVkYzhlMTZlY2VjZWZkYzlmZWM1NzIwNTA5NGU0ZGZkYzdmZmU",
"commit_html_url":"https://github.com/openstack/nova/commit/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"commit_date":"2022-02-09T20:59:55Z",
"files":[
{
"sha":"de9a2e297b65ab8eaf6e74ccdc5bd01697886d1f",
"filename":"nova/conf/pci.py",
"status":"modified",
"additions":27,
"deletions":0,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/conf/pci.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/conf/pci.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/pci.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -134,6 +134,15 @@\n \n     - ``physical_network``\n     - ``trusted``\n+    - ``remote_managed`` - a VF is managed remotely by an off-path networking\n+      backend. May have boolean-like string values case-insensitive values:\n+      \"true\" or \"false\". By default, \"false\" is assumed for all devices.\n+      Using this option requires a networking service backend capable of\n+      handling those devices. PCI devices are also required to have a PCI\n+      VPD capability with a card serial number (either on a VF itself on\n+      its corresponding PF), otherwise they will be ignored and not\n+      available for allocation.\n+\n \n   Valid examples are::\n \n@@ -158,13 +167,31 @@\n                              \"physical_network\":\"physnet1\"}\n     passthrough_whitelist = {\"devname\": \"eth0\", \"physical_network\":\"physnet1\",\n                              \"trusted\": \"true\"}\n+    passthrough_whitelist = {\"vendor_id\":\"a2d6\",\n+                             \"product_id\":\"15b3\",\n+                             \"remote_managed\": \"true\"}\n+    passthrough_whitelist = {\"vendor_id\":\"a2d6\",\n+                             \"product_id\":\"15b3\",\n+                             \"address\": \"0000:82:00.0\",\n+                             \"physical_network\":\"physnet1\",\n+                             \"remote_managed\": \"true\"}\n \n   The following are invalid, as they specify mutually exclusive options::\n \n     passthrough_whitelist = {\"devname\":\"eth0\",\n                              \"physical_network\":\"physnet\",\n                              \"address\":\"*:0a:00.*\"}\n \n+  The following example is invalid because it specifies the ``remote_managed``\n+  tag for a PF - it will result in an error during config validation at the\n+  Nova Compute service startup::\n+\n+    passthrough_whitelist = {\"address\": \"0000:82:00.0\",\n+                             \"product_id\": \"a2d6\",\n+                             \"vendor_id\": \"15b3\",\n+                             \"physical_network\": null,\n+                             \"remote_managed\": \"true\"}\n+\n * A JSON list of JSON dictionaries corresponding to the above format. For\n   example::\n "
},
{
"sha":"bda5a009f1a418c70334221b97625985bab9c394",
"filename":"nova/exception.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -1565,6 +1565,16 @@ class PciRequestFromVIFNotFound(NotFound):\n                 \"PCI address: %(pci_slot)s on compute node: %(node_id)s\")\n \n \n+class PciDeviceRemoteManagedNotPresent(NovaException):\n+    msg_fmt = _('Invalid PCI Whitelist: A device specified as \"remote_managed\"'\n+                ' is not actually present on the host')\n+\n+\n+class PciDeviceInvalidPFRemoteManaged(NovaException):\n+    msg_fmt = _('Invalid PCI Whitelist: PFs must not have the \"remote_managed\"'\n+                'tag, device address: %(address)s')\n+\n+\n # Cannot be templated, msg needs to be constructed when raised.\n class InternalError(NovaException):\n     \"\"\"Generic hypervisor errors."
},
{
"sha":"1cefaed0cbf4e3e81ac656ae601bc5cf259ff2bb",
"filename":"nova/pci/devspec.py",
"status":"modified",
"additions":99,
"deletions":18,
"changes":117,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/devspec.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/devspec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/devspec.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -19,7 +19,10 @@\n from nova import exception\n from nova.i18n import _\n from nova import objects\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import utils\n+from oslo_log import log as logging\n+from oslo_utils import strutils\n \n MAX_VENDOR_ID = 0xFFFF\n MAX_PRODUCT_ID = 0xFFFF\n@@ -30,6 +33,7 @@\n ANY = '*'\n REGEX_ANY = '.*'\n \n+LOG = logging.getLogger(__name__)\n \n PCISpecAddressType = ty.Union[ty.Dict[str, str], str]\n \n@@ -111,6 +115,9 @@ def match(self, phys_pci_addr: PciAddressSpec) -> bool:\n             ]\n         return all(conditions)\n \n+    def __str__(self):\n+        return f'{self.domain}:{self.bus}:{self.slot}.{self.func}'\n+\n \n class PciAddressGlobSpec(PciAddressSpec):\n     \"\"\"Manages the address fields with glob style.\n@@ -263,6 +270,20 @@ def __init__(self, dev_spec: ty.Dict[str, str]) -> None:\n         self.tags = dev_spec\n         self._init_dev_details()\n \n+    def _address_obj(self) -> ty.Optional[WhitelistPciAddress]:\n+        address_obj = None\n+        if self.dev_name:\n+            address_str, pf = utils.get_function_by_ifname(self.dev_name)\n+            if not address_str:\n+                return None\n+            # Note(moshele): In this case we always passing a string\n+            # of the PF pci address\n+            address_obj = WhitelistPciAddress(address_str, pf)\n+        else:  # use self.address\n+            address_obj = self.address\n+\n+        return address_obj\n+\n     def _init_dev_details(self) -> None:\n         self.vendor_id = self.tags.pop(\"vendor_id\", ANY)\n         self.product_id = self.tags.pop(\"product_id\", ANY)\n@@ -283,33 +304,93 @@ def _init_dev_details(self) -> None:\n         if not self.dev_name:\n             self.address = WhitelistPciAddress(address or '*:*:*.*', False)\n \n-    def match(self, dev_dict: ty.Dict[str, str]) -> bool:\n-        address_obj: ty.Optional[WhitelistPciAddress]\n-\n-        if self.dev_name:\n-            address_str, pf = utils.get_function_by_ifname(self.dev_name)\n-            if not address_str:\n-                return False\n-            # Note(moshele): In this case we always passing a string\n-            # of the PF pci address\n-            address_obj = WhitelistPciAddress(address_str, pf)\n-        else:  # use self.address\n-            address_obj = self.address\n-\n+        # PFs with remote_managed tags are explicitly not supported. If they\n+        # are tagged as such by mistake in the whitelist Nova will\n+        # raise an exception. The reason for excluding PFs is the lack of a way\n+        # for an instance to access the control plane at the remote side (e.g.\n+        # on a DPU) for managing the PF representor corresponding to the PF.\n+        address_obj = self._address_obj()\n+        self._remote_managed = strutils.bool_from_string(\n+            self.tags.get(PCI_REMOTE_MANAGED_TAG))\n+        if self._remote_managed:\n+            if address_obj is None:\n+                # Note that this will happen if a netdev was specified in the\n+                # whitelist but it is not actually present on a system - in\n+                # this case Nova is not able to look up an address by\n+                # a netdev name.\n+                raise exception.PciDeviceRemoteManagedNotPresent()\n+            elif address_obj.is_physical_function:\n+                pf_addr = str(address_obj.pci_address_spec)\n+                vf_product_id = utils.get_vf_product_id_by_pf_addr(pf_addr)\n+                # VF vendor IDs have to match the corresponding PF vendor IDs\n+                # per the SR-IOV spec so we use it for matching here.\n+                pf_vendor_id, pf_product_id = utils.get_pci_ids_by_pci_addr(\n+                    pf_addr)\n+                # Check the actual vendor ID and VF product ID of an assumed\n+                # VF (based on the actual PF). The VF product ID must match\n+                # the actual one if this is a VF device spec.\n+                if (self.product_id == vf_product_id and\n+                        self.vendor_id in (pf_vendor_id, ANY)):\n+                    pass\n+                elif (self.product_id in (pf_product_id, ANY) and\n+                      self.vendor_id in (pf_vendor_id, ANY)):\n+                    raise exception.PciDeviceInvalidPFRemoteManaged(\n+                        address_obj.pci_address_spec)\n+                else:\n+                    # The specified product and vendor IDs of what is supposed\n+                    # to be a VF corresponding to the PF PCI address do not\n+                    # match the actual ones for this PF. This means that the\n+                    # whitelist is invalid.\n+                    raise exception.PciConfigInvalidWhitelist(\n+                        reason=_('the specified VF vendor ID %(vendor_id)s and'\n+                                 ' product ID %(product_id)s do not match the'\n+                                 ' expected VF IDs based on the corresponding'\n+                                 ' PF identified by PCI address %(pf_addr)s') %\n+                        {'vendor_id': self.vendor_id,\n+                         'product_id': self.product_id,\n+                         'pf_addr': pf_addr})\n+\n+    def _ensure_remote_managed_dev_vpd_serial(\n+        self, dev_dict: ty.Dict[str, ty.Any]) -> bool:\n+        \"\"\"Ensure the presence of a serial number field in PCI VPD.\n+\n+        A card serial number extracted from PCI VPD is required to allow a\n+        networking backend to identify which remote host needs to program a\n+        given device. So if a device is tagged as remote_managed, it must\n+        have the card serial number or be filtered out.\n+        \"\"\"\n+        if not self._remote_managed:\n+            return True\n+        card_sn = dev_dict.get('capabilities', {}).get(\n+            'vpd', {}).get('card_serial_number')\n+        # None or empty card_serial_number should be filtered out. That would\n+        # mean either no serial number in the VPD (if present at all) or SN is\n+        # an empty string which is not useful for device identification.\n+        return bool(card_sn)\n+\n+    def match(self, dev_dict: ty.Dict[str, ty.Any]) -> bool:\n+        address_obj: ty.Optional[WhitelistPciAddress] = self._address_obj()\n         if not address_obj:\n             return False\n \n         return all([\n             self.vendor_id in (ANY, dev_dict['vendor_id']),\n             self.product_id in (ANY, dev_dict['product_id']),\n             address_obj.match(dev_dict['address'],\n-                dev_dict.get('parent_addr'))])\n+                dev_dict.get('parent_addr')),\n+            self._ensure_remote_managed_dev_vpd_serial(dev_dict),\n+        ])\n \n     def match_pci_obj(self, pci_obj: 'objects.PciDevice') -> bool:\n-        return self.match({'vendor_id': pci_obj.vendor_id,\n-                           'product_id': pci_obj.product_id,\n-                           'address': pci_obj.address,\n-                           'parent_addr': pci_obj.parent_addr})\n+        dev_dict = {\n+            'vendor_id': pci_obj.vendor_id,\n+            'product_id': pci_obj.product_id,\n+            'address': pci_obj.address,\n+            'parent_addr': pci_obj.parent_addr,\n+            'capabilities': {\n+                'vpd': {'card_serial_number': pci_obj.card_serial_number}}\n+        }\n+        return self.match(dev_dict)\n \n     def get_tags(self) -> ty.Dict[str, str]:\n         return self.tags"
},
{
"sha":"d179d36cd981e9cc8956652d4726be5402944ae2",
"filename":"nova/pci/request.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/request.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/request.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/request.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -58,6 +58,7 @@\n PCI_NET_TAG = 'physical_network'\n PCI_TRUSTED_TAG = 'trusted'\n PCI_DEVICE_TYPE_TAG = 'dev_type'\n+PCI_REMOTE_MANAGED_TAG = 'remote_managed'\n \n DEVICE_TYPE_FOR_VNIC_TYPE = {\n     network_model.VNIC_TYPE_DIRECT_PHYSICAL: obj_fields.PciDeviceType.SRIOV_PF,"
},
{
"sha":"5da56ee94d376a8bdd56c19830592066d518c98a",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":58,
"deletions":0,
"changes":58,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -19,11 +19,13 @@\n \n from oslo_config import cfg\n from oslo_log import log as logging\n+from oslo_utils import strutils\n \n from nova import exception\n from nova import objects\n from nova.objects import fields\n from nova.objects import pci_device_pool\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import utils\n from nova.pci import whitelist\n \n@@ -95,6 +97,24 @@ def _find_pool(self, dev_pool: Pool) -> ty.Optional[Pool]:\n \n         return None\n \n+    @staticmethod\n+    def _ensure_remote_managed_tag(\n+            dev: 'objects.PciDevice', pool: Pool):\n+        \"\"\"Add a remote_managed tag depending on a device type if needed.\n+\n+        Network devices may be managed remotely, e.g. by a SmartNIC DPU. If\n+        a tag has not been explicitly provided, populate it by assuming that\n+        a device is not remote managed by default.\n+        \"\"\"\n+        if dev.dev_type not in (fields.PciDeviceType.SRIOV_VF,\n+                                fields.PciDeviceType.SRIOV_PF,\n+                                fields.PciDeviceType.VDPA):\n+            return\n+        if pool.get(PCI_REMOTE_MANAGED_TAG) is None:\n+            # NOTE: tags are compared as strings case-insensitively, see\n+            # pci_device_prop_match in nova/pci/utils.py.\n+            pool[PCI_REMOTE_MANAGED_TAG] = 'false'\n+\n     def _create_pool_keys_from_dev(\n         self, dev: 'objects.PciDevice',\n     ) -> ty.Optional[Pool]:\n@@ -120,6 +140,9 @@ def _create_pool_keys_from_dev(\n         # already in placement.\n         if dev.extra_info.get('parent_ifname'):\n             pool['parent_ifname'] = dev.extra_info['parent_ifname']\n+\n+        self._ensure_remote_managed_tag(dev, pool)\n+\n         return pool\n \n     def _get_pool_with_device_type_mismatch(\n@@ -458,6 +481,27 @@ def _filter_pools_for_unrequested_vdpa_devices(\n             ]\n         return pools\n \n+    def _filter_pools_for_unrequested_remote_managed_devices(\n+        self, pools: ty.List[Pool], request: 'objects.InstancePCIRequest',\n+    ) -> ty.List[Pool]:\n+        \"\"\"Filter out pools with remote_managed devices, unless requested.\n+\n+        Remote-managed devices are not usable for legacy SR-IOV or hardware\n+        offload scenarios and must be excluded from allocation.\n+\n+        :param pools: A list of PCI device pool dicts\n+        :param request: An InstancePCIRequest object describing the type,\n+            quantity and required NUMA affinity of device(s) we want.\n+        :returns: A list of pools that can be used to support the request if\n+            this is possible.\n+        \"\"\"\n+        if all(not strutils.bool_from_string(spec.get(PCI_REMOTE_MANAGED_TAG))\n+               for spec in request.spec):\n+            pools = [pool for pool in pools\n+                     if not strutils.bool_from_string(\n+                         pool.get(PCI_REMOTE_MANAGED_TAG))]\n+        return pools\n+\n     def _filter_pools(\n         self,\n         pools: ty.List[Pool],\n@@ -547,6 +591,20 @@ def _filter_pools(\n                 before_count - after_count\n             )\n \n+        # If we're not requesting remote_managed devices then we should not\n+        # use these either. Exclude them.\n+        before_count = after_count\n+        pools = self._filter_pools_for_unrequested_remote_managed_devices(\n+            pools, request)\n+        after_count = sum([pool['count'] for pool in pools])\n+\n+        if after_count < before_count:\n+            LOG.debug(\n+                'Dropped %d device(s) as they are remote-managed devices which'\n+                'we have not requested',\n+                before_count - after_count\n+            )\n+\n         if after_count < request.count:\n             LOG.debug('Not enough PCI devices left to satisfy request')\n             return None"
},
{
"sha":"51716c9d98e8171f65cc9d77838edd34aecfed22",
"filename":"nova/pci/utils.py",
"status":"modified",
"additions":60,
"deletions":0,
"changes":60,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/utils.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -211,3 +211,63 @@ def get_vf_num_by_pci_address(pci_addr: str) -> int:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n     return int(vf_num)\n+\n+\n+def get_vf_product_id_by_pf_addr(pci_addr: str) -> str:\n+    \"\"\"Get the VF product ID for a given PF.\n+\n+    \"Product ID\" or Device ID in the PCIe spec terms for a PF is\n+    possible to retrieve via the VF Device ID field present as of\n+    SR-IOV 1.0 in the \"3.3.11. VF Device ID (1Ah)\" section. It is\n+    described as a field that \"contains the Device ID that should\n+    be presented for every VF to the SI\".\n+\n+    It is available as of Linux kernel 4.15, commit\n+    7dfca15276fc3f18411a2b2182704fa1222bcb60\n+\n+    :param pci_addr: A string of the form \"<domain>:<bus>:<slot>.<function>\".\n+    :return: A string containing a product ID of a VF corresponding to the PF.\n+    \"\"\"\n+    sriov_vf_device_path = f\"/sys/bus/pci/devices/{pci_addr}/sriov_vf_device\"\n+    try:\n+        with open(sriov_vf_device_path) as f:\n+            vf_product_id = f.readline().strip()\n+    except IOError as e:\n+        LOG.warning(\n+            \"Could not find the expected sysfs file for \"\n+            \"determining the VF product ID of a PCI VF by PF\"\n+            \"with addr %(addr)s. May not be a PF. Error: %(e)s\",\n+            {\"addr\": pci_addr, \"e\": e},\n+        )\n+        raise exception.PciDeviceNotFoundById(id=pci_addr)\n+    if not vf_product_id:\n+        raise ValueError(\"sriov_vf_device file does not contain\"\n+                         \" a VF product ID\")\n+    return vf_product_id\n+\n+\n+def get_pci_ids_by_pci_addr(pci_addr: str) -> ty.Tuple[str, ...]:\n+    \"\"\"Get the product ID and vendor ID for a given PCI device.\n+\n+    :param pci_addr: A string of the form \"<domain>:<bus>:<slot>.<function>\".\n+    :return: A list containing a vendor and product ids.\n+    \"\"\"\n+    id_prefix = f\"/sys/bus/pci/devices/{pci_addr}\"\n+    ids: ty.List[str] = []\n+    for id_name in (\"vendor\", \"product\"):\n+        try:\n+            with open(os.path.join(id_prefix, id_name)) as f:\n+                id_value = f.readline()\n+                if not id_value:\n+                    raise ValueError(f\"{id_name} file does not contain\"\n+                                     \" a valid value\")\n+                ids.append(id_value.strip().replace(\"0x\", \"\"))\n+        except IOError as e:\n+            LOG.warning(\n+                \"Could not find the expected sysfs file for \"\n+                f\"determining the {id_name} ID of a PCI device \"\n+                \"with addr %(addr)s. Error: %(e)s\",\n+                {\"addr\": pci_addr, \"e\": e},\n+            )\n+            raise exception.PciDeviceNotFoundById(id=pci_addr)\n+    return tuple(ids)"
},
{
"sha":"1e4997123765919549366eabe16ab0067964d37e",
"filename":"nova/pci/whitelist.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/whitelist.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/pci/whitelist.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/whitelist.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -82,7 +82,7 @@ def _parse_white_list_from_config(\n \n         return specs\n \n-    def device_assignable(self, dev: ty.Dict[str, str]) -> bool:\n+    def device_assignable(self, dev: ty.Dict[str, ty.Any]) -> bool:\n         \"\"\"Check if a device can be assigned to a guest.\n \n         :param dev: A dictionary describing the device properties"
},
{
"sha":"1b7af103168ed5206d2d8ddf1df57c0b26cb18dc",
"filename":"nova/tests/unit/pci/test_devspec.py",
"status":"modified",
"additions":232,
"deletions":0,
"changes":232,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_devspec.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_devspec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_devspec.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -17,6 +17,7 @@\n from nova import exception\n from nova import objects\n from nova.pci import devspec\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova import test\n \n dev = {\"vendor_id\": \"8086\",\n@@ -449,3 +450,234 @@ def test_pci_obj(self):\n \n         pci_obj = objects.PciDevice.create(None, pci_dev)\n         self.assertTrue(pci.match_pci_obj(pci_obj))\n+\n+\n+class PciDevSpecRemoteManagedTestCase(test.NoDBTestCase):\n+\n+    def setUp(self):\n+        self.test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        super().setUp()\n+\n+    @mock.patch('nova.pci.utils.get_function_by_ifname',\n+                new=mock.Mock(return_value=(None, False)))\n+    def test_remote_managed_unknown_raises(self):\n+        pci_info = {\"devname\": \"nonexdev0\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceRemoteManagedNotPresent,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_pf_raises(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        5058 is the expected VF product ID which differs from the\n+        one specified in the whitelist. This is to simulate a mistake\n+        in the whitelist where a user uses both the PF PCI address and\n+        PF product and vendor ID instead of using the VF product ID.\n+        \"\"\"\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_vf_by_pf(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        This is to test the supported matching of a VF by using\n+        its product and vendor ID and a specific PF PCI address.\n+        \"\"\"\n+        # Full match: 5058 is the expected VF product ID which\n+        # matches the one specified in the whitelist. This is to\n+        # simulate the supported matching of a VF by using its\n+        # product and vendor ID and a specific PF PCI address.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        devspec.PciDeviceSpec(pci_info)\n+\n+        # This spec would match both PFs and VFs. Since we care that\n+        # remote-managed PFs are not allowed, we have to prohibit the\n+        # this altogether.\n+        pci_info = {\"vendor_id\": \"*\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"*\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # Don't care about a VF product ID. Like above, this would\n+        # match both PFs and VFs (since VFs have the same vendor ID).\n+        # Therefore, this case is prohibited to avoid remote-managed PFs.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"*\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # Don't care about a VF vendor ID.\n+        pci_info = {\"vendor_id\": \"*\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        devspec.PciDeviceSpec(pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_vf_by_pf_raises(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        5058 is the expected VF product ID which matches the one\n+        specified in the whitelist. This is to simulate the supported\n+        matching of a VF by using its product and vendor ID and a\n+        specific PF PCI address.\n+        \"\"\"\n+        # VF vendor ID and device ID mismatch.\n+        pci_info = {\"vendor_id\": \"8080\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5050\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # VF device ID mismatch.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5050\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # VF vendor ID mismatch.\n+        pci_info = {\"vendor_id\": \"8080\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_not_remote_managed_pf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"false\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_no_remote_managed_specified_pf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_no_serial_vf_no_match(self):\n+        # No card serial number available - must not get a match.\n+        test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+        }\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertFalse(pci.match(test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_empty_serial_vf_no_match(self):\n+        # Card serial is an empty string.\n+        test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"\"}},\n+        }\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertFalse(pci.match(test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_not_remote_managed_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"false\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_no_remote_managed_specified_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    def test_remote_managed_vf_match_by_pci_obj(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.2\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        pci_dev = {\n+            \"compute_node_id\": 1,\n+            \"address\": \"0000:0a:00.2\",\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+            \"status\": \"available\",\n+            \"parent_addr\": \"0000:0a:00.1\",\n+        }\n+\n+        pci_obj = objects.PciDevice.create(None, pci_dev)\n+        self.assertTrue(pci.match_pci_obj(pci_obj))\n+\n+    def test_remote_managed_vf_no_match_by_pci_obj(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        pci_dev = {\n+            \"compute_node_id\": 1,\n+            \"address\": \"0000:0a:00.2\",\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"status\": \"available\",\n+            \"parent_addr\": \"0000:0a:00.1\",\n+        }\n+\n+        pci_obj = objects.PciDevice.create(None, pci_dev)\n+        self.assertFalse(pci.match_pci_obj(pci_obj))"
},
{
"sha":"804b76ffba4dbda2a7e9a04e06a90c44e82d7df5",
"filename":"nova/tests/unit/pci/test_stats.py",
"status":"modified",
"additions":214,
"deletions":13,
"changes":227,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_stats.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_stats.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -19,6 +19,7 @@\n from nova import exception\n from nova import objects\n from nova.objects import fields\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import stats\n from nova.pci import whitelist\n from nova import test\n@@ -466,7 +467,12 @@ def setUp(self):\n         super(PciDeviceStatsWithTagsTestCase, self).setUp()\n         white_list = ['{\"vendor_id\":\"1137\",\"product_id\":\"0071\",'\n                         '\"address\":\"*:0a:00.*\",\"physical_network\":\"physnet1\"}',\n-                       '{\"vendor_id\":\"1137\",\"product_id\":\"0072\"}']\n+                      '{\"vendor_id\":\"1137\",\"product_id\":\"0072\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101e\", '\n+                      '\"remote_managed\": \"true\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101c\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"1018\", '\n+                      '\"remote_managed\": \"false\"}']\n         self.flags(passthrough_whitelist=white_list, group='pci')\n         dev_filter = whitelist.Whitelist(white_list)\n         self.pci_stats = stats.PciDeviceStats(\n@@ -502,12 +508,64 @@ def _create_pci_devices(self):\n             self.pci_untagged_devices.append(objects.PciDevice.create(None,\n                                                                       pci_dev))\n \n+        self.locally_managed_netdevs = []\n+        self.remote_managed_netdevs = []\n+        self.remote_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0c:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '101e',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0c:00.0',\n+                    'numa_node': 0,\n+                    \"capabilities\": {\"vpd\": {\n+                        \"card_serial_number\": \"MT2113X00000\"}}\n+                }))\n+\n+        # For testing implicit remote_managed == False tagging.\n+        self.locally_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0d:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '101c',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0d:00.0',\n+                    'numa_node': 0}))\n+\n+        # For testing explicit remote_managed == False tagging.\n+        self.locally_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0e:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '1018',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0e:00.0',\n+                    'numa_node': 0}))\n+\n         for dev in self.pci_tagged_devices:\n             self.pci_stats.add_device(dev)\n \n         for dev in self.pci_untagged_devices:\n             self.pci_stats.add_device(dev)\n \n+        for dev in self.remote_managed_netdevs:\n+            self.pci_stats.add_device(dev)\n+\n+        for dev in self.locally_managed_netdevs:\n+            self.pci_stats.add_device(dev)\n+\n     def _assertPoolContent(self, pool, vendor_id, product_id, count, **tags):\n         self.assertEqual(vendor_id, pool['vendor_id'])\n         self.assertEqual(product_id, pool['product_id'])\n@@ -520,9 +578,10 @@ def _assertPools(self):\n         # Pools are ordered based on the number of keys. 'product_id',\n         # 'vendor_id' are always part of the keys. When tags are present,\n         # they are also part of the keys. In this test class, we have\n-        # two pools with the second one having the tag 'physical_network'\n-        # and the value 'physnet1'\n-        self.assertEqual(2, len(self.pci_stats.pools))\n+        # 5 pools with the second one having the tag 'physical_network'\n+        # and the value 'physnet1' and multiple pools for testing\n+        # variations of explicit/implicit remote_managed tagging.\n+        self.assertEqual(5, len(self.pci_stats.pools))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072',\n                                 len(self.pci_untagged_devices))\n         self.assertEqual(self.pci_untagged_devices,\n@@ -532,6 +591,19 @@ def _assertPools(self):\n                                 physical_network='physnet1')\n         self.assertEqual(self.pci_tagged_devices,\n                          self.pci_stats.pools[1]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[2], '15b3', '101e',\n+                                len(self.remote_managed_netdevs),\n+                                remote_managed='true')\n+        self.assertEqual(self.remote_managed_netdevs,\n+                         self.pci_stats.pools[2]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[3], '15b3', '101c', 1,\n+                                remote_managed='false')\n+        self.assertEqual([self.locally_managed_netdevs[0]],\n+                         self.pci_stats.pools[3]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[4], '15b3', '1018', 1,\n+                                remote_managed='false')\n+        self.assertEqual([self.locally_managed_netdevs[1]],\n+                         self.pci_stats.pools[4]['devices'])\n \n     def test_add_devices(self):\n         self._create_pci_devices()\n@@ -543,14 +615,32 @@ def test_consume_requests(self):\n                             spec=[{'physical_network': 'physnet1'}]),\n                         objects.InstancePCIRequest(count=1,\n                             spec=[{'vendor_id': '1137',\n-                                   'product_id': '0072'}])]\n+                                   'product_id': '0072'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'True'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '101c',\n+                                   PCI_REMOTE_MANAGED_TAG: 'False'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '1018',\n+                                   PCI_REMOTE_MANAGED_TAG: 'False'}])]\n         devs = self.pci_stats.consume_requests(pci_requests)\n-        self.assertEqual(2, len(devs))\n-        self.assertEqual(set(['0071', '0072']),\n+        self.assertEqual(5, len(devs))\n+        self.assertEqual(set(['0071', '0072', '1018', '101e', '101c']),\n                          set([dev.product_id for dev in devs]))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072', 2)\n         self._assertPoolContent(self.pci_stats.pools[1], '1137', '0071', 3,\n                                 physical_network='physnet1')\n+        self._assertPoolContent(self.pci_stats.pools[2], '15b3', '101e', 0,\n+                                remote_managed='true')\n+        self._assertPoolContent(self.pci_stats.pools[3], '15b3', '101c', 0,\n+                                remote_managed='false')\n+        self._assertPoolContent(self.pci_stats.pools[4], '15b3', '1018', 0,\n+                                remote_managed='false')\n \n     def test_add_device_no_devspec(self):\n         self._create_pci_devices()\n@@ -600,7 +690,7 @@ def test_update_device(self):\n         dev1 = self.pci_tagged_devices.pop()\n         dev1.dev_type = 'type-PF'\n         self.pci_stats.update_device(dev1)\n-        self.assertEqual(3, len(self.pci_stats.pools))\n+        self.assertEqual(6, len(self.pci_stats.pools))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072',\n                                 len(self.pci_untagged_devices))\n         self.assertEqual(self.pci_untagged_devices,\n@@ -610,19 +700,24 @@ def test_update_device(self):\n                                 physical_network='physnet1')\n         self.assertEqual(self.pci_tagged_devices,\n                          self.pci_stats.pools[1]['devices'])\n-        self._assertPoolContent(self.pci_stats.pools[2], '1137', '0071',\n+        self._assertPoolContent(self.pci_stats.pools[5], '1137', '0071',\n                                 1,\n-                                physical_network='physnet1')\n+                                physical_network='physnet1',\n+                                remote_managed='false')\n         self.assertEqual(dev1,\n-                         self.pci_stats.pools[2]['devices'][0])\n+                         self.pci_stats.pools[5]['devices'][0])\n \n \n class PciDeviceVFPFStatsTestCase(test.NoDBTestCase):\n \n     def setUp(self):\n         super(PciDeviceVFPFStatsTestCase, self).setUp()\n         white_list = ['{\"vendor_id\":\"8086\",\"product_id\":\"1528\"}',\n-                      '{\"vendor_id\":\"8086\",\"product_id\":\"1515\"}']\n+                      '{\"vendor_id\":\"8086\",\"product_id\":\"1515\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"a2d6\", '\n+                      '\"remote_managed\": \"false\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101e\", '\n+                      '\"remote_managed\": \"true\"}']\n         self.flags(passthrough_whitelist=white_list, group='pci')\n         self.pci_stats = stats.PciDeviceStats(objects.NUMATopology())\n \n@@ -644,6 +739,26 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n             dev_obj.child_devices = []\n             self.sriov_pf_devices.append(dev_obj)\n \n+        # PF devices for remote_managed VFs.\n+        self.sriov_pf_devices_remote = []\n+        for dev in range(2):\n+            pci_dev = {\n+                'compute_node_id': 1,\n+                'address': '0001:81:00.%d' % dev,\n+                'vendor_id': '15b3',\n+                'product_id': 'a2d6',\n+                'status': 'available',\n+                'request_id': None,\n+                'dev_type': fields.PciDeviceType.SRIOV_PF,\n+                'parent_addr': None,\n+                'numa_node': 0,\n+                \"capabilities\": {\"vpd\": {\n+                    \"card_serial_number\": \"MT2113X00000\"}},\n+            }\n+            dev_obj = objects.PciDevice.create(None, pci_dev)\n+            dev_obj.child_devices = []\n+            self.sriov_pf_devices_remote.append(dev_obj)\n+\n         self.sriov_vf_devices = []\n         for dev in range(8):\n             pci_dev = {\n@@ -662,6 +777,25 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n             dev_obj.parent_device.child_devices.append(dev_obj)\n             self.sriov_vf_devices.append(dev_obj)\n \n+        self.sriov_vf_devices_remote = []\n+        for dev in range(8):\n+            pci_dev = {\n+                'compute_node_id': 1,\n+                'address': '0001:81:10.%d' % dev,\n+                'vendor_id': '15b3',\n+                'product_id': '101e',\n+                'status': 'available',\n+                'request_id': None,\n+                'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                'parent_addr': '0001:81:00.%d' % int(dev / 4),\n+                'numa_node': 0,\n+                \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}}\n+            }\n+            dev_obj = objects.PciDevice.create(None, pci_dev)\n+            dev_obj.parent_device = self.sriov_pf_devices_remote[int(dev / 4)]\n+            dev_obj.parent_device.child_devices.append(dev_obj)\n+            self.sriov_vf_devices_remote.append(dev_obj)\n+\n         self.vdpa_devices = []\n         for dev in range(8):\n             pci_dev = {\n@@ -683,6 +817,8 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n         list(map(self.pci_stats.add_device, self.sriov_pf_devices))\n         list(map(self.pci_stats.add_device, self.sriov_vf_devices))\n         list(map(self.pci_stats.add_device, self.vdpa_devices))\n+        list(map(self.pci_stats.add_device, self.sriov_pf_devices_remote))\n+        list(map(self.pci_stats.add_device, self.sriov_vf_devices_remote))\n \n     def test_consume_VDPA_requests(self):\n         self._create_pci_devices()\n@@ -726,7 +862,8 @@ def test_consume_PF_requests(self):\n         free_devs = self.pci_stats.get_free_devs()\n         # Validate that there are no free devices left, as when allocating\n         # both available PFs, its VFs should not be available.\n-        self.assertEqual(0, len(free_devs))\n+        self.assertEqual(0, len([d for d in free_devs\n+                                 if d.product_id == '1515']))\n \n     def test_consume_VF_and_PF_requests(self):\n         self._create_pci_devices()\n@@ -754,3 +891,67 @@ def test_consume_VF_and_PF_same_prodict_id_failed(self):\n         pci_requests = [objects.InstancePCIRequest(count=9,\n                             spec=[{'product_id': '1515'}])]\n         self.assertIsNone(self.pci_stats.consume_requests(pci_requests))\n+\n+    def test_consume_PF_not_remote_managed(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=2,\n+                            spec=[{'product_id': '1528',\n+                                   'dev_type': 'type-PF',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['1528']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that there are no free devices left with the\n+        # product ID under test, as when allocating both available\n+        # PFs, its VFs should not be available.\n+        self.assertEqual(0, len([d for d in free_devs\n+                                 if d.product_id == '1528']))\n+\n+    def test_consume_VF_requests_remote_managed(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=2,\n+                            spec=[{PCI_REMOTE_MANAGED_TAG: 'true'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['101e']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that the parents of these VFs has been removed\n+        # from pools.\n+        for dev in devs:\n+            self.assertNotIn(dev.parent_addr,\n+                             [free_dev.address for free_dev in free_devs])\n+\n+    def test_consume_VF_requests_remote_managed_filtered(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e'}])]\n+        free_devs_before = self.pci_stats.get_free_devs()\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertIsNone(devs)\n+        free_devs_after = self.pci_stats.get_free_devs()\n+        self.assertEqual(free_devs_before, free_devs_after)\n+\n+    def test_consume_VF_requests_remote_managed_mix(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'true'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '1515',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['101e', '1515']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that the parents of these VFs has been removed\n+        # from pools.\n+        for dev in devs:\n+            self.assertNotIn(dev.parent_addr,\n+                             [free_dev.address for free_dev in free_devs])"
},
{
"sha":"8170f47b97c19fe20d912c8a3d18e99dcea2fc01",
"filename":"nova/tests/unit/pci/test_utils.py",
"status":"modified",
"additions":177,
"deletions":0,
"changes":177,
"blob_url":"https://github.com/openstack/nova/blob/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_utils.py",
"raw_url":"https://github.com/openstack/nova/raw/1aaedc8e16ececefdc9fec57205094e4dfdc7ffe/nova/tests/unit/pci/test_utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_utils.py?ref=1aaedc8e16ececefdc9fec57205094e4dfdc7ffe",
"patch":"@@ -251,3 +251,180 @@ def test_vf_number_not_found(self, mock_iglob, mock_readlink):\n             utils.get_vf_num_by_pci_address,\n             self.pci_address\n         )\n+\n+\n+class GetProductIDByPfPciAddressTestCase(test.NoDBTestCase):\n+    def setUp(self):\n+        super().setUp()\n+        self.pci_address = \"0000:0a:00.0\"\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        read_data=\"101e\\n\"\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read(self):\n+        product_id = utils.get_vf_product_id_by_pf_addr(self.pci_address)\n+        self.assertEqual(product_id, \"101e\")\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        read_data=\"\"\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read_value_error(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_vf_product_id_by_pf_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read_io_error(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_vf_product_id_by_pf_addr,\n+            self.pci_address,\n+        )\n+\n+\n+class GetPciIdsByPciAddressTestCase(test.NoDBTestCase):\n+    def setUp(self):\n+        super().setUp()\n+        self.pci_address = \"0000:0a:00.0\"\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        read_data=\"0x101e\\n\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids(self):\n+        self.assertEqual(\n+            utils.get_pci_ids_by_pci_addr(self.pci_address), (\"15b3\", \"101e\")\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\": mock.mock_open(\n+                        read_data=\"\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_value_error_vendor(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        read_data=\"\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_value_error_product(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\": mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_io_error_vendor(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_io_error_product(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )"
}
]
},
{
"commit_sha":"7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"commit_node_id":"C_kwDOAAwOD9oAKDdjYjE1ZmEyNDU3MGMwZDMyNmM5MmJlZDNiY2Y3ZDllOTZiYTE5NGQ",
"commit_html_url":"https://github.com/openstack/nova/commit/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"commit_date":"2022-02-09T20:59:46Z",
"files":[
{
"sha":"9ebc03129712754314f7e392cd801d8ad5bc2222",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":48,
"deletions":6,
"changes":54,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -669,7 +669,8 @@ def _unbind_ports(self, context, ports,\n             # information in the binding profile.\n             for profile_key in ('pci_vendor_info', 'pci_slot',\n                                 constants.ALLOCATION, 'arq_uuid',\n-                                'physical_network', 'card_serial_number'):\n+                                'physical_network', 'card_serial_number',\n+                                'vf_num', 'pf_mac_address'):\n                 if profile_key in port_profile:\n                     del port_profile[profile_key]\n             port_req_body['port'][constants.BINDING_PROFILE] = port_profile\n@@ -1559,6 +1560,50 @@ def delete_port_binding(self, context, port_id, host):\n                 raise exception.PortBindingDeletionFailed(\n                     port_id=port_id, host=host)\n \n+    def _get_vf_pci_device_profile(self, pci_dev):\n+        \"\"\"Get VF-specific fields to add to the PCI device profile.\n+\n+        This data can be useful, e.g. for off-path networking backends that\n+        need to do the necessary plumbing in order to set a VF up for packet\n+        forwarding.\n+        \"\"\"\n+        vf_profile: ty.Dict[str, ty.Union[str, int]] = {}\n+        try:\n+            pf_mac = pci_utils.get_mac_by_pci_address(pci_dev.parent_addr)\n+        except (exception.PciDeviceNotFoundById) as e:\n+            LOG.debug(\n+                \"Could not determine PF MAC address for a VF with\"\n+                \" addr %(addr)s, error: %(e)s\",\n+                {\"addr\": pci_dev.address, \"e\": e})\n+            # NOTE(dmitriis): we do not raise here since not all PFs will\n+            # have netdevs even when VFs are netdevs (see LP: #1915255). The\n+            # rest of the fields (VF number and card serial) are not enough\n+            # to fully identify the VF so they are not populated either.\n+            return vf_profile\n+        try:\n+            vf_num = pci_utils.get_vf_num_by_pci_address(\n+                pci_dev.address)\n+        except exception.PciDeviceNotFoundById as e:\n+            # This is unlikely to happen because the kernel has a common SR-IOV\n+            # code that creates physfn symlinks, however, it would be better\n+            # to avoid raising an exception here and simply warn an operator\n+            # that things did not go as planned.\n+            LOG.warning(\n+                \"Could not determine a VF logical number for a VF\"\n+                \" with addr %(addr)s, error: %(e)s\", {\n+                    \"addr\": pci_dev.address, \"e\": e})\n+            return vf_profile\n+        card_serial_number = pci_dev.card_serial_number\n+        if card_serial_number:\n+            vf_profile.update({\n+                'card_serial_number': card_serial_number\n+            })\n+        vf_profile.update({\n+            'pf_mac_address': pf_mac,\n+            'vf_num': vf_num,\n+        })\n+        return vf_profile\n+\n     def _get_pci_device_profile(self, pci_dev):\n         dev_spec = self.pci_whitelist.get_devspec(pci_dev)\n         if dev_spec:\n@@ -1571,11 +1616,8 @@ def _get_pci_device_profile(self, pci_dev):\n                 ),\n             }\n             if pci_dev.dev_type == obj_fields.PciDeviceType.SRIOV_VF:\n-                card_serial_number = pci_dev.card_serial_number\n-                if card_serial_number:\n-                    dev_profile.update({\n-                        'card_serial_number': card_serial_number\n-                    })\n+                dev_profile.update(\n+                    self._get_vf_pci_device_profile(pci_dev))\n             return dev_profile\n \n         raise exception.PciDeviceNotFound(node_id=pci_dev.compute_node_id,"
},
{
"sha":"90c20056b5c0612c909b0eb159fb8a302458ddac",
"filename":"nova/pci/utils.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/pci/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/pci/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/utils.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -191,7 +191,7 @@ def get_mac_by_pci_address(pci_addr: str, pf_interface: bool = False) -> str:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n \n-def get_vf_num_by_pci_address(pci_addr: str) -> str:\n+def get_vf_num_by_pci_address(pci_addr: str) -> int:\n     \"\"\"Get the VF number based on a VF's pci address\n \n     A VF is associated with an VF number, which ip link command uses to\n@@ -210,4 +210,4 @@ def get_vf_num_by_pci_address(pci_addr: str) -> str:\n     else:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n-    return vf_num\n+    return int(vf_num)"
},
{
"sha":"445c49a8e26f3e9d53af652f1359167b593516c5",
"filename":"nova/tests/fixtures/libvirt.py",
"status":"modified",
"additions":4,
"deletions":0,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/fixtures/libvirt.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/fixtures/libvirt.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/libvirt.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -2162,6 +2162,10 @@ def setUp(self):\n             'nova.pci.utils.get_ifname_by_pci_address',\n             return_value='fake_pf_interface_name'))\n \n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_mac_by_pci_address',\n+            return_value='52:54:00:1e:59:c6'))\n+\n         # libvirt calls out to sysfs to get the vfs ID during macvtap plug\n         self.useFixture(fixtures.MockPatch(\n             'nova.pci.utils.get_vf_num_by_pci_address', return_value=1))"
},
{
"sha":"bd16f42408bd26880e983d00ec67140776d38adf",
"filename":"nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"status":"modified",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/libvirt/test_pci_sriov_servers.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -287,6 +287,8 @@ def fake_create(cls, xml, host):\n                 'pci_vendor_info': '8086:1515',\n                 'pci_slot': '0000:81:00.2',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )\n@@ -529,6 +531,8 @@ def test_live_migrate_server_with_neutron(self):\n                 # matching one)\n                 'pci_slot': '0000:81:01.4',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )\n@@ -561,6 +565,8 @@ def test_live_migrate_server_with_neutron(self):\n                 'pci_vendor_info': '8086:1515',\n                 'pci_slot': '0000:81:00.2',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )"
},
{
"sha":"6663ebe8cd3faa735a265f6f51fc16a90cf0c678",
"filename":"nova/tests/functional/regressions/test_bug_1896463.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/functional/regressions/test_bug_1896463.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/functional/regressions/test_bug_1896463.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/regressions/test_bug_1896463.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -51,6 +51,14 @@ def setUp(self):\n         self.api_fixture = self.useFixture(nova_fixtures.OSAPIFixture(\n             api_version='v2.1'))\n \n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_mac_by_pci_address',\n+            return_value='52:54:00:1e:59:c6'))\n+\n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_vf_num_by_pci_address',\n+            return_value=1))\n+\n         self.admin_api = self.api_fixture.admin_api\n         self.admin_api.microversion = 'latest'\n         self.api = self.admin_api"
},
{
"sha":"675f8d3f1145875b9d8d51079bb40705058d9d9e",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":197,
"deletions":16,
"changes":213,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -4487,16 +4487,16 @@ def test_update_port_bindings_for_instance_same_host(\n                       'device_owner': 'compute:%s' %\n                                       instance.availability_zone}})\n \n+    @mock.patch.object(neutronapi.API, '_get_vf_pci_device_profile',\n+                       new=mock.Mock(return_value={}))\n     @mock.patch(\n         'nova.network.neutron.API.has_extended_resource_request_extension',\n         new=mock.Mock(return_value=False),\n     )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(neutronapi, 'get_client', return_value=mock.Mock())\n-    def test_update_port_bindings_for_instance_with_pci(self,\n-                                            get_client_mock,\n-                                            get_pci_device_devspec_mock):\n-\n+    def test_update_port_bindings_for_instance_with_pci(\n+            self, get_client_mock, get_pci_device_devspec_mock):\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         get_pci_device_devspec_mock.return_value = devspec\n@@ -7434,11 +7434,16 @@ def test_populate_neutron_extension_values_binding(self, mock_get_client):\n         mock_get_client.assert_called_once_with(mock.ANY)\n         mocked_client.list_extensions.assert_called_once_with()\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value={\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+        }))\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_populate_neutron_extension_values_binding_sriov(self,\n-                                         mock_get_instance_pci_devs,\n-                                         mock_get_pci_device_devspec):\n+    def test_populate_neutron_extension_values_binding_sriov(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n         port_req_body = {'port': {}}\n@@ -7447,7 +7452,7 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n                    'card_serial_number': None,\n-                   'dev_type': 'TEST_TYPE',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n                                ['vendor_id', 'product_id', 'address',\n@@ -7456,19 +7461,30 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         mock_get_pci_device_devspec.return_value = devspec\n+\n         self.api._populate_neutron_binding_profile(\n             instance, pci_req_id, port_req_body, None)\n \n         self.assertEqual(profile,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value= {\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+            'card_serial_number': 'MT2113X00000',\n+        })\n+    )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n     def test_populate_neutron_extension_values_binding_sriov_card_serial(\n@@ -7479,7 +7495,7 @@ def test_populate_neutron_extension_values_binding_sriov_card_serial(\n         pci_req_id = 'my_req_id'\n         pci_dev = {'vendor_id': 'a2d6',\n                    'product_id': '15b3',\n-                   'address': '0000:82:00.1',\n+                   'address': '0000:0a:00.1',\n                    'card_serial_number': 'MT2113X00000',\n                    'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n@@ -7488,11 +7504,13 @@ def test_populate_neutron_extension_values_binding_sriov_card_serial(\n                                 'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': 'a2d6:15b3',\n-                   'pci_slot': '0000:82:00.1',\n+                   'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n                    # card_serial_number is a property of the object obtained\n                    # from extra_info.\n                    'card_serial_number': 'MT2113X00000',\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n@@ -7544,11 +7562,17 @@ def test_populate_neutron_extension_values_with_arq(self,\n             profile,\n             port_req_body['port'][constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value= {\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+        })\n+    )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n-                                         mock_get_instance_pci_devs,\n-                                         mock_get_pci_device_devspec):\n+    def test_populate_neutron_extension_values_binding_sriov_with_cap(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n         port_req_body = {'port': {\n@@ -7559,7 +7583,7 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n                    'card_serial_number': None,\n-                   'dev_type': 'TEST_TYPE',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n                                ['vendor_id', 'product_id', 'address',\n@@ -7569,19 +7593,165 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n                    'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n                    'capabilities': ['switchdev'],\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         mock_get_pci_device_devspec.return_value = devspec\n+\n         self.api._populate_neutron_binding_profile(\n             instance, pci_req_id, port_req_body, None)\n \n         self.assertEqual(profile,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: 1\n+                     if vf_a == '0000:0a:00.1' else None)))\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a)))\n+    )\n+    def test__get_vf_pci_device_profile(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev),\n+                         {'pf_mac_address': '52:54:00:1e:59:c6',\n+                          'vf_num': 1,\n+                          'card_serial_number': 'MT2113X00000'})\n+\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=exception.PciDeviceNotFoundById(id='0000:0a:00.1'))\n+    )\n+    def test__get_vf_pci_device_profile_invalid_pf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev), {})\n+\n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=exception.PciDeviceNotFoundById(id='0000:0a:00.0'))\n+    )\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a))))\n+    def test__get_vf_pci_device_profile_invalid_vf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        vf_profile = self.api._get_vf_pci_device_profile(mydev)\n+        self.assertEqual(vf_profile, {})\n+\n+    def test__get_vf_pci_device_profile_not_vf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': None,\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev), {})\n+\n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.MagicMock(side_effect=(\n+            lambda dev: {'0000:0a:00.1': {\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n+                'card_serial_number': 'MT2113X00000',\n+            }}.get(dev.address)\n+    )))\n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    def test__get_pci_device_profile_vf(self, mock_get_pci_device_devspec):\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+\n+        self.assertEqual({'card_serial_number': 'MT2113X00000',\n+                          'pci_slot': '0000:0a:00.1',\n+                          'pci_vendor_info': 'a2d6:15b3',\n+                          'pf_mac_address': '52:54:00:1e:59:c6',\n+                          'physical_network': 'physnet1',\n+                          'vf_num': 1},\n+                         self.api._get_pci_device_profile(mydev))\n+\n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    def test__get_pci_device_profile_pf(self, mock_get_pci_device_devspec):\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_PF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+\n+        self.assertEqual({'pci_slot': '0000:0a:00.0',\n+                          'pci_vendor_info': 'a2d6:15b3',\n+                          'physical_network': 'physnet1'},\n+                         self.api._get_pci_device_profile(mydev))\n+\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n     def test_populate_neutron_extension_values_binding_sriov_fail(\n@@ -7617,9 +7787,19 @@ def test_populate_neutron_binding_profile_pci_dev_not_found(\n         mock_get_instance_pci_devs.assert_called_once_with(\n             instance, pci_req_id)\n \n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=(lambda vf_a: {'0000:0a:00.1': 1}.get(vf_a)))\n+    )\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a)))\n+    )\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_pci_parse_whitelist_called_once(self,\n-                                             mock_get_instance_pci_devs):\n+    def test_pci_parse_whitelist_called_once(\n+        self, mock_get_instance_pci_devs):\n         white_list = [\n             '{\"address\":\"0000:0a:00.1\",\"physical_network\":\"default\"}']\n         cfg.CONF.set_override('passthrough_whitelist', white_list, 'pci')\n@@ -7634,6 +7814,7 @@ def test_pci_parse_whitelist_called_once(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n                    'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n "
},
{
"sha":"0c45e93f9442caf9dab36ae5e256d464ca5576f9",
"filename":"nova/tests/unit/pci/test_utils.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/unit/pci/test_utils.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/tests/unit/pci/test_utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_utils.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -239,7 +239,7 @@ def test_vf_number_found(self, mock_iglob, mock_readlink):\n         mock_iglob.return_value = self.paths\n         mock_readlink.return_value = '../../0000:00:00.1'\n         vf_num = utils.get_vf_num_by_pci_address(self.pci_address)\n-        self.assertEqual(vf_num, '3')\n+        self.assertEqual(vf_num, 3)\n \n     @mock.patch.object(os, 'readlink')\n     @mock.patch.object(glob, 'iglob')"
},
{
"sha":"e0bcda554ca5d60f671e36d64cc5ac94adda012c",
"filename":"nova/virt/fake.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/virt/fake.py",
"raw_url":"https://github.com/openstack/nova/raw/7cb15fa24570c0d326c92bed3bcf7d9e96ba194d/nova/virt/fake.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/fake.py?ref=7cb15fa24570c0d326c92bed3bcf7d9e96ba194d",
"patch":"@@ -954,6 +954,14 @@ def setUp(self):\n             ],\n                              group='pci')\n \n+            self.useFixture(fixtures.MockPatch(\n+                'nova.pci.utils.get_mac_by_pci_address',\n+                return_value='52:54:00:1e:59:c6'))\n+\n+            self.useFixture(fixtures.MockPatch(\n+                'nova.pci.utils.get_vf_num_by_pci_address',\n+                return_value=1))\n+\n     def get_available_resource(self, nodename):\n         host_status = super(\n             FakeDriverWithPciResources, self).get_available_resource(nodename)"
}
]
},
{
"commit_sha":"a656748cf9dc441d79bde120785904ff2626646d",
"commit_node_id":"C_kwDOAAwOD9oAKGE2NTY3NDhjZjlkYzQ0MWQ3OWJkZTEyMDc4NTkwNGZmMjYyNjY0NmQ",
"commit_html_url":"https://github.com/openstack/nova/commit/a656748cf9dc441d79bde120785904ff2626646d",
"commit_date":"2022-02-09T20:42:47Z",
"files":[
{
"sha":"642e553094c8810de2ec4537a474a1f337195db7",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/a656748cf9dc441d79bde120785904ff2626646d/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/a656748cf9dc441d79bde120785904ff2626646d/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=a656748cf9dc441d79bde120785904ff2626646d",
"patch":"@@ -366,6 +366,8 @@\n the announce-self command to the QEMU monitor so that it generates RARP frames\n to update network switches in the post live migration phase on the destination.\n \n+Please note that this causes the domain to be considered tainted by libvirt.\n+\n Related options:\n \n * :oslo.config:option:`DEFAULT.compute_driver` (libvirt)"
}
]
},
{
"commit_sha":"c9a0c7da9bd945b1693b4210f57717d650e224d2",
"commit_node_id":"C_kwDOAAwOD9oAKGM5YTBjN2RhOWJkOTQ1YjE2OTNiNDIxMGY1NzcxN2Q2NTBlMjI0ZDI",
"commit_html_url":"https://github.com/openstack/nova/commit/c9a0c7da9bd945b1693b4210f57717d650e224d2",
"commit_date":"2022-02-09T18:12:45Z",
"files":[
{
"sha":"61f23f9804cc81ec27db8616863af6eb1c283487",
"filename":"doc/source/admin/networking.rst",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/c9a0c7da9bd945b1693b4210f57717d650e224d2/doc/source/admin/networking.rst",
"raw_url":"https://github.com/openstack/nova/raw/c9a0c7da9bd945b1693b4210f57717d650e224d2/doc/source/admin/networking.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/networking.rst?ref=c9a0c7da9bd945b1693b4210f57717d650e224d2",
"patch":"@@ -206,10 +206,10 @@ virtio-net Multiqueue\n \n .. versionadded:: 12.0.0 (Liberty)\n \n-.. versionchanged:: 24.0.0 (Xena)\n+.. versionchanged:: 25.0.0 (Yoga)\n \n    Support for configuring multiqueue via the ``hw:vif_multiqueue_enabled``\n-   flavor extra spec was introduced in the Xena (24.0.0) release.\n+   flavor extra spec was introduced in the Yoga (25.0.0) release.\n \n .. important::\n "
}
]
},
{
"commit_sha":"95157314bddd7eacc325f3f47a046f907abd8a87",
"commit_node_id":"C_kwDOAAwOD9oAKDk1MTU3MzE0YmRkZDdlYWNjMzI1ZjNmNDdhMDQ2ZjkwN2FiZDhhODc",
"commit_html_url":"https://github.com/openstack/nova/commit/95157314bddd7eacc325f3f47a046f907abd8a87",
"commit_date":"2021-05-20T11:41:33Z",
"files":[
{
"sha":"af7174a8acc7a650e39c936732f21927894724b5",
"filename":"doc/source/admin/networking.rst",
"status":"modified",
"additions":90,
"deletions":0,
"changes":90,
"blob_url":"https://github.com/openstack/nova/blob/95157314bddd7eacc325f3f47a046f907abd8a87/doc/source/admin/networking.rst",
"raw_url":"https://github.com/openstack/nova/raw/95157314bddd7eacc325f3f47a046f907abd8a87/doc/source/admin/networking.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/networking.rst?ref=95157314bddd7eacc325f3f47a046f907abd8a87",
"patch":"@@ -199,3 +199,93 @@ As with the L2-type networks, this configuration will ensure instances using\n one or more L3-type networks must be scheduled on host cores from NUMA node 0.\n It is also possible to define more than one NUMA node, in which case the\n instance must be split across these nodes.\n+\n+\n+virtio-net Multiqueue\n+---------------------\n+\n+.. versionadded:: 12.0.0 (Liberty)\n+\n+.. versionchanged:: 24.0.0 (Xena)\n+\n+   Support for configuring multiqueue via the ``hw:vif_multiqueue_enabled``\n+   flavor extra spec was introduced in the Xena (24.0.0) release.\n+\n+.. important::\n+\n+   The functionality described below is currently only supported by the\n+   libvirt/KVM driver.\n+\n+Virtual NICs using the virtio-net driver support the multiqueue feature. By\n+default, these vNICs will only use a single virtio-net TX/RX queue pair,\n+meaning guests will not transmit or receive packets in parallel. As a result,\n+the scale of the protocol stack in a guest may be restricted as the network\n+performance will not scale as the number of vCPUs increases and per-queue data\n+processing limits in the underlying vSwitch are encountered. The solution to\n+this issue is to enable virtio-net multiqueue, which can allow the guest\n+instances to increase the total network throughput by scaling the number of\n+receive and transmit queue pairs with CPU count.\n+\n+Multiqueue virtio-net isn't always necessary, but it can provide a significant\n+performance benefit when:\n+\n+- Traffic packets are relatively large.\n+- The guest is active on many connections at the same time, with traffic\n+  running between guests, guest to host, or guest to an external system.\n+- The number of queues is equal to the number of vCPUs. This is because\n+  multi-queue support optimizes RX interrupt affinity and TX queue selection in\n+  order to make a specific queue private to a specific vCPU.\n+\n+However, while the virtio-net multiqueue feature will often provide a welcome\n+performance benefit, it has some limitations and therefore should not be\n+unconditionally enabled:\n+\n+- Enabling virtio-net multiqueue increases the total network throughput, but in\n+  parallel it also increases the CPU consumption.\n+- Enabling virtio-net multiqueue in the host QEMU config does not enable the\n+  functionality in the guest OS. The guest OS administrator needs to manually\n+  turn it on for each guest NIC that requires this feature, using\n+  :command:`ethtool`.\n+- In case the number of vNICs in a guest instance is proportional to the number\n+  of vCPUs, enabling the multiqueue feature is less important.\n+\n+Having considered these points, multiqueue can be enabled or explicitly\n+disabled using either the :nova:extra-spec:`hw:vif_multiqueue_enabled` flavor\n+extra spec or equivalent ``hw_vif_multiqueue_enabled`` image metadata property.\n+For example, to enable virtio-net multiqueue for a chosen flavor:\n+\n+.. code-block:: bash\n+\n+    $ openstack flavor set --property hw:vif_multiqueue_enabled=true $FLAVOR\n+\n+Alternatively, to explicitly disable multiqueue for a chosen image:\n+\n+.. code-block:: bash\n+\n+    $ openstack image set --property hw_vif_multiqueue_enabled=false $IMAGE\n+\n+.. note::\n+\n+    If both the flavor extra spec and image metadata property are provided,\n+    their values must match or an error will be raised.\n+\n+Once the guest has started, you must enable multiqueue using\n+:command:`ethtool`. For example:\n+\n+.. code-block:: bash\n+\n+    $ ethtool -L $devname combined $N\n+\n+where ``$devname`` is the name of the network device, and ``$N`` is the number\n+of TX/RX queue pairs to configure corresponding to the number of instance\n+vCPUs. Alternatively, you can configure this persistently using udev. For\n+example, to configure four TX/RX queue pairs for network device ``eth0``:\n+\n+.. code-block:: bash\n+\n+    # cat /etc/udev/rules.d/50-ethtool.rules\n+    ACTION==\"add\", SUBSYSTEM==\"net\", NAME==\"eth0\", RUN+=\"/sbin/ethtool -L eth0 combined 4\"\n+\n+For more information on this feature, refer to the `original spec`__.\n+\n+.. __: https://specs.openstack.org/openstack/nova-specs/specs/liberty/implemented/libvirt-virtiomq.html"
}
]
},
{
"commit_sha":"6e126869f0591fe1743f115e0609f9b4831605c5",
"commit_node_id":"C_kwDOAAwOD9oAKDZlMTI2ODY5ZjA1OTFmZTE3NDNmMTE1ZTA2MDlmOWI0ODMxNjA1YzU",
"commit_html_url":"https://github.com/openstack/nova/commit/6e126869f0591fe1743f115e0609f9b4831605c5",
"commit_date":"2022-02-09T13:16:32Z",
"files":[
{
"sha":"32ed68cabf024cccf7841032c001afe42efa8112",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":8,
"deletions":3,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/6e126869f0591fe1743f115e0609f9b4831605c5/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/6e126869f0591fe1743f115e0609f9b4831605c5/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=6e126869f0591fe1743f115e0609f9b4831605c5",
"patch":"@@ -21530,6 +21530,8 @@ def test_migrate_disk_and_power_off_exception(\n                           context.get_admin_context(), ins_ref, '10.0.0.2',\n                           flavor_obj, None)\n \n+    @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.'\n+                '_cleanup_failed_instance_base')\n     @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs')\n     @mock.patch('nova.virt.libvirt.utils.save_and_migrate_vtpm_dir')\n     @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.'\n@@ -21546,7 +21548,7 @@ def _test_migrate_disk_and_power_off(\n             self, ctxt, flavor_obj, mock_execute, mock_exists, mock_rename,\n             mock_is_shared, mock_get_host_ip, mock_destroy,\n             mock_get_disk_info, mock_vtpm, mock_unplug_vifs,\n-            block_device_info=None, params_for_instance=None):\n+            mock_cleanup, block_device_info=None, params_for_instance=None):\n         \"\"\"Test for nova.virt.libvirt.driver.LivirtConnection\n         .migrate_disk_and_power_off.\n         \"\"\"\n@@ -21561,6 +21563,8 @@ def _test_migrate_disk_and_power_off(\n                ctxt, instance, '10.0.0.2', flavor_obj, None,\n                block_device_info=block_device_info)\n \n+        mock_cleanup.assert_called_once()\n+        mock_cleanup.reset_mock()\n         self.assertEqual(out, disk_info_text)\n         mock_vtpm.assert_called_with(\n             instance.uuid, mock.ANY, mock.ANY, '10.0.0.2', mock.ANY, mock.ANY)\n@@ -21571,6 +21575,7 @@ def _test_migrate_disk_and_power_off(\n                ctxt, instance, '10.0.0.1', flavor_obj, None,\n                block_device_info=block_device_info)\n \n+        mock_cleanup.assert_called_once()\n         self.assertEqual(out, disk_info_text)\n         mock_vtpm.assert_called_with(\n             instance.uuid, mock.ANY, mock.ANY, '10.0.0.1', mock.ANY, mock.ANY)\n@@ -22468,8 +22473,8 @@ def test_finish_revert_migration_snap_backend_image_does_not_exist(self):\n             self.assertFalse(drvr.image_backend.remove_snap.called)\n \n     @mock.patch.object(shutil, 'rmtree')\n-    def test_cleanup_failed_migration(self, mock_rmtree):\n-        self.drvr._cleanup_failed_migration('/fake/inst')\n+    def test_cleanup_failed_instance_base(self, mock_rmtree):\n+        self.drvr._cleanup_failed_instance_base('/fake/inst')\n         mock_rmtree.assert_called_once_with('/fake/inst')\n \n     @mock.patch.object(libvirt_driver.LibvirtDriver, '_cleanup_resize')"
},
{
"sha":"11f3eb088956e8f8cd7d5a61690d886382242eb2",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":7,
"deletions":4,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/6e126869f0591fe1743f115e0609f9b4831605c5/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/6e126869f0591fe1743f115e0609f9b4831605c5/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=6e126869f0591fe1743f115e0609f9b4831605c5",
"patch":"@@ -10979,6 +10979,9 @@ def migrate_disk_and_power_off(self, context, instance, dest,\n         disk_info = self._get_instance_disk_info(instance, block_device_info)\n \n         try:\n+            # If cleanup failed in previous resize attempts we try to remedy\n+            # that before a resize is tried again\n+            self._cleanup_failed_instance_base(inst_base_resize)\n             os.rename(inst_base, inst_base_resize)\n             # if we are migrating the instance with shared instance path then\n             # create the directory.  If it is a remote node the directory\n@@ -11202,9 +11205,9 @@ def finish_migration(\n \n         LOG.debug(\"finish_migration finished successfully.\", instance=instance)\n \n-    def _cleanup_failed_migration(self, inst_base):\n-        \"\"\"Make sure that a failed migrate doesn't prevent us from rolling\n-        back in a revert.\n+    def _cleanup_failed_instance_base(self, inst_base):\n+        \"\"\"Make sure that a failed migrate or resize doesn't prevent us from\n+        rolling back in a revert or retrying a resize.\n         \"\"\"\n         try:\n             shutil.rmtree(inst_base)\n@@ -11260,7 +11263,7 @@ def finish_revert_migration(\n         # that would conflict. Also, don't fail on the rename if the\n         # failure happened early.\n         if os.path.exists(inst_base_resize):\n-            self._cleanup_failed_migration(inst_base)\n+            self._cleanup_failed_instance_base(inst_base)\n             os.rename(inst_base_resize, inst_base)\n \n         root_disk = self.image_backend.by_name(instance, 'disk')"
},
{
"sha":"7a89c66092f3cc73a96d0c63aa426d8e6a769fcd",
"filename":"releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"status":"added",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/6e126869f0591fe1743f115e0609f9b4831605c5/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"raw_url":"https://github.com/openstack/nova/raw/6e126869f0591fe1743f115e0609f9b4831605c5/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml?ref=6e126869f0591fe1743f115e0609f9b4831605c5",
"patch":"@@ -0,0 +1,6 @@\n+---\n+fixes:\n+  - |\n+    Fixed bug `1960230 <https://bugs.launchpad.net/nova/+bug/1960230>`_ that\n+    prevented resize of instances that had previously failed and not been\n+    cleaned up."
}
]
},
{
"commit_sha":"f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"commit_node_id":"C_kwDOAAwOD9oAKGY3ZmEzYmY1ZmNmYzM5ZjhhYzlkY2ZhMTI2NzQ3ZTM3NmQ4MDFlYjU",
"commit_html_url":"https://github.com/openstack/nova/commit/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"commit_date":"2022-02-08T22:56:47Z",
"files":[
{
"sha":"f55ef9b16513b6dff8d718f6a5214d2f61a14107",
"filename":"nova/compute/manager.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/compute/manager.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/compute/manager.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/manager.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -8046,7 +8046,7 @@ def check_can_live_migrate_destination(self, ctxt, instance,\n                 LOG.info('Destination was ready for NUMA live migration, '\n                          'but source is either too old, or is set to an '\n                          'older upgrade level.', instance=instance)\n-            if self.network_api.supports_port_binding_extension(ctxt):\n+            if self.network_api.has_port_binding_extension(ctxt):\n                 # Create migrate_data vifs if not provided by driver.\n                 if 'vifs' not in migrate_data:\n                     migrate_data.vifs = ("
},
{
"sha":"e04378f805c68e6a65e477d9e22881aba3f862c8",
"filename":"nova/conductor/tasks/cross_cell_migrate.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/conductor/tasks/cross_cell_migrate.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/conductor/tasks/cross_cell_migrate.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conductor/tasks/cross_cell_migrate.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -698,7 +698,7 @@ def _perform_external_api_checks(self):\n         LOG.debug('Making sure neutron is new enough for cross-cell resize.')\n         # Check that the port binding-extended API extension is available in\n         # neutron because if it's not we can just fail fast.\n-        if not self.network_api.supports_port_binding_extension(self.context):\n+        if not self.network_api.has_port_binding_extension(self.context):\n             raise exception.MigrationPreCheckError(\n                 reason=_(\"Required networking service API extension '%s' \"\n                          \"not found.\") %"
},
{
"sha":"1acae88b26454b34e64c8d344bf33c9b3186e362",
"filename":"nova/conductor/tasks/live_migrate.py",
"status":"modified",
"additions":2,
"deletions":3,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/conductor/tasks/live_migrate.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/conductor/tasks/live_migrate.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conductor/tasks/live_migrate.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -245,8 +245,7 @@ def _check_can_migrate_pci(self, src_host, dest_host):\n                             \"are not allowed for live migration.\")\n         # All PCI requests are VIF related, now check neutron,\n         # source and destination compute nodes.\n-        if not self.network_api.supports_port_binding_extension(\n-                self.context):\n+        if not self.network_api.has_port_binding_extension(self.context):\n             raise exception.MigrationPreCheckError(\n                 reason=\"Cannot live migrate VIF with related PCI, Neutron \"\n                        \"does not support required port binding extension.\")\n@@ -366,7 +365,7 @@ def _call_livem_checks_on_host(self, destination, provider_mapping):\n             raise exception.MigrationPreCheckError(msg)\n \n         # Check to see that neutron supports the binding-extended API.\n-        if self.network_api.supports_port_binding_extension(self.context):\n+        if self.network_api.has_port_binding_extension(self.context):\n             bindings = self._bind_ports_on_destination(\n                 destination, provider_mapping)\n             self._update_migrate_vifs_from_bindings(self.migrate_data.vifs,"
},
{
"sha":"eff49022c16a1b55f8316b025fa0d58c4b636535",
"filename":"nova/network/constants.py",
"status":"modified",
"additions":32,
"deletions":15,
"changes":47,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/network/constants.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/network/constants.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/constants.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -13,23 +13,40 @@\n #    License for the specific language governing permissions and limitations\n #    under the License.\n \n-QOS_QUEUE = 'QoS Queue'\n-NET_EXTERNAL = 'router:external'\n-VNIC_INDEX_EXT = 'VNIC Index'\n-DNS_INTEGRATION = 'DNS Integration'\n-MULTI_NET_EXT = 'Multi Provider Network'\n-FIP_PORT_DETAILS = 'Floating IP Port Details Extension'\n-SUBSTR_PORT_FILTERING = 'IP address substring filtering'\n-PORT_BINDING = 'Port Binding'\n-PORT_BINDING_EXTENDED = 'Port Bindings Extended'\n-DEFAULT_SECGROUP = 'default'\n+# Port fields\n+\n BINDING_PROFILE = 'binding:profile'\n BINDING_HOST_ID = 'binding:host_id'\n-MIGRATING_ATTR = 'migrating_to'\n-L3_NETWORK_TYPES = ['vxlan', 'gre', 'geneve']\n-ALLOCATION = 'allocation'\n RESOURCE_REQUEST = 'resource_request'\n REQUEST_GROUPS = 'request_groups'\n-SEGMENT = 'Segment'\n NUMA_POLICY = 'numa_affinity_policy'\n-RESOURCE_REQUEST_GROUPS_EXTENSION = \"Port Resource Request Groups\"\n+\n+# Binding profile fields\n+\n+MIGRATING_ATTR = 'migrating_to'\n+ALLOCATION = 'allocation'\n+\n+# Core extensions\n+\n+DNS_INTEGRATION = 'dns-integration'\n+MULTI_PROVIDER = 'multi-provider'\n+FIP_PORT_DETAILS = 'fip-port-details'\n+PORT_BINDING = 'binding'\n+PORT_BINDING_EXTENDED = 'binding-extended'\n+SUBSTR_PORT_FILTERING = 'ip-substring-filtering'\n+SEGMENT = 'segment'\n+RESOURCE_REQUEST_GROUPS = 'port-resource-request-groups'\n+\n+# Third-party extensions\n+\n+VNIC_INDEX = 'vnic-index'  # this is provided by the vmware_nsx project\n+QOS_QUEUE = 'qos-queue'  # TODO(stephenfin): what defines this? Xen?\n+\n+# Search fields\n+\n+NET_EXTERNAL = 'router:external'\n+\n+# Misc\n+\n+DEFAULT_SECGROUP = 'default'\n+L3_NETWORK_TYPES = ['vxlan', 'gre', 'geneve']"
},
{
"sha":"a3c7afdb7c600eff1b1da1e2ed0b3ba1b1d6b845",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":120,
"deletions":58,
"changes":178,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -382,7 +382,8 @@ def setup_networks_on_host(self, context, instance, host=None,\n                 # If a host was provided, delete any bindings between that\n                 # host and the ports as long as the host isn't the same as\n                 # the current instance.host.\n-                has_binding_ext = self.supports_port_binding_extension(context)\n+                has_binding_ext = self.has_port_binding_extension(\n+                    client=admin_client)\n                 if port_migrating and has_binding_ext:\n                     self._delete_port_bindings(context, ports, host)\n             elif port_migrating:\n@@ -676,8 +677,12 @@ def _unbind_ports(self, context, ports,\n             # NOTE: For internal DNS integration (network does not have a\n             # dns_domain), or if we cannot retrieve network info, we use the\n             # admin client to reset dns_name.\n-            if self._has_dns_extension() and not network.get('dns_domain'):\n+            if (\n+                self.has_dns_extension(client=port_client) and\n+                not network.get('dns_domain')\n+            ):\n                 port_req_body['port']['dns_name'] = ''\n+\n             try:\n                 port_client.update_port(port_id, port_req_body)\n             except neutron_client_exc.PortNotFoundClient:\n@@ -1334,62 +1339,112 @@ def _update_ports_for_instance(self, context, instance, neutron,\n         return (nets_in_requested_order, ports_in_requested_order,\n             preexisting_port_ids, created_port_ids)\n \n-    def _refresh_neutron_extensions_cache(self, context, neutron=None):\n+    def _refresh_neutron_extensions_cache(self, client):\n         \"\"\"Refresh the neutron extensions cache when necessary.\"\"\"\n         if (not self.last_neutron_extension_sync or\n             ((time.time() - self.last_neutron_extension_sync) >=\n              CONF.neutron.extension_sync_interval)):\n-            if neutron is None:\n-                neutron = get_client(context)\n-            extensions_list = neutron.list_extensions()['extensions']\n+            extensions_list = client.list_extensions()['extensions']\n             self.last_neutron_extension_sync = time.time()\n             self.extensions.clear()\n-            self.extensions = {ext['name']: ext for ext in extensions_list}\n+            self.extensions = {ext['alias']: ext for ext in extensions_list}\n+\n+    def _has_extension(self, extension, context=None, client=None):\n+        \"\"\"Check if the provided neutron extension is enabled.\n \n-    def _has_multi_provider_extension(self, context, neutron=None):\n-        self._refresh_neutron_extensions_cache(context, neutron=neutron)\n-        return constants.MULTI_NET_EXT in self.extensions\n+        :param extension: The alias of the extension to check\n+        :param client: keystoneauth1.adapter.Adapter\n+        :param context: nova.context.RequestContext\n+        :returns: True if the neutron extension is available, else False\n+        \"\"\"\n+        if client is None:\n+            client = get_client(context)\n \n-    def _has_dns_extension(self):\n-        return constants.DNS_INTEGRATION in self.extensions\n+        self._refresh_neutron_extensions_cache(client)\n+        return extension in self.extensions\n \n-    def _has_qos_queue_extension(self, context, neutron=None):\n-        self._refresh_neutron_extensions_cache(context, neutron=neutron)\n-        return constants.QOS_QUEUE in self.extensions\n+    def has_multi_provider_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'multi-provider' extension is enabled.\n \n-    def _has_fip_port_details_extension(self, context, neutron=None):\n-        self._refresh_neutron_extensions_cache(context, neutron=neutron)\n-        return constants.FIP_PORT_DETAILS in self.extensions\n+        This extension allows administrative users to define multiple physical\n+        bindings for a logical network.\n+        \"\"\"\n+        return self._has_extension(constants.MULTI_PROVIDER, context, client)\n \n-    def has_substr_port_filtering_extension(self, context):\n-        self._refresh_neutron_extensions_cache(context)\n-        return constants.SUBSTR_PORT_FILTERING in self.extensions\n+    def has_dns_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'dns-integration' extension is enabled.\n \n-    def _has_segment_extension(self, context, neutron=None):\n-        self._refresh_neutron_extensions_cache(context, neutron=neutron)\n-        return constants.SEGMENT in self.extensions\n+        This extension adds the 'dns_name' and 'dns_assignment' attributes to\n+        port resources.\n+        \"\"\"\n+        return self._has_extension(constants.DNS_INTEGRATION, context, client)\n \n     # TODO(gibi): Remove all branches where this is False after Neutron made\n     # the this extension mandatory. In Xena this extension will be optional to\n     # support the scenario where Neutron upgraded first. So Neutron can mark\n     # this mandatory earliest in Yoga.\n-    def has_extended_resource_request_extension(self, context, neutron=None):\n-        self._refresh_neutron_extensions_cache(context, neutron=neutron)\n-        return constants.RESOURCE_REQUEST_GROUPS_EXTENSION in self.extensions\n+    def has_extended_resource_request_extension(\n+        self, context=None, client=None,\n+    ):\n+        return self._has_extension(\n+            constants.RESOURCE_REQUEST_GROUPS, context, client,\n+        )\n+\n+    # TODO(stephenfin): This is optionally used by the XenAPI virt driver, but\n+    # I can't find what defines it and suspect it's dead code. Consider\n+    # removing the functionality\n+    def has_qos_queue_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'qos-queue' extension is enabled.\n \n-    def supports_port_binding_extension(self, context):\n-        \"\"\"This is a simple check to see if the neutron \"binding-extended\"\n-        extension exists and is enabled.\n+        This extension is provided by a XenServer neutron plugin...we think.\n+        \"\"\"\n+        return self._has_extension(constants.QOS_QUEUE, context, client)\n \n-        The \"binding-extended\" extension allows nova to bind a port to multiple\n-        hosts at the same time, like during live migration.\n+    def has_vnic_index_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'vnic-index' extension is enabled.\n \n-        :param context: the user request context\n-        :returns: True if the binding-extended API extension is available,\n-                  False otherwise\n+        This extension is provided by the VMWare NSX neutron plugin.\n+        \"\"\"\n+        return self._has_extension(constants.VNIC_INDEX, context, client)\n+\n+    def has_fip_port_details_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'fip-port-details' extension is enabled.\n+\n+        This extension adds the 'port_details' attribute to floating IPs.\n         \"\"\"\n-        self._refresh_neutron_extensions_cache(context)\n-        return constants.PORT_BINDING_EXTENDED in self.extensions\n+        return self._has_extension(constants.FIP_PORT_DETAILS, context, client)\n+\n+    def has_substr_port_filtering_extension(self, context=None, client=None):\n+        \"\"\"Check if the 'ip-substring-filtering' extension is enabled.\n+\n+        This extension adds support for filtering ports by using part of an IP\n+        address.\n+        \"\"\"\n+        return self._has_extension(\n+            constants.SUBSTR_PORT_FILTERING, context, client\n+        )\n+\n+    def has_segment_extension(self, context=None, client=None):\n+        \"\"\"Check if the neutron 'segment' extension is enabled.\n+\n+        This extension exposes information about L2 segments of a network.\n+        \"\"\"\n+        return self._has_extension(\n+            constants.SEGMENT, context, client,\n+        )\n+\n+    def has_port_binding_extension(self, context=None, client=None):\n+        \"\"\"Check if the neutron 'binding-extended' extension is enabled.\n+\n+        This extensions exposes port bindings of a virtual port to external\n+        application.\n+\n+        This extension allows nova to bind a port to multiple hosts at the same\n+        time, like during live migration.\n+        \"\"\"\n+        return self._has_extension(\n+            constants.PORT_BINDING_EXTENDED, context, client\n+        )\n \n     def bind_ports_to_host(self, context, instance, host,\n                            vnic_types=None, port_profiles=None):\n@@ -1403,7 +1458,7 @@ def bind_ports_to_host(self, context, instance, host,\n         In the event of an error, any ports which were successfully bound to\n         the host should have those host bindings removed from the ports.\n \n-        This method should not be used if \"supports_port_binding_extension\"\n+        This method should not be used if \"has_port_binding_extension\"\n         returns False.\n \n         :param context: the user request context\n@@ -1482,7 +1537,7 @@ def bind_ports_to_host(self, context, instance, host,\n     def delete_port_binding(self, context, port_id, host):\n         \"\"\"Delete the port binding for the given port ID and host\n \n-        This method should not be used if \"supports_port_binding_extension\"\n+        This method should not be used if \"has_port_binding_extension\"\n         returns False.\n \n         :param context: The request context for the operation.\n@@ -1602,7 +1657,10 @@ def _populate_neutron_extension_values(self, context, instance,\n \n         If the extensions loaded contain QOS_QUEUE then pass the rxtx_factor.\n         \"\"\"\n-        if self._has_qos_queue_extension(context, neutron=neutron):\n+        if neutron is None:\n+            neutron = get_client(context)\n+\n+        if self.has_qos_queue_extension(client=neutron):\n             flavor = instance.get_flavor()\n             rxtx_factor = flavor.get('rxtx_factor')\n             port_req_body['port']['rxtx_factor'] = rxtx_factor\n@@ -1612,7 +1670,7 @@ def _populate_neutron_extension_values(self, context, instance,\n                                                port_req_body,\n                                                port_arq)\n \n-        if self._has_dns_extension():\n+        if self.has_dns_extension(client=neutron):\n             # If the DNS integration extension is enabled in Neutron, most\n             # ports will get their dns_name attribute set in the port create or\n             # update requests in allocate_for_instance. So we just add the\n@@ -1638,7 +1696,8 @@ def _update_port_dns_name(self, context, instance, network, port_id,\n         an additional update request. Only a very small fraction of ports will\n         require this additional update request.\n         \"\"\"\n-        if self._has_dns_extension() and network.get('dns_domain'):\n+        if self.has_dns_extension(client=neutron) and network.get(\n+                'dns_domain'):\n             try:\n                 port_req_body = {'port': {'dns_name': instance.hostname}}\n                 neutron.update_port(port_id, port_req_body)\n@@ -1650,7 +1709,7 @@ def _update_port_dns_name(self, context, instance, network, port_id,\n                          'name') % {'hostname': instance.hostname})\n                 raise exception.InvalidInput(reason=msg)\n \n-    def _reset_port_dns_name(self, network, port_id, neutron_client):\n+    def _reset_port_dns_name(self, network, port_id, client):\n         \"\"\"Reset an instance port dns_name attribute to empty when using\n         external DNS service.\n \n@@ -1660,10 +1719,11 @@ def _reset_port_dns_name(self, network, port_id, neutron_client):\n         request with a Neutron client using user's context, so that the DNS\n         record can be found under user's zone and domain.\n         \"\"\"\n-        if self._has_dns_extension() and network.get('dns_domain'):\n+        if self.has_dns_extension(client=client) and network.get(\n+                'dns_domain'):\n             try:\n                 port_req_body = {'port': {'dns_name': ''}}\n-                neutron_client.update_port(port_id, port_req_body)\n+                client.update_port(port_id, port_req_body)\n             except neutron_client_exc.NeutronClientException:\n                 LOG.exception(\"Failed to reset dns_name for port %s\", port_id)\n \n@@ -2037,7 +2097,7 @@ def _get_physnet_tunneled_info(self, context, neutron, net_id):\n             segments, the first segment that defines a physnet value will be\n             used for the physnet name.\n         \"\"\"\n-        if self._has_multi_provider_extension(context, neutron=neutron):\n+        if self.has_multi_provider_extension(client=neutron):\n             network = neutron.show_network(net_id,\n                                            fields='segments').get('network')\n             segments = network.get('segments', {})\n@@ -2712,7 +2772,7 @@ def get_floating_ip(self, context, id):\n         # ...and retrieve the port details for the same reason, but only if\n         # they're not already there because the fip-port-details extension is\n         # present\n-        if not self._has_fip_port_details_extension(context, client):\n+        if not self.has_fip_port_details_extension(client=client):\n             port_id = fip['port_id']\n             try:\n                 fip['port_details'] = client.show_port(\n@@ -2740,7 +2800,7 @@ def get_floating_ip_by_address(self, context, address):\n         # ...and retrieve the port details for the same reason, but only if\n         # they're not already there because the fip-port-details extension is\n         # present\n-        if not self._has_fip_port_details_extension(context, client):\n+        if not self.has_fip_port_details_extension(client=client):\n             port_id = fip['port_id']\n             try:\n                 fip['port_details'] = client.show_port(\n@@ -2779,7 +2839,7 @@ def get_floating_ips_by_project(self, context):\n         # ...and retrieve the port details for the same reason, but only if\n         # they're not already there because the fip-port-details extension is\n         # present\n-        if not self._has_fip_port_details_extension(context, client):\n+        if not self.has_fip_port_details_extension(client=client):\n             ports = {port['id']: port for port in client.list_ports(\n                 **{'tenant_id': project_id})['ports']}\n             for fip in fips:\n@@ -2975,7 +3035,7 @@ def migrate_instance_start(self, context, instance, migration):\n         :raises: nova.exception.PortBindingActivationFailed if any port binding\n             activation fails\n         \"\"\"\n-        if not self.supports_port_binding_extension(context):\n+        if not self.has_port_binding_extension(context):\n             # If neutron isn't new enough yet for the port \"binding-extended\"\n             # API extension, we just no-op. The port binding host will be\n             # be updated in migrate_instance_finish, which is functionally OK,\n@@ -3501,7 +3561,8 @@ def cleanup_instance_network_on_host(self, context, instance, host):\n         :raises: PortBindingDeletionFailed if port binding deletion fails.\n         \"\"\"\n         # First check to see if the port binding extension is supported.\n-        if not self.supports_port_binding_extension(context):\n+        client = get_client(context)\n+        if not self.has_port_binding_extension(client=client):\n             LOG.info(\"Neutron extension '%s' is not supported; not cleaning \"\n                      \"up port bindings for host %s.\",\n                      constants.PORT_BINDING_EXTENDED, host, instance=instance)\n@@ -3692,9 +3753,8 @@ def update_instance_vnic_index(self, context, instance, vif, index):\n         :param vif: The VIF in question.\n         :param index: The index on the instance for the VIF.\n         \"\"\"\n-        self._refresh_neutron_extensions_cache(context)\n-        if constants.VNIC_INDEX_EXT in self.extensions:\n-            neutron = get_client(context)\n+        neutron = get_client(context)\n+        if self.has_vnic_index_extension(client=neutron):\n             port_req_body = {'port': {'vnic_index': index}}\n             try:\n                 neutron.update_port(vif['id'], port_req_body)\n@@ -3717,10 +3777,11 @@ def get_segment_ids_for_network(\n             either Segment extension isn't enabled in Neutron or if the network\n             isn't configured for routing.\n         \"\"\"\n-        if not self._has_segment_extension(context):\n+        client = get_client(context)\n+\n+        if not self.has_segment_extension(client=client):\n             return []\n \n-        client = get_client(context)\n         try:\n             # NOTE(sbauza): We can't use list_segments() directly because the\n             # API is borked and returns both segments but also segmentation IDs\n@@ -3747,10 +3808,11 @@ def get_segment_id_for_subnet(\n             extension isn't enabled in Neutron or the provided subnet doesn't\n             have segments (if the related network isn't configured for routing)\n         \"\"\"\n-        if not self._has_segment_extension(context):\n+        client = get_client(context)\n+\n+        if not self.has_segment_extension(client=client):\n             return None\n \n-        client = get_client(context)\n         try:\n             subnet = client.show_subnet(subnet_id)['subnet']\n         except neutron_client_exc.NeutronClientException as e:"
},
{
"sha":"e582ad3e8519167e6267042dcb87afec6a7793e2",
"filename":"nova/tests/functional/regressions/test_bug_1888395.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/functional/regressions/test_bug_1888395.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/functional/regressions/test_bug_1888395.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/regressions/test_bug_1888395.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -108,7 +108,7 @@ def test_live_migrate(self):\n             networks=[{'port': self.neutron.port_1['id']}])\n \n         self.assertFalse(\n-            self.neutron_api.supports_port_binding_extension(self.ctxt))\n+            self.neutron_api.has_port_binding_extension(self.ctxt))\n         # TODO(sean-k-mooney): extend _live_migrate to support passing a host\n         self.api.post_server_action(\n             server['id'],"
},
{
"sha":"1fb39ac98a8b807500128cc67e42bc73643b64df",
"filename":"nova/tests/functional/test_servers_resource_request.py",
"status":"modified",
"additions":3,
"deletions":2,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/functional/test_servers_resource_request.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/functional/test_servers_resource_request.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_servers_resource_request.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -146,12 +146,13 @@ def list_extensions(self, *args, **kwargs):\n             # port_resource_request_groups.py\n             {\n                 \"updated\": \"2021-08-02T10:00:00-00:00\",\n-                \"name\": constants.RESOURCE_REQUEST_GROUPS_EXTENSION,\n+                \"name\": \"Port Resource Request Groups\",\n                 \"links\": [],\n                 \"alias\": \"port-resource-request-groups\",\n-                \"description\":\n+                \"description\": (\n                     \"Support requesting multiple groups of resources and \"\n                     \"traits from the same RP subtree in resource_request\"\n+                ),\n             }\n         )\n         return extensions"
},
{
"sha":"1d877e0900ec6e7a6b4afe3fbb2fff5bc93026dc",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":3,
"deletions":4,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -6066,10 +6066,9 @@ def stupid(*args, **kwargs):\n             return fake_network.fake_get_instance_nw_info(self)\n \n         self.stub_out('nova.network.neutron.API.get_instance_nw_info', stupid)\n-        self.useFixture(\n-            std_fixtures.MonkeyPatch(\n-                'nova.network.neutron.API.supports_port_binding_extension',\n-                lambda *args: True))\n+        self.useFixture(std_fixtures.MonkeyPatch(\n+            'nova.network.neutron.API.has_port_binding_extension',\n+            lambda *args: True))\n         # creating instance testdata\n         instance = self._create_fake_instance_obj({'host': 'dummy'})\n         c = context.get_admin_context()"
},
{
"sha":"836755b4e68d368f9dbcbd5b655b71feb45fac3c",
"filename":"nova/tests/unit/compute/test_compute_mgr.py",
"status":"modified",
"additions":6,
"deletions":6,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/compute/test_compute_mgr.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/compute/test_compute_mgr.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute_mgr.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -3460,15 +3460,15 @@ def _test_check_can_live_migrate_destination(self, do_raise=False,\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_success(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: True))\n         self._test_check_can_live_migrate_destination()\n \n     @mock.patch('nova.objects.InstanceGroup.get_by_instance_uuid', mock.Mock(\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_fail(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: True))\n         self.assertRaises(\n             test.TestingException,\n@@ -3479,7 +3479,7 @@ def test_check_can_live_migrate_destination_fail(self):\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_contains_vifs(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: True))\n         migrate_data = self._test_check_can_live_migrate_destination()\n         self.assertIn('vifs', migrate_data)\n@@ -3489,7 +3489,7 @@ def test_check_can_live_migrate_destination_contains_vifs(self):\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_no_binding_extended(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: False))\n         migrate_data = self._test_check_can_live_migrate_destination()\n         self.assertNotIn('vifs', migrate_data)\n@@ -3498,15 +3498,15 @@ def test_check_can_live_migrate_destination_no_binding_extended(self):\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_src_numa_lm_false(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: True))\n         self._test_check_can_live_migrate_destination(src_numa_lm=False)\n \n     @mock.patch('nova.objects.InstanceGroup.get_by_instance_uuid', mock.Mock(\n         side_effect=exception.InstanceGroupNotFound(group_uuid='')))\n     def test_check_can_live_migrate_destination_src_numa_lm_true(self):\n         self.useFixture(std_fixtures.MonkeyPatch(\n-            'nova.network.neutron.API.supports_port_binding_extension',\n+            'nova.network.neutron.API.has_port_binding_extension',\n             lambda *args: True))\n         self._test_check_can_live_migrate_destination(src_numa_lm=True)\n "
},
{
"sha":"ec07e6f55fae3dacab6516cf1f313956f1c04199",
"filename":"nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/conductor/tasks/test_cross_cell_migrate.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -439,15 +439,15 @@ def test_perform_external_api_checks_ok(self):\n         what we need.\n         \"\"\"\n         with mock.patch.object(\n-                self.task.network_api, 'supports_port_binding_extension',\n+                self.task.network_api, 'has_port_binding_extension',\n                 return_value=True) as mock_neutron_check:\n             self.task._perform_external_api_checks()\n         mock_neutron_check.assert_called_once_with(self.task.context)\n \n     def test_perform_external_api_checks_old_neutron(self):\n         \"\"\"Tests the case that neutron API is old.\"\"\"\n         with mock.patch.object(\n-                self.task.network_api, 'supports_port_binding_extension',\n+                self.task.network_api, 'has_port_binding_extension',\n                 return_value=False):\n             ex = self.assertRaises(exception.MigrationPreCheckError,\n                                    self.task._perform_external_api_checks)"
},
{
"sha":"cb40c076c82dfb03299960f65a9165359924b261",
"filename":"nova/tests/unit/conductor/tasks/test_live_migrate.py",
"status":"modified",
"additions":3,
"deletions":3,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/conductor/tasks/test_live_migrate.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/conductor/tasks/test_live_migrate.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/conductor/tasks/test_live_migrate.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -353,7 +353,7 @@ def test_check_requested_destination(self, mock_check):\n \n         with test.nested(\n             mock.patch.object(self.task.network_api,\n-                              'supports_port_binding_extension',\n+                              'has_port_binding_extension',\n                               return_value=False),\n             mock.patch.object(self.task, '_check_can_migrate_pci')):\n             self.assertIsNone(self.task._check_requested_destination())\n@@ -387,7 +387,7 @@ def test_check_requested_destination_fails_different_cells(\n \n         with test.nested(\n             mock.patch.object(self.task.network_api,\n-                              'supports_port_binding_extension',\n+                              'has_port_binding_extension',\n                               return_value=False),\n             mock.patch.object(self.task, '_check_can_migrate_pci')):\n             ex = self.assertRaises(exception.MigrationPreCheckError,\n@@ -813,7 +813,7 @@ def test_check_can_migrate_pci(self):\n         \"\"\"\n \n         @mock.patch.object(self.task.network_api,\n-                           'supports_port_binding_extension')\n+                           'has_port_binding_extension')\n         @mock.patch.object(live_migrate,\n                            'supports_vif_related_pci_allocations')\n         def _test(instance_pci_reqs,"
},
{
"sha":"433966ae1a27a4456e21272edad1683efcbb009e",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":107,
"deletions":61,
"changes":168,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -515,7 +515,11 @@ def _test_allocate_for_instance(self, mock_get_client, mock_get_nw,\n         has_dns_extension = False\n         if kwargs.get('dns_extension'):\n             has_dns_extension = True\n-            self.api.extensions[constants.DNS_INTEGRATION] = 1\n+            self.api.extensions = {\n+                constants.DNS_INTEGRATION: {\n+                    'alias': constants.DNS_INTEGRATION,\n+                },\n+            }\n \n         # Net idx is 1-based for compatibility with existing unit tests\n         nets = self.nets[net_idx - 1]\n@@ -1167,17 +1171,14 @@ def test_get_instance_nw_info_without_subnet(\n         mock_get_physnet.assert_called_once_with(\n             mock.ANY, mock.ANY, self.port_data1[0]['network_id'])\n \n-    @mock.patch.object(neutronapi, 'get_client')\n-    def test_refresh_neutron_extensions_cache(self, mock_get_client):\n+    def test_refresh_neutron_extensions_cache(self):\n         mocked_client = mock.create_autospec(client.Client)\n-        mock_get_client.return_value = mocked_client\n         mocked_client.list_extensions.return_value = {\n-            'extensions': [{'name': constants.QOS_QUEUE}]}\n-        self.api._refresh_neutron_extensions_cache(self.context)\n+            'extensions': [{'alias': constants.QOS_QUEUE}]}\n+        self.api._refresh_neutron_extensions_cache(mocked_client)\n         self.assertEqual(\n-            {constants.QOS_QUEUE: {'name': constants.QOS_QUEUE}},\n+            {constants.QOS_QUEUE: {'alias': constants.QOS_QUEUE}},\n             self.api.extensions)\n-        mock_get_client.assert_called_once_with(self.context)\n         mocked_client.list_extensions.assert_called_once_with()\n \n     @mock.patch.object(neutronapi, 'get_client')\n@@ -1186,7 +1187,7 @@ def test_populate_neutron_extension_values_rxtx_factor(\n         mocked_client = mock.create_autospec(client.Client)\n         mock_get_client.return_value = mocked_client\n         mocked_client.list_extensions.return_value = {\n-            'extensions': [{'name': constants.QOS_QUEUE}]}\n+            'extensions': [{'alias': constants.QOS_QUEUE}]}\n         flavor = objects.Flavor.get_by_name(self.context, 'm1.small')\n         flavor['rxtx_factor'] = 1\n         instance = objects.Instance(system_metadata={})\n@@ -2415,9 +2416,13 @@ def _test_get_floating_ip(\n             mock_nc.show_port.side_effect = exceptions.PortNotFoundClient\n \n         if fip_ext_enabled:\n-            self.api.extensions = [constants.FIP_PORT_DETAILS]\n+            self.api.extensions = {\n+                constants.FIP_PORT_DETAILS: {\n+                    'alias': constants.FIP_PORT_DETAILS,\n+                },\n+            }\n         else:\n-            self.api.extensions = []\n+            self.api.extensions = {}\n \n         fip = self.api.get_floating_ip(self.context, uuids.fip_id)\n \n@@ -2490,9 +2495,13 @@ def _test_get_floating_ip_by_address(\n             mock_nc.show_port.side_effect = exceptions.PortNotFoundClient\n \n         if fip_ext_enabled:\n-            self.api.extensions = [constants.FIP_PORT_DETAILS]\n+            self.api.extensions = {\n+                constants.FIP_PORT_DETAILS: {\n+                    'alias': constants.FIP_PORT_DETAILS,\n+                },\n+            }\n         else:\n-            self.api.extensions = []\n+            self.api.extensions = {}\n \n         fip = self.api.get_floating_ip_by_address(self.context, '172.1.2.3')\n \n@@ -3474,7 +3483,7 @@ def test_get_physnet_tunneled_info_multi_segment(self, mock_get_client):\n                                       'provider:network_type': 'vxlan'}]}}\n         test_ext_list = {'extensions':\n                             [{'name': 'Multi Provider Network',\n-                             'alias': 'multi-segments'}]}\n+                             'alias': 'multi-provider'}]}\n \n         mock_client = mock_get_client.return_value\n         mock_client.list_extensions.return_value = test_ext_list\n@@ -3495,7 +3504,7 @@ def test_get_physnet_tunneled_info_vlan_with_multi_segment_ext(\n                                 'provider:network_type': 'vlan'}}\n         test_ext_list = {'extensions':\n                             [{'name': 'Multi Provider Network',\n-                             'alias': 'multi-segments'}]}\n+                             'alias': 'multi-provider'}]}\n \n         mock_client = mock_get_client.return_value\n         mock_client.list_extensions.return_value = test_ext_list\n@@ -3521,7 +3530,7 @@ def test_get_physnet_tunneled_info_multi_segment_no_physnet(\n                                       'provider:network_type': 'vlan'}]}}\n         test_ext_list = {'extensions':\n                             [{'name': 'Multi Provider Network',\n-                             'alias': 'multi-segments'}]}\n+                             'alias': 'multi-provider'}]}\n \n         mock_client = mock_get_client.return_value\n         mock_client.list_extensions.return_value = test_ext_list\n@@ -4357,7 +4366,7 @@ def test_get_all_networks(self):\n     def test_update_instance_vnic_index(self, mock_get_client,\n                                         mock_refresh_extensions):\n         api = neutronapi.API()\n-        api.extensions = set([constants.VNIC_INDEX_EXT])\n+        api.extensions = set([constants.VNIC_INDEX])\n         mock_client = mock_get_client.return_value\n         mock_client.update_port.return_value = 'port'\n \n@@ -4382,7 +4391,7 @@ def test_update_port_bindings_for_instance_with_migration_profile(\n         self, get_client_mock\n     ):\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n \n         # We pass in a port profile which has a migration attribute and also\n         # a second port profile attribute 'fake_profile' this can be\n@@ -4426,7 +4435,7 @@ def test_update_port_bindings_for_instance_binding_profile_none(\n         value is None.\n         \"\"\"\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n \n         fake_ports = {'ports': [\n                         {'id': uuids.portid,\n@@ -4602,7 +4611,7 @@ def test_update_port_bindings_for_instance_with_pci_fail(self,\n     def test_update_port_bindings_for_instance_with_pci_no_migration(self,\n                                             get_client_mock,\n                                             get_pci_device_devspec_mock):\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n \n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n@@ -4652,7 +4661,7 @@ def test_update_port_bindings_for_instance_with_pci_no_migration(self,\n     def test_update_port_bindings_for_instance_with_same_host_failed_vif_type(\n         self, get_client_mock):\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         list_ports_mock = mock.Mock()\n         update_port_mock = mock.Mock()\n \n@@ -4697,7 +4706,7 @@ def test_update_port_bindings_for_instance_with_same_host_failed_vif_type(\n     def test_update_port_bindings_for_instance_with_diff_host_unbound_vif_type(\n         self, get_client_mock):\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n \n         binding_profile = {'fake_profile': 'fake_data',\n                            constants.MIGRATING_ATTR: 'my-dest-host'}\n@@ -4987,7 +4996,7 @@ def test_update_port_profile_for_migration_teardown_false(\n         self, get_client_mock):\n \n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         # We test with an instance host and destination_host where the\n         # port will be moving.\n         get_ports = {'ports': [\n@@ -5017,7 +5026,7 @@ def test_update_port_profile_for_migration_teardown_false_none_profile(\n         destination host and the binding:profile is None in the port.\n         \"\"\"\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         # We test with an instance host and destination_host where the\n         # port will be moving but with binding:profile set to None.\n         get_ports = {\n@@ -5048,7 +5057,7 @@ def test__setup_migration_port_profile_called_on_teardown_false(\n         self, get_client_mock):\n \n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         port_id = uuids.port_id\n         get_ports = {'ports': [\n                         {'id': port_id,\n@@ -5068,7 +5077,7 @@ def test__setup_migration_port_profile_not_called_with_host_match(\n         self, get_client_mock):\n \n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         get_ports = {'ports': [\n                         {'id': uuids.port_id,\n                          constants.BINDING_HOST_ID: instance.host}]}\n@@ -5104,7 +5113,7 @@ def test_update_port_profile_for_migration_teardown_true_with_profile(\n         self, get_client_mock):\n \n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         migrate_profile = {\n             constants.MIGRATING_ATTR: 'new-host'}\n         # Pass a port with an migration porfile attribute.\n@@ -5116,8 +5125,9 @@ def test_update_port_profile_for_migration_teardown_true_with_profile(\n         self.api.list_ports = mock.Mock(return_value=get_ports)\n         mocked_client = get_client_mock.return_value\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             self.api.setup_networks_on_host(self.context,\n                                             instance,\n                                             host='new-host',\n@@ -5135,7 +5145,7 @@ def test_update_port_profile_for_migration_teardown_true_with_profile_exc(\n         which is raised through to the caller.\n         \"\"\"\n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         migrate_profile = {\n             constants.MIGRATING_ATTR: 'new-host'}\n         # Pass a port with an migration porfile attribute.\n@@ -5153,8 +5163,9 @@ def test_update_port_profile_for_migration_teardown_true_with_profile_exc(\n         mocked_client = get_client_mock.return_value\n         mocked_client.delete_port_binding.side_effect = NeutronError\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             ex = self.assertRaises(\n                 exception.PortBindingDeletionFailed,\n                 self.api.setup_networks_on_host,\n@@ -5176,15 +5187,15 @@ def test_update_port_profile_for_migration_teardown_true_no_profile(\n         self, get_client_mock):\n \n         instance = fake_instance.fake_instance_obj(self.context)\n-        self.api._has_port_binding_extension = mock.Mock(return_value=True)\n+        self.api.has_port_binding_extension = mock.Mock(return_value=True)\n         # Pass a port without any migration porfile attribute.\n         get_ports = {'ports': [\n                         {'id': uuids.port_id,\n                          constants.BINDING_HOST_ID: instance.host}]}\n         self.api.list_ports = mock.Mock(return_value=get_ports)\n         update_port_mock = mock.Mock()\n         get_client_mock.return_value.update_port = update_port_mock\n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n+        with mock.patch.object(self.api, 'has_port_binding_extension',\n                                return_value=False):\n             self.api.setup_networks_on_host(self.context,\n                                             instance,\n@@ -5242,6 +5253,8 @@ def test_unbind_ports_get_client_binding_extension(self,\n     def test_unbind_ports_get_client(self, mock_neutron):\n         self._test_unbind_ports_get_client(mock_neutron)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port')\n     def _test_unbind_ports(self, mock_neutron, mock_show):\n         mock_client = mock.Mock()\n@@ -5284,7 +5297,11 @@ def test_unbind_ports_no_port_ids(self):\n \n     @mock.patch(\n         'nova.network.neutron.API.has_extended_resource_request_extension',\n-        new=mock.Mock()\n+        new=mock.Mock(return_value=True),\n+    )\n+    @mock.patch(\n+        'nova.network.neutron.API.has_dns_extension',\n+        new=mock.Mock(return_value=True),\n     )\n     @mock.patch('nova.network.neutron.API.get_instance_nw_info')\n     @mock.patch('nova.network.neutron.excutils')\n@@ -5827,9 +5844,13 @@ def _test_get_floating_ips_by_project(\n             mock_nc.list_ports.return_value = {'ports': []}\n \n         if fip_ext_enabled:\n-            self.api.extensions = [constants.FIP_PORT_DETAILS]\n+            self.api.extensions = {\n+                constants.FIP_PORT_DETAILS: {\n+                    'alias': constants.FIP_PORT_DETAILS,\n+                },\n+            }\n         else:\n-            self.api.extensions = []\n+            self.api.extensions = {}\n \n         fips = self.api.get_floating_ips_by_project(self.context)\n \n@@ -5862,6 +5883,8 @@ def test_get_floating_ips_by_project_without_ports(self):\n         \"\"\"Make sure we don't fail for floating IPs without attached ports.\"\"\"\n         self._test_get_floating_ips_by_project(False, False)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=True))\n     @mock.patch('nova.network.neutron.API._show_port')\n     def test_unbind_ports_reset_dns_name_by_admin(self, mock_show):\n         neutron = mock.Mock()\n@@ -5872,7 +5895,6 @@ def test_unbind_ports_reset_dns_name_by_admin(self, mock_show):\n             }\n         }\n         port_client = mock.Mock()\n-        self.api.extensions = [constants.DNS_INTEGRATION]\n         ports = [uuids.port_id]\n         mock_show.return_value = {'id': uuids.port}\n         self.api._unbind_ports(self.context, ports, neutron, port_client)\n@@ -5885,6 +5907,8 @@ def test_unbind_ports_reset_dns_name_by_admin(self, mock_show):\n             uuids.port_id, port_req_body)\n         neutron.update_port.assert_not_called()\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=True))\n     @mock.patch('nova.network.neutron.API._show_port')\n     def test_unbind_ports_reset_dns_name_by_non_admin(self, mock_show):\n         neutron = mock.Mock()\n@@ -5895,7 +5919,6 @@ def test_unbind_ports_reset_dns_name_by_non_admin(self, mock_show):\n             }\n         }\n         port_client = mock.Mock()\n-        self.api.extensions = [constants.DNS_INTEGRATION]\n         ports = [uuids.port_id]\n         mock_show.return_value = {'id': uuids.port}\n         self.api._unbind_ports(self.context, ports, neutron, port_client)\n@@ -5909,6 +5932,8 @@ def test_unbind_ports_reset_dns_name_by_non_admin(self, mock_show):\n         neutron.update_port.assert_called_once_with(\n             uuids.port_id, non_admin_port_req_body)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port')\n     def test_unbind_ports_reset_allocation_in_port_binding(self, mock_show):\n         neutron = mock.Mock()\n@@ -5924,6 +5949,8 @@ def test_unbind_ports_reset_allocation_in_port_binding(self, mock_show):\n         port_client.update_port.assert_called_once_with(\n             uuids.port_id, port_req_body)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port')\n     def test_unbind_ports_reset_binding_profile(self, mock_show):\n         neutron = mock.Mock()\n@@ -5947,6 +5974,8 @@ def test_unbind_ports_reset_binding_profile(self, mock_show):\n         port_client.update_port.assert_called_once_with(\n             uuids.port_id, port_req_body)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._populate_neutron_extension_values')\n     @mock.patch('nova.network.neutron.API._update_port',\n                 # called twice, fails on the 2nd call and triggers the cleanup\n@@ -6028,6 +6057,8 @@ def test_unbind_ports_port_show_portnotfound(self, mock_log, mock_show):\n             neutron_client=mock.ANY)\n         mock_log.assert_not_called()\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port',\n                 side_effect=Exception)\n     @mock.patch.object(neutronapi.LOG, 'exception')\n@@ -6045,6 +6076,8 @@ def test_unbind_ports_port_show_unexpected_error(self,\n                 'binding:profile': {}, 'binding:host_id': None}})\n         self.assertTrue(mock_log.called)\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port')\n     @mock.patch.object(neutronapi.LOG, 'exception')\n     def test_unbind_ports_portnotfound(self, mock_log, mock_show):\n@@ -6061,6 +6094,8 @@ def test_unbind_ports_portnotfound(self, mock_log, mock_show):\n                 'binding:profile': {}, 'binding:host_id': None}})\n         mock_log.assert_not_called()\n \n+    @mock.patch('nova.network.neutron.API.has_dns_extension',\n+                new=mock.Mock(return_value=False))\n     @mock.patch('nova.network.neutron.API._show_port')\n     @mock.patch.object(neutronapi.LOG, 'exception')\n     def test_unbind_ports_unexpected_error(self, mock_log, mock_show):\n@@ -6676,7 +6711,7 @@ def test_migrate_instance_start_no_binding_ext(self, get_client_mock):\n         \"\"\"Tests that migrate_instance_start exits early if neutron doesn't\n         have the binding-extended API extension.\n         \"\"\"\n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n+        with mock.patch.object(self.api, 'has_port_binding_extension',\n                                return_value=False):\n             self.api.migrate_instance_start(\n                 self.context, mock.sentinel.instance, {})\n@@ -6696,8 +6731,9 @@ def test_migrate_instance_start_activate(self, get_client_mock):\n         migration = objects.Migration(\n             source_compute='source', dest_compute='dest')\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             self.api.migrate_instance_start(\n                 self.context, instance, migration)\n \n@@ -6721,8 +6757,9 @@ def test_migrate_instance_start_already_active(self, get_client_mock):\n         migration = objects.Migration(\n             source_compute='source', dest_compute='dest')\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             self.api.migrate_instance_start(\n                 self.context, instance, migration)\n \n@@ -6748,8 +6785,9 @@ def test_migrate_instance_start_no_bindings(self, get_client_mock):\n         migration = objects.Migration(\n             source_compute='source', dest_compute='dest')\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             self.api.migrate_instance_start(\n                 self.context, instance, migration)\n \n@@ -6772,8 +6810,9 @@ def test_migrate_instance_start_get_error(self, get_client_mock):\n         migration = objects.Migration(\n             source_compute='source', dest_compute='dest')\n \n-        with mock.patch.object(self.api, 'supports_port_binding_extension',\n-                               return_value=True):\n+        with mock.patch.object(\n+            self.api, 'has_port_binding_extension', return_value=True,\n+        ):\n             self.api.migrate_instance_start(\n                 self.context, instance, migration)\n \n@@ -6952,7 +6991,7 @@ def test_get_requested_resource_for_instance_with_multiple_ports_extended(\n \n     def test_get_segment_ids_for_network_no_segment_ext(self):\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=False\n+            self.api, 'has_segment_extension', return_value=False,\n         ):\n             self.assertEqual(\n                 [], self.api.get_segment_ids_for_network(self.context,\n@@ -6965,7 +7004,7 @@ def test_get_segment_ids_for_network_passes(self, mock_client):\n         mock_client.return_value = mocked_client\n         mocked_client.list_subnets.return_value = subnets\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             res = self.api.get_segment_ids_for_network(\n                 self.context, uuids.network_id)\n@@ -6980,7 +7019,7 @@ def test_get_segment_ids_for_network_with_no_segments(self, mock_client):\n         mock_client.return_value = mocked_client\n         mocked_client.list_subnets.return_value = subnets\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             res = self.api.get_segment_ids_for_network(\n                 self.context, uuids.network_id)\n@@ -6995,15 +7034,15 @@ def test_get_segment_ids_for_network_fails(self, mock_client):\n         mocked_client.list_subnets.side_effect = (\n             exceptions.NeutronClientException(status_code=404))\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             self.assertRaises(exception.InvalidRoutedNetworkConfiguration,\n                               self.api.get_segment_ids_for_network,\n                               self.context, uuids.network_id)\n \n     def test_get_segment_id_for_subnet_no_segment_ext(self):\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=False\n+            self.api, 'has_segment_extension', return_value=False,\n         ):\n             self.assertIsNone(\n                 self.api.get_segment_id_for_subnet(self.context,\n@@ -7016,7 +7055,7 @@ def test_get_segment_id_for_subnet_passes(self, mock_client):\n         mock_client.return_value = mocked_client\n         mocked_client.show_subnet.return_value = subnet\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             res = self.api.get_segment_id_for_subnet(\n                 self.context, uuids.subnet_id)\n@@ -7030,7 +7069,7 @@ def test_get_segment_id_for_subnet_with_no_segment(self, mock_client):\n         mock_client.return_value = mocked_client\n         mocked_client.show_subnet.return_value = subnet\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             self.assertIsNone(\n                 self.api.get_segment_id_for_subnet(self.context,\n@@ -7043,7 +7082,7 @@ def test_get_segment_id_for_subnet_fails(self, mock_client):\n         mocked_client.show_subnet.side_effect = (\n             exceptions.NeutronClientException(status_code=404))\n         with mock.patch.object(\n-            self.api, '_has_segment_extension', return_value=True\n+            self.api, 'has_segment_extension', return_value=True,\n         ):\n             self.assertRaises(exception.InvalidRoutedNetworkConfiguration,\n                               self.api.get_segment_id_for_subnet,\n@@ -7251,9 +7290,9 @@ def setUp(self):\n         self.addCleanup(patcher.stop)\n         self.mock_client = patcher.start().return_value\n         self.extension = {\n-            \"extensions\": [\n+            'extensions': [\n                 {\n-                    \"name\": constants.RESOURCE_REQUEST_GROUPS_EXTENSION,\n+                    'alias': constants.RESOURCE_REQUEST_GROUPS,\n                 }\n             ]\n         }\n@@ -7901,6 +7940,9 @@ def fake_delete(port_id, host):\n                 self.api.delete_port_binding(self.context, port_id,\n                                              'fake-host')\n \n+    @mock.patch(\n+        'nova.network.neutron.API.has_dns_extension',\n+        new=mock.Mock(return_value=False))\n     @mock.patch('nova.accelerator.cyborg._CyborgClient.delete_arqs_by_uuid')\n     @mock.patch('nova.network.neutron.get_binding_profile')\n     @mock.patch('nova.network.neutron.API._show_port')\n@@ -8290,7 +8332,7 @@ def test_update_ports_for_instance_with_portbinding(self, mock_create):\n         requested_ports_dict = {uuids.port1: {}, uuids.port2: {}}\n \n         mock_neutron.list_extensions.return_value = {\"extensions\": [\n-            {\"name\": \"asdf\"}]}\n+            {\"alias\": \"asdf\"}]}\n         port1 = {\"port\": {\"id\": uuids.port1, \"mac_address\": \"mac1r\"}}\n         port2 = {\"port\": {\"id\": uuids.port2, \"mac_address\": \"mac2r\"}}\n         mock_admin.update_port.side_effect = [port1, port2]\n@@ -8372,6 +8414,10 @@ def test_allocate_for_instance_with_requested_port(self):\n             bind_host_id=self.instance.get('host'),\n             requested_networks=requested_networks)\n \n+    @mock.patch(\n+        'nova.network.neutron.API.has_dns_extension',\n+        new=mock.Mock(return_value=True),\n+    )\n     @mock.patch(\n         'nova.network.neutron.API.has_extended_resource_request_extension',\n         new=mock.Mock(return_value=False)\n@@ -8385,8 +8431,8 @@ def test_allocate_for_instance_create_port_with_dns_domain(self):\n             11, dns_extension=True, bind_host_id=self.instance.get('host'))\n \n     @mock.patch(\n-        \"nova.network.neutron.API._has_dns_extension\",\n-        new=mock.Mock(return_value=True)\n+        'nova.network.neutron.API.has_dns_extension',\n+        new=mock.Mock(return_value=True),\n     )\n     def test_allocate_for_instance_with_requested_port_with_dns_domain(self):\n         # The port's dns_name attribute should be set by the port update"
},
{
"sha":"d1e362fef51d446b6ed0ca41455d8a813897b7cd",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":11,
"deletions":11,
"changes":22,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -10606,7 +10606,7 @@ def _check_xml_and_uri(self, instance, mock_serial,\n             self.assertEqual(drvr._uri(), testuri)\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n         '_create_shared_storage_test_file')\n@@ -10645,7 +10645,7 @@ def test_check_can_live_migrate_dest_all_pass_with_block_migration(\n                          return_value.obj_to_primitive()['nova_object.data'])\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n         '_create_shared_storage_test_file')\n@@ -10685,7 +10685,7 @@ def test_check_can_live_migrate_dest_all_pass_with_over_commit(\n                          return_value.obj_to_primitive()['nova_object.data'])\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n         '_create_shared_storage_test_file')\n@@ -10722,7 +10722,7 @@ def test_check_can_live_migrate_dest_all_pass_no_block_migration(\n                          return_value.obj_to_primitive()['nova_object.data'])\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n                        '_create_shared_storage_test_file',\n@@ -10754,7 +10754,7 @@ def test_check_can_live_migrate_dest_fills_listen_addrs(\n                          str(result.serial_listen_addr))\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n                        '_create_shared_storage_test_file',\n@@ -10775,7 +10775,7 @@ def test_check_can_live_migrate_dest_ensure_serial_adds_not_set(\n         self.assertIsNone(result.serial_listen_addr)\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n                        '_create_shared_storage_test_file',\n@@ -10808,7 +10808,7 @@ def test_check_can_live_migrate_guest_cpu_none_model(\n                          result.obj_to_primitive()['nova_object.data'])\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n                        '_create_shared_storage_test_file',\n@@ -10827,7 +10827,7 @@ def test_check_can_live_migrate_dest_numa_lm(\n         self.assertTrue(result.dst_supports_numa_live_migration)\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n                        '_create_shared_storage_test_file',\n@@ -10844,7 +10844,7 @@ def test_check_can_live_migrate_dest_numa_lm_no_instance_numa(\n         self.assertNotIn('dst_supports_numa_live_migration', result)\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n         '_create_shared_storage_test_file')\n@@ -10885,7 +10885,7 @@ def test_check_can_live_migrate_dest_no_instance_cpu_info(\n                          return_value.obj_to_primitive()['nova_object.data'])\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=False))\n     @mock.patch.object(libvirt_driver.LibvirtDriver,\n         '_create_shared_storage_test_file')\n@@ -10930,7 +10930,7 @@ def test_check_can_live_migrate_dest_incompatible_cpu_raises(\n                           compute_info, compute_info, False)\n \n     @mock.patch(\n-        'nova.network.neutron.API.supports_port_binding_extension',\n+        'nova.network.neutron.API.has_port_binding_extension',\n         new=mock.Mock(return_value=True))\n     @mock.patch.object(\n         libvirt_driver.LibvirtDriver,"
},
{
"sha":"97b9f87aabbee9f3cf95670f019c061180088540",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=f7fa3bf5fcfc39f8ac9dcfa126747e376d801eb5",
"patch":"@@ -9161,7 +9161,7 @@ def check_can_live_migrate_destination(self, context, instance,\n         # populate it if we are using multiple port bindings.\n         # TODO(stephenfin): Remove once we can do this unconditionally in X or\n         # later\n-        if self._network_api.supports_port_binding_extension(context):\n+        if self._network_api.has_port_binding_extension(context):\n             data.vifs = (\n                 migrate_data_obj.VIFMigrateData.create_skeleton_migrate_vifs(\n                     instance.get_network_info()))"
}
]
},
{
"commit_sha":"0620678344d0f032a33e952d4d0fa653741f09e7",
"commit_node_id":"C_kwDOAAwOD9oAKDA2MjA2NzgzNDRkMGYwMzJhMzNlOTUyZDRkMGZhNjUzNzQxZjA5ZTc",
"commit_html_url":"https://github.com/openstack/nova/commit/0620678344d0f032a33e952d4d0fa653741f09e7",
"commit_date":"2022-01-16T20:27:38Z",
"files":[
{
"sha":"34edf30cb680f560be574038a86d65ecb7206397",
"filename":"nova/api/openstack/compute/attach_interfaces.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/api/openstack/compute/attach_interfaces.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/api/openstack/compute/attach_interfaces.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/attach_interfaces.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -178,6 +178,7 @@ def create(self, req, server_id, body):\n                 exception.InterfaceAttachPciClaimFailed,\n                 exception.InterfaceAttachResourceAllocationFailed,\n                 exception.ForbiddenPortsWithAccelerator,\n+                exception.ForbiddenWithRemoteManagedPorts,\n                 exception.ExtendedResourceRequestOldCompute,\n                 ) as e:\n             raise exc.HTTPBadRequest(explanation=e.format_message())"
},
{
"sha":"1bfb3db698e5a36a3b31266777adda207b023983",
"filename":"nova/api/openstack/compute/servers.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/api/openstack/compute/servers.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/api/openstack/compute/servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/servers.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -862,6 +862,7 @@ def create(self, req, body):\n                 exception.DeviceProfileError,\n                 exception.ComputeHostNotFound,\n                 exception.ForbiddenPortsWithAccelerator,\n+                exception.ForbiddenWithRemoteManagedPorts,\n                 exception.ExtendedResourceRequestOldCompute,\n                 ) as error:\n             raise exc.HTTPBadRequest(explanation=error.format_message())"
},
{
"sha":"20c7ee7959175c16d2b35047c4fdbb825a01410a",
"filename":"nova/compute/api.py",
"status":"modified",
"additions":23,
"deletions":0,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/compute/api.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/compute/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/api.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -115,6 +115,8 @@\n MIN_COMPUTE_MOVE_WITH_EXTENDED_RESOURCE_REQUEST = 59\n MIN_COMPUTE_INT_ATTACH_WITH_EXTENDED_RES_REQ = 60\n \n+SUPPORT_VNIC_TYPE_REMOTE_MANAGED = 61\n+\n # FIXME(danms): Keep a global cache of the cells we find the\n # first time we look. This needs to be refreshed on a timer or\n # trigger.\n@@ -1017,6 +1019,22 @@ def _check_support_vnic_accelerator(self, context, requested_networks):\n                             \" until upgrade finished.\")\n                         raise exception.ForbiddenPortsWithAccelerator(msg)\n \n+    def _check_vnic_remote_managed_min_version(self, context):\n+        min_version = (objects.service.get_minimum_version_all_cells(\n+            context, ['nova-compute']))\n+        if min_version < SUPPORT_VNIC_TYPE_REMOTE_MANAGED:\n+            msg = (\"Remote-managed ports are not supported\"\n+                   \" until an upgrade is fully finished.\")\n+            raise exception.ForbiddenWithRemoteManagedPorts(msg)\n+\n+    def _check_support_vnic_remote_managed(self, context, requested_networks):\n+        if requested_networks:\n+            for request_net in requested_networks:\n+                if (request_net.port_id and\n+                        self.network_api.is_remote_managed_port(\n+                            context, request_net.port_id)):\n+                    self._check_vnic_remote_managed_min_version(context)\n+\n     def _validate_and_build_base_options(\n         self, context, flavor, boot_meta, image_href, image_id, kernel_id,\n         ramdisk_id, display_name, display_description, hostname, key_name,\n@@ -1087,6 +1105,7 @@ def _validate_and_build_base_options(\n         network_metadata, port_resource_requests, req_lvl_params = result\n \n         self._check_support_vnic_accelerator(context, requested_networks)\n+        self._check_support_vnic_remote_managed(context, requested_networks)\n \n         # Creating servers with ports that have resource requests, like QoS\n         # minimum bandwidth rules, is only supported in a requested minimum\n@@ -5161,6 +5180,10 @@ def attach_interface(self, context, instance, network_id, port_id,\n                 network_model.VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL):\n                 raise exception.ForbiddenPortsWithAccelerator()\n \n+            if port.get('binding:vnic_type',\n+                        'normal') == network_model.VNIC_TYPE_REMOTE_MANAGED:\n+                self._check_vnic_remote_managed_min_version(context)\n+\n             self.ensure_compute_version_for_resource_request(\n                 context, instance, port)\n "
},
{
"sha":"bbfbb73215df2c68c76c3fd81611a360fcb5131e",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -313,6 +313,7 @@\n                         \"vdpa\",\n                         \"accelerator-direct\",\n                         \"accelerator-direct-physical\",\n+                        \"remote-managed\",\n                     ]),\n                 default=[],\n                 help=\"\"\"\n@@ -336,6 +337,7 @@\n * vdpa\n * accelerator-direct\n * accelerator-direct-physical\n+* remote-managed\n \n Adding a ``vnic_type`` to this configuration makes Nova wait for a\n network-vif-plugged event for each of the instance's vifs having the specific"
},
{
"sha":"e898ab3786e5f44c64a105badd517dd5c9fdc957",
"filename":"nova/exception.py",
"status":"modified",
"additions":5,
"deletions":0,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -175,6 +175,11 @@ class ForbiddenPortsWithAccelerator(NotSupported):\n     msg_fmt = _(\"Feature not supported with Ports that have accelerators.\")\n \n \n+class ForbiddenWithRemoteManagedPorts(NotSupported):\n+    msg_fmt = _(\"This feature is not supported when remote-managed ports\"\n+                \" are in use.\")\n+\n+\n class AdminRequired(Forbidden):\n     msg_fmt = _(\"User does not have admin privileges\")\n "
},
{
"sha":"a33b212c2a47e8db443677ee0f36ee5d1e4621d8",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -2315,7 +2315,13 @@ def create_resource_requests(\n                 # libvirt to expose the nic feature. At the moment\n                 # there is a limitation that deployers cannot use both\n                 # SR-IOV modes (legacy and ovs) in the same deployment.\n-                spec = {pci_request.PCI_NET_TAG: physnet}\n+                spec = {\n+                    pci_request.PCI_NET_TAG: physnet,\n+                    # Convert the value to string since tags are compared as\n+                    # string values case-insensitively.\n+                    pci_request.PCI_REMOTE_MANAGED_TAG:\n+                    str(self._is_remote_managed(vnic_type)),\n+                }\n                 dev_type = pci_request.DEVICE_TYPE_FOR_VNIC_TYPE.get(vnic_type)\n                 if dev_type:\n                     spec[pci_request.PCI_DEVICE_TYPE_TAG] = dev_type"
},
{
"sha":"21d6f66b79210343df9011a5ffabe6aa9d278f2b",
"filename":"nova/network/os_vif_util.py",
"status":"modified",
"additions":9,
"deletions":0,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/network/os_vif_util.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/network/os_vif_util.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/os_vif_util.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -338,6 +338,15 @@ def _nova_to_osvif_vif_ovs(vif):\n             port_profile=_get_ovs_representor_port_profile(vif),\n             plugin=\"ovs\")\n         _set_representor_datapath_offload_settings(vif, obj)\n+    elif vnic_type == model.VNIC_TYPE_REMOTE_MANAGED:\n+        # A networking backend is responsible for setting up a\n+        # representor in this case so the driver is noop.\n+        obj = _get_vif_instance(\n+            vif, objects.vif.VIFHostDevice,\n+            plugin=\"noop\",\n+            vif_name=vif_name,\n+            dev_address=vif[\"profile\"][\"pci_slot\"],\n+            dev_type=objects.fields.VIFHostDeviceDevType.ETHERNET)\n     elif vif.is_hybrid_plug_enabled():\n         obj = _get_vif_instance(\n             vif,"
},
{
"sha":"7d34204b0e54c36fd9bfa88707bb076d79f2ee35",
"filename":"nova/objects/service.py",
"status":"modified",
"additions":4,
"deletions":1,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/objects/service.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/objects/service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/service.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -31,7 +31,7 @@\n \n \n # NOTE(danms): This is the global service version counter\n-SERVICE_VERSION = 60\n+SERVICE_VERSION = 61\n \n \n # NOTE(danms): This is our SERVICE_VERSION history. The idea is that any\n@@ -213,6 +213,9 @@\n     # Add support for interface attach operation with neutron extended resource\n     # request\n     {'compute_rpc': '6.0'},\n+    # Version 61: Compute RPC v6.0:\n+    # Add support for remotely-managed ports (vnic-type 'remote-managed')\n+    {'compute_rpc': '6.0'},\n )\n \n # This is used to raise an error at service startup if older than N-1 computes"
},
{
"sha":"0932b07ce404eced709f5785c188fc27158e899f",
"filename":"nova/tests/unit/compute/test_api.py",
"status":"modified",
"additions":35,
"deletions":0,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/compute/test_api.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/compute/test_api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_api.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -206,6 +206,10 @@ def _obj_to_list_obj(self, list_obj, obj):\n         list_obj.obj_reset_changes()\n         return list_obj\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     @mock.patch('nova.objects.Quotas.check_deltas')\n     @mock.patch('nova.conductor.conductor_api.ComputeTaskAPI.build_instances')\n     @mock.patch('nova.compute.api.API._record_action_start')\n@@ -7243,6 +7247,37 @@ def test_check_support_vnic_accelerator_version_after_57(self, mock_get):\n             requested_networks)\n         mock_get.assert_called_once_with(self.context, ['nova-compute'])\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=True),\n+    )\n+    @mock.patch('nova.objects.service.get_minimum_version_all_cells',\n+                return_value=60)\n+    def test_check_support_vnic_remote_managed_version_before_61(\n+            self, mock_get):\n+        requested_networks = objects.NetworkRequestList(\n+            objects=[objects.NetworkRequest(port_id=uuids.port)])\n+        self.assertRaisesRegex(exception.ForbiddenWithRemoteManagedPorts,\n+            'Remote-managed ports are not supported until an upgrade is fully'\n+            ' finished.',\n+            self.compute_api._check_support_vnic_remote_managed,\n+            self.context,\n+            requested_networks)\n+        mock_get.assert_called_once_with(self.context, ['nova-compute'])\n+\n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=True),\n+    )\n+    @mock.patch('nova.objects.service.get_minimum_version_all_cells',\n+                return_value=61)\n+    def test_check_support_vnic_remote_managed_version_61(self, mock_get):\n+        requested_networks = objects.NetworkRequestList(\n+            objects=[objects.NetworkRequest(port_id=uuids.port)])\n+        self.compute_api._check_support_vnic_remote_managed(self.context,\n+            requested_networks)\n+        mock_get.assert_called_once_with(self.context, ['nova-compute'])\n+\n     def test_validate_and_build_base_options_translate_neutron_secgroup(self):\n         \"\"\"Tests that _check_requested_secgroups will return a uuid for a\n         requested Neutron security group and that will be returned from"
},
{
"sha":"cd0556e9a5e4ae863c898b14af1899c03ba983eb",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -8692,6 +8692,10 @@ def test_create_instance_with_invalid_security_group_raises(self):\n                          len(db.instance_get_all(self.context)))\n         mock_secgroups.assert_called_once_with(mock.ANY, 'invalid_sec_group')\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     def test_create_instance_associates_requested_networks(self):\n         # Make sure create adds the requested networks to the RequestSpec\n \n@@ -9827,6 +9831,10 @@ def test_multi_instance_display_name(self):\n             self.assertEqual(refs[i]['display_name'], name)\n             self.assertEqual(refs[i]['hostname'], name)\n \n+    @mock.patch(\n+        'nova.network.neutron.API.is_remote_managed_port',\n+        new=mock.Mock(return_value=False),\n+    )\n     @mock.patch(\"nova.objects.service.get_minimum_version_all_cells\")\n     @mock.patch(\n         \"nova.network.neutron.API.has_extended_resource_request_extension\")"
},
{
"sha":"7c44729105fe0b0455d3b66756d9d22863471902",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":22,
"deletions":5,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -6162,7 +6162,8 @@ def test_create_resource_requests(\n                 objects.NetworkRequest(port_id=uuids.portid_4),\n                 objects.NetworkRequest(port_id=uuids.portid_5),\n                 objects.NetworkRequest(port_id=uuids.trusted_port),\n-                objects.NetworkRequest(port_id=uuids.portid_vdpa)])\n+                objects.NetworkRequest(port_id=uuids.portid_vdpa),\n+                objects.NetworkRequest(port_id=uuids.portid_remote_managed)])\n         pci_requests = objects.InstancePCIRequests(requests=[])\n         # _get_port_vnic_info should be called for every NetworkRequest with a\n         # port_id attribute (so six times)\n@@ -6176,13 +6177,14 @@ def test_create_resource_requests(\n             (model.VNIC_TYPE_DIRECT, True, 'netN',\n              mock.sentinel.resource_request2, None, None),\n             (model.VNIC_TYPE_VDPA, None, 'netN', None, None, None),\n+            (model.VNIC_TYPE_REMOTE_MANAGED, None, 'netN', None, None, None),\n         ]\n         # _get_physnet_tunneled_info should be called for every NetworkRequest\n         # (so seven times)\n         mock_get_physnet_tunneled_info.side_effect = [\n             ('physnet1', False), ('physnet1', False), ('', True),\n             ('physnet1', False), ('physnet2', False), ('physnet3', False),\n-            ('physnet4', False), ('physnet1', False)\n+            ('physnet4', False), ('physnet1', False), ('physnet1', False),\n         ]\n         api = neutronapi.API()\n \n@@ -6199,13 +6201,16 @@ def test_create_resource_requests(\n                 mock.sentinel.request_group1,\n                 mock.sentinel.request_group2],\n             port_resource_requests)\n-        self.assertEqual(6, len(pci_requests.requests))\n+        self.assertEqual(7, len(pci_requests.requests))\n         has_pci_request_id = [net.pci_request_id is not None for net in\n                               requested_networks.objects]\n         self.assertEqual(pci_requests.requests[3].spec[0][\"dev_type\"],\n                          \"type-PF\")\n         self.assertEqual(pci_requests.requests[5].spec[0][\"dev_type\"], \"vdpa\")\n-        expected_results = [True, False, False, True, True, True, True, True]\n+        self.assertEqual(pci_requests.requests[6].spec[0][\"remote_managed\"],\n+                         'True')\n+        expected_results = [True, False, False, True, True, True, True, True,\n+                            True]\n         self.assertEqual(expected_results, has_pci_request_id)\n         # Make sure only the trusted VF has the 'trusted' tag set in the spec.\n         for pci_req in pci_requests.requests:\n@@ -6217,11 +6222,23 @@ def test_create_resource_requests(\n             else:\n                 self.assertNotIn(pci_request.PCI_TRUSTED_TAG, spec)\n \n+        # Only remote-managed ports must have the remote_managed tag set\n+        # to True.\n+        for pci_req in pci_requests.requests:\n+            spec = pci_req.spec[0]\n+            if pci_req.requester_id == uuids.portid_remote_managed:\n+                self.assertEqual('True',\n+                                 spec[pci_request.PCI_REMOTE_MANAGED_TAG])\n+            else:\n+                self.assertEqual('False',\n+                                 spec[pci_request.PCI_REMOTE_MANAGED_TAG])\n+\n         # Only SRIOV ports and those with a resource_request will have\n         # pci_req.requester_id.\n         self.assertEqual(\n             [uuids.portid_1, uuids.portid_3, uuids.portid_4, uuids.portid_5,\n-             uuids.trusted_port, uuids.portid_vdpa],\n+             uuids.trusted_port, uuids.portid_vdpa,\n+             uuids.portid_remote_managed],\n             [pci_req.requester_id for pci_req in pci_requests.requests])\n \n         self.assertCountEqual("
},
{
"sha":"338492aef0d24c08277351c33d8db630366d295d",
"filename":"nova/tests/unit/network/test_os_vif_util.py",
"status":"modified",
"additions":33,
"deletions":0,
"changes":33,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/network/test_os_vif_util.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/network/test_os_vif_util.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_os_vif_util.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -696,6 +696,39 @@ def test_nova_to_osvif_ovs_with_vnic_direct(self):\n \n         self.assertObjEqual(expect, actual)\n \n+    def test_nova_to_osvif_ovs_with_vnic_remote_managed(self):\n+        vif = model.VIF(\n+            id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\",\n+            type=model.VIF_TYPE_OVS,\n+            address=\"22:52:25:62:e2:aa\",\n+            vnic_type=model.VNIC_TYPE_REMOTE_MANAGED,\n+            network=model.Network(\n+                id=\"b82c1929-051e-481d-8110-4669916c7915\",\n+                label=\"Demo Net\",\n+                subnets=[]),\n+            profile={'pci_slot': '0000:0a:00.1'}\n+        )\n+\n+        actual = os_vif_util.nova_to_osvif_vif(vif)\n+\n+        expect = osv_objects.vif.VIFHostDevice(\n+            id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\",\n+            active=False,\n+            address=\"22:52:25:62:e2:aa\",\n+            dev_address='0000:0a:00.1',\n+            dev_type=os_vif_fields.VIFHostDeviceDevType.ETHERNET,\n+            plugin=\"noop\",\n+            has_traffic_filtering=False,\n+            preserve_on_delete=False,\n+            network=osv_objects.network.Network(\n+                id=\"b82c1929-051e-481d-8110-4669916c7915\",\n+                bridge_interface=None,\n+                label=\"Demo Net\",\n+                subnets=osv_objects.subnet.SubnetList(\n+                    objects=[])))\n+\n+        self.assertObjEqual(expect, actual)\n+\n     def test_nova_to_osvif_ovs_with_vnic_vdpa(self):\n         vif = model.VIF(\n             id=\"dc065497-3c8d-4f44-8fb4-e1d33c16a536\","
},
{
"sha":"a31abc70ae12d6abc138f6f91f6f22acad1bb96c",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":21,
"deletions":2,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -19214,8 +19214,10 @@ def fake_prepare(instance, name, tag):\n \n         instance = objects.Instance(**self.test_instance)\n         instance.vm_state = vm_states.BUILDING\n-        vifs = [{'id': uuids.vif_1, 'active': False},\n-                {'id': uuids.vif_2, 'active': False}]\n+        vifs = [\n+            network_model.VIF(id=uuids.vif_1, active=False),\n+            network_model.VIF(id=uuids.vif_2, active=False)\n+        ]\n \n         @mock.patch.object(drvr, 'plug_vifs')\n         @mock.patch.object(drvr, '_create_guest')\n@@ -19412,6 +19414,23 @@ def test_get_neutron_events(self):\n         events = drvr._get_neutron_events(network_info)\n         self.assertEqual([('network-vif-plugged', '1')], events)\n \n+    def test_get_neutron_events_remote_managed(self):\n+        drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)\n+        network_info = [\n+            network_model.VIF(\n+                id=uuids.vif_1,\n+                vnic_type=network_model.VNIC_TYPE_REMOTE_MANAGED),\n+            network_model.VIF(\n+                id=uuids.vif_2,\n+                vnic_type=network_model.VNIC_TYPE_REMOTE_MANAGED,\n+                active=True),\n+        ]\n+        events = drvr._get_neutron_events(network_info)\n+        # For VNIC_TYPE_REMOTE_MANAGED events are only bind-time currently.\n+        # Until this changes, they need to be filtered out to avoid waiting\n+        # for them unnecessarily.\n+        self.assertEqual([], events)\n+\n     def test_unplug_vifs_ignores_errors(self):\n         drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI())\n         with mock.patch.object(drvr, 'vif_driver') as vif_driver:"
},
{
"sha":"246308a79f50f45ebca473ee1c15c1355849632b",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":2,
"deletions":1,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -7232,7 +7232,8 @@ def _get_neutron_events(self, network_info):\n         # anything that might be stale (cache-wise) assume it's\n         # already up so we don't block on it.\n         return [('network-vif-plugged', vif['id'])\n-                for vif in network_info if vif.get('active', True) is False]\n+                for vif in network_info if vif.get('active', True) is False and\n+                vif['vnic_type'] != network_model.VNIC_TYPE_REMOTE_MANAGED]\n \n     def _create_guest_with_network(\n         self,"
},
{
"sha":"826729f378d9849dfe045cd7c0d17d64d7771f6f",
"filename":"releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"status":"added",
"additions":27,
"deletions":0,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/0620678344d0f032a33e952d4d0fa653741f09e7/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"raw_url":"https://github.com/openstack/nova/raw/0620678344d0f032a33e952d4d0fa653741f09e7/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/vnic-type-remote-managed-b90cacf1c91df22b.yaml?ref=0620678344d0f032a33e952d4d0fa653741f09e7",
"patch":"@@ -0,0 +1,27 @@\n+---\n+features:\n+  - |\n+    Added support for off-path networking backends where devices exposed to the\n+    hypervisor host are managed remotely (which is the case, for example, with\n+    various SmartNIC DPU devices). ``VNIC_TYPE_REMOTE_MANAGED`` ports can now\n+    be added to Nova instances as soon as all compute nodes are upgraded to\n+    the new compute service version. In order to use this feature, VF PCI/PCIe\n+    devices need to be tagged as ``remote_managed: \"true\"` in the Nova config\n+    in the ``passthrough_whitelist`` option.\n+\n+    This feature relies on Neutron being upgraded to the corresponding release\n+    of OpenStack and having an appropriate backend capable of binding\n+    ``VNIC_TYPE_REMOTE_MANAGED`` ports (at the time of writing, ML2 with the OVN\n+    ML2 mechanism driver is the only supported backend, see the Neutron\n+    documentation for more details).\n+\n+    Note that the PCI devices (VFs or, alternatively, their PF) must have a\n+    valid PCI Vital Product Data (VPD) with a serial number present in it for\n+    this feature to work properly. Also note that only VFs can be tagged as\n+    ``remote_managed: \"true\"`` and they cannot be used for legacy SR-IOV\n+    use-cases.\n+\n+    Nova operations on instances with ``VNIC_TYPE_REMOTE_MANAGED`` ports\n+    follow the same logic as the operations on direct SR-IOV ports.\n+\n+    This feature is only supported with the Libvirt driver."
}
]
},
{
"commit_sha":"c487c730d010013f8579622337af63d93b733f3b",
"commit_node_id":"C_kwDOAAwOD9oAKGM0ODdjNzMwZDAxMDAxM2Y4NTc5NjIyMzM3YWY2M2Q5M2I3MzNmM2I",
"commit_html_url":"https://github.com/openstack/nova/commit/c487c730d010013f8579622337af63d93b733f3b",
"commit_date":"2022-02-04T09:50:28Z",
"files":[
{
"sha":"e92874c7f9a54c1e301a3081260e09db80bbd35e",
"filename":"nova/compute/resource_tracker.py",
"status":"modified",
"additions":27,
"deletions":1,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/compute/resource_tracker.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/compute/resource_tracker.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/resource_tracker.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -1126,6 +1126,28 @@ def _sync_compute_service_disabled_trait(self, context, traits):\n             LOG.error('Unable to find services table record for nova-compute '\n                       'host %s', self.host)\n \n+    def _should_expose_remote_managed_ports_trait(self,\n+                                                  is_supported: bool):\n+        \"\"\"Determine whether COMPUTE_REMOTE_MANAGED_PORTS should be exposed.\n+\n+        Determines if the COMPUTE_REMOTE_MANAGED_PORTS trait needs to be\n+        exposed based on the respective compute driver capability and\n+        the presence of remote managed devices on a given host. Whether such\n+        devices are present or not depends on the Whitelist configuration\n+        (presence of a remote_managed tag association with some PCI devices)\n+        and their physical presence (plugged in, enumerated by the OS).\n+\n+        The aim of having this check is to optimize host lookup by prefiltering\n+        hosts that have compute driver support but no hardware. The check\n+        does not consider free device count - just the presence of device\n+        pools since device availability may change between a prefilter check\n+        and a later check in PciPassthroughFilter.\n+\n+        :param bool is_supported: Is the trait supported by the compute driver\n+        \"\"\"\n+        return (is_supported and\n+            self.pci_tracker.pci_stats.has_remote_managed_device_pools())\n+\n     def _get_traits(self, context, nodename, provider_tree):\n         \"\"\"Synchronizes internal and external traits for the node provider.\n \n@@ -1149,7 +1171,11 @@ def _get_traits(self, context, nodename, provider_tree):\n         # traits that are missing, and remove any existing set traits\n         # that are not currently supported.\n         for trait, supported in self.driver.capabilities_as_traits().items():\n-            if supported:\n+            add_trait = supported\n+            if trait == os_traits.COMPUTE_REMOTE_MANAGED_PORTS:\n+                add_trait &= self._should_expose_remote_managed_ports_trait(\n+                    supported)\n+            if add_trait:\n                 traits.add(trait)\n             elif trait in traits:\n                 traits.remove(trait)"
},
{
"sha":"5bd70837db55d48ac16468ef44a42dc64206fe03",
"filename":"nova/network/model.py",
"status":"modified",
"additions":4,
"deletions":2,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/network/model.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/network/model.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/model.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -106,6 +106,7 @@\n VNIC_TYPE_VDPA = 'vdpa'\n VNIC_TYPE_ACCELERATOR_DIRECT = 'accelerator-direct'\n VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL = 'accelerator-direct-physical'\n+VNIC_TYPE_REMOTE_MANAGED = \"remote-managed\"\n \n # Define list of ports which needs pci request.\n # Note: The macvtap port needs a PCI request as it is a tap interface\n@@ -121,14 +122,15 @@\n # selected compute node.\n VNIC_TYPES_SRIOV = (\n     VNIC_TYPE_DIRECT, VNIC_TYPE_MACVTAP, VNIC_TYPE_DIRECT_PHYSICAL,\n-    VNIC_TYPE_VIRTIO_FORWARDER, VNIC_TYPE_VDPA)\n+    VNIC_TYPE_VIRTIO_FORWARDER, VNIC_TYPE_VDPA, VNIC_TYPE_REMOTE_MANAGED)\n \n # Define list of ports which are passthrough to the guest\n # and need a special treatment on snapshot and suspend/resume\n VNIC_TYPES_DIRECT_PASSTHROUGH = (VNIC_TYPE_DIRECT,\n                                  VNIC_TYPE_DIRECT_PHYSICAL,\n                                  VNIC_TYPE_ACCELERATOR_DIRECT,\n-                                 VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL)\n+                                 VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL,\n+                                 VNIC_TYPE_REMOTE_MANAGED)\n \n # Define list of ports which contains devices managed by cyborg.\n VNIC_TYPES_ACCELERATOR = ("
},
{
"sha":"1bdafcfc1590e06e28e9faca84a517c6de2eebd0",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":21,
"deletions":0,
"changes":21,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -2123,6 +2123,27 @@ def _get_trusted_mode_from_port(port):\n             # the port binding profile and we can handle it as a boolean.\n             return strutils.bool_from_string(value)\n \n+    @staticmethod\n+    def _is_remote_managed(vnic_type):\n+        \"\"\"Determine if the port is remote_managed or not by VNIC type.\n+\n+        :param str vnic_type: The VNIC type to assess.\n+        :return: A boolean indicator whether the NIC is remote managed or not.\n+        :rtype: bool\n+        \"\"\"\n+        return vnic_type == network_model.VNIC_TYPE_REMOTE_MANAGED\n+\n+    def is_remote_managed_port(self, context, port_id):\n+        \"\"\"Determine if a port has a REMOTE_MANAGED VNIC type.\n+\n+        :param context: The request context\n+        :param port_id: The id of the Neutron port\n+        \"\"\"\n+        port = self.show_port(context, port_id)['port']\n+        return self._is_remote_managed(\n+            port.get('binding:vnic_type', network_model.VNIC_TYPE_NORMAL)\n+        )\n+\n     # NOTE(sean-k-mooney): we might want to have this return a\n     # nova.network.model.VIF object instead in the future.\n     def _get_port_vnic_info(self, context, neutron, port_id):"
},
{
"sha":"c8dda84d4bfbdca32a1ef05a87a9febbc62f427a",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":13,
"deletions":0,
"changes":13,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -729,3 +729,16 @@ def to_device_pools_obj(self) -> 'objects.PciDevicePoolList':\n         \"\"\"Return the contents of the pools as a PciDevicePoolList object.\"\"\"\n         stats = [x for x in self]\n         return pci_device_pool.from_pci_stats(stats)\n+\n+    def has_remote_managed_device_pools(self) -> bool:\n+        \"\"\"Determine whether remote managed device pools are present on a host.\n+\n+        The check is pool-based, not free device-based and is NUMA cell\n+        agnostic.\n+        \"\"\"\n+        dummy_req = objects.InstancePCIRequest(\n+            count=0,\n+            spec=[{'remote_managed': True}]\n+        )\n+        pools = self._filter_pools_for_spec(self.pools, dummy_req)\n+        return bool(pools)"
},
{
"sha":"be1455df888566a3409ee91570ea709bbf08dcb1",
"filename":"nova/scheduler/request_filter.py",
"status":"modified",
"additions":28,
"deletions":0,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/scheduler/request_filter.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/scheduler/request_filter.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/scheduler/request_filter.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -365,6 +365,33 @@ def routed_networks_filter(\n     return True\n \n \n+@trace_request_filter\n+def remote_managed_ports_filter(\n+    context: nova_context.RequestContext,\n+    request_spec: 'objects.RequestSpec',\n+) -> bool:\n+    \"\"\"Filter out hosts without remote managed port support (driver or hw).\n+\n+    If a request spec contains VNIC_TYPE_REMOTE_MANAGED ports then a\n+    remote-managed port trait (COMPUTE_REMOTE_MANAGED_PORTS) is added to\n+    the request in order to pre-filter hosts that do not use compute\n+    drivers supporting remote managed ports and the ones that do not have\n+    the device pools providing remote-managed ports (actual device\n+    availability besides a pool presence check is done at the time of\n+    PciPassthroughFilter execution).\n+    \"\"\"\n+    if request_spec.requested_networks:\n+        network_api = neutron.API()\n+        for request_net in request_spec.requested_networks:\n+            if request_net.port_id and network_api.is_remote_managed_port(\n+                context, request_net.port_id):\n+                request_spec.root_required.add(\n+                    os_traits.COMPUTE_REMOTE_MANAGED_PORTS)\n+                LOG.debug('remote_managed_ports_filter request filter added '\n+                          f'trait {os_traits.COMPUTE_REMOTE_MANAGED_PORTS}')\n+    return True\n+\n+\n ALL_REQUEST_FILTERS = [\n     require_tenant_aggregate,\n     map_az_to_placement_aggregate,\n@@ -374,6 +401,7 @@ def routed_networks_filter(\n     transform_image_metadata,\n     accelerators_filter,\n     routed_networks_filter,\n+    remote_managed_ports_filter,\n ]\n \n "
},
{
"sha":"0eff6c6bda06315328aa0b6799e9c356d5cc63ab",
"filename":"nova/tests/functional/test_servers_provider_tree.py",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/tests/functional/test_servers_provider_tree.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/tests/functional/test_servers_provider_tree.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_servers_provider_tree.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -45,7 +45,6 @@ class ProviderTreeTests(integrated_helpers.ProviderUsageBaseTestCase):\n             os_traits.COMPUTE_VOLUME_EXTEND,\n             os_traits.COMPUTE_VOLUME_MULTI_ATTACH,\n             os_traits.COMPUTE_TRUSTED_CERTS,\n-            os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n         ]\n     ])\n "
},
{
"sha":"36236d58dedea41461838d046d2c9e61e82c94de",
"filename":"nova/tests/unit/compute/test_resource_tracker.py",
"status":"modified",
"additions":14,
"deletions":1,
"changes":15,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/tests/unit/compute/test_resource_tracker.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/tests/unit/compute/test_resource_tracker.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_resource_tracker.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -1577,16 +1577,29 @@ def test_existing_compute_node_updated_new_resources(self, save_mock):\n         self.rt._update(mock.sentinel.ctx, new_compute)\n         save_mock.assert_called_once_with()\n \n+    @mock.patch(\n+        'nova.pci.stats.PciDeviceStats.has_remote_managed_device_pools',\n+        return_value=True)\n     @mock.patch('nova.compute.resource_tracker.ResourceTracker.'\n                 '_sync_compute_service_disabled_trait')\n-    def test_existing_node_capabilities_as_traits(self, mock_sync_disabled):\n+    def test_existing_node_capabilities_as_traits(\n+        self, mock_sync_disabled, mock_has_remote_managed_device_pools):\n         \"\"\"The capabilities_as_traits() driver method returns traits\n         information for a node/provider.\n         \"\"\"\n         self._setup_rt()\n         rc = self.rt.reportclient\n         rc.set_traits_for_provider = mock.MagicMock()\n \n+        # TODO(dmitriis): Remove once the PCI tracker is always created\n+        # upon the resource tracker initialization.\n+        with mock.patch.object(\n+            objects.PciDeviceList, 'get_by_compute_node',\n+            return_value=objects.PciDeviceList()\n+        ):\n+            self.rt.pci_tracker = pci_manager.PciDevTracker(\n+                mock.sentinel.ctx, _COMPUTE_NODE_FIXTURES[0])\n+\n         # Emulate a driver that has implemented the update_from_provider_tree()\n         # virt driver method\n         self.driver_mock.update_provider_tree = mock.Mock()"
},
{
"sha":"38d5e490f1780e953c0d3bf759636a12e20b3f73",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/c487c730d010013f8579622337af63d93b733f3b/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/c487c730d010013f8579622337af63d93b733f3b/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=c487c730d010013f8579622337af63d93b733f3b",
"patch":"@@ -3566,6 +3566,23 @@ def test_get_phynet_tunneled_info_non_tunneled(\n         self.assertFalse(tunneled)\n         self.assertIsNone(physnet_name)\n \n+    def test_is_remote_managed(self):\n+        cases = {\n+            (model.VNIC_TYPE_NORMAL, False),\n+            (model.VNIC_TYPE_DIRECT, False),\n+            (model.VNIC_TYPE_MACVTAP, False),\n+            (model.VNIC_TYPE_DIRECT_PHYSICAL, False),\n+            (model.VNIC_TYPE_BAREMETAL, False),\n+            (model.VNIC_TYPE_VIRTIO_FORWARDER, False),\n+            (model.VNIC_TYPE_VDPA, False),\n+            (model.VNIC_TYPE_ACCELERATOR_DIRECT, False),\n+            (model.VNIC_TYPE_ACCELERATOR_DIRECT_PHYSICAL, False),\n+            (model.VNIC_TYPE_REMOTE_MANAGED, True),\n+        }\n+\n+        for vnic_type, expected in cases:\n+            self.assertEqual(self.api._is_remote_managed(vnic_type), expected)\n+\n     def _test_get_port_vnic_info(\n         self, mock_get_client, binding_vnic_type, expected_vnic_type,\n         port_resource_request=None, numa_policy=None"
}
]
},
{
"commit_sha":"d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"commit_node_id":"C_kwDOAAwOD9oAKGQxZTllY2I0NDNkZDZiZDVkYzY0NTZhM2Y5ZTMzYzE1NTE0MzYzNjQ",
"commit_html_url":"https://github.com/openstack/nova/commit/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"commit_date":"2022-02-04T10:40:00Z",
"files":[
{
"sha":"0ec49b5d71965b2677f51b3fb173c737900c23f2",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":4,
"deletions":0,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -110,6 +110,10 @@ def _ensure_remote_managed_tag(\n                                 fields.PciDeviceType.SRIOV_PF,\n                                 fields.PciDeviceType.VDPA):\n             return\n+\n+        # A tag is added here rather than at the client side to avoid an\n+        # issue with having objects without this tag specified during an\n+        # upgrade to the first version that supports handling this tag.\n         if pool.get(PCI_REMOTE_MANAGED_TAG) is None:\n             # NOTE: tags are compared as strings case-insensitively, see\n             # pci_device_prop_match in nova/pci/utils.py."
},
{
"sha":"334c4f329bebf0ba1488d861ec26119b9d7cb9fd",
"filename":"nova/tests/functional/test_servers_provider_tree.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/functional/test_servers_provider_tree.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/functional/test_servers_provider_tree.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_servers_provider_tree.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -45,6 +45,7 @@ class ProviderTreeTests(integrated_helpers.ProviderUsageBaseTestCase):\n             os_traits.COMPUTE_VOLUME_EXTEND,\n             os_traits.COMPUTE_VOLUME_MULTI_ATTACH,\n             os_traits.COMPUTE_TRUSTED_CERTS,\n+            os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n         ]\n     ])\n "
},
{
"sha":"755b02d5b84c4abf7a3d75ee6003ba2521554e6d",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":16,
"deletions":0,
"changes":16,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -885,6 +885,22 @@ def test_driver_capabilities_secure_boot(self, mock_supports):\n         )\n         mock_supports.assert_called_once_with()\n \n+    @mock.patch.object(\n+        libvirt_driver.LibvirtDriver, '_register_instance_machine_type',\n+        new=mock.Mock())\n+    @mock.patch.object(\n+        host.Host, 'supports_remote_managed_ports',\n+        new_callable=mock.PropertyMock)\n+    def test_driver_capabilities_remote_managed_ports(self, mock_supports):\n+        drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)\n+        drvr.init_host(\"dummyhost\")\n+        self.assertTrue(\n+            drvr.capabilities['supports_remote_managed_ports'],\n+            \"Driver capabilities for 'supports_remote_managed_ports' \"\n+            \"is invalid when host should support this feature\"\n+        )\n+        mock_supports.assert_called_once_with()\n+\n     def test_driver_raises_on_non_linux_platform(self):\n         with utils.temporary_mutation(sys, platform='darwin'):\n             self.assertRaises("
},
{
"sha":"3aba6b35ee8d667658fc2ab3840cbe73be290c84",
"filename":"nova/tests/unit/virt/libvirt/test_host.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/unit/virt/libvirt/test_host.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/tests/unit/virt/libvirt/test_host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_host.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -1816,6 +1816,16 @@ def test_supports_secure_boot__true(self, mock_caps, mock_domcaps):\n         \"\"\"\n         self.assertTrue(self.host.supports_secure_boot)\n \n+    @mock.patch.object(fakelibvirt.virConnect, \"getLibVersion\")\n+    def test_supports_remote_managed_ports__true(self, mock_libversion):\n+        mock_libversion.return_value = 7009000\n+        self.assertTrue(self.host.supports_remote_managed_ports)\n+\n+    @mock.patch.object(fakelibvirt.virConnect, \"getLibVersion\")\n+    def test_supports_remote_managed_ports__false(self, mock_libversion):\n+        mock_libversion.return_value = 7008000\n+        self.assertFalse(self.host.supports_remote_managed_ports)\n+\n     @mock.patch.object(host.Host, 'loaders', new_callable=mock.PropertyMock)\n     @mock.patch.object(host.Host, 'get_canonical_machine_type')\n     def test_get_loader(self, mock_get_mtype, mock_loaders):"
},
{
"sha":"dfe97938eb2434dca191756915b3325c368adc6c",
"filename":"nova/virt/driver.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -126,6 +126,7 @@ def block_device_info_get_mapping(block_device_info):\n     \"supports_secure_boot\": os_traits.COMPUTE_SECURITY_UEFI_SECURE_BOOT,\n     \"supports_socket_pci_numa_affinity\":\n         os_traits.COMPUTE_SOCKET_PCI_NUMA_AFFINITY,\n+    \"supports_remote_managed_ports\": os_traits.COMPUTE_REMOTE_MANAGED_PORTS,\n }\n \n \n@@ -194,6 +195,7 @@ class ComputeDriver(object):\n         \"supports_vtpm\": False,\n         \"supports_secure_boot\": False,\n         \"supports_socket_pci_numa_affinity\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"5aab8ce300786ec33d6b2e8a8a213292e739e9c9",
"filename":"nova/virt/fake.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/fake.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/fake.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/fake.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -116,6 +116,7 @@ class FakeDriver(driver.ComputeDriver):\n         \"supports_trusted_certs\": True,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": True,\n+        \"supports_remote_managed_ports\": True,\n \n         # Supported image types\n         \"supports_image_type_raw\": True,"
},
{
"sha":"1291f975add266be0e8b971f6c4b8ad35f99ef0b",
"filename":"nova/virt/hyperv/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/hyperv/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/hyperv/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/hyperv/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -103,6 +103,7 @@ class HyperVDriver(driver.ComputeDriver):\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n         \"supports_secure_boot\": True,\n+        \"supports_remote_managed_ports\": False,\n \n         # Supported image types\n         \"supports_image_type_vhd\": True,"
},
{
"sha":"7970f185412b6e418f514c7c2b938d7e0660fcbe",
"filename":"nova/virt/ironic/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/ironic/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/ironic/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/ironic/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -164,6 +164,7 @@ class IronicDriver(virt_driver.ComputeDriver):\n         \"supports_trusted_certs\": False,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"4e920afe13fb269d9a29fb88bc16c734e0e60e36",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -812,6 +812,8 @@ def _update_host_specific_capabilities(self) -> None:\n         # or UEFI bootloader support in this manner\n         self.capabilities.update({\n             'supports_secure_boot': self._host.supports_secure_boot,\n+            'supports_remote_managed_ports':\n+            self._host.supports_remote_managed_ports\n         })\n \n     def _register_instance_machine_type(self):"
},
{
"sha":"f37ebba473e1caafed1e96d0bb070d631b932cc6",
"filename":"nova/virt/libvirt/host.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/libvirt/host.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/libvirt/host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/host.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -1701,6 +1701,23 @@ def supports_amd_sev(self) -> bool:\n         LOG.debug(\"No AMD SEV support detected for any (arch, machine_type)\")\n         return self._supports_amd_sev\n \n+    @property\n+    def supports_remote_managed_ports(self) -> bool:\n+        \"\"\"Determine if the host supports remote managed ports.\n+\n+        Returns a boolean indicating whether remote managed ports are\n+        possible to use on this host.\n+\n+        The check is based on a Libvirt version which added support for\n+        parsing and exposing PCI VPD since a card serial number (if present in\n+        the VPD) since the use of remote managed ports depends on this.\n+        https://libvirt.org/news.html#v7-9-0-2021-11-01\n+\n+        The actual presence of a card serial number for a particular device\n+        is meant to be checked elsewhere.\n+        \"\"\"\n+        return self.has_min_version(lv_ver=(7, 9, 0))\n+\n     @property\n     def loaders(self) -> ty.List[dict]:\n         \"\"\"Retrieve details of loader configuration for the host."
},
{
"sha":"d3eb9fc7706ad39f3841063117bdeb42535bf39d",
"filename":"nova/virt/powervm/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/powervm/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/powervm/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/powervm/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -82,6 +82,7 @@ def __init__(self, virtapi):\n             'supports_vtpm': False,\n             'supports_secure_boot': False,\n             'supports_socket_pci_numa_affinity': False,\n+            'supports_remote_managed_ports': False,\n \n             # Supported image types\n             \"supports_image_type_aki\": False,"
},
{
"sha":"cc80ca775efcd0a2d8c58a18a8985a09f394fba7",
"filename":"nova/virt/vmwareapi/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/vmwareapi/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/vmwareapi/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/vmwareapi/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -72,6 +72,7 @@ class VMwareVCDriver(driver.ComputeDriver):\n         \"supports_trusted_certs\": False,\n         \"supports_pcpus\": False,\n         \"supports_accelerators\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
},
{
"sha":"a1fa721515c39e579c15cb2f28fb68881a88b45b",
"filename":"nova/virt/zvm/driver.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/zvm/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/d1e9ecb443dd6bd5dc6456a3f9e33c1551436364/nova/virt/zvm/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/zvm/driver.py?ref=d1e9ecb443dd6bd5dc6456a3f9e33c1551436364",
"patch":"@@ -46,6 +46,7 @@ class ZVMDriver(driver.ComputeDriver):\n     \"\"\"z/VM implementation of ComputeDriver.\"\"\"\n     capabilities = {\n         \"supports_pcpus\": False,\n+        \"supports_remote_managed_ports\": False,\n \n         # Image type support flags\n         \"supports_image_type_aki\": False,"
}
]
},
{
"commit_sha":"6294c144e7953019030e50deeb8beab2f13844df",
"commit_node_id":"C_kwDOAAwOD9oAKDYyOTRjMTQ0ZTc5NTMwMTkwMzBlNTBkZWViOGJlYWIyZjEzODQ0ZGY",
"commit_html_url":"https://github.com/openstack/nova/commit/6294c144e7953019030e50deeb8beab2f13844df",
"commit_date":"2022-01-27T13:44:39Z",
"files":[
{
"sha":"4e4b1cca9a5f7ff37c98d42c7a3da489367fd682",
"filename":"lower-constraints.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/6294c144e7953019030e50deeb8beab2f13844df/lower-constraints.txt",
"raw_url":"https://github.com/openstack/nova/raw/6294c144e7953019030e50deeb8beab2f13844df/lower-constraints.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/lower-constraints.txt?ref=6294c144e7953019030e50deeb8beab2f13844df",
"patch":"@@ -62,7 +62,7 @@ os-brick==4.3.1\n os-client-config==1.29.0\n os-resource-classes==1.1.0\n os-service-types==1.7.0\n-os-traits==2.5.0\n+os-traits==2.7.0\n os-vif==1.15.2\n os-win==5.4.0\n osc-lib==1.10.0"
},
{
"sha":"6b47321b4c736bdcaaf5e39a05badb8eaaa23ff8",
"filename":"requirements.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/6294c144e7953019030e50deeb8beab2f13844df/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/6294c144e7953019030e50deeb8beab2f13844df/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=6294c144e7953019030e50deeb8beab2f13844df",
"patch":"@@ -50,7 +50,7 @@ psutil>=3.2.2 # BSD\n oslo.versionedobjects>=1.35.0 # Apache-2.0\n os-brick>=4.3.1 # Apache-2.0\n os-resource-classes>=1.1.0 # Apache-2.0\n-os-traits>=2.5.0 # Apache-2.0\n+os-traits>=2.7.0 # Apache-2.0\n os-vif>=1.15.2 # Apache-2.0\n os-win>=5.4.0 # Apache-2.0\n castellan>=0.16.0 # Apache-2.0"
}
]
},
{
"commit_sha":"0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"commit_node_id":"C_kwDOAAwOD9oAKDBkNWY4ZmZjMmIyNzk4ODhhZjAzZTc5ODNkY2VlOWQxZDI2N2Y5ODA",
"commit_html_url":"https://github.com/openstack/nova/commit/0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"commit_date":"2022-01-16T19:58:46Z",
"files":[
{
"sha":"de9a2e297b65ab8eaf6e74ccdc5bd01697886d1f",
"filename":"nova/conf/pci.py",
"status":"modified",
"additions":27,
"deletions":0,
"changes":27,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/conf/pci.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/conf/pci.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/pci.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -134,6 +134,15 @@\n \n     - ``physical_network``\n     - ``trusted``\n+    - ``remote_managed`` - a VF is managed remotely by an off-path networking\n+      backend. May have boolean-like string values case-insensitive values:\n+      \"true\" or \"false\". By default, \"false\" is assumed for all devices.\n+      Using this option requires a networking service backend capable of\n+      handling those devices. PCI devices are also required to have a PCI\n+      VPD capability with a card serial number (either on a VF itself on\n+      its corresponding PF), otherwise they will be ignored and not\n+      available for allocation.\n+\n \n   Valid examples are::\n \n@@ -158,13 +167,31 @@\n                              \"physical_network\":\"physnet1\"}\n     passthrough_whitelist = {\"devname\": \"eth0\", \"physical_network\":\"physnet1\",\n                              \"trusted\": \"true\"}\n+    passthrough_whitelist = {\"vendor_id\":\"a2d6\",\n+                             \"product_id\":\"15b3\",\n+                             \"remote_managed\": \"true\"}\n+    passthrough_whitelist = {\"vendor_id\":\"a2d6\",\n+                             \"product_id\":\"15b3\",\n+                             \"address\": \"0000:82:00.0\",\n+                             \"physical_network\":\"physnet1\",\n+                             \"remote_managed\": \"true\"}\n \n   The following are invalid, as they specify mutually exclusive options::\n \n     passthrough_whitelist = {\"devname\":\"eth0\",\n                              \"physical_network\":\"physnet\",\n                              \"address\":\"*:0a:00.*\"}\n \n+  The following example is invalid because it specifies the ``remote_managed``\n+  tag for a PF - it will result in an error during config validation at the\n+  Nova Compute service startup::\n+\n+    passthrough_whitelist = {\"address\": \"0000:82:00.0\",\n+                             \"product_id\": \"a2d6\",\n+                             \"vendor_id\": \"15b3\",\n+                             \"physical_network\": null,\n+                             \"remote_managed\": \"true\"}\n+\n * A JSON list of JSON dictionaries corresponding to the above format. For\n   example::\n "
},
{
"sha":"bda5a009f1a418c70334221b97625985bab9c394",
"filename":"nova/exception.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -1565,6 +1565,16 @@ class PciRequestFromVIFNotFound(NotFound):\n                 \"PCI address: %(pci_slot)s on compute node: %(node_id)s\")\n \n \n+class PciDeviceRemoteManagedNotPresent(NovaException):\n+    msg_fmt = _('Invalid PCI Whitelist: A device specified as \"remote_managed\"'\n+                ' is not actually present on the host')\n+\n+\n+class PciDeviceInvalidPFRemoteManaged(NovaException):\n+    msg_fmt = _('Invalid PCI Whitelist: PFs must not have the \"remote_managed\"'\n+                'tag, device address: %(address)s')\n+\n+\n # Cannot be templated, msg needs to be constructed when raised.\n class InternalError(NovaException):\n     \"\"\"Generic hypervisor errors."
},
{
"sha":"1cefaed0cbf4e3e81ac656ae601bc5cf259ff2bb",
"filename":"nova/pci/devspec.py",
"status":"modified",
"additions":99,
"deletions":18,
"changes":117,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/devspec.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/devspec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/devspec.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -19,7 +19,10 @@\n from nova import exception\n from nova.i18n import _\n from nova import objects\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import utils\n+from oslo_log import log as logging\n+from oslo_utils import strutils\n \n MAX_VENDOR_ID = 0xFFFF\n MAX_PRODUCT_ID = 0xFFFF\n@@ -30,6 +33,7 @@\n ANY = '*'\n REGEX_ANY = '.*'\n \n+LOG = logging.getLogger(__name__)\n \n PCISpecAddressType = ty.Union[ty.Dict[str, str], str]\n \n@@ -111,6 +115,9 @@ def match(self, phys_pci_addr: PciAddressSpec) -> bool:\n             ]\n         return all(conditions)\n \n+    def __str__(self):\n+        return f'{self.domain}:{self.bus}:{self.slot}.{self.func}'\n+\n \n class PciAddressGlobSpec(PciAddressSpec):\n     \"\"\"Manages the address fields with glob style.\n@@ -263,6 +270,20 @@ def __init__(self, dev_spec: ty.Dict[str, str]) -> None:\n         self.tags = dev_spec\n         self._init_dev_details()\n \n+    def _address_obj(self) -> ty.Optional[WhitelistPciAddress]:\n+        address_obj = None\n+        if self.dev_name:\n+            address_str, pf = utils.get_function_by_ifname(self.dev_name)\n+            if not address_str:\n+                return None\n+            # Note(moshele): In this case we always passing a string\n+            # of the PF pci address\n+            address_obj = WhitelistPciAddress(address_str, pf)\n+        else:  # use self.address\n+            address_obj = self.address\n+\n+        return address_obj\n+\n     def _init_dev_details(self) -> None:\n         self.vendor_id = self.tags.pop(\"vendor_id\", ANY)\n         self.product_id = self.tags.pop(\"product_id\", ANY)\n@@ -283,33 +304,93 @@ def _init_dev_details(self) -> None:\n         if not self.dev_name:\n             self.address = WhitelistPciAddress(address or '*:*:*.*', False)\n \n-    def match(self, dev_dict: ty.Dict[str, str]) -> bool:\n-        address_obj: ty.Optional[WhitelistPciAddress]\n-\n-        if self.dev_name:\n-            address_str, pf = utils.get_function_by_ifname(self.dev_name)\n-            if not address_str:\n-                return False\n-            # Note(moshele): In this case we always passing a string\n-            # of the PF pci address\n-            address_obj = WhitelistPciAddress(address_str, pf)\n-        else:  # use self.address\n-            address_obj = self.address\n-\n+        # PFs with remote_managed tags are explicitly not supported. If they\n+        # are tagged as such by mistake in the whitelist Nova will\n+        # raise an exception. The reason for excluding PFs is the lack of a way\n+        # for an instance to access the control plane at the remote side (e.g.\n+        # on a DPU) for managing the PF representor corresponding to the PF.\n+        address_obj = self._address_obj()\n+        self._remote_managed = strutils.bool_from_string(\n+            self.tags.get(PCI_REMOTE_MANAGED_TAG))\n+        if self._remote_managed:\n+            if address_obj is None:\n+                # Note that this will happen if a netdev was specified in the\n+                # whitelist but it is not actually present on a system - in\n+                # this case Nova is not able to look up an address by\n+                # a netdev name.\n+                raise exception.PciDeviceRemoteManagedNotPresent()\n+            elif address_obj.is_physical_function:\n+                pf_addr = str(address_obj.pci_address_spec)\n+                vf_product_id = utils.get_vf_product_id_by_pf_addr(pf_addr)\n+                # VF vendor IDs have to match the corresponding PF vendor IDs\n+                # per the SR-IOV spec so we use it for matching here.\n+                pf_vendor_id, pf_product_id = utils.get_pci_ids_by_pci_addr(\n+                    pf_addr)\n+                # Check the actual vendor ID and VF product ID of an assumed\n+                # VF (based on the actual PF). The VF product ID must match\n+                # the actual one if this is a VF device spec.\n+                if (self.product_id == vf_product_id and\n+                        self.vendor_id in (pf_vendor_id, ANY)):\n+                    pass\n+                elif (self.product_id in (pf_product_id, ANY) and\n+                      self.vendor_id in (pf_vendor_id, ANY)):\n+                    raise exception.PciDeviceInvalidPFRemoteManaged(\n+                        address_obj.pci_address_spec)\n+                else:\n+                    # The specified product and vendor IDs of what is supposed\n+                    # to be a VF corresponding to the PF PCI address do not\n+                    # match the actual ones for this PF. This means that the\n+                    # whitelist is invalid.\n+                    raise exception.PciConfigInvalidWhitelist(\n+                        reason=_('the specified VF vendor ID %(vendor_id)s and'\n+                                 ' product ID %(product_id)s do not match the'\n+                                 ' expected VF IDs based on the corresponding'\n+                                 ' PF identified by PCI address %(pf_addr)s') %\n+                        {'vendor_id': self.vendor_id,\n+                         'product_id': self.product_id,\n+                         'pf_addr': pf_addr})\n+\n+    def _ensure_remote_managed_dev_vpd_serial(\n+        self, dev_dict: ty.Dict[str, ty.Any]) -> bool:\n+        \"\"\"Ensure the presence of a serial number field in PCI VPD.\n+\n+        A card serial number extracted from PCI VPD is required to allow a\n+        networking backend to identify which remote host needs to program a\n+        given device. So if a device is tagged as remote_managed, it must\n+        have the card serial number or be filtered out.\n+        \"\"\"\n+        if not self._remote_managed:\n+            return True\n+        card_sn = dev_dict.get('capabilities', {}).get(\n+            'vpd', {}).get('card_serial_number')\n+        # None or empty card_serial_number should be filtered out. That would\n+        # mean either no serial number in the VPD (if present at all) or SN is\n+        # an empty string which is not useful for device identification.\n+        return bool(card_sn)\n+\n+    def match(self, dev_dict: ty.Dict[str, ty.Any]) -> bool:\n+        address_obj: ty.Optional[WhitelistPciAddress] = self._address_obj()\n         if not address_obj:\n             return False\n \n         return all([\n             self.vendor_id in (ANY, dev_dict['vendor_id']),\n             self.product_id in (ANY, dev_dict['product_id']),\n             address_obj.match(dev_dict['address'],\n-                dev_dict.get('parent_addr'))])\n+                dev_dict.get('parent_addr')),\n+            self._ensure_remote_managed_dev_vpd_serial(dev_dict),\n+        ])\n \n     def match_pci_obj(self, pci_obj: 'objects.PciDevice') -> bool:\n-        return self.match({'vendor_id': pci_obj.vendor_id,\n-                           'product_id': pci_obj.product_id,\n-                           'address': pci_obj.address,\n-                           'parent_addr': pci_obj.parent_addr})\n+        dev_dict = {\n+            'vendor_id': pci_obj.vendor_id,\n+            'product_id': pci_obj.product_id,\n+            'address': pci_obj.address,\n+            'parent_addr': pci_obj.parent_addr,\n+            'capabilities': {\n+                'vpd': {'card_serial_number': pci_obj.card_serial_number}}\n+        }\n+        return self.match(dev_dict)\n \n     def get_tags(self) -> ty.Dict[str, str]:\n         return self.tags"
},
{
"sha":"d179d36cd981e9cc8956652d4726be5402944ae2",
"filename":"nova/pci/request.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/request.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/request.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/request.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -58,6 +58,7 @@\n PCI_NET_TAG = 'physical_network'\n PCI_TRUSTED_TAG = 'trusted'\n PCI_DEVICE_TYPE_TAG = 'dev_type'\n+PCI_REMOTE_MANAGED_TAG = 'remote_managed'\n \n DEVICE_TYPE_FOR_VNIC_TYPE = {\n     network_model.VNIC_TYPE_DIRECT_PHYSICAL: obj_fields.PciDeviceType.SRIOV_PF,"
},
{
"sha":"5da56ee94d376a8bdd56c19830592066d518c98a",
"filename":"nova/pci/stats.py",
"status":"modified",
"additions":58,
"deletions":0,
"changes":58,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/stats.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/stats.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -19,11 +19,13 @@\n \n from oslo_config import cfg\n from oslo_log import log as logging\n+from oslo_utils import strutils\n \n from nova import exception\n from nova import objects\n from nova.objects import fields\n from nova.objects import pci_device_pool\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import utils\n from nova.pci import whitelist\n \n@@ -95,6 +97,24 @@ def _find_pool(self, dev_pool: Pool) -> ty.Optional[Pool]:\n \n         return None\n \n+    @staticmethod\n+    def _ensure_remote_managed_tag(\n+            dev: 'objects.PciDevice', pool: Pool):\n+        \"\"\"Add a remote_managed tag depending on a device type if needed.\n+\n+        Network devices may be managed remotely, e.g. by a SmartNIC DPU. If\n+        a tag has not been explicitly provided, populate it by assuming that\n+        a device is not remote managed by default.\n+        \"\"\"\n+        if dev.dev_type not in (fields.PciDeviceType.SRIOV_VF,\n+                                fields.PciDeviceType.SRIOV_PF,\n+                                fields.PciDeviceType.VDPA):\n+            return\n+        if pool.get(PCI_REMOTE_MANAGED_TAG) is None:\n+            # NOTE: tags are compared as strings case-insensitively, see\n+            # pci_device_prop_match in nova/pci/utils.py.\n+            pool[PCI_REMOTE_MANAGED_TAG] = 'false'\n+\n     def _create_pool_keys_from_dev(\n         self, dev: 'objects.PciDevice',\n     ) -> ty.Optional[Pool]:\n@@ -120,6 +140,9 @@ def _create_pool_keys_from_dev(\n         # already in placement.\n         if dev.extra_info.get('parent_ifname'):\n             pool['parent_ifname'] = dev.extra_info['parent_ifname']\n+\n+        self._ensure_remote_managed_tag(dev, pool)\n+\n         return pool\n \n     def _get_pool_with_device_type_mismatch(\n@@ -458,6 +481,27 @@ def _filter_pools_for_unrequested_vdpa_devices(\n             ]\n         return pools\n \n+    def _filter_pools_for_unrequested_remote_managed_devices(\n+        self, pools: ty.List[Pool], request: 'objects.InstancePCIRequest',\n+    ) -> ty.List[Pool]:\n+        \"\"\"Filter out pools with remote_managed devices, unless requested.\n+\n+        Remote-managed devices are not usable for legacy SR-IOV or hardware\n+        offload scenarios and must be excluded from allocation.\n+\n+        :param pools: A list of PCI device pool dicts\n+        :param request: An InstancePCIRequest object describing the type,\n+            quantity and required NUMA affinity of device(s) we want.\n+        :returns: A list of pools that can be used to support the request if\n+            this is possible.\n+        \"\"\"\n+        if all(not strutils.bool_from_string(spec.get(PCI_REMOTE_MANAGED_TAG))\n+               for spec in request.spec):\n+            pools = [pool for pool in pools\n+                     if not strutils.bool_from_string(\n+                         pool.get(PCI_REMOTE_MANAGED_TAG))]\n+        return pools\n+\n     def _filter_pools(\n         self,\n         pools: ty.List[Pool],\n@@ -547,6 +591,20 @@ def _filter_pools(\n                 before_count - after_count\n             )\n \n+        # If we're not requesting remote_managed devices then we should not\n+        # use these either. Exclude them.\n+        before_count = after_count\n+        pools = self._filter_pools_for_unrequested_remote_managed_devices(\n+            pools, request)\n+        after_count = sum([pool['count'] for pool in pools])\n+\n+        if after_count < before_count:\n+            LOG.debug(\n+                'Dropped %d device(s) as they are remote-managed devices which'\n+                'we have not requested',\n+                before_count - after_count\n+            )\n+\n         if after_count < request.count:\n             LOG.debug('Not enough PCI devices left to satisfy request')\n             return None"
},
{
"sha":"51716c9d98e8171f65cc9d77838edd34aecfed22",
"filename":"nova/pci/utils.py",
"status":"modified",
"additions":60,
"deletions":0,
"changes":60,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/utils.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -211,3 +211,63 @@ def get_vf_num_by_pci_address(pci_addr: str) -> int:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n     return int(vf_num)\n+\n+\n+def get_vf_product_id_by_pf_addr(pci_addr: str) -> str:\n+    \"\"\"Get the VF product ID for a given PF.\n+\n+    \"Product ID\" or Device ID in the PCIe spec terms for a PF is\n+    possible to retrieve via the VF Device ID field present as of\n+    SR-IOV 1.0 in the \"3.3.11. VF Device ID (1Ah)\" section. It is\n+    described as a field that \"contains the Device ID that should\n+    be presented for every VF to the SI\".\n+\n+    It is available as of Linux kernel 4.15, commit\n+    7dfca15276fc3f18411a2b2182704fa1222bcb60\n+\n+    :param pci_addr: A string of the form \"<domain>:<bus>:<slot>.<function>\".\n+    :return: A string containing a product ID of a VF corresponding to the PF.\n+    \"\"\"\n+    sriov_vf_device_path = f\"/sys/bus/pci/devices/{pci_addr}/sriov_vf_device\"\n+    try:\n+        with open(sriov_vf_device_path) as f:\n+            vf_product_id = f.readline().strip()\n+    except IOError as e:\n+        LOG.warning(\n+            \"Could not find the expected sysfs file for \"\n+            \"determining the VF product ID of a PCI VF by PF\"\n+            \"with addr %(addr)s. May not be a PF. Error: %(e)s\",\n+            {\"addr\": pci_addr, \"e\": e},\n+        )\n+        raise exception.PciDeviceNotFoundById(id=pci_addr)\n+    if not vf_product_id:\n+        raise ValueError(\"sriov_vf_device file does not contain\"\n+                         \" a VF product ID\")\n+    return vf_product_id\n+\n+\n+def get_pci_ids_by_pci_addr(pci_addr: str) -> ty.Tuple[str, ...]:\n+    \"\"\"Get the product ID and vendor ID for a given PCI device.\n+\n+    :param pci_addr: A string of the form \"<domain>:<bus>:<slot>.<function>\".\n+    :return: A list containing a vendor and product ids.\n+    \"\"\"\n+    id_prefix = f\"/sys/bus/pci/devices/{pci_addr}\"\n+    ids: ty.List[str] = []\n+    for id_name in (\"vendor\", \"product\"):\n+        try:\n+            with open(os.path.join(id_prefix, id_name)) as f:\n+                id_value = f.readline()\n+                if not id_value:\n+                    raise ValueError(f\"{id_name} file does not contain\"\n+                                     \" a valid value\")\n+                ids.append(id_value.strip().replace(\"0x\", \"\"))\n+        except IOError as e:\n+            LOG.warning(\n+                \"Could not find the expected sysfs file for \"\n+                f\"determining the {id_name} ID of a PCI device \"\n+                \"with addr %(addr)s. Error: %(e)s\",\n+                {\"addr\": pci_addr, \"e\": e},\n+            )\n+            raise exception.PciDeviceNotFoundById(id=pci_addr)\n+    return tuple(ids)"
},
{
"sha":"1e4997123765919549366eabe16ab0067964d37e",
"filename":"nova/pci/whitelist.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/whitelist.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/pci/whitelist.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/whitelist.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -82,7 +82,7 @@ def _parse_white_list_from_config(\n \n         return specs\n \n-    def device_assignable(self, dev: ty.Dict[str, str]) -> bool:\n+    def device_assignable(self, dev: ty.Dict[str, ty.Any]) -> bool:\n         \"\"\"Check if a device can be assigned to a guest.\n \n         :param dev: A dictionary describing the device properties"
},
{
"sha":"1b7af103168ed5206d2d8ddf1df57c0b26cb18dc",
"filename":"nova/tests/unit/pci/test_devspec.py",
"status":"modified",
"additions":232,
"deletions":0,
"changes":232,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_devspec.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_devspec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_devspec.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -17,6 +17,7 @@\n from nova import exception\n from nova import objects\n from nova.pci import devspec\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova import test\n \n dev = {\"vendor_id\": \"8086\",\n@@ -449,3 +450,234 @@ def test_pci_obj(self):\n \n         pci_obj = objects.PciDevice.create(None, pci_dev)\n         self.assertTrue(pci.match_pci_obj(pci_obj))\n+\n+\n+class PciDevSpecRemoteManagedTestCase(test.NoDBTestCase):\n+\n+    def setUp(self):\n+        self.test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        super().setUp()\n+\n+    @mock.patch('nova.pci.utils.get_function_by_ifname',\n+                new=mock.Mock(return_value=(None, False)))\n+    def test_remote_managed_unknown_raises(self):\n+        pci_info = {\"devname\": \"nonexdev0\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceRemoteManagedNotPresent,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_pf_raises(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        5058 is the expected VF product ID which differs from the\n+        one specified in the whitelist. This is to simulate a mistake\n+        in the whitelist where a user uses both the PF PCI address and\n+        PF product and vendor ID instead of using the VF product ID.\n+        \"\"\"\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_vf_by_pf(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        This is to test the supported matching of a VF by using\n+        its product and vendor ID and a specific PF PCI address.\n+        \"\"\"\n+        # Full match: 5058 is the expected VF product ID which\n+        # matches the one specified in the whitelist. This is to\n+        # simulate the supported matching of a VF by using its\n+        # product and vendor ID and a specific PF PCI address.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        devspec.PciDeviceSpec(pci_info)\n+\n+        # This spec would match both PFs and VFs. Since we care that\n+        # remote-managed PFs are not allowed, we have to prohibit the\n+        # this altogether.\n+        pci_info = {\"vendor_id\": \"*\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"*\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # Don't care about a VF product ID. Like above, this would\n+        # match both PFs and VFs (since VFs have the same vendor ID).\n+        # Therefore, this case is prohibited to avoid remote-managed PFs.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"*\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciDeviceInvalidPFRemoteManaged,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # Don't care about a VF vendor ID.\n+        pci_info = {\"vendor_id\": \"*\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        devspec.PciDeviceSpec(pci_info)\n+\n+    @mock.patch('nova.pci.utils.get_vf_product_id_by_pf_addr',\n+                new=mock.Mock(return_value=\"5058\"))\n+    @mock.patch('nova.pci.utils.get_pci_ids_by_pci_addr',\n+                new=mock.Mock(return_value=(\"8086\", \"5057\")))\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_remote_managed_vf_by_pf_raises(self):\n+        \"\"\"Remote-managed PF test case with PF-based VF matching\n+\n+        5058 is the expected VF product ID which matches the one\n+        specified in the whitelist. This is to simulate the supported\n+        matching of a VF by using its product and vendor ID and a\n+        specific PF PCI address.\n+        \"\"\"\n+        # VF vendor ID and device ID mismatch.\n+        pci_info = {\"vendor_id\": \"8080\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5050\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # VF device ID mismatch.\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5050\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+        # VF vendor ID mismatch.\n+        pci_info = {\"vendor_id\": \"8080\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5058\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        self.assertRaises(exception.PciConfigInvalidWhitelist,\n+                          devspec.PciDeviceSpec, pci_info)\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_not_remote_managed_pf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"false\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=True))\n+    def test_no_remote_managed_specified_pf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_no_serial_vf_no_match(self):\n+        # No card serial number available - must not get a match.\n+        test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+        }\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertFalse(pci.match(test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_remote_managed_specified_empty_serial_vf_no_match(self):\n+        # Card serial is an empty string.\n+        test_dev = {\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"address\": \"0000:0a:00.0\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"\"}},\n+        }\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertFalse(pci.match(test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_not_remote_managed_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"false\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    @mock.patch('nova.pci.utils.is_physical_function',\n+                new=mock.Mock(return_value=False))\n+    def test_no_remote_managed_specified_vf_match(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\"}\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        self.assertTrue(pci.match(self.test_dev))\n+\n+    def test_remote_managed_vf_match_by_pci_obj(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.2\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        pci_dev = {\n+            \"compute_node_id\": 1,\n+            \"address\": \"0000:0a:00.2\",\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+            \"status\": \"available\",\n+            \"parent_addr\": \"0000:0a:00.1\",\n+        }\n+\n+        pci_obj = objects.PciDevice.create(None, pci_dev)\n+        self.assertTrue(pci.match_pci_obj(pci_obj))\n+\n+    def test_remote_managed_vf_no_match_by_pci_obj(self):\n+        pci_info = {\"vendor_id\": \"8086\", \"address\": \"0000:0a:00.0\",\n+                    \"product_id\": \"5057\", \"physical_network\": \"hr_net\",\n+                    PCI_REMOTE_MANAGED_TAG: \"true\"}\n+\n+        pci = devspec.PciDeviceSpec(pci_info)\n+        pci_dev = {\n+            \"compute_node_id\": 1,\n+            \"address\": \"0000:0a:00.2\",\n+            \"vendor_id\": \"8086\",\n+            \"product_id\": \"5057\",\n+            \"status\": \"available\",\n+            \"parent_addr\": \"0000:0a:00.1\",\n+        }\n+\n+        pci_obj = objects.PciDevice.create(None, pci_dev)\n+        self.assertFalse(pci.match_pci_obj(pci_obj))"
},
{
"sha":"804b76ffba4dbda2a7e9a04e06a90c44e82d7df5",
"filename":"nova/tests/unit/pci/test_stats.py",
"status":"modified",
"additions":214,
"deletions":13,
"changes":227,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_stats.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_stats.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_stats.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -19,6 +19,7 @@\n from nova import exception\n from nova import objects\n from nova.objects import fields\n+from nova.pci.request import PCI_REMOTE_MANAGED_TAG\n from nova.pci import stats\n from nova.pci import whitelist\n from nova import test\n@@ -466,7 +467,12 @@ def setUp(self):\n         super(PciDeviceStatsWithTagsTestCase, self).setUp()\n         white_list = ['{\"vendor_id\":\"1137\",\"product_id\":\"0071\",'\n                         '\"address\":\"*:0a:00.*\",\"physical_network\":\"physnet1\"}',\n-                       '{\"vendor_id\":\"1137\",\"product_id\":\"0072\"}']\n+                      '{\"vendor_id\":\"1137\",\"product_id\":\"0072\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101e\", '\n+                      '\"remote_managed\": \"true\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101c\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"1018\", '\n+                      '\"remote_managed\": \"false\"}']\n         self.flags(passthrough_whitelist=white_list, group='pci')\n         dev_filter = whitelist.Whitelist(white_list)\n         self.pci_stats = stats.PciDeviceStats(\n@@ -502,12 +508,64 @@ def _create_pci_devices(self):\n             self.pci_untagged_devices.append(objects.PciDevice.create(None,\n                                                                       pci_dev))\n \n+        self.locally_managed_netdevs = []\n+        self.remote_managed_netdevs = []\n+        self.remote_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0c:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '101e',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0c:00.0',\n+                    'numa_node': 0,\n+                    \"capabilities\": {\"vpd\": {\n+                        \"card_serial_number\": \"MT2113X00000\"}}\n+                }))\n+\n+        # For testing implicit remote_managed == False tagging.\n+        self.locally_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0d:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '101c',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0d:00.0',\n+                    'numa_node': 0}))\n+\n+        # For testing explicit remote_managed == False tagging.\n+        self.locally_managed_netdevs.append(\n+            objects.PciDevice.create(\n+                None, {\n+                    'compute_node_id': 1,\n+                    'address': '0000:0e:00.1',\n+                    'vendor_id': '15b3',\n+                    'product_id': '1018',\n+                    'status': 'available',\n+                    'request_id': None,\n+                    'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                    'parent_addr': '0000:0e:00.0',\n+                    'numa_node': 0}))\n+\n         for dev in self.pci_tagged_devices:\n             self.pci_stats.add_device(dev)\n \n         for dev in self.pci_untagged_devices:\n             self.pci_stats.add_device(dev)\n \n+        for dev in self.remote_managed_netdevs:\n+            self.pci_stats.add_device(dev)\n+\n+        for dev in self.locally_managed_netdevs:\n+            self.pci_stats.add_device(dev)\n+\n     def _assertPoolContent(self, pool, vendor_id, product_id, count, **tags):\n         self.assertEqual(vendor_id, pool['vendor_id'])\n         self.assertEqual(product_id, pool['product_id'])\n@@ -520,9 +578,10 @@ def _assertPools(self):\n         # Pools are ordered based on the number of keys. 'product_id',\n         # 'vendor_id' are always part of the keys. When tags are present,\n         # they are also part of the keys. In this test class, we have\n-        # two pools with the second one having the tag 'physical_network'\n-        # and the value 'physnet1'\n-        self.assertEqual(2, len(self.pci_stats.pools))\n+        # 5 pools with the second one having the tag 'physical_network'\n+        # and the value 'physnet1' and multiple pools for testing\n+        # variations of explicit/implicit remote_managed tagging.\n+        self.assertEqual(5, len(self.pci_stats.pools))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072',\n                                 len(self.pci_untagged_devices))\n         self.assertEqual(self.pci_untagged_devices,\n@@ -532,6 +591,19 @@ def _assertPools(self):\n                                 physical_network='physnet1')\n         self.assertEqual(self.pci_tagged_devices,\n                          self.pci_stats.pools[1]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[2], '15b3', '101e',\n+                                len(self.remote_managed_netdevs),\n+                                remote_managed='true')\n+        self.assertEqual(self.remote_managed_netdevs,\n+                         self.pci_stats.pools[2]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[3], '15b3', '101c', 1,\n+                                remote_managed='false')\n+        self.assertEqual([self.locally_managed_netdevs[0]],\n+                         self.pci_stats.pools[3]['devices'])\n+        self._assertPoolContent(self.pci_stats.pools[4], '15b3', '1018', 1,\n+                                remote_managed='false')\n+        self.assertEqual([self.locally_managed_netdevs[1]],\n+                         self.pci_stats.pools[4]['devices'])\n \n     def test_add_devices(self):\n         self._create_pci_devices()\n@@ -543,14 +615,32 @@ def test_consume_requests(self):\n                             spec=[{'physical_network': 'physnet1'}]),\n                         objects.InstancePCIRequest(count=1,\n                             spec=[{'vendor_id': '1137',\n-                                   'product_id': '0072'}])]\n+                                   'product_id': '0072'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'True'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '101c',\n+                                   PCI_REMOTE_MANAGED_TAG: 'False'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'vendor_id': '15b3',\n+                                   'product_id': '1018',\n+                                   PCI_REMOTE_MANAGED_TAG: 'False'}])]\n         devs = self.pci_stats.consume_requests(pci_requests)\n-        self.assertEqual(2, len(devs))\n-        self.assertEqual(set(['0071', '0072']),\n+        self.assertEqual(5, len(devs))\n+        self.assertEqual(set(['0071', '0072', '1018', '101e', '101c']),\n                          set([dev.product_id for dev in devs]))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072', 2)\n         self._assertPoolContent(self.pci_stats.pools[1], '1137', '0071', 3,\n                                 physical_network='physnet1')\n+        self._assertPoolContent(self.pci_stats.pools[2], '15b3', '101e', 0,\n+                                remote_managed='true')\n+        self._assertPoolContent(self.pci_stats.pools[3], '15b3', '101c', 0,\n+                                remote_managed='false')\n+        self._assertPoolContent(self.pci_stats.pools[4], '15b3', '1018', 0,\n+                                remote_managed='false')\n \n     def test_add_device_no_devspec(self):\n         self._create_pci_devices()\n@@ -600,7 +690,7 @@ def test_update_device(self):\n         dev1 = self.pci_tagged_devices.pop()\n         dev1.dev_type = 'type-PF'\n         self.pci_stats.update_device(dev1)\n-        self.assertEqual(3, len(self.pci_stats.pools))\n+        self.assertEqual(6, len(self.pci_stats.pools))\n         self._assertPoolContent(self.pci_stats.pools[0], '1137', '0072',\n                                 len(self.pci_untagged_devices))\n         self.assertEqual(self.pci_untagged_devices,\n@@ -610,19 +700,24 @@ def test_update_device(self):\n                                 physical_network='physnet1')\n         self.assertEqual(self.pci_tagged_devices,\n                          self.pci_stats.pools[1]['devices'])\n-        self._assertPoolContent(self.pci_stats.pools[2], '1137', '0071',\n+        self._assertPoolContent(self.pci_stats.pools[5], '1137', '0071',\n                                 1,\n-                                physical_network='physnet1')\n+                                physical_network='physnet1',\n+                                remote_managed='false')\n         self.assertEqual(dev1,\n-                         self.pci_stats.pools[2]['devices'][0])\n+                         self.pci_stats.pools[5]['devices'][0])\n \n \n class PciDeviceVFPFStatsTestCase(test.NoDBTestCase):\n \n     def setUp(self):\n         super(PciDeviceVFPFStatsTestCase, self).setUp()\n         white_list = ['{\"vendor_id\":\"8086\",\"product_id\":\"1528\"}',\n-                      '{\"vendor_id\":\"8086\",\"product_id\":\"1515\"}']\n+                      '{\"vendor_id\":\"8086\",\"product_id\":\"1515\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"a2d6\", '\n+                      '\"remote_managed\": \"false\"}',\n+                      '{\"vendor_id\":\"15b3\",\"product_id\":\"101e\", '\n+                      '\"remote_managed\": \"true\"}']\n         self.flags(passthrough_whitelist=white_list, group='pci')\n         self.pci_stats = stats.PciDeviceStats(objects.NUMATopology())\n \n@@ -644,6 +739,26 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n             dev_obj.child_devices = []\n             self.sriov_pf_devices.append(dev_obj)\n \n+        # PF devices for remote_managed VFs.\n+        self.sriov_pf_devices_remote = []\n+        for dev in range(2):\n+            pci_dev = {\n+                'compute_node_id': 1,\n+                'address': '0001:81:00.%d' % dev,\n+                'vendor_id': '15b3',\n+                'product_id': 'a2d6',\n+                'status': 'available',\n+                'request_id': None,\n+                'dev_type': fields.PciDeviceType.SRIOV_PF,\n+                'parent_addr': None,\n+                'numa_node': 0,\n+                \"capabilities\": {\"vpd\": {\n+                    \"card_serial_number\": \"MT2113X00000\"}},\n+            }\n+            dev_obj = objects.PciDevice.create(None, pci_dev)\n+            dev_obj.child_devices = []\n+            self.sriov_pf_devices_remote.append(dev_obj)\n+\n         self.sriov_vf_devices = []\n         for dev in range(8):\n             pci_dev = {\n@@ -662,6 +777,25 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n             dev_obj.parent_device.child_devices.append(dev_obj)\n             self.sriov_vf_devices.append(dev_obj)\n \n+        self.sriov_vf_devices_remote = []\n+        for dev in range(8):\n+            pci_dev = {\n+                'compute_node_id': 1,\n+                'address': '0001:81:10.%d' % dev,\n+                'vendor_id': '15b3',\n+                'product_id': '101e',\n+                'status': 'available',\n+                'request_id': None,\n+                'dev_type': fields.PciDeviceType.SRIOV_VF,\n+                'parent_addr': '0001:81:00.%d' % int(dev / 4),\n+                'numa_node': 0,\n+                \"capabilities\": {\"vpd\": {\"card_serial_number\": \"MT2113X00000\"}}\n+            }\n+            dev_obj = objects.PciDevice.create(None, pci_dev)\n+            dev_obj.parent_device = self.sriov_pf_devices_remote[int(dev / 4)]\n+            dev_obj.parent_device.child_devices.append(dev_obj)\n+            self.sriov_vf_devices_remote.append(dev_obj)\n+\n         self.vdpa_devices = []\n         for dev in range(8):\n             pci_dev = {\n@@ -683,6 +817,8 @@ def _create_pci_devices(self, vf_product_id=1515, pf_product_id=1528):\n         list(map(self.pci_stats.add_device, self.sriov_pf_devices))\n         list(map(self.pci_stats.add_device, self.sriov_vf_devices))\n         list(map(self.pci_stats.add_device, self.vdpa_devices))\n+        list(map(self.pci_stats.add_device, self.sriov_pf_devices_remote))\n+        list(map(self.pci_stats.add_device, self.sriov_vf_devices_remote))\n \n     def test_consume_VDPA_requests(self):\n         self._create_pci_devices()\n@@ -726,7 +862,8 @@ def test_consume_PF_requests(self):\n         free_devs = self.pci_stats.get_free_devs()\n         # Validate that there are no free devices left, as when allocating\n         # both available PFs, its VFs should not be available.\n-        self.assertEqual(0, len(free_devs))\n+        self.assertEqual(0, len([d for d in free_devs\n+                                 if d.product_id == '1515']))\n \n     def test_consume_VF_and_PF_requests(self):\n         self._create_pci_devices()\n@@ -754,3 +891,67 @@ def test_consume_VF_and_PF_same_prodict_id_failed(self):\n         pci_requests = [objects.InstancePCIRequest(count=9,\n                             spec=[{'product_id': '1515'}])]\n         self.assertIsNone(self.pci_stats.consume_requests(pci_requests))\n+\n+    def test_consume_PF_not_remote_managed(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=2,\n+                            spec=[{'product_id': '1528',\n+                                   'dev_type': 'type-PF',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['1528']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that there are no free devices left with the\n+        # product ID under test, as when allocating both available\n+        # PFs, its VFs should not be available.\n+        self.assertEqual(0, len([d for d in free_devs\n+                                 if d.product_id == '1528']))\n+\n+    def test_consume_VF_requests_remote_managed(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=2,\n+                            spec=[{PCI_REMOTE_MANAGED_TAG: 'true'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['101e']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that the parents of these VFs has been removed\n+        # from pools.\n+        for dev in devs:\n+            self.assertNotIn(dev.parent_addr,\n+                             [free_dev.address for free_dev in free_devs])\n+\n+    def test_consume_VF_requests_remote_managed_filtered(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e'}])]\n+        free_devs_before = self.pci_stats.get_free_devs()\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertIsNone(devs)\n+        free_devs_after = self.pci_stats.get_free_devs()\n+        self.assertEqual(free_devs_before, free_devs_after)\n+\n+    def test_consume_VF_requests_remote_managed_mix(self):\n+        self._create_pci_devices()\n+        pci_requests = [objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '101e',\n+                                   PCI_REMOTE_MANAGED_TAG: 'true'}]),\n+                        objects.InstancePCIRequest(count=1,\n+                            spec=[{'product_id': '1515',\n+                                   PCI_REMOTE_MANAGED_TAG: 'false'}])]\n+        devs = self.pci_stats.consume_requests(pci_requests)\n+        self.assertEqual(2, len(devs))\n+        self.assertEqual(set(['101e', '1515']),\n+                            set([dev.product_id for dev in devs]))\n+        free_devs = self.pci_stats.get_free_devs()\n+        # Validate that the parents of these VFs has been removed\n+        # from pools.\n+        for dev in devs:\n+            self.assertNotIn(dev.parent_addr,\n+                             [free_dev.address for free_dev in free_devs])"
},
{
"sha":"8170f47b97c19fe20d912c8a3d18e99dcea2fc01",
"filename":"nova/tests/unit/pci/test_utils.py",
"status":"modified",
"additions":177,
"deletions":0,
"changes":177,
"blob_url":"https://github.com/openstack/nova/blob/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_utils.py",
"raw_url":"https://github.com/openstack/nova/raw/0d5f8ffc2b279888af03e7983dcee9d1d267f980/nova/tests/unit/pci/test_utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_utils.py?ref=0d5f8ffc2b279888af03e7983dcee9d1d267f980",
"patch":"@@ -251,3 +251,180 @@ def test_vf_number_not_found(self, mock_iglob, mock_readlink):\n             utils.get_vf_num_by_pci_address,\n             self.pci_address\n         )\n+\n+\n+class GetProductIDByPfPciAddressTestCase(test.NoDBTestCase):\n+    def setUp(self):\n+        super().setUp()\n+        self.pci_address = \"0000:0a:00.0\"\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        read_data=\"101e\\n\"\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read(self):\n+        product_id = utils.get_vf_product_id_by_pf_addr(self.pci_address)\n+        self.assertEqual(product_id, \"101e\")\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        read_data=\"\"\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read_value_error(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_vf_product_id_by_pf_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/sriov_vf_device\":\n+                    mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_sriov_vf_device_read_io_error(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_vf_product_id_by_pf_addr,\n+            self.pci_address,\n+        )\n+\n+\n+class GetPciIdsByPciAddressTestCase(test.NoDBTestCase):\n+    def setUp(self):\n+        super().setUp()\n+        self.pci_address = \"0000:0a:00.0\"\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        read_data=\"0x101e\\n\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids(self):\n+        self.assertEqual(\n+            utils.get_pci_ids_by_pci_addr(self.pci_address), (\"15b3\", \"101e\")\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\": mock.mock_open(\n+                        read_data=\"\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_value_error_vendor(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        read_data=\"\"\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_value_error_product(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\": mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )()\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_io_error_vendor(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )\n+\n+    @mock.patch(\n+        \"builtins.open\",\n+        new=mock.MagicMock(\n+            side_effect=(\n+                lambda f: {\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/vendor\":\n+                    mock.mock_open(\n+                        read_data=\"0x15b3\\n\"\n+                    )(),\n+                    \"/sys/bus/pci/devices/0000:0a:00.0/product\":\n+                    mock.mock_open(\n+                        mock=mock.MagicMock(side_effect=IOError())\n+                    )(),\n+                }.get(f)\n+            )\n+        ),\n+    )\n+    def test_get_pci_ids_io_error_product(self):\n+        self.assertRaises(\n+            ValueError,\n+            utils.get_pci_ids_by_pci_addr,\n+            self.pci_address,\n+        )"
}
]
},
{
"commit_sha":"72058b7a405bade6ca9584cb74591e35a73fb458",
"commit_node_id":"C_kwDOAAwOD9oAKDcyMDU4YjdhNDA1YmFkZTZjYTk1ODRjYjc0NTkxZTM1YTczZmI0NTg",
"commit_html_url":"https://github.com/openstack/nova/commit/72058b7a405bade6ca9584cb74591e35a73fb458",
"commit_date":"2022-02-07T20:30:46Z",
"files":[
{
"sha":"b3f461cca42b3bc413767649e7284db3c7332f42",
"filename":"nova/api/openstack/compute/deferred_delete.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/deferred_delete.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/deferred_delete.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/deferred_delete.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -40,7 +40,7 @@ def _restore(self, req, id, body):\n                     target={'project_id': instance.project_id})\n         try:\n             self.compute_api.restore(context, instance)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise webob.exc.HTTPForbidden(explanation=error.format_message())\n         except exception.InstanceInvalidState as state_error:\n             common.raise_http_conflict_for_instance_invalid_state(state_error,"
},
{
"sha":"59b9c384df60d670f526f91ffb10fa09d12ab7ba",
"filename":"nova/api/openstack/compute/migrate_server.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/migrate_server.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/migrate_server.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/migrate_server.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -57,7 +57,7 @@ def _migrate(self, req, id, body):\n         try:\n             self.compute_api.resize(req.environ['nova.context'], instance,\n                                     host_name=host_name)\n-        except (exception.TooManyInstances, exception.QuotaError) as e:\n+        except exception.OverQuota as e:\n             raise exc.HTTPForbidden(explanation=e.format_message())\n         except (\n             exception.InstanceIsLocked,"
},
{
"sha":"e92becb582ad1b9ac5f044f7e4b312cf76806cc0",
"filename":"nova/api/openstack/compute/server_metadata.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/server_metadata.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/server_metadata.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/server_metadata.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -114,7 +114,7 @@ def _update_instance_metadata(self, context, server, metadata,\n                                                              server,\n                                                              metadata,\n                                                              delete)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(explanation=error.format_message())\n         except exception.InstanceIsLocked as e:\n             raise exc.HTTPConflict(explanation=e.format_message())"
},
{
"sha":"9c2ed62961c0163af622c154869b8aad32d73bf0",
"filename":"nova/api/openstack/compute/servers.py",
"status":"modified",
"additions":3,
"deletions":4,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/servers.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/api/openstack/compute/servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/servers.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -797,8 +797,7 @@ def create(self, req, body):\n                 supports_multiattach=supports_multiattach,\n                 supports_port_resource_request=supports_port_resource_request,\n                 **create_kwargs)\n-        except (exception.QuotaError,\n-                exception.PortLimitExceeded) as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(\n                 explanation=error.format_message())\n         except exception.ImageNotFound:\n@@ -1053,7 +1052,7 @@ def _resize(self, req, instance_id, flavor_id, auto_disk_config=None):\n         try:\n             self.compute_api.resize(context, instance, flavor_id,\n                                     auto_disk_config=auto_disk_config)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(\n                 explanation=error.format_message())\n         except (\n@@ -1237,7 +1236,7 @@ def _action_rebuild(self, req, id, body):\n         except exception.KeypairNotFound:\n             msg = _(\"Invalid key_name provided.\")\n             raise exc.HTTPBadRequest(explanation=msg)\n-        except exception.QuotaError as error:\n+        except exception.OverQuota as error:\n             raise exc.HTTPForbidden(explanation=error.format_message())\n         except (exception.AutoDiskConfigDisabledByImage,\n                 exception.CertificateValidationFailed,"
},
{
"sha":"ae756945ea2ab418fce66ec3f6ca74cef46043e5",
"filename":"nova/compute/api.py",
"status":"modified",
"additions":3,
"deletions":3,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/compute/api.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/compute/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/api.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -398,7 +398,7 @@ def _record_action_start(self, context, instance, action):\n     def _check_injected_file_quota(self, context, injected_files):\n         \"\"\"Enforce quota limits on injected files.\n \n-        Raises a QuotaError if any limit is exceeded.\n+        Raises a OverQuota if any limit is exceeded.\n         \"\"\"\n         if not injected_files:\n             return\n@@ -1455,7 +1455,7 @@ def _provision_instances(\n                         except exception.OverQuota:\n                             msg = _(\"Quota exceeded, too many servers in \"\n                                     \"group\")\n-                            raise exception.QuotaError(msg)\n+                            raise exception.OverQuota(msg)\n \n                     members = objects.InstanceGroup.add_members(\n                         context, instance_group.uuid, [instance.uuid])\n@@ -1475,7 +1475,7 @@ def _provision_instances(\n                                 context, instance_group.id, [instance.uuid])\n                             msg = _(\"Quota exceeded, too many servers in \"\n                                     \"group\")\n-                            raise exception.QuotaError(msg)\n+                            raise exception.OverQuota(msg)\n                     # list of members added to servers group in this iteration\n                     # is needed to check quota of server group during add next\n                     # instance"
},
{
"sha":"a140a2e30b2df7bc823cc9bd8f4d5e9c23fb35be",
"filename":"nova/exception.py",
"status":"modified",
"additions":9,
"deletions":16,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -993,10 +993,6 @@ class QuotaClassExists(NovaException):\n     msg_fmt = _(\"Quota class %(class_name)s exists for resource %(resource)s\")\n \n \n-class OverQuota(NovaException):\n-    msg_fmt = _(\"Quota exceeded for resources: %(overs)s\")\n-\n-\n class SecurityGroupNotFound(NotFound):\n     msg_fmt = _(\"Security group %(security_group_id)s not found.\")\n \n@@ -1233,29 +1229,26 @@ class MaxRetriesExceeded(NoValidHost):\n     msg_fmt = _(\"Exceeded maximum number of retries. %(reason)s\")\n \n \n-class QuotaError(NovaException):\n-    msg_fmt = _(\"Quota exceeded: code=%(code)s\")\n-    # NOTE(cyeoh): 413 should only be used for the ec2 API\n-    # The error status code for out of quota for the nova api should be\n-    # 403 Forbidden.\n+class OverQuota(NovaException):\n+    msg_fmt = _(\"Quota exceeded for resources: %(overs)s\")\n     code = 413\n     safe = True\n \n \n-class TooManyInstances(QuotaError):\n+class TooManyInstances(OverQuota):\n     msg_fmt = _(\"Quota exceeded for %(overs)s: Requested %(req)s,\"\n                 \" but already used %(used)s of %(allowed)s %(overs)s\")\n \n \n-class FloatingIpLimitExceeded(QuotaError):\n+class FloatingIpLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of floating IPs exceeded\")\n \n \n-class MetadataLimitExceeded(QuotaError):\n+class MetadataLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of metadata items exceeds %(allowed)d\")\n \n \n-class OnsetFileLimitExceeded(QuotaError):\n+class OnsetFileLimitExceeded(OverQuota):\n     msg_fmt = _(\"Personality file limit exceeded\")\n \n \n@@ -1267,15 +1260,15 @@ class OnsetFileContentLimitExceeded(OnsetFileLimitExceeded):\n     msg_fmt = _(\"Personality file content exceeds maximum %(allowed)s\")\n \n \n-class KeypairLimitExceeded(QuotaError):\n+class KeypairLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of key pairs exceeded\")\n \n \n-class SecurityGroupLimitExceeded(QuotaError):\n+class SecurityGroupLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of security groups or rules exceeded\")\n \n \n-class PortLimitExceeded(QuotaError):\n+class PortLimitExceeded(OverQuota):\n     msg_fmt = _(\"Maximum number of ports exceeded\")\n \n "
},
{
"sha":"d1bb6babb779b2053d7ea801cbd2beea7a0705dc",
"filename":"nova/tests/unit/api/openstack/compute/test_api.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/api/openstack/compute/test_api.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/api/openstack/compute/test_api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/api/openstack/compute/test_api.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -143,7 +143,7 @@ def fail(req):\n                 self.assertEqual(resp.headers[key], str(value))\n \n     def test_quota_error_mapping(self):\n-        self._do_test_exception_mapping(exception.QuotaError, 'too many used')\n+        self._do_test_exception_mapping(exception.OverQuota, 'too many used')\n \n     def test_non_nova_notfound_exception_mapping(self):\n         class ExceptionWithCode(Exception):"
},
{
"sha":"78dfff2fc7f1643f34e553c69e07081c40a5f825",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -8856,7 +8856,7 @@ def test_create_instance_group_members_over_quota_during_recheck(\n         group.create()\n         get_group_mock.return_value = group\n \n-        self.assertRaises(exception.QuotaError, self.compute_api.create,\n+        self.assertRaises(exception.OverQuota, self.compute_api.create,\n             self.context, self.default_flavor, self.fake_image['id'],\n             scheduler_hints={'group': group.uuid},\n             check_server_group_quota=True)"
},
{
"sha":"48910cf75cb862f122c6a53e26bcf9875f605395",
"filename":"nova/tests/unit/test_quota.py",
"status":"modified",
"additions":11,
"deletions":11,
"changes":22,
"blob_url":"https://github.com/openstack/nova/blob/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/test_quota.py",
"raw_url":"https://github.com/openstack/nova/raw/72058b7a405bade6ca9584cb74591e35a73fb458/nova/tests/unit/test_quota.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/test_quota.py?ref=72058b7a405bade6ca9584cb74591e35a73fb458",
"patch":"@@ -109,15 +109,15 @@ def test_too_many_instances(self):\n             self.compute_api.create(\n                 self.context, min_count=1, max_count=1,\n                 flavor=self.flavor, image_href=image_uuid)\n-        except exception.QuotaError as e:\n+        except exception.OverQuota as e:\n             expected_kwargs = {'code': 413,\n                                'req': '1, 1',\n                                'used': '8, 2',\n                                'allowed': '4, 2',\n                                'overs': 'cores, instances'}\n             self.assertEqual(expected_kwargs, e.kwargs)\n         else:\n-            self.fail('Expected QuotaError exception')\n+            self.fail('Expected OverQuota exception')\n \n     def test_too_many_cores(self):\n         self._create_instance()\n@@ -126,15 +126,15 @@ def test_too_many_cores(self):\n             self.compute_api.create(\n                 self.context, min_count=1, max_count=1, flavor=self.flavor,\n                 image_href=image_uuid)\n-        except exception.QuotaError as e:\n+        except exception.OverQuota as e:\n             expected_kwargs = {'code': 413,\n                                'req': '1',\n                                'used': '4',\n                                'allowed': '4',\n                                'overs': 'cores'}\n             self.assertEqual(expected_kwargs, e.kwargs)\n         else:\n-            self.fail('Expected QuotaError exception')\n+            self.fail('Expected OverQuota exception')\n \n     def test_many_cores_with_unlimited_quota(self):\n         # Setting cores quota to unlimited:\n@@ -150,7 +150,7 @@ def test_too_many_metadata_items(self):\n             metadata['key%s' % i] = 'value%s' % i\n         image_uuid = 'cedef40a-ed67-4d10-800e-17455edce175'\n         self.assertRaises(\n-            exception.QuotaError, self.compute_api.create,\n+            exception.OverQuota, self.compute_api.create,\n             self.context, min_count=1, max_count=1, flavor=self.flavor,\n             image_href=image_uuid, metadata=metadata)\n \n@@ -170,39 +170,39 @@ def test_max_injected_files(self):\n         files = []\n         for i in range(CONF.quota.injected_files):\n             files.append(('/my/path%d' % i, 'config = test\\n'))\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_files(self):\n         files = []\n         for i in range(CONF.quota.injected_files + 1):\n             files.append(('/my/path%d' % i, 'my\\ncontent%d\\n' % i))\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n     def test_max_injected_file_content_bytes(self):\n         max = CONF.quota.injected_file_content_bytes\n         content = ''.join(['a' for i in range(max)])\n         files = [('/test/path', content)]\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_file_content_bytes(self):\n         max = CONF.quota.injected_file_content_bytes\n         content = ''.join(['a' for i in range(max + 1)])\n         files = [('/test/path', content)]\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n     def test_max_injected_file_path_bytes(self):\n         max = CONF.quota.injected_file_path_length\n         path = ''.join(['a' for i in range(max)])\n         files = [(path, 'config = quotatest')]\n-        self._create_with_injected_files(files)  # no QuotaError\n+        self._create_with_injected_files(files)  # no OverQuota\n \n     def test_too_many_injected_file_path_bytes(self):\n         max = CONF.quota.injected_file_path_length\n         path = ''.join(['a' for i in range(max + 1)])\n         files = [(path, 'config = quotatest')]\n-        self.assertRaises(exception.QuotaError,\n+        self.assertRaises(exception.OverQuota,\n                           self._create_with_injected_files, files)\n \n "
}
]
},
{
"commit_sha":"1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"commit_node_id":"C_kwDOAAwOD9oAKDFmNzE2OTZlY2MyY2QxYWJmYzMwZjJmMDNmM2M0ODU3ZTUxYjlmYmY",
"commit_html_url":"https://github.com/openstack/nova/commit/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"commit_date":"2022-01-16T18:53:49Z",
"files":[
{
"sha":"cd8450ef717970a866d566d90c5191bcdbde3169",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":48,
"deletions":6,
"changes":54,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -668,7 +668,8 @@ def _unbind_ports(self, context, ports,\n             # information in the binding profile.\n             for profile_key in ('pci_vendor_info', 'pci_slot',\n                                 constants.ALLOCATION, 'arq_uuid',\n-                                'physical_network', 'card_serial_number'):\n+                                'physical_network', 'card_serial_number',\n+                                'vf_num', 'pf_mac_address'):\n                 if profile_key in port_profile:\n                     del port_profile[profile_key]\n             port_req_body['port'][constants.BINDING_PROFILE] = port_profile\n@@ -1504,6 +1505,50 @@ def delete_port_binding(self, context, port_id, host):\n                 raise exception.PortBindingDeletionFailed(\n                     port_id=port_id, host=host)\n \n+    def _get_vf_pci_device_profile(self, pci_dev):\n+        \"\"\"Get VF-specific fields to add to the PCI device profile.\n+\n+        This data can be useful, e.g. for off-path networking backends that\n+        need to do the necessary plumbing in order to set a VF up for packet\n+        forwarding.\n+        \"\"\"\n+        vf_profile: ty.Dict[str, ty.Union[str, int]] = {}\n+        try:\n+            pf_mac = pci_utils.get_mac_by_pci_address(pci_dev.parent_addr)\n+        except (exception.PciDeviceNotFoundById) as e:\n+            LOG.debug(\n+                \"Could not determine PF MAC address for a VF with\"\n+                \" addr %(addr)s, error: %(e)s\",\n+                {\"addr\": pci_dev.address, \"e\": e})\n+            # NOTE(dmitriis): we do not raise here since not all PFs will\n+            # have netdevs even when VFs are netdevs (see LP: #1915255). The\n+            # rest of the fields (VF number and card serial) are not enough\n+            # to fully identify the VF so they are not populated either.\n+            return vf_profile\n+        try:\n+            vf_num = pci_utils.get_vf_num_by_pci_address(\n+                pci_dev.address)\n+        except exception.PciDeviceNotFoundById as e:\n+            # This is unlikely to happen because the kernel has a common SR-IOV\n+            # code that creates physfn symlinks, however, it would be better\n+            # to avoid raising an exception here and simply warn an operator\n+            # that things did not go as planned.\n+            LOG.warning(\n+                \"Could not determine a VF logical number for a VF\"\n+                \" with addr %(addr)s, error: %(e)s\", {\n+                    \"addr\": pci_dev.address, \"e\": e})\n+            return vf_profile\n+        card_serial_number = pci_dev.card_serial_number\n+        if card_serial_number:\n+            vf_profile.update({\n+                'card_serial_number': card_serial_number\n+            })\n+        vf_profile.update({\n+            'pf_mac_address': pf_mac,\n+            'vf_num': vf_num,\n+        })\n+        return vf_profile\n+\n     def _get_pci_device_profile(self, pci_dev):\n         dev_spec = self.pci_whitelist.get_devspec(pci_dev)\n         if dev_spec:\n@@ -1516,11 +1561,8 @@ def _get_pci_device_profile(self, pci_dev):\n                 ),\n             }\n             if pci_dev.dev_type == obj_fields.PciDeviceType.SRIOV_VF:\n-                card_serial_number = pci_dev.card_serial_number\n-                if card_serial_number:\n-                    dev_profile.update({\n-                        'card_serial_number': card_serial_number\n-                    })\n+                dev_profile.update(\n+                    self._get_vf_pci_device_profile(pci_dev))\n             return dev_profile\n \n         raise exception.PciDeviceNotFound(node_id=pci_dev.compute_node_id,"
},
{
"sha":"90c20056b5c0612c909b0eb159fb8a302458ddac",
"filename":"nova/pci/utils.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/pci/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/pci/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/pci/utils.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -191,7 +191,7 @@ def get_mac_by_pci_address(pci_addr: str, pf_interface: bool = False) -> str:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n \n-def get_vf_num_by_pci_address(pci_addr: str) -> str:\n+def get_vf_num_by_pci_address(pci_addr: str) -> int:\n     \"\"\"Get the VF number based on a VF's pci address\n \n     A VF is associated with an VF number, which ip link command uses to\n@@ -210,4 +210,4 @@ def get_vf_num_by_pci_address(pci_addr: str) -> str:\n     else:\n         raise exception.PciDeviceNotFoundById(id=pci_addr)\n \n-    return vf_num\n+    return int(vf_num)"
},
{
"sha":"445c49a8e26f3e9d53af652f1359167b593516c5",
"filename":"nova/tests/fixtures/libvirt.py",
"status":"modified",
"additions":4,
"deletions":0,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/fixtures/libvirt.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/fixtures/libvirt.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/libvirt.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -2162,6 +2162,10 @@ def setUp(self):\n             'nova.pci.utils.get_ifname_by_pci_address',\n             return_value='fake_pf_interface_name'))\n \n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_mac_by_pci_address',\n+            return_value='52:54:00:1e:59:c6'))\n+\n         # libvirt calls out to sysfs to get the vfs ID during macvtap plug\n         self.useFixture(fixtures.MockPatch(\n             'nova.pci.utils.get_vf_num_by_pci_address', return_value=1))"
},
{
"sha":"bd16f42408bd26880e983d00ec67140776d38adf",
"filename":"nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"status":"modified",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/functional/libvirt/test_pci_sriov_servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/libvirt/test_pci_sriov_servers.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -287,6 +287,8 @@ def fake_create(cls, xml, host):\n                 'pci_vendor_info': '8086:1515',\n                 'pci_slot': '0000:81:00.2',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )\n@@ -529,6 +531,8 @@ def test_live_migrate_server_with_neutron(self):\n                 # matching one)\n                 'pci_slot': '0000:81:01.4',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )\n@@ -561,6 +565,8 @@ def test_live_migrate_server_with_neutron(self):\n                 'pci_vendor_info': '8086:1515',\n                 'pci_slot': '0000:81:00.2',\n                 'physical_network': 'physnet4',\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n             },\n             port['binding:profile'],\n         )"
},
{
"sha":"6663ebe8cd3faa735a265f6f51fc16a90cf0c678",
"filename":"nova/tests/functional/regressions/test_bug_1896463.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/functional/regressions/test_bug_1896463.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/functional/regressions/test_bug_1896463.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/regressions/test_bug_1896463.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -51,6 +51,14 @@ def setUp(self):\n         self.api_fixture = self.useFixture(nova_fixtures.OSAPIFixture(\n             api_version='v2.1'))\n \n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_mac_by_pci_address',\n+            return_value='52:54:00:1e:59:c6'))\n+\n+        self.useFixture(fixtures.MockPatch(\n+            'nova.pci.utils.get_vf_num_by_pci_address',\n+            return_value=1))\n+\n         self.admin_api = self.api_fixture.admin_api\n         self.admin_api.microversion = 'latest'\n         self.api = self.admin_api"
},
{
"sha":"0671897a010bfa8d61f7ec387bd347b957c1b4b4",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":197,
"deletions":16,
"changes":213,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -4478,16 +4478,16 @@ def test_update_port_bindings_for_instance_same_host(\n                       'device_owner': 'compute:%s' %\n                                       instance.availability_zone}})\n \n+    @mock.patch.object(neutronapi.API, '_get_vf_pci_device_profile',\n+                       new=mock.Mock(return_value={}))\n     @mock.patch(\n         'nova.network.neutron.API.has_extended_resource_request_extension',\n         new=mock.Mock(return_value=False),\n     )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(neutronapi, 'get_client', return_value=mock.Mock())\n-    def test_update_port_bindings_for_instance_with_pci(self,\n-                                            get_client_mock,\n-                                            get_pci_device_devspec_mock):\n-\n+    def test_update_port_bindings_for_instance_with_pci(\n+            self, get_client_mock, get_pci_device_devspec_mock):\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         get_pci_device_devspec_mock.return_value = devspec\n@@ -7395,11 +7395,16 @@ def test_populate_neutron_extension_values_binding(self, mock_get_client):\n         mock_get_client.assert_called_once_with(mock.ANY)\n         mocked_client.list_extensions.assert_called_once_with()\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value={\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+        }))\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_populate_neutron_extension_values_binding_sriov(self,\n-                                         mock_get_instance_pci_devs,\n-                                         mock_get_pci_device_devspec):\n+    def test_populate_neutron_extension_values_binding_sriov(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n         port_req_body = {'port': {}}\n@@ -7408,7 +7413,7 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n                    'card_serial_number': None,\n-                   'dev_type': 'TEST_TYPE',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n                                ['vendor_id', 'product_id', 'address',\n@@ -7417,19 +7422,30 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         mock_get_pci_device_devspec.return_value = devspec\n+\n         self.api._populate_neutron_binding_profile(\n             instance, pci_req_id, port_req_body, None)\n \n         self.assertEqual(profile,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value= {\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+            'card_serial_number': 'MT2113X00000',\n+        })\n+    )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n     def test_populate_neutron_extension_values_binding_sriov_card_serial(\n@@ -7440,7 +7456,7 @@ def test_populate_neutron_extension_values_binding_sriov_card_serial(\n         pci_req_id = 'my_req_id'\n         pci_dev = {'vendor_id': 'a2d6',\n                    'product_id': '15b3',\n-                   'address': '0000:82:00.1',\n+                   'address': '0000:0a:00.1',\n                    'card_serial_number': 'MT2113X00000',\n                    'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n@@ -7449,11 +7465,13 @@ def test_populate_neutron_extension_values_binding_sriov_card_serial(\n                                 'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': 'a2d6:15b3',\n-                   'pci_slot': '0000:82:00.1',\n+                   'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n                    # card_serial_number is a property of the object obtained\n                    # from extra_info.\n                    'card_serial_number': 'MT2113X00000',\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n@@ -7505,11 +7523,17 @@ def test_populate_neutron_extension_values_with_arq(self,\n             profile,\n             port_req_body['port'][constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.Mock(return_value= {\n+            'pf_mac_address': '52:54:00:1e:59:c6',\n+            'vf_num': 1,\n+        })\n+    )\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n-                                         mock_get_instance_pci_devs,\n-                                         mock_get_pci_device_devspec):\n+    def test_populate_neutron_extension_values_binding_sriov_with_cap(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n         port_req_body = {'port': {\n@@ -7520,7 +7544,7 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n                    'card_serial_number': None,\n-                   'dev_type': 'TEST_TYPE',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n                                ['vendor_id', 'product_id', 'address',\n@@ -7530,19 +7554,165 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n                    'pci_slot': '0000:0a:00.1',\n                    'physical_network': 'physnet1',\n                    'capabilities': ['switchdev'],\n+                   'pf_mac_address': '52:54:00:1e:59:c6',\n+                   'vf_num': 1,\n                   }\n \n         mock_get_instance_pci_devs.return_value = [mydev]\n         devspec = mock.Mock()\n         devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n         mock_get_pci_device_devspec.return_value = devspec\n+\n         self.api._populate_neutron_binding_profile(\n             instance, pci_req_id, port_req_body, None)\n \n         self.assertEqual(profile,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: 1\n+                     if vf_a == '0000:0a:00.1' else None)))\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a)))\n+    )\n+    def test__get_vf_pci_device_profile(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev),\n+                         {'pf_mac_address': '52:54:00:1e:59:c6',\n+                          'vf_num': 1,\n+                          'card_serial_number': 'MT2113X00000'})\n+\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=exception.PciDeviceNotFoundById(id='0000:0a:00.1'))\n+    )\n+    def test__get_vf_pci_device_profile_invalid_pf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev), {})\n+\n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=exception.PciDeviceNotFoundById(id='0000:0a:00.0'))\n+    )\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a))))\n+    def test__get_vf_pci_device_profile_invalid_vf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        vf_profile = self.api._get_vf_pci_device_profile(mydev)\n+        self.assertEqual(vf_profile, {})\n+\n+    def test__get_vf_pci_device_profile_not_vf_address(self):\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'parent_addr': None,\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type',\n+                                'parent_addr'])\n+        mydev = PciDevice(**pci_dev)\n+        self.assertEqual(self.api._get_vf_pci_device_profile(mydev), {})\n+\n+    @mock.patch.object(\n+        neutronapi.API, '_get_vf_pci_device_profile',\n+        new=mock.MagicMock(side_effect=(\n+            lambda dev: {'0000:0a:00.1': {\n+                'pf_mac_address': '52:54:00:1e:59:c6',\n+                'vf_num': 1,\n+                'card_serial_number': 'MT2113X00000',\n+            }}.get(dev.address)\n+    )))\n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    def test__get_pci_device_profile_vf(self, mock_get_pci_device_devspec):\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.1',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+\n+        self.assertEqual({'card_serial_number': 'MT2113X00000',\n+                          'pci_slot': '0000:0a:00.1',\n+                          'pci_vendor_info': 'a2d6:15b3',\n+                          'pf_mac_address': '52:54:00:1e:59:c6',\n+                          'physical_network': 'physnet1',\n+                          'vf_num': 1},\n+                         self.api._get_pci_device_profile(mydev))\n+\n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    def test__get_pci_device_profile_pf(self, mock_get_pci_device_devspec):\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:0a:00.0',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_PF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+\n+        self.assertEqual({'pci_slot': '0000:0a:00.0',\n+                          'pci_vendor_info': 'a2d6:15b3',\n+                          'physical_network': 'physnet1'},\n+                         self.api._get_pci_device_profile(mydev))\n+\n     @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n     def test_populate_neutron_extension_values_binding_sriov_fail(\n@@ -7578,9 +7748,19 @@ def test_populate_neutron_binding_profile_pci_dev_not_found(\n         mock_get_instance_pci_devs.assert_called_once_with(\n             instance, pci_req_id)\n \n+    @mock.patch.object(\n+        pci_utils, 'get_vf_num_by_pci_address',\n+        new=mock.MagicMock(\n+            side_effect=(lambda vf_a: {'0000:0a:00.1': 1}.get(vf_a)))\n+    )\n+    @mock.patch.object(\n+        pci_utils, 'get_mac_by_pci_address',\n+        new=mock.MagicMock(side_effect=(lambda vf_a: {\n+            '0000:0a:00.0': '52:54:00:1e:59:c6'}.get(vf_a)))\n+    )\n     @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n-    def test_pci_parse_whitelist_called_once(self,\n-                                             mock_get_instance_pci_devs):\n+    def test_pci_parse_whitelist_called_once(\n+        self, mock_get_instance_pci_devs):\n         white_list = [\n             '{\"address\":\"0000:0a:00.1\",\"physical_network\":\"default\"}']\n         cfg.CONF.set_override('passthrough_whitelist', white_list, 'pci')\n@@ -7595,6 +7775,7 @@ def test_pci_parse_whitelist_called_once(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'parent_addr': '0000:0a:00.0',\n                    'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n "
},
{
"sha":"0c45e93f9442caf9dab36ae5e256d464ca5576f9",
"filename":"nova/tests/unit/pci/test_utils.py",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/unit/pci/test_utils.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/tests/unit/pci/test_utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/pci/test_utils.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -239,7 +239,7 @@ def test_vf_number_found(self, mock_iglob, mock_readlink):\n         mock_iglob.return_value = self.paths\n         mock_readlink.return_value = '../../0000:00:00.1'\n         vf_num = utils.get_vf_num_by_pci_address(self.pci_address)\n-        self.assertEqual(vf_num, '3')\n+        self.assertEqual(vf_num, 3)\n \n     @mock.patch.object(os, 'readlink')\n     @mock.patch.object(glob, 'iglob')"
},
{
"sha":"e0bcda554ca5d60f671e36d64cc5ac94adda012c",
"filename":"nova/virt/fake.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/virt/fake.py",
"raw_url":"https://github.com/openstack/nova/raw/1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf/nova/virt/fake.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/fake.py?ref=1f71696ecc2cd1abfc30f2f03f3c4857e51b9fbf",
"patch":"@@ -954,6 +954,14 @@ def setUp(self):\n             ],\n                              group='pci')\n \n+            self.useFixture(fixtures.MockPatch(\n+                'nova.pci.utils.get_mac_by_pci_address',\n+                return_value='52:54:00:1e:59:c6'))\n+\n+            self.useFixture(fixtures.MockPatch(\n+                'nova.pci.utils.get_vf_num_by_pci_address',\n+                return_value=1))\n+\n     def get_available_resource(self, nodename):\n         host_status = super(\n             FakeDriverWithPciResources, self).get_available_resource(nodename)"
}
]
},
{
"commit_sha":"9111b99f739d41c092db8d01712a5aa72388b5fb",
"commit_node_id":"C_kwDOAAwOD9oAKDkxMTFiOTlmNzM5ZDQxYzA5MmRiOGQwMTcxMmE1YWE3MjM4OGI1ZmI",
"commit_html_url":"https://github.com/openstack/nova/commit/9111b99f739d41c092db8d01712a5aa72388b5fb",
"commit_date":"2022-02-04T14:01:36Z",
"files":[
{
"sha":"4d62c74115f72775769bab66ef4d58344e29a9a4",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":8,
"deletions":3,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/9111b99f739d41c092db8d01712a5aa72388b5fb/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/9111b99f739d41c092db8d01712a5aa72388b5fb/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=9111b99f739d41c092db8d01712a5aa72388b5fb",
"patch":"@@ -21544,6 +21544,8 @@ def test_migrate_disk_and_power_off_exception(\n                           context.get_admin_context(), ins_ref, '10.0.0.2',\n                           flavor_obj, None)\n \n+    @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.'\n+                '_cleanup_failed_instance_base')\n     @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs')\n     @mock.patch('nova.virt.libvirt.utils.save_and_migrate_vtpm_dir')\n     @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.'\n@@ -21560,7 +21562,7 @@ def _test_migrate_disk_and_power_off(\n             self, ctxt, flavor_obj, mock_execute, mock_exists, mock_rename,\n             mock_is_shared, mock_get_host_ip, mock_destroy,\n             mock_get_disk_info, mock_vtpm, mock_unplug_vifs,\n-            block_device_info=None, params_for_instance=None):\n+            mock_cleanup, block_device_info=None, params_for_instance=None):\n         \"\"\"Test for nova.virt.libvirt.driver.LivirtConnection\n         .migrate_disk_and_power_off.\n         \"\"\"\n@@ -21575,6 +21577,8 @@ def _test_migrate_disk_and_power_off(\n                ctxt, instance, '10.0.0.2', flavor_obj, None,\n                block_device_info=block_device_info)\n \n+        mock_cleanup.assert_called_once()\n+        mock_cleanup.reset_mock()\n         self.assertEqual(out, disk_info_text)\n         mock_vtpm.assert_called_with(\n             instance.uuid, mock.ANY, mock.ANY, '10.0.0.2', mock.ANY, mock.ANY)\n@@ -21585,6 +21589,7 @@ def _test_migrate_disk_and_power_off(\n                ctxt, instance, '10.0.0.1', flavor_obj, None,\n                block_device_info=block_device_info)\n \n+        mock_cleanup.assert_called_once()\n         self.assertEqual(out, disk_info_text)\n         mock_vtpm.assert_called_with(\n             instance.uuid, mock.ANY, mock.ANY, '10.0.0.1', mock.ANY, mock.ANY)\n@@ -22514,8 +22519,8 @@ def test_finish_revert_migration_snap_backend_image_does_not_exist(self):\n             self.assertFalse(drvr.image_backend.remove_snap.called)\n \n     @mock.patch.object(shutil, 'rmtree')\n-    def test_cleanup_failed_migration(self, mock_rmtree):\n-        self.drvr._cleanup_failed_migration('/fake/inst')\n+    def test_cleanup_failed_instance_base(self, mock_rmtree):\n+        self.drvr._cleanup_failed_instance_base('/fake/inst')\n         mock_rmtree.assert_called_once_with('/fake/inst')\n \n     @mock.patch.object(libvirt_driver.LibvirtDriver, '_cleanup_resize')"
},
{
"sha":"f83046b5016b2d32b47171edca601babc9294019",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":7,
"deletions":4,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/9111b99f739d41c092db8d01712a5aa72388b5fb/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/9111b99f739d41c092db8d01712a5aa72388b5fb/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=9111b99f739d41c092db8d01712a5aa72388b5fb",
"patch":"@@ -10973,6 +10973,9 @@ def migrate_disk_and_power_off(self, context, instance, dest,\n         disk_info = self._get_instance_disk_info(instance, block_device_info)\n \n         try:\n+            # If cleanup failed in previous resize attempts we try to remedy\n+            # that before a resize is tried again\n+            self._cleanup_failed_instance_base(inst_base_resize)\n             os.rename(inst_base, inst_base_resize)\n             # if we are migrating the instance with shared instance path then\n             # create the directory.  If it is a remote node the directory\n@@ -11196,9 +11199,9 @@ def finish_migration(\n \n         LOG.debug(\"finish_migration finished successfully.\", instance=instance)\n \n-    def _cleanup_failed_migration(self, inst_base):\n-        \"\"\"Make sure that a failed migrate doesn't prevent us from rolling\n-        back in a revert.\n+    def _cleanup_failed_instance_base(self, inst_base):\n+        \"\"\"Make sure that a failed migrate or resize doesn't prevent us from\n+        rolling back in a revert or retrying a resize.\n         \"\"\"\n         try:\n             shutil.rmtree(inst_base)\n@@ -11254,7 +11257,7 @@ def finish_revert_migration(\n         # that would conflict. Also, don't fail on the rename if the\n         # failure happened early.\n         if os.path.exists(inst_base_resize):\n-            self._cleanup_failed_migration(inst_base)\n+            self._cleanup_failed_instance_base(inst_base)\n             os.rename(inst_base_resize, inst_base)\n \n         root_disk = self.image_backend.by_name(instance, 'disk')"
},
{
"sha":"7a89c66092f3cc73a96d0c63aa426d8e6a769fcd",
"filename":"releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"status":"added",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/9111b99f739d41c092db8d01712a5aa72388b5fb/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"raw_url":"https://github.com/openstack/nova/raw/9111b99f739d41c092db8d01712a5aa72388b5fb/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/bug-1960230-cleanup-instances-dir-resize-56282e1b436a4908.yaml?ref=9111b99f739d41c092db8d01712a5aa72388b5fb",
"patch":"@@ -0,0 +1,6 @@\n+---\n+fixes:\n+  - |\n+    Fixed bug `1960230 <https://bugs.launchpad.net/nova/+bug/1960230>`_ that\n+    prevented resize of instances that had previously failed and not been\n+    cleaned up."
}
]
},
{
"commit_sha":"2aa1ed5810b67b9a8f18b2ec5e21004f93831168",
"commit_node_id":"C_kwDOAAwOD9oAKDJhYTFlZDU4MTBiNjdiOWE4ZjE4YjJlYzVlMjEwMDRmOTM4MzExNjg",
"commit_html_url":"https://github.com/openstack/nova/commit/2aa1ed5810b67b9a8f18b2ec5e21004f93831168",
"commit_date":"2022-01-28T08:39:20Z",
"files":[
{
"sha":"642e553094c8810de2ec4537a474a1f337195db7",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":2,
"deletions":0,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/2aa1ed5810b67b9a8f18b2ec5e21004f93831168/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/2aa1ed5810b67b9a8f18b2ec5e21004f93831168/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=2aa1ed5810b67b9a8f18b2ec5e21004f93831168",
"patch":"@@ -366,6 +366,8 @@\n the announce-self command to the QEMU monitor so that it generates RARP frames\n to update network switches in the post live migration phase on the destination.\n \n+Please note that this causes the domain to be considered tainted by libvirt.\n+\n Related options:\n \n * :oslo.config:option:`DEFAULT.compute_driver` (libvirt)"
}
]
},
{
"commit_sha":"b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"commit_node_id":"C_kwDOAAwOD9oAKGI2ZmU3NTIxYWZhOGQ0MmZlYmM2OGY1Zjc5NzgyZjdiY2MzYjU2OGY",
"commit_html_url":"https://github.com/openstack/nova/commit/b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"commit_date":"2022-02-07T10:27:51Z",
"files":[
{
"sha":"68695b758d279c63df4933734bfa64cf907236e1",
"filename":"doc/source/admin/architecture.rst",
"status":"modified",
"additions":29,
"deletions":35,
"changes":64,
"blob_url":"https://github.com/openstack/nova/blob/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/architecture.rst",
"raw_url":"https://github.com/openstack/nova/raw/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/architecture.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/architecture.rst?ref=b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"patch":"@@ -11,23 +11,26 @@ reads/writes, optionally sending RPC messages to other Nova services,\n and generating responses to the REST calls.\n RPC messaging is done via the **oslo.messaging** library,\n an abstraction on top of message queues.\n-Nova uses a messaging-based, ``shared nothing`` architecture and most of the\n+Nova uses a messaging-based, \"shared nothing\" architecture and most of the\n major nova components can be run on multiple servers, and have a manager that\n is listening for RPC messages.\n-The one major exception is ``nova-compute``, where a single process runs on the\n+The one major exception is the compute service, where a single process runs on the\n hypervisor it is managing (except when using the VMware or Ironic drivers).\n The manager also, optionally, has periodic tasks.\n-For more details on our RPC system, please see: :doc:`/reference/rpc`\n+For more details on our RPC system, refer to :doc:`/reference/rpc`.\n \n-Nova also uses a central database that is (logically) shared between all\n-components. However, to aid upgrade, the DB is accessed through an object\n-layer that ensures an upgraded control plane can still communicate with\n-a ``nova-compute`` running the previous release.\n-To make this possible ``nova-compute`` proxies DB requests over RPC to a\n-central manager called ``nova-conductor``.\n+Nova uses traditional SQL databases to store information.\n+These are (logically) shared between multiple components.\n+To aid upgrade, the database is accessed through an object layer that ensures\n+an upgraded control plane can still communicate with a compute nodes running\n+the previous release.\n+To make this possible, services running on the compute node proxy database\n+requests over RPC to a central manager called the conductor.\n \n To horizontally expand Nova deployments, we have a deployment sharding\n-concept called cells. For more information please see: :doc:`/admin/cells`\n+concept called :term:`cells <cell>`.\n+All deployments contain at least one cell.\n+For more information, refer to :doc:`/admin/cells`.\n \n \n Components\n@@ -109,11 +112,9 @@ projects on a shared system, and role-based access assignments. Roles control\n the actions that a user is allowed to perform.\n \n Projects are isolated resource containers that form the principal\n-organizational structure within the Nova service. They typically consist of an\n-individual VLAN, and volumes, instances, images, keys, and users. A user can\n-specify the project by appending ``project_id`` to their access key.  If no\n-project is specified in the API request, Nova attempts to use a project with\n-the same ID as the user.\n+organizational structure within the Nova service. They typically consist of\n+networks, volumes, instances, images, keys, and users. A user can\n+specify the project by appending ``project_id`` to their access key.\n \n For projects, you can use quota controls to limit the number of processor cores\n and the amount of RAM that can be allocated. Other projects also allow quotas\n@@ -142,21 +143,22 @@ consumption across available hardware resources.\n Block storage\n -------------\n \n-OpenStack provides two classes of block storage: ephemeral storage and\n-persistent volume.\n+OpenStack provides two classes of block storage: storage that is provisioned by\n+Nova itself, and storage that is managed by the block storage service, Cinder.\n \n-.. rubric:: Ephemeral storage\n+.. rubric:: Nova-provisioned block storage\n \n-Ephemeral storage includes a root ephemeral volume and an additional ephemeral\n-volume. These are provided by nova itself.\n+Nova provides the ability to create a root disk and an optional \"ephemeral\"\n+volume. The root disk will always be present unless the instance is a\n+:term:`Boot From Volume` instance.\n \n The root disk is associated with an instance, and exists only for the life of\n this very instance. Generally, it is used to store an instance's root file\n system, persists across the guest operating system reboots, and is removed on\n an instance deletion. The amount of the root ephemeral volume is defined by the\n flavor of an instance.\n \n-In addition to the ephemeral root volume, flavors can provide an additional\n+In addition to the root volume, flavors can provide an additional\n ephemeral block device. It is represented as a raw block device with no\n partition table or file system. A cloud-aware operating system can discover,\n format, and mount such a storage device. Nova defines the default file system\n@@ -171,17 +173,17 @@ is possible to configure other filesystem types.\n    mounts it on ``/mnt``. This is a cloud-init feature, and is not an OpenStack\n    mechanism. OpenStack only provisions the raw storage.\n \n-.. rubric:: Persistent volume\n+.. rubric:: Cinder-provisioned block storage\n \n-A persistent volume is represented by a persistent virtualized block device\n-independent of any particular instance. These are provided by the OpenStack\n-Block Storage service, cinder.\n+The OpenStack Block Storage service, Cinder, provides persistent volumes hat\n+are represented by a persistent virtualized block device independent of any\n+particular instance.\n \n Persistent volumes can be accessed by a single instance or attached to multiple\n instances. This type of configuration requires a traditional network file\n system to allow multiple instances accessing the persistent volume. It also\n requires a traditional network file system like NFS, CIFS, or a cluster file\n-system such as GlusterFS. These systems can be built within an OpenStack\n+system such as Ceph. These systems can be built within an OpenStack\n cluster, or provisioned outside of it, but OpenStack software does not provide\n these features.\n \n@@ -194,14 +196,6 @@ if the instance is shut down. For more information about this type of\n configuration, see :cinder-doc:`Introduction to the Block Storage service\n <configuration/block-storage/block-storage-overview.html>`.\n \n-.. note::\n-\n-   A persistent volume does not provide concurrent access from multiple\n-   instances. That type of configuration requires a traditional network file\n-   system like NFS, or CIFS, or a cluster file system such as GlusterFS. These\n-   systems can be built within an OpenStack cluster, or provisioned outside of\n-   it, but OpenStack software does not provide these features.\n-\n \n Building blocks\n ---------------\n@@ -245,7 +239,7 @@ The displayed image attributes are:\n \n Virtual hardware templates are called ``flavors``. By default, these are\n configurable by admin users, however, that behavior can be changed by redefining\n-the access controls ``policy.yaml`` on the ``nova-compute`` server. For more\n+the access controls ``policy.yaml`` on the ``nova-api`` server. For more\n information, refer to :doc:`/configuration/policy`.\n \n For a list of flavors that are available on your system:"
},
{
"sha":"ffe1be06f97d1f7fb7272f5f349b9aeb70575f95",
"filename":"doc/source/admin/availability-zones.rst",
"status":"modified",
"additions":16,
"deletions":9,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/availability-zones.rst",
"raw_url":"https://github.com/openstack/nova/raw/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/availability-zones.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/availability-zones.rst?ref=b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"patch":"@@ -9,15 +9,22 @@ Availability Zones\n     zones, refer to the :doc:`user guide </user/availability-zones>`.\n \n Availability Zones are an end-user visible logical abstraction for partitioning\n-a cloud without knowing the physical infrastructure. Availability zones are not\n-modeled in the database; rather, they are defined by attaching specific\n-metadata information to an :doc:`aggregate </admin/aggregates>` The addition of\n-this specific metadata to an aggregate makes the aggregate visible from an\n-end-user perspective and consequently allows users to schedule instances to a\n-specific set of hosts, the ones belonging to the aggregate.\n-\n-However, despite their similarities, there are a few additional differences to\n-note when comparing availability zones and host aggregates:\n+a cloud without knowing the physical infrastructure. They can be used to\n+partition a cloud on arbitrary factors, such as location (country, datacenter,\n+rack), network layout and/or power source.\n+\n+.. note::\n+\n+   Availability Zones should not be assumed to map to fault domains and provide\n+   no intrinsic HA benefit by themselves.\n+\n+Availability zones are not modeled in the database; rather, they are defined by\n+attaching specific metadata information to an\n+:doc:`aggregate </admin/aggregates>` The addition of this specific metadata to\n+an aggregate makes the aggregate visible from an end-user perspective and\n+consequently allows users to schedule instances to a specific set of hosts, the\n+ones belonging to the aggregate. There are a few additional differences to note\n+when comparing availability zones and host aggregates:\n \n - A host can be part of multiple aggregates but it can only be in one\n   availability zone."
},
{
"sha":"bad3566bd92a7e5c04ccb1297db7e9521b85bd44",
"filename":"doc/source/admin/cells.rst",
"status":"modified",
"additions":50,
"deletions":68,
"changes":118,
"blob_url":"https://github.com/openstack/nova/blob/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/cells.rst",
"raw_url":"https://github.com/openstack/nova/raw/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/cells.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/cells.rst?ref=b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"patch":"@@ -26,9 +26,13 @@ Laski gave at the Austin (Newton) summit which may be worth watching.\n Overview\n --------\n \n-The purpose of the cells functionality in nova is specifically to\n-allow larger deployments to shard their many compute nodes into cells.\n-A basic Nova system consists of the following components:\n+The purpose of the cells functionality in nova is to allow larger deployments\n+to shard their many compute nodes into cells. All nova deployments are by\n+definition cells deployments, even if most will only ever have a single cell.\n+This means a multi-cell deployment will not b radically different from a\n+\"standard\" nova deployment.\n+\n+Consider such a deployment. It will consists of the following components:\n \n - The :program:`nova-api` service which provides the external REST API to\n   users.\n@@ -43,7 +47,7 @@ A basic Nova system consists of the following components:\n   instances being built but not yet scheduled.\n \n - The :program:`nova-conductor` service which offloads long-running tasks for\n-  the API-level service and insulates compute nodes from direct database access\n+  the API-level services and insulates compute nodes from direct database access\n \n - The :program:`nova-compute` service which manages the virt driver and\n   hypervisor host.\n@@ -60,15 +64,19 @@ A basic Nova system consists of the following components:\n - A message queue which allows the services to communicate with each\n   other via RPC.\n \n-All deployments have at least the above components. Smaller deployments\n-likely have a single message queue that all services share and a\n-single database server which hosts the API database, a single cell\n-database, as well as the required cell0 database. This is considered a\n-\"single-cell deployment\" because it only has one \"real\" cell.\n-However, while there will only ever be one global API database, a larger\n-deployments can have many cell databases (where the bulk of the instance\n-information lives), each with a portion of the instances for the entire\n-deployment within, as well as per-cell message queues.\n+In smaller deployments, there will typically be a single message queue that all\n+services share and a single database server which hosts the API database, a\n+single cell database, as well as the required cell0 database. Because we only\n+have one \"real\" cell, we consider this a \"single-cell deployment\".\n+\n+In larger deployments, we can opt to shard the deployment using multiple cells.\n+In this configuration there will still only be one global API database but\n+there will be a cell database (where the bulk of the instance information\n+lives) for each cell, each containing a portion of the instances for the entire\n+deployment within, as well as per-cell message queues and per-cell\n+:program:`nova-conductor` instances. There will also be an additional\n+:program:`nova-conductor` instance, known as a *super conductor*, to handle\n+API-level operations.\n \n In these larger deployments, each of the nova services will use a cell-specific\n configuration file, all of which will at a minimum specify a message queue\n@@ -98,6 +106,9 @@ other cells in the API database, with records called *cell mappings*.\n    lower-level services. See the ``nova-manage`` :ref:`man-page-cells-v2`\n    commands for more information about how to create and examine these records.\n \n+The following section goes into more detail about the difference between\n+single-cell and multi-cell deployments.\n+\n \n Service layout\n --------------\n@@ -242,70 +253,42 @@ any other API-layer services via RPC, nor do they have access to the\n API database for global visibility of resources across the cloud.\n This is intentional and provides security and failure domain\n isolation benefits, but also has impacts on some things that would\n-otherwise require this any-to-any communication style. Check the\n-release notes for the version of Nova you are using for the most\n-up-to-date information about any caveats that may be present due to\n-this limitation.\n+otherwise require this any-to-any communication style. Check :ref:`upcall`\n+below for the most up-to-date information about any caveats that may be present\n+due to this limitation.\n \n \n Database layout\n ---------------\n \n As mentioned previously, there is a split between global data and data that is\n-local to a cell.\n+local to a cell. These databases schema are referred to as the *API* and *main*\n+database schemas, respectively.\n \n-The following is a breakdown of what data can uncontroversially considered\n-global versus local to a cell.  Missing data will be filled in as consensus is\n-reached on the data that is more difficult to cleanly place.  The missing data\n-is mostly concerned with scheduling and networking.\n-\n-.. note::\n+API database\n+~~~~~~~~~~~~\n \n-   This list of tables is accurate as of the 15.0.0 (Pike) release. It's\n-   possible that schema changes may have added additional tables since.\n+The API database is the database used for API-level services, such as\n+:program:`nova-api` and, in a multi-cell deployment, the superconductor.\n+The models and migrations related to this database can be found in\n+``nova.db.api``, and the database can be managed using the\n+:program:`nova-manage api_db` commands.\n \n-Global (API-level) tables\n-~~~~~~~~~~~~~~~~~~~~~~~~~\n+Main (cell-level) database\n+~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n-- ``instance_types``\n-- ``instance_type_projects``\n-- ``instance_type_extra_specs``\n-- ``quotas``\n-- ``project_user_quotas``\n-- ``quota_classes``\n-- ``quota_usages``\n-- ``security_groups``\n-- ``security_group_rules``\n-- ``security_group_default_rules``\n-- ``provider_fw_rules``\n-- ``key_pairs``\n-- ``migrations``\n-- ``networks``\n-- ``tags``\n-\n-Cell-level tables\n-~~~~~~~~~~~~~~~~~\n-\n-- ``instances``\n-- ``instance_info_caches``\n-- ``instance_extra``\n-- ``instance_metadata``\n-- ``instance_system_metadata``\n-- ``instance_faults``\n-- ``instance_actions``\n-- ``instance_actions_events``\n-- ``instance_id_mappings``\n-- ``pci_devices``\n-- ``block_device_mapping``\n-- ``virtual_interfaces``\n+The main database is the database used for cell-level :program:`nova-conductor`\n+instances. The models and migrations related to this database can be found in\n+``nova.db.main``, and the database can be managed using the\n+:program:`nova-manage db` commands.\n \n \n Usage\n -----\n \n As noted previously, all deployments are in effect now cells v2 deployments. As\n-a result, setup of a any nova deployment - even those that intend to only have\n-once cell - will involve some level of cells configuration. These changes are\n+a result, setup of any nova deployment - even those that intend to only have\n+one cell - will involve some level of cells configuration. These changes are\n configuration-related, both in the main nova configuration file as well as some\n extra records in the databases.\n \n@@ -345,11 +328,11 @@ Configuring a new deployment\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n If you are installing Nova for the first time and have no compute hosts in the\n-database yet then it will be necessary to configure cell0 and at least once\n-additional \"real\" cell. To begin, ensure your API database has been created\n-using the :program:`nova-manage api_db sync` command. Ensure the connection\n-information for this database is stored in the ``nova.conf`` file using the\n-:oslo.config:option:`api_database.connection` config option:\n+database yet then it will be necessary to configure cell0 and at least one\n+additional \"real\" cell. To begin, ensure your API database schema has been\n+populated using the :program:`nova-manage api_db sync` command. Ensure the\n+connection information for this database is stored in the ``nova.conf`` file\n+using the :oslo.config:option:`api_database.connection` config option:\n \n .. code-block:: ini\n \n@@ -557,7 +540,6 @@ existing instances to the new cell(s). For example:\n    have been mapped. An exit code of 1 indicates that there are remaining\n    instances that need to be mapped.\n \n-\n Template URLs in Cell Mappings\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n@@ -1152,7 +1134,7 @@ real-world users of the feature.\n - `Rocky Summit Video - Moving from CellsV1 to CellsV2 at CERN`__\n - `Stein Summit Video - Scaling Nova with CellsV2: The Nova Developer and the\n   CERN Operator perspective`__\n-- `Ussuri Summit Video - What's new in Nova Cellsv2?`__\n+- `Train Summit Video - What's new in Nova Cellsv2?`__\n \n .. __: https://www.openstack.org/videos/austin-2016/nova-cells-v2-whats-going-on\n .. __: https://www.openstack.org/videos/boston-2017/scaling-nova-how-cellsv2-affects-your-deployment"
},
{
"sha":"04078f0852c6cb7c547d8078e6a3ddbcb94de2fd",
"filename":"doc/source/admin/index.rst",
"status":"modified",
"additions":1,
"deletions":3,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/admin/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/index.rst?ref=b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"patch":"@@ -101,9 +101,7 @@ the defaults from the :doc:`install guide </install/index>` will be sufficient.\n \n * :doc:`Availablity Zones </admin/availability-zones>`: Availability Zones are\n   an end-user visible logical abstraction for partitioning a cloud without\n-  knowing the physical infrastructure. They can be used to partition a cloud on\n-  arbitrary factors, such as location (country, datacenter, rack), network\n-  layout and/or power source.\n+  knowing the physical infrastructure.\n \n * :placement-doc:`Placement service <>`: Overview of the placement\n   service, including how it fits in with the rest of nova."
},
{
"sha":"e48a4acc2e7d57dc001b00c566fe7e5291e2098e",
"filename":"doc/source/reference/glossary.rst",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/reference/glossary.rst",
"raw_url":"https://github.com/openstack/nova/raw/b6fe7521afa8d42febc68f5f79782f7bcc3b568f/doc/source/reference/glossary.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/reference/glossary.rst?ref=b6fe7521afa8d42febc68f5f79782f7bcc3b568f",
"patch":"@@ -23,6 +23,14 @@ Glossary\n         has an empty (\"\") ``image`` parameter in ``GET /servers/{server_id}``\n         responses.\n \n+    Cell\n+        A cell is a shard or horizontal partition in a nova deployment.\n+        A cell mostly consists of a database, queue, and set of compute nodes.\n+        All deployments willl have at least one cell (and one \"fake\" cell).\n+        Larger deployments can have many.\n+\n+        For more information, refer to :doc:`/admin/cells`.\n+\n     Cross-Cell Resize\n         A resize (or cold migrate) operation where the source and destination\n         compute hosts are mapped to different cells. By default, resize and"
}
]
},
{
"commit_sha":"87dd10dcd482c7711e81322ff04af4bced67f06d",
"commit_node_id":"C_kwDOAAwOD9oAKDg3ZGQxMGRjZDQ4MmM3NzExZTgxMzIyZmYwNGFmNGJjZWQ2N2YwNmQ",
"commit_html_url":"https://github.com/openstack/nova/commit/87dd10dcd482c7711e81322ff04af4bced67f06d",
"commit_date":"2022-02-05T09:33:35Z",
"files":[
{
"sha":"294ccaebbecb0b5e8a9292c691efc41280e14739",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":18,
"deletions":6,
"changes":24,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -667,7 +667,8 @@ def _unbind_ports(self, context, ports,\n             # for the physical device but don't want to overwrite the other\n             # information in the binding profile.\n             for profile_key in ('pci_vendor_info', 'pci_slot',\n-                                constants.ALLOCATION, 'arq_uuid'):\n+                                constants.ALLOCATION, 'arq_uuid',\n+                                'physical_network', 'card_serial_number'):\n                 if profile_key in port_profile:\n                     del port_profile[profile_key]\n             port_req_body['port'][constants.BINDING_PROFILE] = port_profile\n@@ -1506,11 +1507,22 @@ def delete_port_binding(self, context, port_id, host):\n     def _get_pci_device_profile(self, pci_dev):\n         dev_spec = self.pci_whitelist.get_devspec(pci_dev)\n         if dev_spec:\n-            return {'pci_vendor_info': \"%s:%s\" %\n-                        (pci_dev.vendor_id, pci_dev.product_id),\n-                    'pci_slot': pci_dev.address,\n-                    'physical_network':\n-                        dev_spec.get_tags().get('physical_network')}\n+            dev_profile = {\n+                'pci_vendor_info': \"%s:%s\"\n+                % (pci_dev.vendor_id, pci_dev.product_id),\n+                'pci_slot': pci_dev.address,\n+                'physical_network': dev_spec.get_tags().get(\n+                    'physical_network'\n+                ),\n+            }\n+            if pci_dev.dev_type == obj_fields.PciDeviceType.SRIOV_VF:\n+                card_serial_number = pci_dev.card_serial_number\n+                if card_serial_number:\n+                    dev_profile.update({\n+                        'card_serial_number': card_serial_number\n+                    })\n+            return dev_profile\n+\n         raise exception.PciDeviceNotFound(node_id=pci_dev.compute_node_id,\n                                           address=pci_dev.address)\n "
},
{
"sha":"275d5da3564aa0540829c3a6e7439d1655c49886",
"filename":"nova/objects/pci_device.py",
"status":"modified",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/objects/pci_device.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/objects/pci_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/pci_device.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -511,6 +511,12 @@ def free(self, instance=None):\n     def is_available(self):\n         return self.status == fields.PciDeviceStatus.AVAILABLE\n \n+    @property\n+    def card_serial_number(self):\n+        caps_json = self.extra_info.get('capabilities', \"{}\")\n+        caps = jsonutils.loads(caps_json)\n+        return caps.get('vpd', {}).get('card_serial_number')\n+\n \n @base.NovaObjectRegistry.register\n class PciDeviceList(base.ObjectListBase, base.NovaObject):"
},
{
"sha":"43fcc8c950aee71c2ea14b7734ceb43543af31c1",
"filename":"nova/tests/fixtures/libvirt_data.py",
"status":"modified",
"additions":162,
"deletions":0,
"changes":162,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/fixtures/libvirt_data.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/fixtures/libvirt_data.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/libvirt_data.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -2002,6 +2002,168 @@ def fake_kvm_guest():\n       </capability>\n     </device>\n     \"\"\",\n+    # A PF with the VPD capability.\n+    \"pci_0000_82_00_0\": \"\"\"\n+    <device>\n+      <name>pci_0000_82_00_0</name>\n+      <path>/sys/devices/pci0000:80/0000:80:03.0/0000:82:00.0</path>\n+      <parent>pci_0000_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>0</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>0</function>\n+        <product id='0xa2d6'>MT42822 BlueField-2 integrated ConnectX-6 Dx network controller</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='virt_functions' maxCount='8'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x3'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x4'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x5'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x6'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x7'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x0'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x1'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x2'/>\n+        </capability>\n+        <capability type='vpd'>\n+          <name>BlueField-2 DPU 25GbE Dual-Port SFP56, Crypto Enabled, 16GB on-board DDR, 1GbE OOB management, Tall Bracket</name>\n+          <fields access='readonly'>\n+            <change_level>B1</change_level>\n+            <manufacture_id>foobar</manufacture_id>\n+            <part_number>MBF2H332A-AEEOT</part_number>\n+            <serial_number>MT2113X00000</serial_number>\n+            <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+            <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+            <vendor_field index='3'>3c53d07eec484d8aab34dabd24fe575aa</vendor_field>\n+            <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+          </fields>\n+          <fields access='readwrite'>\n+            <asset_tag>fooasset</asset_tag>\n+            <vendor_field index='0'>vendorfield0</vendor_field>\n+            <vendor_field index='2'>vendorfield2</vendor_field>\n+            <vendor_field index='A'>vendorfieldA</vendor_field>\n+            <system_field index='B'>systemfieldB</system_field>\n+            <system_field index='0'>systemfield0</system_field>\n+          </fields>\n+        </capability>\n+        <iommuGroup number='65'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x0'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' speed='8' width='8'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n+    # A VF without the VPD capability with a PF that has a VPD capability.\n+    \"pci_0000_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0000_82_00_3</name>\n+      <path>/sys/devices/pci0000:80/0000:80:03.0/0000:82:00.3</path>\n+      <parent>pci_0000_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>0</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",\n+    # A VF with the VPD capability but without a parent defined in test data\n+    # so that the VPD cap is extracted from the VF directly.\n+    \"pci_0001_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0001_82_00_3</name>\n+      <path>/sys/devices/pci0001:80/0001:80:03.0/0001:82:00.3</path>\n+      <parent>pci_0001_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>1</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0001' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <capability type='vpd'>\n+          <name>BlueField-2 DPU 25GbE Dual-Port SFP56, Crypto Enabled, 16GB on-board DDR, 1GbE OOB management, Tall Bracket</name>\n+          <fields access='readonly'>\n+            <change_level>B1</change_level>\n+            <part_number>MBF2H332A-AEEOT</part_number>\n+            <serial_number>MT2113XBEEF0</serial_number>\n+            <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+            <vendor_field index='3'>9644e3586190eb118000b8cef671bf3e</vendor_field>\n+            <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+            <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+          </fields>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0001' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n+    # A VF without the VPD capability and without a parent PF defined\n+    # in the test data.\n+    \"pci_0002_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0002_82_00_3</name>\n+      <path>/sys/devices/pci0002:80/0002:80:03.0/0002:82:00.3</path>\n+      <parent>pci_0002_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>2</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0002' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0002' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n }\n \n _fake_NodeDevXml_parents = {"
},
{
"sha":"a06549b609c6ba5ccce566bb732f6acdf52b59e8",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":63,
"deletions":14,
"changes":77,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -39,6 +39,7 @@\n from nova.network import model\n from nova.network import neutron as neutronapi\n from nova import objects\n+from nova.objects import fields as obj_fields\n from nova.objects import network_request as net_req_obj\n from nova.objects import virtual_interface as obj_vif\n from nova.pci import manager as pci_manager\n@@ -4494,17 +4495,21 @@ def test_update_port_bindings_for_instance_with_pci(self,\n         instance = fake_instance.fake_instance_obj(self.context)\n         instance.migration_context = objects.MigrationContext()\n         instance.migration_context.old_pci_devices = objects.PciDeviceList(\n-            objects=[objects.PciDevice(vendor_id='1377',\n-                                       product_id='0047',\n-                                       address='0000:0a:00.1',\n-                                       compute_node_id=1,\n-                                       request_id='1234567890')])\n+            objects=[objects.PciDevice(\n+                vendor_id='1377',\n+                product_id='0047',\n+                address='0000:0a:00.1',\n+                compute_node_id=1,\n+                request_id='1234567890',\n+                dev_type=obj_fields.PciDeviceType.SRIOV_VF)])\n         instance.migration_context.new_pci_devices = objects.PciDeviceList(\n-            objects=[objects.PciDevice(vendor_id='1377',\n-                                       product_id='0047',\n-                                       address='0000:0b:00.1',\n-                                       compute_node_id=2,\n-                                       request_id='1234567890')])\n+            objects=[objects.PciDevice(\n+                vendor_id='1377',\n+                product_id='0047',\n+                address='0000:0b:00.1',\n+                compute_node_id=2,\n+                request_id='1234567890',\n+                dev_type=obj_fields.PciDeviceType.SRIOV_VF)])\n         instance.pci_devices = instance.migration_context.old_pci_devices\n \n         # Validate that non-direct port aren't updated (fake-port-2).\n@@ -5928,14 +5933,14 @@ def test_unbind_ports_reset_binding_profile(self, mock_show):\n             'id': uuids.port,\n             'binding:profile': {'pci_vendor_info': '1377:0047',\n                                 'pci_slot': '0000:0a:00.1',\n+                                'card_serial_number': 'MT2113X00000',\n                                 'physical_network': 'physnet1',\n                                 'capabilities': ['switchdev']}\n             }\n         self.api._unbind_ports(self.context, ports, neutron, port_client)\n         port_req_body = {'port': {'binding:host_id': None,\n                                   'binding:profile':\n-                                    {'physical_network': 'physnet1',\n-                                     'capabilities': ['switchdev']},\n+                                    {'capabilities': ['switchdev']},\n                                   'device_id': '',\n                                   'device_owner': ''}\n                         }\n@@ -7402,9 +7407,12 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'card_serial_number': None,\n+                   'dev_type': 'TEST_TYPE',\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n-                               ['vendor_id', 'product_id', 'address'])\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n@@ -7422,6 +7430,43 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n+    def test_populate_neutron_extension_values_binding_sriov_card_serial(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n+        host_id = 'my_host_id'\n+        instance = {'host': host_id}\n+        port_req_body = {'port': {}}\n+        pci_req_id = 'my_req_id'\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:82:00.1',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+        profile = {'pci_vendor_info': 'a2d6:15b3',\n+                   'pci_slot': '0000:82:00.1',\n+                   'physical_network': 'physnet1',\n+                   # card_serial_number is a property of the object obtained\n+                   # from extra_info.\n+                   'card_serial_number': 'MT2113X00000',\n+                  }\n+\n+        mock_get_instance_pci_devs.return_value = [mydev]\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+        self.api._populate_neutron_binding_profile(\n+            instance, pci_req_id, port_req_body, None)\n+\n+        self.assertEqual(profile,\n+                         port_req_body['port'][\n+                             constants.BINDING_PROFILE])\n+\n     def test_populate_neutron_extension_values_binding_arq(self):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n@@ -7474,9 +7519,12 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'card_serial_number': None,\n+                   'dev_type': 'TEST_TYPE',\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n-                               ['vendor_id', 'product_id', 'address'])\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n@@ -7547,6 +7595,7 @@ def test_pci_parse_whitelist_called_once(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n \n         whitelist = pci_whitelist.Whitelist(CONF.pci.passthrough_whitelist)"
},
{
"sha":"4087b89800923d89a2e5936b657aa0a0ca54288a",
"filename":"nova/tests/unit/objects/test_pci_device.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/objects/test_pci_device.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/objects/test_pci_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_pci_device.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -161,6 +161,16 @@ def test_pci_device_extra_info_with_dict(self):\n                               'vendor_id', 'numa_node', 'status', 'uuid',\n                               'extra_info', 'dev_type', 'parent_addr']))\n \n+    def test_pci_device_extra_info_card_serial_number(self):\n+        self.dev_dict = copy.copy(dev_dict)\n+        self.pci_device = pci_device.PciDevice.create(None, self.dev_dict)\n+        self.assertIsNone(self.pci_device.card_serial_number)\n+\n+        self.dev_dict = copy.copy(dev_dict)\n+        self.dev_dict['capabilities'] = {'vpd': {'card_serial_number': '42'}}\n+        self.pci_device = pci_device.PciDevice.create(None, self.dev_dict)\n+        self.assertEqual(self.pci_device.card_serial_number, '42')\n+\n     def test_update_device(self):\n         self.pci_device = pci_device.PciDevice.create(None, dev_dict)\n         self.pci_device.obj_reset_changes()"
},
{
"sha":"396edfd0248292385b9ed8c19b166a4bb085da60",
"filename":"nova/tests/unit/virt/libvirt/test_config.py",
"status":"modified",
"additions":80,
"deletions":0,
"changes":80,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/virt/libvirt/test_config.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/virt/libvirt/test_config.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_config.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -3273,6 +3273,86 @@ def test_config_device_pci_mdev_capable(self):\n             'name': 'GRID M60-0B',\n             'type': 'nvidia-11'}], obj.mdev_capability[0].mdev_types)\n \n+    def test_config_device_pci_vpd(self):\n+        xmlin = \"\"\"\n+    <capability type='pci'>\n+      <class>0x020000</class>\n+      <domain>0</domain>\n+      <bus>130</bus>\n+      <slot>0</slot>\n+      <function>1</function>\n+      <product id='0xa2d6'>MT42822 BlueField-2</product>\n+      <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+      <capability type='virt_functions' maxCount='16'/>\n+      <capability type='vpd'>\n+        <name>BlueField-2 DPU 25GbE</name>\n+        <fields access='readonly'>\n+          <change_level>B1</change_level>\n+          <manufacture_id>foobar</manufacture_id>\n+          <part_number>MBF2H332A-AEEOT</part_number>\n+          <serial_number>MT2113X00000</serial_number>\n+          <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+          <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+          <vendor_field index='3'>3c53d07eec484d8aab34dabd24fe575aa</vendor_field>\n+          <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+        </fields>\n+        <fields access='readwrite'>\n+          <asset_tag>fooasset</asset_tag>\n+          <vendor_field index='0'>vendorfield0</vendor_field>\n+          <vendor_field index='2'>vendorfield2</vendor_field>\n+          <vendor_field index='A'>vendorfieldA</vendor_field>\n+          <system_field index='B'>systemfieldB</system_field>\n+          <system_field index='0'>systemfield0</system_field>\n+        </fields>\n+      </capability>\n+      <iommuGroup number='66'>\n+        <address domain='0x0000' bus='0x82' slot='0x00' function='0x1'/>\n+      </iommuGroup>\n+      <numa node='1'/>\n+      <pci-express>\n+        <link validity='cap' port='0' speed='16' width='8'/>\n+        <link validity='sta' speed='8' width='8'/>\n+      </pci-express>\n+    </capability>\"\"\"  # noqa: E501\n+        obj = config.LibvirtConfigNodeDevicePciCap()\n+        obj.parse_str(xmlin)\n+\n+        # Asserting common PCI attribute parsing.\n+        self.assertEqual(0, obj.domain)\n+        self.assertEqual(130, obj.bus)\n+        self.assertEqual(0, obj.slot)\n+        self.assertEqual(1, obj.function)\n+        # Asserting vpd capability parsing.\n+        self.assertEqual(\"MT42822 BlueField-2\", obj.product)\n+        self.assertEqual(0xA2D6, obj.product_id)\n+        self.assertEqual(\"Mellanox Technologies\", obj.vendor)\n+        self.assertEqual(0x15B3, obj.vendor_id)\n+        self.assertEqual(obj.numa_node, 1)\n+        self.assertIsInstance(obj.vpd_capability,\n+                              config.LibvirtConfigNodeDeviceVpdCap)\n+        self.assertEqual(obj.vpd_capability.card_name, 'BlueField-2 DPU 25GbE')\n+\n+        self.assertEqual(obj.vpd_capability.change_level, 'B1')\n+        self.assertEqual(obj.vpd_capability.manufacture_id, 'foobar')\n+        self.assertEqual(obj.vpd_capability.part_number, 'MBF2H332A-AEEOT')\n+        self.assertEqual(obj.vpd_capability.card_serial_number, 'MT2113X00000')\n+        self.assertEqual(obj.vpd_capability.asset_tag, 'fooasset')\n+        self.assertEqual(obj.vpd_capability.ro_vendor_fields, {\n+            '0': 'PCIeGen4 x8',\n+            '2': 'MBF2H332A-AEEOT',\n+            '3': '3c53d07eec484d8aab34dabd24fe575aa',\n+            'A': 'MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A',\n+        })\n+        self.assertEqual(obj.vpd_capability.rw_vendor_fields, {\n+            '0': 'vendorfield0',\n+            '2': 'vendorfield2',\n+            'A': 'vendorfieldA',\n+        })\n+        self.assertEqual(obj.vpd_capability.rw_system_fields, {\n+            '0': 'systemfield0',\n+            'B': 'systemfieldB',\n+        })\n+\n \n class LibvirtConfigNodeDevicePciSubFunctionCap(LibvirtConfigBaseTest):\n "
},
{
"sha":"a33ffef7024bb9a1ffad0063a74a98a7680e5989",
"filename":"nova/tests/unit/virt/libvirt/test_host.py",
"status":"modified",
"additions":87,
"deletions":8,
"changes":95,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/virt/libvirt/test_host.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/tests/unit/virt/libvirt/test_host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_host.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -1119,7 +1119,7 @@ def test_get_pcidev_info_non_nic(self, mock_get_ifname):\n         pci_dev = fakelibvirt.NodeDevice(\n             self.host._get_connection(),\n             xml=fake_libvirt_data._fake_NodeDevXml[dev_name])\n-        actual_vf = self.host._get_pcidev_info(dev_name, pci_dev, [], [])\n+        actual_vf = self.host._get_pcidev_info(dev_name, pci_dev, [], [], [])\n         expect_vf = {\n             \"dev_id\": dev_name, \"address\": \"0000:04:11.7\",\n             \"product_id\": '1520', \"numa_node\": 0,\n@@ -1135,7 +1135,9 @@ def test_get_pcidev_info_non_nic(self, mock_get_ifname):\n     def test_get_pcidev_info(self, mock_get_ifname):\n         devs = {\n             \"pci_0000_04_00_3\", \"pci_0000_04_10_7\", \"pci_0000_04_11_7\",\n-            \"pci_0000_04_00_1\", \"pci_0000_03_00_0\", \"pci_0000_03_00_1\"\n+            \"pci_0000_04_00_1\", \"pci_0000_03_00_0\", \"pci_0000_03_00_1\",\n+            \"pci_0000_82_00_0\", \"pci_0000_82_00_3\", \"pci_0001_82_00_3\",\n+            \"pci_0002_82_00_3\",\n         }\n         node_devs = {}\n         for dev_name in devs:\n@@ -1150,10 +1152,12 @@ def test_get_pcidev_info(self, mock_get_ifname):\n                         xml=fake_libvirt_data._fake_NodeDevXml[child]))\n         net_devs = [\n             dev for dev in node_devs.values() if dev.name() not in devs]\n+        pci_devs = [\n+            dev for dev in node_devs.values() if dev.name() in devs]\n \n         name = \"pci_0000_04_00_3\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_00_3\",\n             \"address\": \"0000:04:00.3\",\n@@ -1167,7 +1171,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_10_7\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_10_7\",\n             \"address\": \"0000:04:10.7\",\n@@ -1186,7 +1190,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_11_7\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_11_7\",\n             \"address\": \"0000:04:11.7\",\n@@ -1205,7 +1209,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_00_1\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_00_1\",\n             \"address\": \"0000:04:00.1\",\n@@ -1219,7 +1223,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_03_00_0\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_03_00_0\",\n             \"address\": \"0000:03:00.0\",\n@@ -1233,7 +1237,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_03_00_1\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_03_00_1\",\n             \"address\": \"0000:03:00.1\",\n@@ -1245,6 +1249,81 @@ def test_get_pcidev_info(self, mock_get_ifname):\n             }\n         self.assertEqual(expect_vf, actual_vf)\n \n+        # Parent PF with a VPD cap.\n+        name = \"pci_0000_82_00_0\"\n+        actual_pf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_pf = {\n+            \"dev_id\": \"pci_0000_82_00_0\",\n+            \"address\": \"0000:82:00.0\",\n+            \"product_id\": \"a2d6\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_a2d6\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_PF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        self.assertEqual(expect_pf, actual_pf)\n+\n+        # A VF without a VPD cap with a parent PF that has a VPD cap.\n+        name = \"pci_0000_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0000_82_00_3\",\n+            \"address\": \"0000:82:00.3\",\n+            \"parent_addr\": \"0000:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        self.assertEqual(expect_vf, actual_vf)\n+\n+        # A VF with a VPD cap without a test parent dev (used to check the\n+        # VPD code path when a VF's own VPD capability is used).\n+        name = \"pci_0001_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0001_82_00_3\",\n+            \"address\": \"0001:82:00.3\",\n+            \"parent_addr\": \"0001:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113XBEEF0\"}},\n+        }\n+\n+        # A VF without a VPD cap and without a test parent dev\n+        # (used to check the code path where a VF VPD capability is\n+        # checked but is not present and a parent PF info is not available).\n+        name = \"pci_0002_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0002_82_00_3\",\n+            \"address\": \"0002:82:00.3\",\n+            \"parent_addr\": \"0002:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+        }\n+\n+        self.assertEqual(expect_vf, actual_vf)\n+\n     def test_list_pci_devices(self):\n         with mock.patch.object(self.host, \"_list_devices\") as mock_listDevices:\n             self.host.list_pci_devices(8)"
},
{
"sha":"b1179b3d1fdf7c12eb7bf80780b95fb494ec98e1",
"filename":"nova/virt/libvirt/config.py",
"status":"modified",
"additions":101,
"deletions":0,
"changes":101,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/config.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/config.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/config.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -3130,6 +3130,7 @@ def __init__(self, **kwargs):\n         self.pci_capability = None\n         self.mdev_information = None\n         self.vdpa_capability = None\n+        self.vpd_capability = None\n \n     def parse_dom(self, xmldoc):\n         super(LibvirtConfigNodeDevice, self).parse_dom(xmldoc)\n@@ -3183,6 +3184,7 @@ def __init__(self, **kwargs):\n         self.numa_node = None\n         self.fun_capability = []\n         self.mdev_capability = []\n+        self.vpd_capability = None\n         self.interface = None\n         self.address = None\n         self.link_state = None\n@@ -3225,6 +3227,10 @@ def parse_dom(self, xmldoc):\n                 mdevcap = LibvirtConfigNodeDeviceMdevCapableSubFunctionCap()\n                 mdevcap.parse_dom(c)\n                 self.mdev_capability.append(mdevcap)\n+            elif c.tag == \"capability\" and c.get('type') in ('vpd',):\n+                vpdcap = LibvirtConfigNodeDeviceVpdCap()\n+                vpdcap.parse_dom(c)\n+                self.vpd_capability = vpdcap\n \n     def pci_address(self):\n         return \"%04x:%02x:%02x.%01x\" % (\n@@ -3288,6 +3294,101 @@ def parse_dom(self, xmldoc):\n                 self.iommu_group = int(c.get('number'))\n \n \n+class LibvirtConfigNodeDeviceVpdCap(LibvirtConfigObject):\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(\n+            root_name=\"capability\", **kwargs)\n+        self._card_name = None\n+        self._change_level = None\n+        self._manufacture_id = None\n+        self._part_number = None\n+        self._serial_number = None\n+        self._asset_tag = None\n+        self._ro_vendor_fields = {}\n+        self._rw_vendor_fields = {}\n+        self._rw_system_fields = {}\n+\n+    @staticmethod\n+    def _process_custom_field(fields_dict, field_element):\n+        index = field_element.get('index')\n+        if index:\n+            fields_dict[index] = field_element.text\n+\n+    def _parse_ro_fields(self, fields_element):\n+        for e in fields_element:\n+            if e.tag == 'change_level':\n+                self._change_level = e.text\n+            elif e.tag == 'manufacture_id':\n+                self._manufacture_id = e.text\n+            elif e.tag == 'part_number':\n+                self._part_number = e.text\n+            elif e.tag == 'serial_number':\n+                self._serial_number = e.text\n+            elif e.tag == 'vendor_field':\n+                self._process_custom_field(self._ro_vendor_fields, e)\n+\n+    def _parse_rw_fields(self, fields_element):\n+        for e in fields_element:\n+            if e.tag == 'asset_tag':\n+                self._asset_tag = e.text\n+            elif e.tag == 'vendor_field':\n+                self._process_custom_field(self._rw_vendor_fields, e)\n+            elif e.tag == 'system_field':\n+                self._process_custom_field(self._rw_system_fields, e)\n+\n+    def parse_dom(self, xmldoc):\n+        super(LibvirtConfigNodeDeviceVpdCap, self).parse_dom(xmldoc)\n+        for c in xmldoc:\n+            if c.tag == \"name\":\n+                self._card_name = c.text\n+            if c.tag == \"fields\":\n+                access = c.get('access')\n+                if access:\n+                    if access == 'readonly':\n+                        self._parse_ro_fields(c)\n+                    elif access == 'readwrite':\n+                        self._parse_rw_fields(c)\n+                    else:\n+                        continue\n+\n+    @property\n+    def card_name(self):\n+        return self._card_name\n+\n+    @property\n+    def change_level(self):\n+        return self._change_level\n+\n+    @property\n+    def manufacture_id(self):\n+        return self._manufacture_id\n+\n+    @property\n+    def part_number(self):\n+        return self._part_number\n+\n+    @property\n+    def card_serial_number(self):\n+        return self._serial_number\n+\n+    @property\n+    def asset_tag(self):\n+        return self._asset_tag\n+\n+    @property\n+    def ro_vendor_fields(self):\n+        return self._ro_vendor_fields\n+\n+    @property\n+    def rw_vendor_fields(self):\n+        return self._rw_vendor_fields\n+\n+    @property\n+    def rw_system_fields(self):\n+        return self._rw_system_fields\n+\n+\n class LibvirtConfigGuestRng(LibvirtConfigGuestDevice):\n \n     def __init__(self, **kwargs):"
},
{
"sha":"c8fd7e22ed3829be8238e5e20586fc68dbcb2d8e",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":8,
"deletions":2,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -7742,9 +7742,15 @@ def _get_pci_passthrough_devices(self):\n         vdpa_devs = [\n             dev for dev in devices.values() if \"vdpa\" in dev.listCaps()\n         ]\n+        pci_devs = {\n+            name: dev for name, dev in devices.items()\n+                    if \"pci\" in dev.listCaps()}\n         pci_info = [\n-            self._host._get_pcidev_info(name, dev, net_devs, vdpa_devs)\n-            for name, dev in devices.items() if \"pci\" in dev.listCaps()\n+            self._host._get_pcidev_info(\n+                name, dev, net_devs,\n+                vdpa_devs, list(pci_devs.values())\n+            )\n+            for name, dev in pci_devs.items()\n         ]\n         return jsonutils.dumps(pci_info)\n "
},
{
"sha":"80663ab1dc43be5ea3f30a0f93c4c93dc31c4715",
"filename":"nova/virt/libvirt/host.py",
"status":"modified",
"additions":87,
"deletions":1,
"changes":88,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/host.py",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/nova/virt/libvirt/host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/host.py?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -1229,12 +1229,51 @@ def _get_pcinet_info(\n         cfgdev.parse_str(xmlstr)\n         return cfgdev.pci_capability.features\n \n+    def _get_vf_parent_pci_vpd_info(\n+        self,\n+        vf_device: 'libvirt.virNodeDevice',\n+        parent_pf_name: str,\n+        candidate_devs: ty.List['libvirt.virNodeDevice']\n+    ) -> ty.Optional[vconfig.LibvirtConfigNodeDeviceVpdCap]:\n+        \"\"\"Returns PCI VPD info of a parent device of a PCI VF.\n+\n+        :param vf_device: a VF device object to use for lookup.\n+        :param str parent_pf_name: parent PF name formatted as pci_dddd_bb_ss_f\n+        :param candidate_devs: devices that could be parent devs for the VF.\n+        :returns: A VPD capability object of a parent device.\n+        \"\"\"\n+        parent_dev = next(\n+            (dev for dev in candidate_devs if dev.name() == parent_pf_name),\n+            None\n+        )\n+        if parent_dev is None:\n+            return None\n+\n+        xmlstr = parent_dev.XMLDesc(0)\n+        cfgdev = vconfig.LibvirtConfigNodeDevice()\n+        cfgdev.parse_str(xmlstr)\n+        return cfgdev.pci_capability.vpd_capability\n+\n+    @staticmethod\n+    def _get_vpd_card_serial_number(\n+        dev: 'libvirt.virNodeDevice',\n+    ) -> ty.Optional[ty.List[str]]:\n+        \"\"\"Returns a card serial number stored in PCI VPD (if present).\"\"\"\n+        xmlstr = dev.XMLDesc(0)\n+        cfgdev = vconfig.LibvirtConfigNodeDevice()\n+        cfgdev.parse_str(xmlstr)\n+        vpd_cap = cfgdev.pci_capability.vpd_capability\n+        if not vpd_cap:\n+            return None\n+        return vpd_cap.card_serial_number\n+\n     def _get_pcidev_info(\n         self,\n         devname: str,\n         dev: 'libvirt.virNodeDevice',\n         net_devs: ty.List['libvirt.virNodeDevice'],\n         vdpa_devs: ty.List['libvirt.virNodeDevice'],\n+        pci_devs: ty.List['libvirt.virNodeDevice'],\n     ) -> ty.Dict[str, ty.Union[str, dict]]:\n         \"\"\"Returns a dict of PCI device.\"\"\"\n \n@@ -1314,6 +1353,52 @@ def _get_device_capabilities(\n                 pcinet_info = self._get_pcinet_info(device, net_devs)\n                 if pcinet_info:\n                     return {'capabilities': {'network': pcinet_info}}\n+\n+            return caps\n+\n+        def _get_vpd_details(\n+            device_dict: dict,\n+            device: 'libvirt.virNodeDevice',\n+            pci_devs: ty.List['libvirt.virNodeDevice']\n+        ) -> ty.Dict[str, ty.Dict[str, ty.Any]]:\n+            \"\"\"Get information from PCI VPD (if present).\n+\n+            PCI/PCIe devices may include the optional VPD capability. It may\n+            contain useful information such as the unique serial number\n+            uniquely assigned at a factory.\n+\n+            If a device is a VF and it does not contain the VPD capability,\n+            a parent device's VPD is used (if present) as a fallback to\n+            retrieve the unique add-in card number. Whether a VF exposes\n+            the VPD capability or not may be controlled via a vendor-specific\n+            firmware setting.\n+            \"\"\"\n+            caps: ty.Dict[str, ty.Dict[str, ty.Any]] = {}\n+            # At the time of writing only the serial number had a clear\n+            # use-case. However, the set of fields may be extended.\n+            card_serial_number = self._get_vpd_card_serial_number(device)\n+\n+            if (not card_serial_number and\n+               device_dict.get('dev_type') == fields.PciDeviceType.SRIOV_VF\n+            ):\n+                # Format the address of a physical function to use underscores\n+                # since that's how Libvirt formats the <name> element content.\n+                pf_addr = device_dict.get('parent_addr')\n+                if not pf_addr:\n+                    LOG.warning(\"A VF device dict does not have a parent PF \"\n+                                \"address in it which is unexpected. Skipping \"\n+                                \"serial number retrieval\")\n+                    return caps\n+\n+                formatted_addr = pf_addr.replace('.', '_').replace(':', '_')\n+                vpd_cap = self._get_vf_parent_pci_vpd_info(\n+                    device, f'pci_{formatted_addr}', pci_devs)\n+                if vpd_cap is not None:\n+                    card_serial_number = vpd_cap.card_serial_number\n+\n+            if card_serial_number:\n+                caps = {'capabilities': {\n+                    'vpd': {\"card_serial_number\": card_serial_number}}}\n             return caps\n \n         xmlstr = dev.XMLDesc(0)\n@@ -1340,6 +1425,7 @@ def _get_device_capabilities(\n         device.update(\n             _get_device_type(cfgdev, address, dev, net_devs, vdpa_devs))\n         device.update(_get_device_capabilities(device, dev, net_devs))\n+        device.update(_get_vpd_details(device, dev, pci_devs))\n         return device\n \n     def get_vdpa_nodedev_by_address(\n@@ -1361,7 +1447,7 @@ def get_vdpa_nodedev_by_address(\n         vdpa_devs = [\n             dev for dev in devices.values() if \"vdpa\" in dev.listCaps()]\n         pci_info = [\n-            self._get_pcidev_info(name, dev, [], vdpa_devs) for name, dev\n+            self._get_pcidev_info(name, dev, [], vdpa_devs, []) for name, dev\n             in devices.items() if \"pci\" in dev.listCaps()]\n         parent_dev = next(\n             dev for dev in pci_info if dev['address'] == pci_address)"
},
{
"sha":"0ca3518351604a5e61847b8b64bb3dc7c7e79f99",
"filename":"releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"status":"added",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/87dd10dcd482c7711e81322ff04af4bced67f06d/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"raw_url":"https://github.com/openstack/nova/raw/87dd10dcd482c7711e81322ff04af4bced67f06d/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml?ref=87dd10dcd482c7711e81322ff04af4bced67f06d",
"patch":"@@ -0,0 +1,20 @@\n+---\n+features:\n+  - |\n+    Add VPD capability parsing support when a PCI VPD capability is exposed\n+    via node device XML in Libvirt. The XML data from Libvirt is parsed and\n+    formatted into PCI device JSON dict that is sent to Nova API and is stored\n+    in the extra_info column of a PciDevice.\n+\n+    The code gracefully handles the lack of the capability since it is optional\n+    or Libvirt may not support it in a particular release.\n+\n+    A serial number is extracted from PCI VPD of network devices (if present)\n+    and is sent to Neutron in port updates.\n+\n+    Libvirt supports parsing the VPD capability from PCI/PCIe devices and\n+    exposing it via nodedev XML as of 7.9.0.\n+\n+    - https://libvirt.org/news.html#v7-9-0-2021-11-01\n+    - https://libvirt.org/drvnodedev.html#VPDCap\n+"
}
]
},
{
"commit_sha":"cc794b3641b0b8ccbdee0d39149f59ed40dc803f",
"commit_node_id":"C_kwDOAAwOD9oAKGNjNzk0YjM2NDFiMGI4Y2NiZGVlMGQzOTE0OWY1OWVkNDBkYzgwM2Y",
"commit_html_url":"https://github.com/openstack/nova/commit/cc794b3641b0b8ccbdee0d39149f59ed40dc803f",
"commit_date":"2022-02-05T00:36:44Z",
"files":[
{
"sha":"3a33e514cd659be31fa511d0a9f5a1910c7537a9",
"filename":".zuul.yaml",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/cc794b3641b0b8ccbdee0d39149f59ed40dc803f/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/cc794b3641b0b8ccbdee0d39149f59ed40dc803f/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=cc794b3641b0b8ccbdee0d39149f59ed40dc803f",
"patch":"@@ -294,7 +294,7 @@\n       # tempest_test_exclude_list.\n       # FIXME(lyarwood): The tempest.api.compute.admin.test_volume_swap tests\n       # are skipped until bug #1929710 is resolved.\n-      tempest_exclude_regex: ^tempest\\.(scenario\\.test_network_(?!qos)|api\\.compute\\.admin\\.test_volume_swap)\n+      tempest_exclude_regex: ^tempest\\.(scenario\\.test_network_(?!qos)|api\\.compute\\.admin\\.test_volume_swap)|tempest.api.compute.servers.test_device_tagging.TaggedAttachmentsTest.test_tagged_attachment\n       devstack_local_conf:\n         post-config:\n           $NOVA_CPU_CONF:"
}
]
},
{
"commit_sha":"bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"commit_node_id":"C_kwDOAAwOD9oAKGJkYWVhZGViNjRmYzIyYmQ0MDQzNGQyOWU1ZmIzMzhlZjgyN2VkY2E",
"commit_html_url":"https://github.com/openstack/nova/commit/bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"commit_date":"2022-02-04T15:23:28Z",
"files":[
{
"sha":"1c3d13d5dd93747da89a37f90809ccaa46dbc195",
"filename":".zuul.yaml",
"status":"modified",
"additions":1,
"deletions":2,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -605,8 +605,7 @@\n         - nova-lvm\n         - nova-multi-cell\n         - nova-next\n-        - nova-ovs-hybrid-plug:\n-            voting: false\n+        - nova-ovs-hybrid-plug\n         - nova-tox-validate-backport:\n             voting: false\n         - nova-tox-functional-centos8-py36"
},
{
"sha":"b066b6cc011de43741cdaa75120c4f989588982a",
"filename":"nova/compute/manager.py",
"status":"modified",
"additions":28,
"deletions":53,
"changes":81,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/compute/manager.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/compute/manager.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/manager.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -4809,8 +4809,18 @@ def _finish_revert_snapshot_based_resize_at_source(\n                   self.host, instance=instance)\n         # TODO(mriedem): Calculate provider mappings when we support\n         # cross-cell resize/migrate with ports having resource requests.\n-        self._finish_revert_resize_network_migrate_finish(\n-            ctxt, instance, migration, provider_mappings=None)\n+        # NOTE(hanrong): we need to change migration.dest_compute to\n+        # source host temporarily.\n+        # \"network_api.migrate_instance_finish\" will setup the network\n+        # for the instance on the destination host. For revert resize,\n+        # the instance will back to the source host, the setup of the\n+        # network for instance should be on the source host. So set\n+        # the migration.dest_compute to source host at here.\n+        with utils.temporary_mutation(\n+            migration, dest_compute=migration.source_compute\n+        ):\n+            self.network_api.migrate_instance_finish(\n+                ctxt, instance, migration, provider_mappings=None)\n         network_info = self.network_api.get_instance_nw_info(ctxt, instance)\n \n         # Remember that prep_snapshot_based_resize_at_source destroyed the\n@@ -4902,50 +4912,6 @@ def revert_resize(self, context, instance, migration, request_spec):\n             self.compute_rpcapi.finish_revert_resize(context, instance,\n                     migration, migration.source_compute, request_spec)\n \n-    def _finish_revert_resize_network_migrate_finish(\n-            self, context, instance, migration, provider_mappings):\n-        \"\"\"Causes port binding to be updated. In some Neutron or port\n-        configurations - see NetworkModel.get_bind_time_events() - we\n-        expect the vif-plugged event from Neutron immediately and wait for it.\n-        The rest of the time, the event is expected further along in the\n-        virt driver, so we don't wait here.\n-\n-        :param context: The request context.\n-        :param instance: The instance undergoing the revert resize.\n-        :param migration: The Migration object of the resize being reverted.\n-        :param provider_mappings: a dict of list of resource provider uuids\n-            keyed by port uuid\n-        :raises: eventlet.timeout.Timeout or\n-                 exception.VirtualInterfacePlugException.\n-        \"\"\"\n-        network_info = instance.get_network_info()\n-        events = []\n-        deadline = CONF.vif_plugging_timeout\n-        if deadline and network_info:\n-            events = network_info.get_bind_time_events(migration)\n-            if events:\n-                LOG.debug('Will wait for bind-time events: %s', events)\n-        error_cb = self._neutron_failed_migration_callback\n-        try:\n-            with self.virtapi.wait_for_instance_event(instance, events,\n-                                                      deadline=deadline,\n-                                                      error_callback=error_cb):\n-                # NOTE(hanrong): we need to change migration.dest_compute to\n-                # source host temporarily.\n-                # \"network_api.migrate_instance_finish\" will setup the network\n-                # for the instance on the destination host. For revert resize,\n-                # the instance will back to the source host, the setup of the\n-                # network for instance should be on the source host. So set\n-                # the migration.dest_compute to source host at here.\n-                with utils.temporary_mutation(\n-                        migration, dest_compute=migration.source_compute):\n-                    self.network_api.migrate_instance_finish(\n-                        context, instance, migration, provider_mappings)\n-        except eventlet.timeout.Timeout:\n-            with excutils.save_and_reraise_exception():\n-                LOG.error('Timeout waiting for Neutron events: %s', events,\n-                          instance=instance)\n-\n     @wrap_exception()\n     @reverts_task_state\n     @wrap_instance_event(prefix='compute')\n@@ -5003,8 +4969,18 @@ def _finish_revert_resize(\n \n             self.network_api.setup_networks_on_host(context, instance,\n                                                     migration.source_compute)\n-            self._finish_revert_resize_network_migrate_finish(\n-                context, instance, migration, provider_mappings)\n+            # NOTE(hanrong): we need to change migration.dest_compute to\n+            # source host temporarily. \"network_api.migrate_instance_finish\"\n+            # will setup the network for the instance on the destination host.\n+            # For revert resize, the instance will back to the source host, the\n+            # setup of the network for instance should be on the source host.\n+            # So set the migration.dest_compute to source host at here.\n+            with utils.temporary_mutation(\n+                    migration, dest_compute=migration.source_compute):\n+                self.network_api.migrate_instance_finish(context,\n+                                                         instance,\n+                                                         migration,\n+                                                         provider_mappings)\n             network_info = self.network_api.get_instance_nw_info(context,\n                                                                  instance)\n \n@@ -5081,8 +5057,7 @@ def _fill_provider_mapping_based_on_allocs(\n             # the provider mappings. If the instance has ports with\n             # resource request then the port update will fail in\n             # _update_port_binding_for_instance() called via\n-            # _finish_revert_resize_network_migrate_finish() in\n-            # finish_revert_resize.\n+            # migrate_instance_finish() in finish_revert_resize.\n             provider_mappings = None\n         return provider_mappings\n \n@@ -8306,8 +8281,8 @@ def pre_live_migration(self, context, instance, disk, migrate_data):\n         return migrate_data\n \n     @staticmethod\n-    def _neutron_failed_migration_callback(event_name, instance):\n-        msg = ('Neutron reported failure during migration '\n+    def _neutron_failed_live_migration_callback(event_name, instance):\n+        msg = ('Neutron reported failure during live migration '\n                'with %(event)s for instance %(uuid)s')\n         msg_args = {'event': event_name, 'uuid': instance.uuid}\n         if CONF.vif_plugging_is_fatal:\n@@ -8403,7 +8378,7 @@ class _BreakWaitForInstanceEvent(Exception):\n                 disk = None\n \n             deadline = CONF.vif_plugging_timeout\n-            error_cb = self._neutron_failed_migration_callback\n+            error_cb = self._neutron_failed_live_migration_callback\n             # In order to avoid a race with the vif plugging that the virt\n             # driver does on the destination host, we register our events\n             # to wait for before calling pre_live_migration. Then if the"
},
{
"sha":"64995c95274677b7701694a839032031a9c88f71",
"filename":"nova/network/model.py",
"status":"modified",
"additions":0,
"deletions":25,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/network/model.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/network/model.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/model.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -485,17 +485,6 @@ def labeled_ips(self):\n                     'ips': ips}\n         return []\n \n-    def has_bind_time_event(self, migration):\n-        \"\"\"Returns whether this VIF's network-vif-plugged external event will\n-        be sent by Neutron at \"bind-time\" - in other words, as soon as the port\n-        binding is updated. This is in the context of updating the port binding\n-        to a host that already has the instance in a shutoff state - in\n-        practice, this means reverting either a cold migration or a\n-        non-same-host resize.\n-        \"\"\"\n-        return (self.is_hybrid_plug_enabled() and not\n-                migration.is_same_host())\n-\n     @property\n     def has_live_migration_plug_time_event(self):\n         \"\"\"Returns whether this VIF's network-vif-plugged external event will\n@@ -564,27 +553,13 @@ def wait(self, do_raise=True):\n     def json(self):\n         return jsonutils.dumps(self)\n \n-    def get_bind_time_events(self, migration):\n-        \"\"\"Returns a list of external events for any VIFs that have\n-        \"bind-time\" events during cold migration.\n-        \"\"\"\n-        return [('network-vif-plugged', vif['id'])\n-                for vif in self if vif.has_bind_time_event(migration)]\n-\n     def get_live_migration_plug_time_events(self):\n         \"\"\"Returns a list of external events for any VIFs that have\n         \"plug-time\" events during live migration.\n         \"\"\"\n         return [('network-vif-plugged', vif['id'])\n                 for vif in self if vif.has_live_migration_plug_time_event]\n \n-    def get_plug_time_events(self, migration):\n-        \"\"\"Returns a list of external events for any VIFs that have\n-        \"plug-time\" events during cold migration.\n-        \"\"\"\n-        return [('network-vif-plugged', vif['id'])\n-                for vif in self if not vif.has_bind_time_event(migration)]\n-\n     def has_port_with_allocation(self):\n         return any(vif.has_allocation() for vif in self)\n "
},
{
"sha":"cacb636ccc8bb82096af7abc2963d53731d36262",
"filename":"nova/objects/migration.py",
"status":"modified",
"additions":0,
"deletions":3,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/objects/migration.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/objects/migration.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/migration.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -202,9 +202,6 @@ def instance(self):\n     def instance(self, instance):\n         self._cached_instance = instance\n \n-    def is_same_host(self):\n-        return self.source_compute == self.dest_compute\n-\n     @property\n     def is_live_migration(self):\n         return self.migration_type == fields.MigrationType.LIVE_MIGRATION"
},
{
"sha":"f65f1abdb740a6c2ef26c71494f6b7f537708ea1",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":2,
"deletions":6,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -5801,9 +5801,7 @@ def fake_finish_revert_migration_driver(*args, **kwargs):\n             old_vm_state = vm_states.ACTIVE\n         else:\n             old_vm_state = vm_states.STOPPED\n-        params = {'vm_state': old_vm_state,\n-                  'info_cache': objects.InstanceInfoCache(\n-                      network_info=network_model.NetworkInfo([]))}\n+        params = {'vm_state': old_vm_state}\n         instance = self._create_fake_instance_obj(params)\n         request_spec = objects.RequestSpec()\n \n@@ -5956,9 +5954,7 @@ def test_finish_revert_resize_validate_source_compute(self):\n         def fake(*args, **kwargs):\n             pass\n \n-        params = {'info_cache': objects.InstanceInfoCache(\n-                      network_info=network_model.NetworkInfo([]))}\n-        instance = self._create_fake_instance_obj(params)\n+        instance = self._create_fake_instance_obj()\n         request_spec = objects.RequestSpec()\n \n         self.stub_out('nova.virt.fake.FakeDriver.finish_migration', fake)"
},
{
"sha":"4d7967b37e487733e873392952efc107ba75c3b8",
"filename":"nova/tests/unit/compute/test_compute_mgr.py",
"status":"modified",
"additions":11,
"deletions":95,
"changes":106,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/compute/test_compute_mgr.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/compute/test_compute_mgr.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute_mgr.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -6051,86 +6051,6 @@ def test_notify_volume_usage_detach_no_block_stats(self):\n                     self.context, fake_instance, fake_bdm)\n         block_stats.assert_called_once_with(fake_instance, 'vda')\n \n-    def _test_finish_revert_resize_network_migrate_finish(\n-            self, vifs, events, migration=None):\n-        instance = fake_instance.fake_instance_obj(self.context)\n-        instance.info_cache = objects.InstanceInfoCache(\n-            network_info=network_model.NetworkInfo(vifs))\n-        if migration is None:\n-            migration = objects.Migration(\n-                source_compute='fake-source',\n-                dest_compute='fake-dest')\n-\n-        def fake_migrate_instance_finish(\n-                context, instance, migration, mapping):\n-            # NOTE(artom) This looks weird, but it's checking that the\n-            # temporaty_mutation() context manager did its job.\n-            self.assertEqual(migration.dest_compute, migration.source_compute)\n-\n-        with test.nested(\n-            mock.patch.object(self.compute.virtapi,\n-                              'wait_for_instance_event'),\n-            mock.patch.object(self.compute.network_api,\n-                              'migrate_instance_finish',\n-                              side_effect=fake_migrate_instance_finish)\n-        ) as (mock_wait, mock_migrate_instance_finish):\n-            self.compute._finish_revert_resize_network_migrate_finish(\n-                self.context, instance, migration, mock.sentinel.mapping)\n-            mock_wait.assert_called_once_with(\n-                instance, events, deadline=CONF.vif_plugging_timeout,\n-                error_callback=self.compute._neutron_failed_migration_callback)\n-            mock_migrate_instance_finish.assert_called_once_with(\n-                self.context, instance, migration, mock.sentinel.mapping)\n-\n-    def test_finish_revert_resize_network_migrate_finish_wait(self):\n-        \"\"\"Test that we wait for bind-time events if we have a hybrid-plugged\n-        VIF.\n-        \"\"\"\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [('network-vif-plugged', uuids.hybrid_vif)])\n-\n-    def test_finish_revert_resize_network_migrate_finish_same_host(self):\n-        \"\"\"Test that we're not waiting for any events if its a same host\n-        resize revert.\n-        \"\"\"\n-        migration = objects.Migration(\n-            source_compute='fake-source', dest_compute='fake-source')\n-\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [], migration=migration\n-        )\n-\n-    def test_finish_revert_resize_network_migrate_finish_dont_wait(self):\n-        \"\"\"Test that we're not waiting for any events if we don't have any\n-        hybrid-plugged VIFs.\n-        \"\"\"\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': False}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [])\n-\n-    def test_finish_revert_resize_network_migrate_finish_no_vif_timeout(self):\n-        \"\"\"Test that we're not waiting for any events if vif_plugging_timeout\n-        is 0.\n-        \"\"\"\n-        self.flags(vif_plugging_timeout=0)\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': True})],\n-            [])\n-\n     @mock.patch('nova.compute.manager.LOG')\n     def test_cache_images_unsupported(self, mock_log):\n         r = self.compute.cache_images(self.context, ['an-image'])\n@@ -8877,8 +8797,7 @@ def do_finish_revert_resize(mock_attachment_complete,\n         do_finish_revert_resize()\n \n     @mock.patch.object(objects.Instance, 'drop_migration_context')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.scheduler.utils.'\n                 'fill_provider_mapping_based_on_allocation')\n     @mock.patch('nova.compute.manager.ComputeManager._revert_allocation')\n@@ -8892,7 +8811,7 @@ def do_finish_revert_resize(mock_attachment_complete,\n     def test_finish_revert_resize_recalc_group_rp_mapping(\n             self, mock_get_bdms, mock_notify_action, mock_notify_usage,\n             mock_set_instance_info, mock_instance_save, mock_revert_allocation,\n-            mock_fill_provider_mapping, mock_network_migrate_finish,\n+            mock_fill_provider_mapping, mock_migrate_instance_finish,\n             mock_drop_migration_context):\n \n         mock_get_bdms.return_value = objects.BlockDeviceMappingList()\n@@ -8909,8 +8828,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping(\n             mock.sentinel.allocation)\n \n     @mock.patch.object(objects.Instance, 'drop_migration_context')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.scheduler.utils.'\n                 'fill_provider_mapping_based_on_allocation')\n     @mock.patch('nova.scheduler.client.report.SchedulerReportClient.'\n@@ -8927,7 +8845,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping_missing_request_spec(\n             self, mock_get_bdms, mock_notify_action, mock_notify_usage,\n             mock_set_instance_info, mock_instance_save, mock_revert_allocation,\n             mock_get_allocations, mock_fill_provider_mapping,\n-            mock_network_migrate_finish, mock_drop_migration_context):\n+            mock_migrate_instance_finish, mock_drop_migration_context):\n \n         mock_get_bdms.return_value = objects.BlockDeviceMappingList()\n         mock_get_allocations.return_value = mock.sentinel.allocation\n@@ -8941,7 +8859,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping_missing_request_spec(\n \n         mock_get_allocations.assert_not_called()\n         mock_fill_provider_mapping.assert_not_called()\n-        mock_network_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration, None)\n \n     def test_confirm_resize_deletes_allocations_and_update_scheduler(self):\n@@ -12126,8 +12044,7 @@ def test_finish_revert_snapshot_based_resize_at_source_error_handling(\n     @mock.patch('nova.objects.BlockDeviceMappingList.get_by_instance_uuid')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_update_volume_attachments')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_get_instance_block_device_info')\n     @mock.patch('nova.objects.Instance.drop_migration_context')\n@@ -12137,7 +12054,7 @@ def test_finish_revert_snapshot_based_resize_at_source_error_handling(\n                 '_complete_volume_attachments')\n     def test_finish_revert_snapshot_based_resize_at_source(\n             self, mock_complete_attachments, mock_update_after_spawn,\n-            mock_drop_mig_context, mock_get_bdi, mock_net_migrate_finish,\n+            mock_drop_mig_context, mock_get_bdi, mock_migrate_instance_finish,\n             mock_update_attachments, mock_get_bdms, mock_revert_allocs,\n             mock_inst_save):\n         \"\"\"Happy path test for finish_revert_snapshot_based_resize_at_source.\n@@ -12177,7 +12094,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n         mock_update_attachments.assert_called_once_with(\n             self.context, self.instance, mock_get_bdms.return_value)\n         # Assert that port bindings were updated to point at the source host.\n-        mock_net_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration,\n             provider_mappings=None)\n         # Assert the driver finished reverting the migration.\n@@ -12202,8 +12119,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n     @mock.patch('nova.objects.BlockDeviceMappingList.get_by_instance_uuid')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_update_volume_attachments')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_get_instance_block_device_info')\n     @mock.patch('nova.objects.Instance.drop_migration_context')\n@@ -12214,7 +12130,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n                 side_effect=test.TestingException('vol complete failed'))\n     def test_finish_revert_snapshot_based_resize_at_source_driver_fails(\n             self, mock_complete_attachments, mock_update_after_spawn,\n-            mock_drop_mig_context, mock_get_bdi, mock_net_migrate_finish,\n+            mock_drop_mig_context, mock_get_bdi, mock_migrate_instance_finish,\n             mock_update_attachments, mock_get_bdms, mock_revert_allocs,\n             mock_inst_save):\n         \"\"\"Test for _finish_revert_snapshot_based_resize_at_source where the\n@@ -12268,7 +12184,7 @@ def test_finish_revert_snapshot_based_resize_at_source_driver_fails(\n         mock_update_attachments.assert_called_once_with(\n             self.context, self.instance, mock_get_bdms.return_value)\n         # Assert that port bindings were updated to point at the source host.\n-        mock_net_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration,\n             provider_mappings=None)\n         # Assert final DB cleanup for the instance did not happen."
},
{
"sha":"0420e2d79198c7f3fbeccc465f008dbaef063e80",
"filename":"nova/tests/unit/network/test_network_info.py",
"status":"modified",
"additions":0,
"deletions":29,
"changes":29,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/network/test_network_info.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/network/test_network_info.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_network_info.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -19,7 +19,6 @@\n \n from nova import exception\n from nova.network import model\n-from nova import objects\n from nova import test\n from nova.tests.unit import fake_network_cache_model\n from nova.virt import netutils\n@@ -855,34 +854,6 @@ def test_injection_ipv6_with_lxc_no_gateway(self):\n                 libvirt_virt_type='lxc')\n         self.assertEqual(expected, template)\n \n-    def test_get_events(self):\n-        network_info = model.NetworkInfo([\n-            model.VIF(\n-                id=uuids.hybrid_vif,\n-                details={'ovs_hybrid_plug': True}),\n-            model.VIF(\n-                id=uuids.normal_vif,\n-                details={'ovs_hybrid_plug': False})])\n-        same_host = objects.Migration(source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        diff_host = objects.Migration(source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        # Same-host migrations will have all events be plug-time.\n-        self.assertCountEqual(\n-            [('network-vif-plugged', uuids.normal_vif),\n-             ('network-vif-plugged', uuids.hybrid_vif)],\n-            network_info.get_plug_time_events(same_host))\n-        # Same host migration will have no plug-time events.\n-        self.assertEqual([], network_info.get_bind_time_events(same_host))\n-        # Diff-host migration + OVS hybrid plug = bind-time events\n-        self.assertEqual(\n-            [('network-vif-plugged', uuids.hybrid_vif)],\n-            network_info.get_bind_time_events(diff_host))\n-        # Diff-host migration + normal OVS = plug-time events\n-        self.assertEqual(\n-            [('network-vif-plugged', uuids.normal_vif)],\n-            network_info.get_plug_time_events(diff_host))\n-\n     def test_has_port_with_allocation(self):\n         network_info = model.NetworkInfo([])\n         self.assertFalse(network_info.has_port_with_allocation())"
},
{
"sha":"970122a4094f9a3f33257e43e0a0912b9f4278cb",
"filename":"nova/tests/unit/objects/test_migration.py",
"status":"modified",
"additions":0,
"deletions":8,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/objects/test_migration.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/objects/test_migration.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_migration.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -359,14 +359,6 @@ def test_get_by_uuid(self, mock_db_get):\n         mig = objects.Migration.get_by_uuid(self.context, uuidsentinel.mig)\n         self.assertEqual(uuidsentinel.mig, mig.uuid)\n \n-    def test_is_same_host(self):\n-        same_host = objects.Migration(source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        diff_host = objects.Migration(source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self.assertTrue(same_host.is_same_host())\n-        self.assertFalse(diff_host.is_same_host())\n-\n \n class TestMigrationObject(test_objects._LocalTest,\n                           _TestMigrationObject):"
},
{
"sha":"50cb5536ef92e7339acde990f2c5fd977df40567",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":9,
"deletions":55,
"changes":64,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -19169,10 +19169,9 @@ def fake_lxc_disk_handler(*args, **kwargs):\n             self.assertEqual(0, domain.resume.call_count)\n \n     def _test_create_guest_with_network__events(\n-        self, neutron_failure=None, power_on=True, events=None,\n+        self, neutron_failure=None, power_on=True,\n     ):\n         generated_events = []\n-        events_passed_to_prepare = []\n \n         def wait_timeout():\n             event = mock.MagicMock()\n@@ -19190,7 +19189,6 @@ def fake_prepare(instance, name, tag):\n             m.event_name = '%s-%s' % (name, tag)\n             m.wait.side_effect = wait_timeout\n             generated_events.append(m)\n-            events_passed_to_prepare.append((name, tag))\n             return m\n \n         virtapi = manager.ComputeVirtAPI(mock.MagicMock())\n@@ -19209,8 +19207,7 @@ def fake_prepare(instance, name, tag):\n         def test_create(cleanup, create, plug_vifs):\n             domain = drvr._create_guest_with_network(self.context, 'xml',\n                                                      instance, vifs, None,\n-                                                     power_on=power_on,\n-                                                     external_events=events)\n+                                                     power_on=power_on)\n             plug_vifs.assert_called_with(instance, vifs)\n \n             pause = self._get_pause_flag(drvr, vifs, power_on=power_on)\n@@ -19225,9 +19222,7 @@ def test_create(cleanup, create, plug_vifs):\n \n         test_create()\n \n-        if events and CONF.vif_plugging_timeout:\n-            self.assertEqual(events_passed_to_prepare, events)\n-        elif CONF.vif_plugging_timeout and power_on:\n+        if CONF.vif_plugging_timeout and power_on:\n             prepare.assert_has_calls([\n                 mock.call(instance, 'network-vif-plugged', uuids.vif_1),\n                 mock.call(instance, 'network-vif-plugged', uuids.vif_2)])\n@@ -19243,15 +19238,6 @@ def test_create(cleanup, create, plug_vifs):\n     def test_create_guest_with_network__events_neutron(self):\n         self._test_create_guest_with_network__events()\n \n-    def test_create_guest_with_network__events_passed_in(self):\n-        self._test_create_guest_with_network__events(\n-            events=[('network-vif-plugged', uuids.fake_vif)])\n-\n-    def test_create_guest_with_network__events_passed_in_0_timeout(self):\n-        self.flags(vif_plugging_timeout=0)\n-        self._test_create_guest_with_network__events(\n-            events=[('network-vif-plugged', uuids.fake_vif)])\n-\n     def test_create_guest_with_network_events_neutron_power_off(self):\n         # Tests that we don't wait for events if we don't start the instance.\n         self._test_create_guest_with_network__events(power_on=False)\n@@ -22241,7 +22227,7 @@ def test_finish_revert_migration_vtpm__no_vtpm(\n         mock_restore_vtpm.assert_not_called()\n         mock_delete_vtpm.assert_not_called()\n \n-    def _test_finish_revert_migration(self, power_on, migration):\n+    def _test_finish_revert_migration(self, power_on):\n         \"\"\"Test for nova.virt.libvirt.libvirt_driver.LivirtConnection\n         .finish_revert_migration.\n         \"\"\"\n@@ -22258,14 +22244,11 @@ def fake_plug_vifs(self, instance, network_info):\n         def fake_create_guest_with_network(\n             _self, context, xml, instance, network_info, block_device_info,\n             power_on=None, vifs_already_plugged=None, post_xml_callback=None,\n-            external_events=None, cleanup_instance_dir=False,\n-            cleanup_instance_disks=False,\n+            cleanup_instance_dir=False, cleanup_instance_disks=False,\n         ):\n             self.fake_create_guest_called = True\n             self.assertEqual(powered_on, power_on)\n             self.assertFalse(vifs_already_plugged)\n-            self.assertEqual(self.events_passed_to_fake_create,\n-                             external_events)\n             return mock.MagicMock()\n \n         def fake_get_info(self, instance):\n@@ -22304,51 +22287,22 @@ def fake_to_xml(self, context, instance, network_info, disk_info,\n             f = open(libvirt_xml_path, 'w')\n             f.close()\n \n-            network_info = network_model.NetworkInfo(\n-                [network_model.VIF(id=uuids.normal_vif),\n-                 network_model.VIF(id=uuids.hybrid_vif,\n-                                   details={'ovs_hybrid_plug': True})])\n-            if migration.is_same_host():\n-                # Same host is all plug-time\n-                self.events_passed_to_fake_create = [\n-                    ('network-vif-plugged', uuids.normal_vif),\n-                    ('network-vif-plugged', uuids.hybrid_vif)]\n-            else:\n-                # For different host migration only non-hybrid plug\n-                # (\"normal\") VIFs \"emit\" plug-time events.\n-                self.events_passed_to_fake_create = [\n-                    ('network-vif-plugged', uuids.normal_vif)]\n-\n             with mock.patch.object(\n                 self.drvr, '_get_all_assigned_mediated_devices',\n                 return_value={}\n             ) as mock_get_a_mdevs:\n                 self.drvr.finish_revert_migration(\n-                    self.context, instance, network_info, migration,\n-                    power_on=power_on)\n+                    self.context, instance, network_model.NetworkInfo(),\n+                        objects.Migration(), power_on=power_on)\n \n             self.assertTrue(self.fake_create_guest_called)\n             mock_get_a_mdevs.assert_called_once_with(mock.ANY)\n \n     def test_finish_revert_migration_power_on(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n+        self._test_finish_revert_migration(True)\n \n     def test_finish_revert_migration_power_off(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=False, migration=migration)\n-\n-    def test_finish_revert_migration_same_host(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n-\n-    def test_finish_revert_migration_diff_host(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n+        self._test_finish_revert_migration(False)\n \n     def _test_finish_revert_migration_after_crash(self, backup_made=True,\n                                                   del_inst_failed=False):"
},
{
"sha":"2ea493d4521179424eb2ed18bcf96ba443f6109f",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":1,
"deletions":10,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/bdaeadeb64fc22bd40434d29e5fb338ef827edca/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=bdaeadeb64fc22bd40434d29e5fb338ef827edca",
"patch":"@@ -11278,18 +11278,9 @@ def finish_revert_migration(\n                                   instance.image_meta,\n                                   block_device_info=block_device_info,\n                                   mdevs=mdevs)\n-        # NOTE(artom) In some Neutron or port configurations we've already\n-        # waited for vif-plugged events in the compute manager's\n-        # _finish_revert_resize_network_migrate_finish(), right after updating\n-        # the port binding. For any ports not covered by those \"bind-time\"\n-        # events, we wait for \"plug-time\" events here.\n-        events = network_info.get_plug_time_events(migration)\n-        if events:\n-            LOG.debug('Instance is using plug-time events: %s', events,\n-                      instance=instance)\n         self._create_guest_with_network(\n             context, xml, instance, network_info, block_device_info,\n-            power_on=power_on, external_events=events)\n+            power_on=power_on)\n \n         if power_on:\n             timer = loopingcall.FixedIntervalLoopingCall("
}
]
},
{
"commit_sha":"f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"commit_node_id":"C_kwDOAAwOD9oAKGY1NDI3NTc2YzQ4M2M0OTY5NGI3ZTUyZjkzZTVhNWU3ZThjNjU4MGI",
"commit_html_url":"https://github.com/openstack/nova/commit/f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"commit_date":"2022-02-04T14:18:09Z",
"files":[
{
"sha":"28e877574d09579d401d292642f718cdc3170103",
"filename":"nova/objects/instance_numa.py",
"status":"modified",
"additions":21,
"deletions":12,
"changes":33,
"blob_url":"https://github.com/openstack/nova/blob/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/objects/instance_numa.py",
"raw_url":"https://github.com/openstack/nova/raw/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/objects/instance_numa.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/instance_numa.py?ref=f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"patch":"@@ -166,8 +166,10 @@ def obj_from_db_obj(cls, context, instance_uuid, db_obj):\n \n         if 'nova_object.name' in primitive:\n             obj = cls.obj_from_primitive(primitive)\n-            cls._migrate_legacy_dedicated_instance_cpuset(\n-                context, instance_uuid, obj)\n+            updated = cls._migrate_legacy_dedicated_instance_cpuset(obj)\n+            if updated:\n+                cls._save_migrated_cpuset_to_instance_extra(\n+                    context, obj, instance_uuid)\n         else:\n             obj = cls._migrate_legacy_object(context, instance_uuid, primitive)\n \n@@ -176,13 +178,14 @@ def obj_from_db_obj(cls, context, instance_uuid, db_obj):\n     # TODO(huaqiang): Remove after Wallaby once we are sure these objects have\n     # been loaded at least once.\n     @classmethod\n-    def _migrate_legacy_dedicated_instance_cpuset(cls, context, instance_uuid,\n-                                                  obj):\n+    def _migrate_legacy_dedicated_instance_cpuset(cls, obj):\n         # NOTE(huaqiang): We may meet some topology object with the old version\n         # 'InstanceNUMACell' cells, in that case, the 'dedicated' CPU is kept\n         # in 'InstanceNUMACell.cpuset' field, but it should be kept in\n         # 'InstanceNUMACell.pcpuset' field since Victoria. Making an upgrade\n-        # and persisting to database.\n+        # here but letting the caller persist the result if needed as we\n+        # don't know which table the InstanceNUMACell is coming from. It can\n+        # come from instance_extra or request_spec too.\n         update_db = False\n         for cell in obj.cells:\n             if len(cell.cpuset) == 0:\n@@ -194,14 +197,20 @@ def _migrate_legacy_dedicated_instance_cpuset(cls, context, instance_uuid,\n             cell.pcpuset = cell.cpuset\n             cell.cpuset = set()\n             update_db = True\n+        return update_db\n \n-        if update_db:\n-            db_obj = jsonutils.dumps(obj.obj_to_primitive())\n-            values = {\n-                'numa_topology': db_obj,\n-            }\n-            db.instance_extra_update_by_uuid(context, instance_uuid,\n-                                             values)\n+    # TODO(huaqiang): Remove after Yoga once we are sure these objects have\n+    # been loaded at least once.\n+    @classmethod\n+    def _save_migrated_cpuset_to_instance_extra(\n+        cls, context, obj, instance_uuid\n+    ):\n+        db_obj = jsonutils.dumps(obj.obj_to_primitive())\n+        values = {\n+            'numa_topology': db_obj,\n+        }\n+        db.instance_extra_update_by_uuid(\n+            context, instance_uuid, values)\n \n     # TODO(stephenfin): Remove in X or later, once this has bedded in\n     @classmethod"
},
{
"sha":"9ce77a40435d0e4c36bdcd02c9de24bdde68cbf8",
"filename":"nova/objects/request_spec.py",
"status":"modified",
"additions":12,
"deletions":0,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/objects/request_spec.py",
"raw_url":"https://github.com/openstack/nova/raw/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/objects/request_spec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/request_spec.py?ref=f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"patch":"@@ -596,6 +596,8 @@ def ensure_network_information(self, instance):\n     @staticmethod\n     def _from_db_object(context, spec, db_spec):\n         spec_obj = spec.obj_from_primitive(jsonutils.loads(db_spec['spec']))\n+        data_migrated = False\n+\n         for key in spec.fields:\n             # Load these from the db model not the serialized object within,\n             # though they should match.\n@@ -616,6 +618,13 @@ def _from_db_object(context, spec, db_spec):\n                 # fields. If they are not set, set None.\n                 if not spec.obj_attr_is_set(key):\n                     setattr(spec, key, None)\n+            elif key == \"numa_topology\":\n+                if key in spec_obj:\n+                    spec.numa_topology = spec_obj.numa_topology\n+                    if spec.numa_topology:\n+                        data_migrated = objects.InstanceNUMATopology.\\\n+                            _migrate_legacy_dedicated_instance_cpuset(\n+                                spec.numa_topology)\n             elif key in spec_obj:\n                 setattr(spec, key, getattr(spec_obj, key))\n         spec._context = context\n@@ -637,6 +646,9 @@ def _from_db_object(context, spec, db_spec):\n                 # NOTE(danms): Instance group may have been deleted\n                 spec.instance_group = None\n \n+        if data_migrated:\n+            spec.save()\n+\n         spec.obj_reset_changes()\n         return spec\n "
},
{
"sha":"31797f8133b6405d2f4336224503f1565378be0d",
"filename":"nova/tests/unit/objects/test_request_spec.py",
"status":"modified",
"additions":5,
"deletions":30,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/tests/unit/objects/test_request_spec.py",
"raw_url":"https://github.com/openstack/nova/raw/f5427576c483c49694b7e52f93e5a5e7e8c6580b/nova/tests/unit/objects/test_request_spec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_request_spec.py?ref=f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"patch":"@@ -615,29 +615,12 @@ def test_get_by_instance_uuid(self, mock_get_ig, get_by_uuid):\n         self.assertIsInstance(req_obj.instance_group, objects.InstanceGroup)\n         self.assertEqual('fresh', req_obj.instance_group.name)\n \n-    # FIXME(gibi): This is bug 1952941. When the cpuset -> pcpuset data\n-    # migration was added to InstanceNUMATopology it was missed that such\n-    # object is not only hydrated via\n-    # InstanceNUMATopology.get_by_instance_uuid() but also hydrated by\n-    # RequestSpec.get_by_instance_uuid() indirectly. However the\n-    # latter code patch does not call InstanceNUMATopology.obj_from_db_obj()\n-    # that triggers the data migration via\n-    # InstanceNUMATopology._migrate_legacy_dedicated_instance_cpuset.\n-    # This causes that when the new nova code loads an old RequestSpec object\n-    # from the DB (e.g. during migration of an instance) the\n-    # InstanceNUMATopology in the RequestSpec will not be migrated to the new\n-    # object version and it will lead to errors when the pcpuset field is read\n-    # during scheduling.\n-    @mock.patch(\n-        'nova.objects.instance_numa.InstanceNUMATopology.'\n-        '_migrate_legacy_dedicated_instance_cpuset',\n-        new=mock.NonCallableMock()\n-    )\n+    @mock.patch('nova.objects.request_spec.RequestSpec.save')\n     @mock.patch.object(\n         request_spec.RequestSpec, '_get_by_instance_uuid_from_db')\n     @mock.patch('nova.objects.InstanceGroup.get_by_uuid')\n     def test_get_by_instance_uuid_numa_topology_migration(\n-        self, mock_get_ig, get_by_uuid\n+        self, mock_get_ig, get_by_uuid, mock_save\n     ):\n         # Simulate a pre-Victoria RequestSpec where the pcpuset field is not\n         # defined for the embedded InstanceNUMACell objects but the cpu_policy\n@@ -665,18 +648,10 @@ def test_get_by_instance_uuid_numa_topology_migration(\n             self.context, fake_spec['instance_uuid'])\n \n         self.assertEqual(2, len(req_obj.numa_topology.cells))\n+        self.assertEqual({1, 2}, req_obj.numa_topology.cells[0].pcpuset)\n+        self.assertEqual({3, 4}, req_obj.numa_topology.cells[1].pcpuset)\n \n-        # This is bug 1952941 as the pcpuset is not defined in object as the\n-        # object is not migrated\n-        ex = self.assertRaises(\n-            NotImplementedError,\n-            lambda: req_obj.numa_topology.cells[0].pcpuset\n-        )\n-        self.assertIn(\"Cannot load 'pcpuset' in the base class\", str(ex))\n-\n-        # This is the expected behavior\n-        # self.assertEqual({1, 2}, req_obj.numa_topology.cells[0].pcpuset)\n-        # self.assertEqual({3, 4}, req_obj.numa_topology.cells[1].pcpuset)\n+        mock_save.assert_called_once()\n \n     def _check_update_primitive(self, req_obj, changes):\n         self.assertEqual(req_obj.instance_uuid, changes['instance_uuid'])"
},
{
"sha":"f582bef0c16503bdc03a18de9deb34d78d23f8ac",
"filename":"releasenotes/notes/bug-1952941-request-spec-numa-topology-migration-c97dbd51b3c6c116.yaml",
"status":"added",
"additions":9,
"deletions":0,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/f5427576c483c49694b7e52f93e5a5e7e8c6580b/releasenotes/notes/bug-1952941-request-spec-numa-topology-migration-c97dbd51b3c6c116.yaml",
"raw_url":"https://github.com/openstack/nova/raw/f5427576c483c49694b7e52f93e5a5e7e8c6580b/releasenotes/notes/bug-1952941-request-spec-numa-topology-migration-c97dbd51b3c6c116.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/bug-1952941-request-spec-numa-topology-migration-c97dbd51b3c6c116.yaml?ref=f5427576c483c49694b7e52f93e5a5e7e8c6580b",
"patch":"@@ -0,0 +1,9 @@\n+---\n+fixes:\n+  - |\n+    The `bug 1952941`_  is fixed where a pre-Victoria server with pinned\n+    CPUs cannot be migrated or evacuated after the cloud is upgraded to\n+    Victoria or newer as the scheduling fails with\n+    ``NotImplementedError: Cannot load 'pcpuset'`` error.\n+\n+    .. _bug 1952941: https://bugs.launchpad.net/nova/+bug/1952941"
}
]
},
{
"commit_sha":"6fdd6232884a1a15f0841490acde686b36587a98",
"commit_node_id":"C_kwDOAAwOD9oAKDZmZGQ2MjMyODg0YTFhMTVmMDg0MTQ5MGFjZGU2ODZiMzY1ODdhOTg",
"commit_html_url":"https://github.com/openstack/nova/commit/6fdd6232884a1a15f0841490acde686b36587a98",
"commit_date":"2022-02-04T12:42:47Z",
"files":[
{
"sha":"b8049f7f38bcbea6b48bbcabd367c15b12a26a7f",
"filename":"nova/tests/unit/fake_request_spec.py",
"status":"modified",
"additions":6,
"deletions":5,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/6fdd6232884a1a15f0841490acde686b36587a98/nova/tests/unit/fake_request_spec.py",
"raw_url":"https://github.com/openstack/nova/raw/6fdd6232884a1a15f0841490acde686b36587a98/nova/tests/unit/fake_request_spec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/fake_request_spec.py?ref=6fdd6232884a1a15f0841490acde686b36587a98",
"patch":"@@ -57,14 +57,15 @@\n PCI_REQUESTS.obj_reset_changes(recursive=True)\n \n \n-def fake_db_spec():\n-    req_obj = fake_spec_obj()\n+def fake_db_spec(spec_obj=None):\n+    if not spec_obj:\n+        spec_obj = fake_spec_obj()\n     # NOTE(takashin): There is not 'retry' information in the DB table.\n-    del req_obj.retry\n+    del spec_obj.retry\n     db_request_spec = {\n             'id': 1,\n-            'instance_uuid': req_obj.instance_uuid,\n-            'spec': jsonutils.dumps(req_obj.obj_to_primitive()),\n+            'instance_uuid': spec_obj.instance_uuid,\n+            'spec': jsonutils.dumps(spec_obj.obj_to_primitive()),\n     }\n \n     return db_request_spec"
},
{
"sha":"7d656c555ecf79e69d5fd5280d0b3b44417513fb",
"filename":"nova/tests/unit/objects/test_request_spec.py",
"status":"modified",
"additions":63,
"deletions":0,
"changes":63,
"blob_url":"https://github.com/openstack/nova/blob/6fdd6232884a1a15f0841490acde686b36587a98/nova/tests/unit/objects/test_request_spec.py",
"raw_url":"https://github.com/openstack/nova/raw/6fdd6232884a1a15f0841490acde686b36587a98/nova/tests/unit/objects/test_request_spec.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_request_spec.py?ref=6fdd6232884a1a15f0841490acde686b36587a98",
"patch":"@@ -615,6 +615,69 @@ def test_get_by_instance_uuid(self, mock_get_ig, get_by_uuid):\n         self.assertIsInstance(req_obj.instance_group, objects.InstanceGroup)\n         self.assertEqual('fresh', req_obj.instance_group.name)\n \n+    # FIXME(gibi): This is bug 1952941. When the cpuset -> pcpuset data\n+    # migration was added to InstanceNUMATopology it was missed that such\n+    # object is not only hydrated via\n+    # InstanceNUMATopology.get_by_instance_uuid() but also hydrated by\n+    # RequestSpec.get_by_instance_uuid() indirectly. However the\n+    # latter code patch does not call InstanceNUMATopology.obj_from_db_obj()\n+    # that triggers the data migration via\n+    # InstanceNUMATopology._migrate_legacy_dedicated_instance_cpuset.\n+    # This causes that when the new nova code loads an old RequestSpec object\n+    # from the DB (e.g. during migration of an instance) the\n+    # InstanceNUMATopology in the RequestSpec will not be migrated to the new\n+    # object version and it will lead to errors when the pcpuset field is read\n+    # during scheduling.\n+    @mock.patch(\n+        'nova.objects.instance_numa.InstanceNUMATopology.'\n+        '_migrate_legacy_dedicated_instance_cpuset',\n+        new=mock.NonCallableMock()\n+    )\n+    @mock.patch.object(\n+        request_spec.RequestSpec, '_get_by_instance_uuid_from_db')\n+    @mock.patch('nova.objects.InstanceGroup.get_by_uuid')\n+    def test_get_by_instance_uuid_numa_topology_migration(\n+        self, mock_get_ig, get_by_uuid\n+    ):\n+        # Simulate a pre-Victoria RequestSpec where the pcpuset field is not\n+        # defined for the embedded InstanceNUMACell objects but the cpu_policy\n+        # is dedicated meaning that cores in cpuset defines pinned cpus. So\n+        # in Victoria or later these InstanceNUMACell objects should be\n+        # translated to hold the cores in the pcpuset field instead.\n+        numa_topology = objects.InstanceNUMATopology(\n+            instance_uuid=uuids.instance_uuid,\n+            cells=[\n+                objects.InstanceNUMACell(\n+                    id=0, cpuset={1, 2}, memory=512, cpu_policy=\"dedicated\"),\n+                objects.InstanceNUMACell(\n+                    id=1, cpuset={3, 4}, memory=512, cpu_policy=\"dedicated\"),\n+            ]\n+        )\n+        spec_obj = fake_request_spec.fake_spec_obj()\n+        spec_obj.numa_topology = numa_topology\n+        fake_spec = fake_request_spec.fake_db_spec(spec_obj)\n+        fake_spec['instance_uuid'] = uuids.instance_uuid\n+\n+        get_by_uuid.return_value = fake_spec\n+        mock_get_ig.return_value = objects.InstanceGroup(name='fresh')\n+\n+        req_obj = request_spec.RequestSpec.get_by_instance_uuid(\n+            self.context, fake_spec['instance_uuid'])\n+\n+        self.assertEqual(2, len(req_obj.numa_topology.cells))\n+\n+        # This is bug 1952941 as the pcpuset is not defined in object as the\n+        # object is not migrated\n+        ex = self.assertRaises(\n+            NotImplementedError,\n+            lambda: req_obj.numa_topology.cells[0].pcpuset\n+        )\n+        self.assertIn(\"Cannot load 'pcpuset' in the base class\", str(ex))\n+\n+        # This is the expected behavior\n+        # self.assertEqual({1, 2}, req_obj.numa_topology.cells[0].pcpuset)\n+        # self.assertEqual({3, 4}, req_obj.numa_topology.cells[1].pcpuset)\n+\n     def _check_update_primitive(self, req_obj, changes):\n         self.assertEqual(req_obj.instance_uuid, changes['instance_uuid'])\n         serialized_obj = objects.RequestSpec.obj_from_primitive("
}
]
},
{
"commit_sha":"b00ce99dd456ab701cef0a9d4429920834d3d840",
"commit_node_id":"C_kwDOAAwOD9oAKGIwMGNlOTlkZDQ1NmFiNzAxY2VmMGE5ZDQ0Mjk5MjA4MzRkM2Q4NDA",
"commit_html_url":"https://github.com/openstack/nova/commit/b00ce99dd456ab701cef0a9d4429920834d3d840",
"commit_date":"2022-02-04T12:28:10Z",
"files":[
{
"sha":"9e531b73ffc79ab8690e274f3551c617a14fd913",
"filename":".zuul.yaml",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/b00ce99dd456ab701cef0a9d4429920834d3d840/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/b00ce99dd456ab701cef0a9d4429920834d3d840/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=b00ce99dd456ab701cef0a9d4429920834d3d840",
"patch":"@@ -294,7 +294,7 @@\n       # tempest_test_exclude_list.\n       # FIXME(lyarwood): The tempest.api.compute.admin.test_volume_swap tests\n       # are skipped until bug #1929710 is resolved.\n-      tempest_exclude_regex: ^tempest\\.(scenario\\.test_network_(?!qos)|api\\.compute\\.admin\\.test_volume_swap)\n+      tempest_exclude_regex: ^tempest\\.(scenario\\.test_network_(?!qos)|api\\.compute\\.admin\\.test_volume_swap)|tempest.api.compute.servers.test_device_tagging.TaggedAttachmentsTest.test_tagged_attachment\n       devstack_local_conf:\n         post-config:\n           $NOVA_CPU_CONF:"
}
]
},
{
"commit_sha":"37bd469199404f8b508455864c86cd55176ccc9f",
"commit_node_id":"C_kwDOAAwOD9oAKDM3YmQ0NjkxOTk0MDRmOGI1MDg0NTU4NjRjODZjZDU1MTc2Y2NjOWY",
"commit_html_url":"https://github.com/openstack/nova/commit/37bd469199404f8b508455864c86cd55176ccc9f",
"commit_date":"2022-02-03T18:51:08Z",
"files":[
{
"sha":"4aaccf639a43e65ffb2a60cfd140a273967ec640",
"filename":"nova/api/validation/extra_specs/hw.py",
"status":"modified",
"additions":14,
"deletions":0,
"changes":14,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/api/validation/extra_specs/hw.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/api/validation/extra_specs/hw.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/validation/extra_specs/hw.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -368,6 +368,20 @@\n             'description': 'Whether to enable the boot menu',\n         },\n     ),\n+    base.ExtraSpecValidator(\n+        name='hw:vif_multiqueue_enabled',\n+        description=(\n+            'Whether to enable the virtio-net multiqueue feature. '\n+            'When set, the driver sets the number of queues equal to the '\n+            'number of guest vCPUs. This makes the network performance scale '\n+            'across a number of vCPUs. This requires guest support and is '\n+            'only supported by the libvirt driver.'\n+        ),\n+        value={\n+            'type': bool,\n+            'description': 'Whether to enable multiqueue',\n+        },\n+    ),\n     base.ExtraSpecValidator(\n         name='hw:mem_encryption',\n         description=("
},
{
"sha":"28368d910fdebe7fd9baac823de15b95ad127583",
"filename":"nova/compute/api.py",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/compute/api.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/compute/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/api.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -852,6 +852,7 @@ def _validate_flavor_image_numa_pci(\n         hardware.get_number_of_serial_ports(flavor, image_meta)\n         hardware.get_realtime_cpu_constraint(flavor, image_meta)\n         hardware.get_cpu_topology_constraints(flavor, image_meta)\n+        hardware.get_vif_multiqueue_constraint(flavor, image_meta)\n         if validate_numa:\n             hardware.numa_get_constraints(flavor, image_meta)\n         if validate_pci:"
},
{
"sha":"43504efeb5397addd573144af990a28b93b20bcf",
"filename":"nova/tests/unit/virt/libvirt/test_vif.py",
"status":"modified",
"additions":39,
"deletions":19,
"changes":58,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/tests/unit/virt/libvirt/test_vif.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/tests/unit/virt/libvirt/test_vif.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_vif.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -702,17 +702,20 @@ def test_vhostuser_os_vif_multiqueue(self):\n         image_meta = objects.ImageMeta.from_dict(\n             {'properties': {'hw_vif_model': 'virtio',\n                             'hw_vif_multiqueue_enabled': 'true'}})\n-        flavor = objects.Flavor(name='m1.small',\n-                    memory_mb=128,\n-                    vcpus=4,\n-                    root_gb=0,\n-                    ephemeral_gb=0,\n-                    swap=0,\n-                    deleted_at=None,\n-                    deleted=0,\n-                    created_at=None, flavorid=1,\n-                    is_public=True, vcpu_weight=None,\n-                    id=2, disabled=False, rxtx_factor=1.0)\n+        flavor = objects.Flavor(\n+            id=2,\n+            name='m1.small',\n+            memory_mb=128,\n+            vcpus=4,\n+            root_gb=0,\n+            ephemeral_gb=0,\n+            swap=0,\n+            deleted_at=None,\n+            deleted=0,\n+            created_at=None, flavorid=1,\n+            is_public=True, vcpu_weight=None,\n+            disabled=False,\n+            extra_specs={})\n         conf = d.get_base_config(None, 'ca:fe:de:ad:be:ef', image_meta,\n                                  flavor, 'kvm', 'normal')\n         self.assertEqual(4, conf.vhost_queues)\n@@ -728,7 +731,8 @@ def _test_virtio_config_queue_sizes(\n         self.flags(tx_queue_size=1024, group='libvirt')\n         v = vif.LibvirtGenericVIFDriver()\n         conf = v.get_base_config(\n-            None, 'ca:fe:de:ad:be:ef', {}, objects.Flavor(), 'kvm', vnic_type)\n+            None, 'ca:fe:de:ad:be:ef', {},\n+            objects.Flavor(vcpus=2), 'kvm', vnic_type)\n         return v, conf\n \n     def test_virtio_vhost_queue_sizes(self):\n@@ -874,8 +878,22 @@ def test_model_with_osinfo(self, mock_set):\n         d = vif.LibvirtGenericVIFDriver()\n         image_meta = {'properties': {'os_name': 'fedora22'}}\n         image_meta = objects.ImageMeta.from_dict(image_meta)\n+        flavor = objects.Flavor(\n+            id=2,\n+            name='m1.small',\n+            memory_mb=128,\n+            vcpus=4,\n+            root_gb=0,\n+            ephemeral_gb=0,\n+            swap=0,\n+            deleted_at=None,\n+            deleted=0,\n+            created_at=None, flavorid=1,\n+            is_public=True, vcpu_weight=None,\n+            disabled=False,\n+            extra_specs={})\n         d.get_base_config(None, 'ca:fe:de:ad:be:ef', image_meta,\n-                          None, 'kvm', 'normal')\n+                          flavor, 'kvm', 'normal')\n         mock_set.assert_called_once_with(mock.ANY, 'ca:fe:de:ad:be:ef',\n                                          'virtio', None, None, None)\n \n@@ -1089,9 +1107,9 @@ def test_plug_tap_kvm_virtio(\n         mq_ins = objects.Instance(\n             id=1, uuid='f0000000-0000-0000-0000-000000000001',\n             image_ref=uuids.image_ref, flavor=self.flavor_2vcpu,\n-            project_id=723, system_metadata={\n+            system_metadata={\n                 'image_hw_vif_multiqueue_enabled': 'True'\n-            }\n+            },\n         )\n         d2.plug(mq_ins, self.vif_tap)\n         mock_create_tap_dev.assert_called_once_with(\n@@ -1129,9 +1147,10 @@ def test_plug_tap_mq_ignored_virt_type(\n         ins = objects.Instance(\n             id=1, uuid='f0000000-0000-0000-0000-000000000001',\n             image_ref=uuids.image_ref, flavor=self.flavor_2vcpu,\n-            project_id=723, system_metadata={\n+            project_id=723,\n+            system_metadata={\n                 'image_hw_vif_multiqueue_enabled': 'True'\n-            }\n+            },\n         )\n         d1.plug(ins, self.vif_tap)\n         mock_create_tap_dev.assert_called_once_with(\n@@ -1147,10 +1166,11 @@ def test_plug_tap_mq_ignored_vif_model(\n         ins = objects.Instance(\n             id=1, uuid='f0000000-0000-0000-0000-000000000001',\n             image_ref=uuids.image_ref, flavor=self.flavor_2vcpu,\n-            project_id=723, system_metadata={\n+            project_id=723,\n+            system_metadata={\n                 'image_hw_vif_multiqueue_enabled': 'True',\n                 'image_hw_vif_model': 'e1000',\n-            }\n+            },\n         )\n         d1.plug(ins, self.vif_tap)\n         mock_create_tap_dev.assert_called_once_with("
},
{
"sha":"6f552255d4c3f1bb76cdd8709b67c2ae51d43f42",
"filename":"nova/tests/unit/virt/test_hardware.py",
"status":"modified",
"additions":44,
"deletions":0,
"changes":44,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/tests/unit/virt/test_hardware.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/tests/unit/virt/test_hardware.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/test_hardware.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -5452,6 +5452,50 @@ def test_get_pci_numa_policy_invalid(self):\n             image_meta.properties.hw_pci_numa_affinity_policy = \"fake\"\n \n \n+@ddt.ddt\n+class VIFMultiqueueEnabledTest(test.NoDBTestCase):\n+\n+    @ddt.unpack\n+    @ddt.data(\n+        # pass: no configuration\n+        (None, None, False),\n+        # pass: flavor-only configuration\n+        ('yes', None, True),\n+        # pass: image-only configuration\n+        (None, False, False),\n+        # pass: identical image and flavor configuration\n+        ('yes', True, True),\n+        # fail: mismatched image and flavor configuration\n+        ('no', True, exception.FlavorImageConflict),\n+    )\n+    def test_get_vif_multiqueue_constraint(\n+        self, flavor_policy, image_policy, expected,\n+    ):\n+        extra_specs = {}\n+\n+        if flavor_policy:\n+            extra_specs['hw:vif_multiqueue_enabled'] = flavor_policy\n+\n+        image_meta_props = {}\n+\n+        if image_policy:\n+            image_meta_props['hw_vif_multiqueue_enabled'] = image_policy\n+\n+        flavor = objects.Flavor(\n+            name='foo', vcpus=2, memory_mb=1024, extra_specs=extra_specs)\n+        image_meta = objects.ImageMeta.from_dict(\n+            {'name': 'bar', 'properties': image_meta_props})\n+\n+        if isinstance(expected, type) and issubclass(expected, Exception):\n+            self.assertRaises(\n+                expected, hw.get_vif_multiqueue_constraint, flavor, image_meta,\n+            )\n+        else:\n+            self.assertEqual(\n+                expected, hw.get_vif_multiqueue_constraint(flavor, image_meta),\n+            )\n+\n+\n @ddt.ddt\n class VTPMConfigTest(test.NoDBTestCase):\n "
},
{
"sha":"994be564180c96b051be92220784a23bbfb8dd76",
"filename":"nova/virt/hardware.py",
"status":"modified",
"additions":49,
"deletions":0,
"changes":49,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/virt/hardware.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/virt/hardware.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/hardware.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -1784,6 +1784,55 @@ def get_pci_numa_policy_constraint(\n     return policy\n \n \n+def get_vif_multiqueue_constraint(\n+    flavor: 'objects.Flavor',\n+    image_meta: 'objects.ImageMeta',\n+) -> bool:\n+    \"\"\"Validate and return the requested VIF multiqueue configuration.\n+\n+    :param flavor: ``nova.objects.Flavor`` instance\n+    :param image_meta: ``nova.objects.ImageMeta`` instance\n+    :raises: nova.exception.FlavorImageConflict if a value is specified in both\n+        the flavor and the image, but the values do not match\n+    :raises: nova.exception.Invalid if a value or combination of values is\n+        invalid\n+    :returns: True if the multiqueue must be enabled, else False.\n+    \"\"\"\n+    if flavor.vcpus < 2:\n+        return False\n+\n+    flavor_value_str, image_value = _get_flavor_image_meta(\n+        'vif_multiqueue_enabled', flavor, image_meta)\n+\n+    flavor_value = None\n+    if flavor_value_str is not None:\n+        flavor_value = strutils.bool_from_string(flavor_value_str)\n+\n+    if (\n+        image_value is not None and\n+        flavor_value is not None and\n+        image_value != flavor_value\n+    ):\n+        msg = _(\n+            \"Flavor %(flavor_name)s has %(prefix)s:%(key)s extra spec \"\n+            \"explicitly set to %(flavor_val)s, conflicting with image \"\n+            \"%(image_name)s which has %(prefix)s_%(key)s explicitly set to \"\n+            \"%(image_val)s.\"\n+        )\n+        raise exception.FlavorImageConflict(\n+            msg % {\n+                'prefix': 'hw',\n+                'key': 'vif_multiqueue_enabled',\n+                'flavor_name': flavor.name,\n+                'flavor_val': flavor_value,\n+                'image_name': image_meta.name,\n+                'image_val': image_value,\n+            }\n+        )\n+\n+    return flavor_value or image_value or False\n+\n+\n def get_vtpm_constraint(\n     flavor: 'objects.Flavor',\n     image_meta: 'objects.ImageMeta',"
},
{
"sha":"85c83572e19306a072a3792c582ae2f855082e02",
"filename":"nova/virt/libvirt/vif.py",
"status":"modified",
"additions":9,
"deletions":17,
"changes":26,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/nova/virt/libvirt/vif.py",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/nova/virt/libvirt/vif.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/vif.py?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -39,6 +39,7 @@\n import nova.privsep.linux_net\n from nova import profiler\n from nova import utils\n+from nova.virt import hardware\n from nova.virt.libvirt import config as vconfig\n from nova.virt.libvirt import designer\n from nova.virt.libvirt import host as libvirt_host\n@@ -256,9 +257,12 @@ def _get_virtio_mq_settings(self, image_meta, flavor):\n         \"\"\"A methods to set the number of virtio queues,\n            if it has been requested in extra specs.\n         \"\"\"\n+        if not isinstance(image_meta, objects.ImageMeta):\n+            image_meta = objects.ImageMeta.from_dict(image_meta)\n+\n         driver = None\n         vhost_queues = None\n-        if self._requests_multiqueue(image_meta):\n+        if hardware.get_vif_multiqueue_constraint(flavor, image_meta):\n             driver = 'vhost'\n             max_tap_queues = self._get_max_tap_queues()\n             if max_tap_queues:\n@@ -269,19 +273,6 @@ def _get_virtio_mq_settings(self, image_meta, flavor):\n \n         return (driver, vhost_queues)\n \n-    def _requests_multiqueue(self, image_meta):\n-        \"\"\"Check if multiqueue property is set in the image metadata.\"\"\"\n-\n-        if not isinstance(image_meta, objects.ImageMeta):\n-            image_meta = objects.ImageMeta.from_dict(image_meta)\n-\n-        img_props = image_meta.properties\n-\n-        if img_props.get('hw_vif_multiqueue_enabled'):\n-            return True\n-\n-        return False\n-\n     def _get_max_tap_queues(self):\n         # Note(sean-k-mooney): some linux distros have backported\n         # changes for newer kernels which make the kernel version\n@@ -692,9 +683,10 @@ def plug_tap(self, instance, vif):\n         vif_model = self.get_vif_model(image_meta=image_meta)\n         # TODO(ganso): explore whether multiqueue works for other vif models\n         # that go through this code path.\n-        multiqueue = (instance.get_flavor().vcpus > 1 and\n-                      self._requests_multiqueue(image_meta) and\n-                      vif_model == network_model.VIF_MODEL_VIRTIO)\n+        multiqueue = False\n+        if vif_model == network_model.VIF_MODEL_VIRTIO:\n+            multiqueue = hardware.get_vif_multiqueue_constraint(\n+                instance.flavor, image_meta)\n         nova.privsep.linux_net.create_tap_dev(dev, mac, multiqueue=multiqueue)\n         network = vif.get('network')\n         mtu = network.get_meta('mtu') if network else None"
},
{
"sha":"a73096104ad89f9c67e5f8f0730e0af9d54e209a",
"filename":"releasenotes/notes/flavor-based-multiqueue-configuration-41e2cbc4ca024682.yaml",
"status":"added",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/37bd469199404f8b508455864c86cd55176ccc9f/releasenotes/notes/flavor-based-multiqueue-configuration-41e2cbc4ca024682.yaml",
"raw_url":"https://github.com/openstack/nova/raw/37bd469199404f8b508455864c86cd55176ccc9f/releasenotes/notes/flavor-based-multiqueue-configuration-41e2cbc4ca024682.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/flavor-based-multiqueue-configuration-41e2cbc4ca024682.yaml?ref=37bd469199404f8b508455864c86cd55176ccc9f",
"patch":"@@ -0,0 +1,8 @@\n+---\n+features:\n+  - |\n+    The ``hw:vif_multiqueue_enabled`` flavor extra spec has been added. This\n+    is a boolean option that, when set, can be used to enable or disable\n+    multiqueue for virtio-net VIFs. It complements the equivalent image\n+    metadata property, ``hw_vif_multiqueue_enabled``. If both values are set,\n+    they must be identical or an error will be raised."
}
]
},
{
"commit_sha":"26ce7b30b2ea3ff921df3515f98669f1197caa47",
"commit_node_id":"C_kwDOAAwOD9oAKDI2Y2U3YjMwYjJlYTNmZjkyMWRmMzUxNWY5ODY2OWYxMTk3Y2FhNDc",
"commit_html_url":"https://github.com/openstack/nova/commit/26ce7b30b2ea3ff921df3515f98669f1197caa47",
"commit_date":"2022-02-03T18:28:02Z",
"files":[
{
"sha":"d9292223bc63cfc8d0769155f4419447aa67900b",
"filename":"doc/source/_extra/.htaccess",
"status":"modified",
"additions":4,
"deletions":2,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/_extra/.htaccess",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/_extra/.htaccess",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/_extra/.htaccess?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -6,7 +6,7 @@ redirectmatch 301 ^/nova/([^/]+)/aggregates.html$ /nova/$1/user/aggregates.html\n redirectmatch 301 ^/nova/([^/]+)/api_microversion_dev.html$ /nova/$1/contributor/microversions.html\n redirectmatch 301 ^/nova/([^/]+)/api_microversion_history.html$ /nova/$1/reference/api-microversion-history.html\n redirectmatch 301 ^/nova/([^/]+)/api_plugins.html$ /nova/$1/contributor/api.html\n-redirectmatch 301 ^/nova/([^/]+)/architecture.html$ /nova/$1/user/architecture.html\n+redirectmatch 301 ^/nova/([^/]+)/architecture.html$ /nova/$1/admin/architecture.html\n redirectmatch 301 ^/nova/([^/]+)/block_device_mapping.html$ /nova/$1/user/block-device-mapping.html\n redirectmatch 301 ^/nova/([^/]+)/blueprints.html$ /nova/$1/contributor/blueprints.html\n redirectmatch 301 ^/nova/([^/]+)/cells.html$ /nova/$1/admin/cells.html\n@@ -64,6 +64,7 @@ redirectmatch 301 ^/nova/([^/]+)/testing/zero-downtime-upgrade.html$ /nova/$1/co\n redirectmatch 301 ^/nova/([^/]+)/threading.html$ /nova/$1/reference/threading.html\n redirectmatch 301 ^/nova/([^/]+)/upgrade.html$ /nova/$1/admin/upgrades.html\n redirectmatch 301 ^/nova/([^/]+)/user/aggregates.html$ /nova/$1/admin/aggregates.html\n+redirectmatch 301 ^/nova/([^/]+)/user/architecture.html$ /nova/$1/admin/architecture.html\n redirectmatch 301 ^/nova/([^/]+)/user/cells.html$ /nova/$1/admin/cells.html\n redirectmatch 301 ^/nova/([^/]+)/user/cellsv2-layout.html$ /nova/$1/admin/cells.html\n redirectmatch 301 ^/nova/([^/]+)/user/cellsv2_layout.html$ /nova/$1/admin/cells.html\n@@ -77,9 +78,10 @@ redirectmatch 301 ^/nova/([^/]+)/user/vendordata.html$ /nova/$1/user/metadata.ht\n redirectmatch 301 ^/nova/([^/]+)/vendordata.html$ /nova/$1/user/metadata.html\n redirectmatch 301 ^/nova/([^/]+)/vmstates.html$ /nova/$1/reference/vm-states.html\n redirectmatch 301 ^/nova/([^/]+)/wsgi.html$ /nova/$1/user/wsgi.html\n+redirectmatch 301 ^/nova/([^/]+)/admin/arch.html$ /nova/$1/admin/architecture.html\n redirectmatch 301 ^/nova/([^/]+)/admin/adv-config.html$ /nova/$1/admin/index.html\n redirectmatch 301 ^/nova/([^/]+)/admin/configuration/schedulers.html$ /nova/$1/admin/scheduling.html\n redirectmatch 301 ^/nova/([^/]+)/admin/system-admin.html$ /nova/$1/admin/index.html\n redirectmatch 301 ^/nova/([^/]+)/admin/port_with_resource_request.html$ /nova/$1/admin/ports-with-resource-requests.html\n-redirectmatch 301 ^/nova/([^/]+)/admin/manage-users.html$ /nova/$1/admin/arch.html\n+redirectmatch 301 ^/nova/([^/]+)/admin/manage-users.html$ /nova/$1/admin/architecture.html\n redirectmatch 301 ^/nova/([^/]+)/admin/mitigation-for-Intel-MDS-security-flaws.html /nova/$1/admin/cpu-models.html"
},
{
"sha":"e0194dd78d8b140152572d2b4af0d9fc824f41e4",
"filename":"doc/source/admin/architecture.rst",
"status":"renamed",
"additions":101,
"deletions":87,
"changes":188,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/admin/architecture.rst",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/admin/architecture.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/architecture.rst?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -1,53 +1,75 @@\n-===================\n-System architecture\n-===================\n+========================\n+Nova System Architecture\n+========================\n \n-OpenStack Compute contains several main components.\n+Nova comprises multiple server processes, each performing different\n+functions. The user-facing interface is a REST API, while internally Nova\n+components communicate via an RPC message passing mechanism.\n \n-- The cloud controller represents the global state and interacts with the\n-  other components. The ``API server`` acts as the web services front end for\n-  the cloud controller. The ``compute controller`` provides compute server\n-  resources and usually also contains the Compute service.\n+The API servers process REST requests, which typically involve database\n+reads/writes, optionally sending RPC messages to other Nova services,\n+and generating responses to the REST calls.\n+RPC messaging is done via the **oslo.messaging** library,\n+an abstraction on top of message queues.\n+Nova uses a messaging-based, ``shared nothing`` architecture and most of the\n+major nova components can be run on multiple servers, and have a manager that\n+is listening for RPC messages.\n+The one major exception is ``nova-compute``, where a single process runs on the\n+hypervisor it is managing (except when using the VMware or Ironic drivers).\n+The manager also, optionally, has periodic tasks.\n+For more details on our RPC system, please see: :doc:`/reference/rpc`\n \n-- The ``object store`` is an optional component that provides storage\n-  services; you can also use OpenStack Object Storage instead.\n+Nova also uses a central database that is (logically) shared between all\n+components. However, to aid upgrade, the DB is accessed through an object\n+layer that ensures an upgraded control plane can still communicate with\n+a ``nova-compute`` running the previous release.\n+To make this possible ``nova-compute`` proxies DB requests over RPC to a\n+central manager called ``nova-conductor``.\n \n-- An ``auth manager`` provides authentication and authorization services when\n-  used with the Compute system; you can also use OpenStack Identity as a\n-  separate authentication service instead.\n+To horizontally expand Nova deployments, we have a deployment sharding\n+concept called cells. For more information please see: :doc:`/admin/cells`\n \n-- A ``volume controller`` provides fast and permanent block-level storage for\n-  the compute servers.\n \n-- The ``network controller`` provides virtual networks to enable compute\n-  servers to interact with each other and with the public network. You can also\n-  use OpenStack Networking instead.\n+Components\n+----------\n \n-- The ``scheduler`` is used to select the most suitable compute controller to\n-  host an instance.\n+Below you will find a helpful explanation of the key components\n+of a typical Nova deployment.\n+\n+.. image:: /_static/images/architecture.svg\n+   :width: 100%\n+\n+* **DB**: SQL database for data storage.\n+\n+* **API**: Component that receives HTTP requests, converts commands and\n+  communicates with other components via the **oslo.messaging** queue or HTTP.\n+\n+* **Scheduler**: Decides which host gets each instance.\n+\n+* **Compute**: Manages communication with hypervisor and virtual machines.\n+\n+* **Conductor**: Handles requests that need coordination (build/resize), acts\n+  as a database proxy, or handles object conversions.\n+\n+* **:placement-doc:`Placement <>`**: Tracks resource provider inventories and\n+  usages.\n+\n+While all services are designed to be horizontally scalable, you should have\n+significantly more computes than anything else.\n \n-Compute uses a messaging-based, ``shared nothing`` architecture. All major\n-components exist on multiple servers, including the compute, volume, and\n-network controllers, and the Object Storage or Image service.  The state of the\n-entire system is stored in a database. The cloud controller communicates with\n-the internal object store using HTTP, but it communicates with the scheduler,\n-network controller, and volume controller using Advanced Message Queuing\n-Protocol (AMQP). To avoid blocking a component while waiting for a response,\n-Compute uses asynchronous calls, with a callback that is triggered when a\n-response is received.\n \n Hypervisors\n-~~~~~~~~~~~\n+-----------\n \n-Compute controls hypervisors through an API server. Selecting the best\n+Nova controls hypervisors through an API server. Selecting the best\n hypervisor to use can be difficult, and you must take budget, resource\n constraints, supported features, and required technical specifications into\n account. However, the majority of OpenStack development is done on systems\n using KVM-based hypervisors. For a detailed list of features and\n support across different hypervisors, see :doc:`/user/support-matrix`.\n \n You can also orchestrate clouds using multiple hypervisors in different\n-availability zones. Compute supports the following hypervisors:\n+availability zones. Nova supports the following hypervisors:\n \n - :ironic-doc:`Baremetal <>`\n \n@@ -75,35 +97,29 @@ For more information about hypervisors, see\n :doc:`/admin/configuration/hypervisors`\n section in the Nova Configuration Reference.\n \n+\n Projects, users, and roles\n-~~~~~~~~~~~~~~~~~~~~~~~~~~\n+--------------------------\n \n-To begin using Compute, you must create a user with the\n+To begin using Nova, you must create a user with the\n :keystone-doc:`Identity service <>`.\n \n-The Compute system is designed to be used by different consumers in the form of\n-projects on a shared system, and role-based access assignments.  Roles control\n+The Nova system is designed to be used by different consumers in the form of\n+projects on a shared system, and role-based access assignments. Roles control\n the actions that a user is allowed to perform.\n \n Projects are isolated resource containers that form the principal\n-organizational structure within the Compute service. They consist of an\n+organizational structure within the Nova service. They typically consist of an\n individual VLAN, and volumes, instances, images, keys, and users. A user can\n specify the project by appending ``project_id`` to their access key.  If no\n-project is specified in the API request, Compute attempts to use a project with\n+project is specified in the API request, Nova attempts to use a project with\n the same ID as the user.\n \n-For projects, you can use quota controls to limit the:\n-\n-- Number of volumes that can be launched.\n-\n-- Number of processor cores and the amount of RAM that can be allocated.\n-\n-- Floating IP addresses assigned to any instance when it launches. This allows\n-  instances to have the same publicly accessible IP addresses.\n-\n-- Fixed IP addresses assigned to the same instance when it launches.  This\n-  allows instances to have the same publicly or privately accessible IP\n-  addresses.\n+For projects, you can use quota controls to limit the number of processor cores\n+and the amount of RAM that can be allocated. Other projects also allow quotas\n+on their own resources. For example, :neutron-doc:`neutron\n+</admin/ops-quotas.html>` allows you to manage the amount of networks that can\n+be created within a project.\n \n Roles control the actions a user is allowed to perform. By default, most\n actions do not require a particular role, but you can configure them by editing\n@@ -122,54 +138,52 @@ consumption across available hardware resources.\n    ``project``. Because of this legacy terminology, some command-line tools use\n    ``--tenant_id`` where you would normally expect to enter a project ID.\n \n+\n Block storage\n-~~~~~~~~~~~~~\n+-------------\n \n OpenStack provides two classes of block storage: ephemeral storage and\n persistent volume.\n \n .. rubric:: Ephemeral storage\n \n Ephemeral storage includes a root ephemeral volume and an additional ephemeral\n-volume.\n+volume. These are provided by nova itself.\n \n The root disk is associated with an instance, and exists only for the life of\n this very instance. Generally, it is used to store an instance's root file\n system, persists across the guest operating system reboots, and is removed on\n an instance deletion. The amount of the root ephemeral volume is defined by the\n flavor of an instance.\n \n-In addition to the ephemeral root volume, all default types of flavors, except\n-``m1.tiny``, which is the smallest one, provide an additional ephemeral block\n-device sized between 20 and 160 GB (a configurable value to suit an\n-environment). It is represented as a raw block device with no partition table\n-or file system. A cloud-aware operating system can discover, format, and mount\n-such a storage device. OpenStack Compute defines the default file system for\n-different operating systems as Ext4 for Linux distributions, VFAT for non-Linux\n-and non-Windows operating systems, and NTFS for Windows. However, it is\n-possible to specify any other filesystem type by using ``virt_mkfs`` or\n-``default_ephemeral_format`` configuration options.\n+In addition to the ephemeral root volume, flavors can provide an additional\n+ephemeral block device. It is represented as a raw block device with no\n+partition table or file system. A cloud-aware operating system can discover,\n+format, and mount such a storage device. Nova defines the default file system\n+for different operating systems as ext4 for Linux distributions, VFAT for\n+non-Linux and non-Windows operating systems, and NTFS for Windows. However, it\n+is possible to configure other filesystem types.\n \n .. note::\n \n    For example, the ``cloud-init`` package included into an Ubuntu's stock\n-   cloud image, by default, formats this space as an Ext4 file system and\n+   cloud image, by default, formats this space as an ext4 file system and\n    mounts it on ``/mnt``. This is a cloud-init feature, and is not an OpenStack\n    mechanism. OpenStack only provisions the raw storage.\n \n .. rubric:: Persistent volume\n \n A persistent volume is represented by a persistent virtualized block device\n-independent of any particular instance, and provided by OpenStack Block\n-Storage.\n+independent of any particular instance. These are provided by the OpenStack\n+Block Storage service, cinder.\n \n-Only a single configured instance can access a persistent volume.  Multiple\n-instances cannot access a persistent volume. This type of configuration\n-requires a traditional network file system to allow multiple instances\n-accessing the persistent volume. It also requires a traditional network file\n-system like NFS, CIFS, or a cluster file system such as GlusterFS. These\n-systems can be built within an OpenStack cluster, or provisioned outside of it,\n-but OpenStack software does not provide these features.\n+Persistent volumes can be accessed by a single instance or attached to multiple\n+instances. This type of configuration requires a traditional network file\n+system to allow multiple instances accessing the persistent volume. It also\n+requires a traditional network file system like NFS, CIFS, or a cluster file\n+system such as GlusterFS. These systems can be built within an OpenStack\n+cluster, or provisioned outside of it, but OpenStack software does not provide\n+these features.\n \n You can configure a persistent volume as bootable and use it to provide a\n persistent virtual instance similar to the traditional non-cloud-based\n@@ -190,17 +204,17 @@ configuration, see :cinder-doc:`Introduction to the Block Storage service\n \n \n Building blocks\n-~~~~~~~~~~~~~~~\n+---------------\n \n In OpenStack the base operating system is usually copied from an image stored\n-in the OpenStack Image service. This is the most common case and results in an\n-ephemeral instance that starts from a known template state and loses all\n-accumulated states on virtual machine deletion. It is also possible to put an\n-operating system on a persistent volume in the OpenStack Block Storage volume\n-system. This gives a more traditional persistent system that accumulates states\n-which are preserved on the OpenStack Block Storage volume across the deletion\n-and re-creation of the virtual machine. To get a list of available images on\n-your system, run:\n+in the OpenStack Image service, glance. This is the most common case and\n+results in an ephemeral instance that starts from a known template state and\n+loses all accumulated states on virtual machine deletion. It is also possible\n+to put an operating system on a persistent volume in the OpenStack Block\n+Storage service. This gives a more traditional persistent system that\n+accumulates states which are preserved on the OpenStack Block Storage volume\n+across the deletion and re-creation of the virtual machine. To get a list of\n+available images on your system, run:\n \n .. code-block:: console\n \n@@ -230,10 +244,9 @@ The displayed image attributes are:\n   field is blank.\n \n Virtual hardware templates are called ``flavors``. By default, these are\n-configurable by admin users, however that behavior can be changed by redefining\n-the access controls for ``compute_extension:flavormanage`` in\n-``/etc/nova/policy.yaml`` on the ``compute-api`` server.\n-For more information, refer to :doc:`/configuration/policy`.\n+configurable by admin users, however, that behavior can be changed by redefining\n+the access controls ``policy.yaml`` on the ``nova-compute`` server. For more\n+information, refer to :doc:`/configuration/policy`.\n \n For a list of flavors that are available on your system:\n \n@@ -250,8 +263,9 @@ For a list of flavors that are available on your system:\n    | 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |\n    +-----+-----------+-------+------+-----------+-------+-----------+\n \n-Compute service architecture\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Nova service architecture\n+-------------------------\n \n These basic categories describe the service architecture and information about\n the cloud controller.",
"previous_filename":"doc/source/admin/arch.rst"
},
{
"sha":"c8515f3ec1a5b7bb9a51b6a52bf680e4ed45fe89",
"filename":"doc/source/admin/index.rst",
"status":"modified",
"additions":118,
"deletions":45,
"changes":163,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/admin/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/admin/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/index.rst?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -1,6 +1,6 @@\n-=======\n-Compute\n-=======\n+===================\n+Admin Documentation\n+===================\n \n The OpenStack Compute service allows you to control an\n Infrastructure-as-a-Service (IaaS) cloud computing platform.  It gives you\n@@ -28,57 +28,143 @@ responsibilities of services and drivers are:\n \n .. rubric:: Services\n \n-``nova-api``\n-  Receives XML requests and sends them to the rest of the system. A WSGI app\n-  routes and authenticates requests. Supports the OpenStack Compute APIs. A\n-  ``nova.conf`` configuration file is created when Compute is installed.\n+:doc:`nova-api-metadata </cli/nova-api-metadata>`\n+  A server daemon that serves the Nova Metadata API.\n \n-.. todo::\n+:doc:`nova-api-os-compute </cli/nova-api-os-compute>`\n+  A server daemon that serves the Nova OpenStack Compute API.\n \n-   Describe nova-api-metadata, nova-api-os-compute, nova-serialproxy and\n-   nova-spicehtml5proxy\n+:doc:`nova-api </cli/nova-api>`\n+  A server daemon that serves the metadata and compute APIs in separate\n+  greenthreads.\n \n-   nova-console, nova-dhcpbridge and nova-xvpvncproxy are all deprecated for\n-   removal so they can be ignored.\n-\n-``nova-compute``\n+:doc:`nova-compute </cli/nova-compute>`\n   Manages virtual machines. Loads a Service object, and exposes the public\n   methods on ComputeManager through a Remote Procedure Call (RPC).\n \n-``nova-conductor``\n+:doc:`nova-conductor </cli/nova-conductor>`\n   Provides database-access support for compute nodes (thereby reducing security\n   risks).\n \n-``nova-scheduler``\n+:doc:`nova-scheduler </cli/nova-scheduler>`\n   Dispatches requests for new virtual machines to the correct node.\n \n-``nova-novncproxy``\n+:doc:`nova-novncproxy </cli/nova-novncproxy>`\n   Provides a VNC proxy for browsers, allowing VNC consoles to access virtual\n   machines.\n \n+:doc:`nova-spicehtml5proxy </cli/nova-spicehtml5proxy>`\n+  Provides a SPICE proxy for browsers, allowing SPICE consoles to access\n+  virtual machines.\n+\n+:doc:`nova-serialproxy </cli/nova-serialproxy>`\n+  Provides a serial console proxy, allowing users to access a virtual machine's\n+  serial console.\n+\n+The architecture is covered in much greater detail in\n+:doc:`/admin/architecture`.\n+\n+.. toctree::\n+   :maxdepth: 2\n+\n+   architecture\n+\n .. note::\n \n    Some services have drivers that change how the service implements its core\n    functionality. For example, the ``nova-compute`` service supports drivers\n    that let you choose which hypervisor type it can use.\n \n+\n+Deployment Considerations\n+-------------------------\n+\n+There is information you might want to consider before doing your deployment,\n+especially if it is going to be a larger deployment. For smaller deployments\n+the defaults from the :doc:`install guide </install/index>` will be sufficient.\n+\n+* **Compute Driver Features Supported**: While the majority of nova deployments use\n+  libvirt/kvm, you can use nova with other compute drivers. Nova attempts to\n+  provide a unified feature set across these, however, not all features are\n+  implemented on all backends, and not all features are equally well tested.\n+\n+  * :doc:`Feature Support by Use Case </user/feature-classification>`: A view of\n+    what features each driver supports based on what's important to some large\n+    use cases (General Purpose Cloud, NFV Cloud, HPC Cloud).\n+\n+  * :doc:`Feature Support full list </user/support-matrix>`: A detailed dive through\n+    features in each compute driver backend.\n+\n+* :doc:`Cells v2 configuration </admin/cells>`: For large deployments, cells v2\n+  cells allow sharding of your compute environment. Upfront planning is key to\n+  a successful cells v2 layout.\n+\n+* :doc:`Availablity Zones </admin/availability-zones>`: Availability Zones are\n+  an end-user visible logical abstraction for partitioning a cloud without\n+  knowing the physical infrastructure. They can be used to partition a cloud on\n+  arbitrary factors, such as location (country, datacenter, rack), network\n+  layout and/or power source.\n+\n+* :placement-doc:`Placement service <>`: Overview of the placement\n+  service, including how it fits in with the rest of nova.\n+\n+* :doc:`Running nova-api on wsgi </user/wsgi>`: Considerations for using a real\n+  WSGI container instead of the baked-in eventlet web server.\n+\n .. toctree::\n    :maxdepth: 2\n \n-   manage-volumes\n-   flavors\n+   cells\n+   aggregates\n    default-ports\n-   admin-password-injection\n+   availability-zones\n+   configuration/index\n+\n+\n+Basic configuration\n+-------------------\n+\n+Once you have an OpenStack deployment up and running, you will want to manage\n+it. The below guides cover everything from creating initial flavor and image to\n+log management and live migration of instances.\n+\n+* :doc:`Quotas </admin/quotas>`: Managing project quotas in nova.\n+\n+* :doc:`Scheduling </admin/scheduling>`: How the scheduler is\n+  configured, and how that will impact where compute instances land in your\n+  environment. If you are seeing unexpected distribution of compute instances\n+  in your hosts, you'll want to dive into this configuration.\n+\n+* :doc:`Exposing custom metadata to compute instances </admin/vendordata>`: How\n+  and when you might want to extend the basic metadata exposed to compute\n+  instances (either via metadata server or config drive) for your specific\n+  purposes.\n+\n+.. toctree::\n+   :maxdepth: 2\n+\n    manage-the-cloud\n+   services\n+   service-groups\n    manage-logs\n    root-wrap-reference\n+   ssh-configuration\n    configuring-migrations\n    live-migration-usage\n+   secure-live-migration-with-qemu-native-tls\n+   manage-volumes\n+   flavors\n+   admin-password-injection\n    remote-console-access\n-   service-groups\n-   node-down\n    scheduling\n-   upgrades\n+   config-drive\n+   image-caching\n+   metadata-service\n+   quotas\n+   networking\n+   security-groups\n+   security\n+   vendordata\n \n \n Advanced configuration\n@@ -125,34 +211,21 @@ instance for these kind of workloads.\n    libvirt-misc\n \n \n-Additional guides\n------------------\n+Maintenance\n+-----------\n \n-.. TODO(mriedem): This index page has a lot of content which should be\n-   organized into groups for things like configuration, operations,\n-   troubleshooting, etc.\n+Once you are running nova, the following information is extremely useful.\n+\n+* :doc:`Upgrades <upgrades>`: How nova is designed to be upgraded for minimal\n+  service impact, and the order you should do them in.\n \n .. toctree::\n    :maxdepth: 2\n \n-   aggregates\n-   arch\n-   availability-zones\n-   cells\n-   config-drive\n-   configuration/index\n+   support-compute\n    evacuate\n-   image-caching\n-   metadata-service\n    migration\n    migrate-instance-with-snapshot\n-   networking\n-   quotas\n-   security-groups\n-   security\n-   services\n-   ssh-configuration\n-   support-compute\n-   secure-live-migration-with-qemu-native-tls\n-   vendordata\n+   upgrades\n+   node-down\n    hw-machine-type"
},
{
"sha":"98da0106f8efb0109115c7dbe351a9a2e5362617",
"filename":"doc/source/index.rst",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/index.rst?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -107,15 +107,15 @@ For Operators\n Architecture Overview\n ---------------------\n \n-* :doc:`Nova architecture </user/architecture>`: An overview of how all the parts in\n+* :doc:`Nova architecture </admin/architecture>`: An overview of how all the parts in\n   nova fit together.\n \n .. # NOTE(amotoki): toctree needs to be placed at the end of the secion to\n    # keep the document structure in the PDF doc.\n .. toctree::\n    :hidden:\n \n-   user/architecture\n+   admin/architecture\n \n Installation\n ------------"
},
{
"sha":"2841cc0001783e9350cb0267b5cf33f76e7335bd",
"filename":"doc/source/user/architecture.rst",
"status":"removed",
"additions":0,
"deletions":64,
"changes":64,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/architecture.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/architecture.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/architecture.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -1,64 +0,0 @@\n-..\n-      Copyright 2010-2011 United States Government as represented by the\n-      Administrator of the National Aeronautics and Space Administration.\n-      All Rights Reserved.\n-\n-      Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n-      not use this file except in compliance with the License. You may obtain\n-      a copy of the License at\n-\n-          http://www.apache.org/licenses/LICENSE-2.0\n-\n-      Unless required by applicable law or agreed to in writing, software\n-      distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n-      WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n-      License for the specific language governing permissions and limitations\n-      under the License.\n-\n-Nova System Architecture\n-========================\n-\n-Nova comprises multiple server processes, each performing different\n-functions. The user-facing interface is a REST API, while internally Nova\n-components communicate via an RPC message passing mechanism.\n-\n-The API servers process REST requests, which typically involve database\n-reads/writes, optionally sending RPC messages to other Nova services,\n-and generating responses to the REST calls.\n-RPC messaging is done via the **oslo.messaging** library,\n-an abstraction on top of message queues.\n-Most of the major nova components can be run on multiple servers, and have\n-a manager that is listening for RPC messages.\n-The one major exception is ``nova-compute``, where a single process runs on the\n-hypervisor it is managing (except when using the VMware or Ironic drivers).\n-The manager also, optionally, has periodic tasks.\n-For more details on our RPC system, please see: :doc:`/reference/rpc`\n-\n-Nova also uses a central database that is (logically) shared between all\n-components. However, to aid upgrade, the DB is accessed through an object\n-layer that ensures an upgraded control plane can still communicate with\n-a ``nova-compute`` running the previous release.\n-To make this possible nova-compute proxies DB requests over RPC to a\n-central manager called ``nova-conductor``.\n-\n-To horizontally expand Nova deployments, we have a deployment sharding\n-concept called cells. For more information please see: :doc:`/admin/cells`\n-\n-Components\n-----------\n-\n-Below you will find a helpful explanation of the key components\n-of a typical Nova deployment.\n-\n-.. image:: /_static/images/architecture.svg\n-   :width: 100%\n-\n-* DB: sql database for data storage.\n-* API: component that receives HTTP requests, converts commands and communicates with other components via the **oslo.messaging** queue or HTTP.\n-* Scheduler: decides which host gets each instance.\n-* Compute: manages communication with hypervisor and virtual machines.\n-* Conductor: handles requests that need coordination (build/resize), acts as a\n-  database proxy, or handles object conversions.\n-* :placement-doc:`Placement <>`: tracks resource provider inventories and usages.\n-\n-While all services are designed to be horizontally scalable, you should have significantly more computes than anything else."
},
{
"sha":"0ecf4344e4595fed3004fb0ecd1638161e1e8247",
"filename":"doc/source/user/index.rst",
"status":"modified",
"additions":9,
"deletions":71,
"changes":80,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/user/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/source/user/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/index.rst?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -2,6 +2,15 @@\n User Documentation\n ==================\n \n+The OpenStack Compute service allows you to control an\n+Infrastructure-as-a-Service (IaaS) cloud computing platform.  It gives you\n+control over instances and networks, and allows you to manage access to the\n+cloud through users and projects.\n+\n+Compute does not include virtualization software. Instead, it defines drivers\n+that interact with underlying virtualization mechanisms that run on your host\n+operating system, and exposes functionality over a web-based API.\n+\n End user guide\n --------------\n \n@@ -18,74 +27,3 @@ End user guide\n    rescue\n    block-device-mapping\n    /reference/api-microversion-history\n-\n-.. todo:: The rest of this document should probably move to the admin guide.\n-\n-Architecture Overview\n----------------------\n-\n-* :doc:`Nova architecture </user/architecture>`: An overview of how all the parts in\n-  nova fit together.\n-\n-* :doc:`Block Device Mapping </user/block-device-mapping>`: One of the more\n-  complicated parts to understand is the Block Device Mapping parameters used\n-  to connect specific block devices to computes. This deserves its own deep\n-  dive.\n-\n-See the :ref:`reference guide <reference-internals>` for details about more\n-internal subsystems.\n-\n-Deployment Considerations\n--------------------------\n-\n-There is information you might want to consider before doing your deployment,\n-especially if it is going to be a larger deployment. For smaller deployments\n-the defaults from the :doc:`install guide </install/index>` will be sufficient.\n-\n-* **Compute Driver Features Supported**: While the majority of nova deployments use\n-  libvirt/kvm, you can use nova with other compute drivers. Nova attempts to\n-  provide a unified feature set across these, however, not all features are\n-  implemented on all backends, and not all features are equally well tested.\n-\n-  * :doc:`Feature Support by Use Case </user/feature-classification>`: A view of\n-    what features each driver supports based on what's important to some large\n-    use cases (General Purpose Cloud, NFV Cloud, HPC Cloud).\n-\n-  * :doc:`Feature Support full list </user/support-matrix>`: A detailed dive through\n-    features in each compute driver backend.\n-\n-* :doc:`Cells v2 configuration </admin/cells>`: For large deployments, cells v2\n-  cells allow sharding of your compute environment. Upfront planning is key to\n-  a successful cells v2 layout.\n-\n-* :placement-doc:`Placement service <>`: Overview of the placement\n-  service, including how it fits in with the rest of nova.\n-\n-* :doc:`Running nova-api on wsgi </user/wsgi>`: Considerations for using a real\n-  WSGI container instead of the baked-in eventlet web server.\n-\n-Maintenance\n------------\n-\n-Once you are running nova, the following information is extremely useful.\n-\n-* :doc:`Admin Guide </admin/index>`: A collection of guides for administrating\n-  nova.\n-\n-* :doc:`Quotas </user/quotas>`: Managing project quotas in nova.\n-\n-* :doc:`Availablity Zones </admin/availability-zones>`: Availability Zones are\n-  an end-user visible logical abstraction for partitioning a cloud without\n-  knowing the physical infrastructure. They can be used to partition a cloud on\n-  arbitrary factors, such as location (country, datacenter, rack), network\n-  layout and/or power source.\n-\n-* :doc:`Scheduling </admin/scheduling>`: How the scheduler is\n-  configured, and how that will impact where compute instances land in your\n-  environment. If you are seeing unexpected distribution of compute instances\n-  in your hosts, you'll want to dive into this configuration.\n-\n-* :doc:`Exposing custom metadata to compute instances </admin/vendordata>`: How\n-  and when you might want to extend the basic metadata exposed to compute\n-  instances (either via metadata server or config drive) for your specific\n-  purposes."
},
{
"sha":"90ae3fa6b372c83c3930735378f65e69f0347fe3",
"filename":"doc/test/redirect-tests.txt",
"status":"modified",
"additions":5,
"deletions":2,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/test/redirect-tests.txt",
"raw_url":"https://github.com/openstack/nova/raw/26ce7b30b2ea3ff921df3515f98669f1197caa47/doc/test/redirect-tests.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/test/redirect-tests.txt?ref=26ce7b30b2ea3ff921df3515f98669f1197caa47",
"patch":"@@ -1,12 +1,13 @@\n /nova/latest/addmethod.openstackapi.html 301 /nova/latest/contributor/api-2.html\n+/nova/latest/admin/arch.html 301 /nova/latest/admin/architecture.html\n /nova/latest/admin/flavors2.html 301 /nova/latest/admin/flavors.html\n /nova/latest/admin/quotas2.html 301 /nova/latest/admin/quotas.html\n /nova/latest/admin/numa.html 301 /nova/latest/admin/cpu-topologies.html\n /nova/latest/aggregates.html 301 /nova/latest/user/aggregates.html\n /nova/latest/api_microversion_dev.html 301 /nova/latest/contributor/microversions.html\n /nova/latest/api_microversion_history.html 301 /nova/latest/reference/api-microversion-history.html\n /nova/latest/api_plugins.html 301 /nova/latest/contributor/api.html\n-/nova/latest/architecture.html 301 /nova/latest/user/architecture.html\n+/nova/latest/architecture.html 301 /nova/latest/admin/architecture.html\n /nova/latest/block_device_mapping.html 301 /nova/latest/user/block-device-mapping.html\n /nova/latest/blueprints.html 301 /nova/latest/contributor/blueprints.html\n /nova/latest/cells.html 301 /nova/latest/admin/cells.html\n@@ -64,6 +65,7 @@\n /nova/latest/threading.html 301 /nova/latest/reference/threading.html\n /nova/latest/upgrade.html 301 /nova/latest/admin/upgrades.html\n /nova/latest/user/aggregates.html 301 /nova/latest/admin/aggregates.html\n+/nova/latest/user/architecture.html 301 /nova/latest/admin/architecture.html\n /nova/latest/user/cells.html 301 /nova/latest/admin/cells.html\n /nova/latest/user/cellsv2_layout.html 301 /nova/latest/admin/cells.html\n /nova/latest/user/cellsv2-layout.html 301 /nova/latest/admin/cells.html\n@@ -77,9 +79,10 @@\n /nova/latest/vendordata.html 301 /nova/latest/user/metadata.html\n /nova/latest/vmstates.html 301 /nova/latest/reference/vm-states.html\n /nova/latest/wsgi.html 301 /nova/latest/user/wsgi.html\n+/nova/latest/admin/arch.html 301 /nova/latest/admin/architecture.html\n /nova/latest/admin/adv-config.html 301 /nova/latest/admin/index.html\n /nova/latest/admin/configuration/schedulers.html 301 /nova/latest/admin/scheduling.html\n /nova/latest/admin/system-admin.html 301 /nova/latest/admin/index.html\n /nova/latest/admin/port_with_resource_request.html 301 /nova/latest/admin/ports-with-resource-requests.html\n-/nova/latest/admin/manage-users.html 301 /nova/latest/admin/arch.html\n+/nova/latest/admin/manage-users.html 301 /nova/latest/admin/architecture.html\n /nova/latest/admin/mitigation-for-Intel-MDS-security-flaws.html 301 /nova/latest/admin/cpu-models.html"
}
]
},
{
"commit_sha":"136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"commit_node_id":"C_kwDOAAwOD9oAKDEzNmYxZGViNmVjMzEyYzFkZGQ2YTEzNTZlMmUyZGJmNjI5MGEyZTQ",
"commit_html_url":"https://github.com/openstack/nova/commit/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"commit_date":"2022-02-01T18:28:48Z",
"files":[
{
"sha":"68695b758d279c63df4933734bfa64cf907236e1",
"filename":"doc/source/admin/architecture.rst",
"status":"modified",
"additions":29,
"deletions":35,
"changes":64,
"blob_url":"https://github.com/openstack/nova/blob/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/architecture.rst",
"raw_url":"https://github.com/openstack/nova/raw/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/architecture.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/architecture.rst?ref=136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"patch":"@@ -11,23 +11,26 @@ reads/writes, optionally sending RPC messages to other Nova services,\n and generating responses to the REST calls.\n RPC messaging is done via the **oslo.messaging** library,\n an abstraction on top of message queues.\n-Nova uses a messaging-based, ``shared nothing`` architecture and most of the\n+Nova uses a messaging-based, \"shared nothing\" architecture and most of the\n major nova components can be run on multiple servers, and have a manager that\n is listening for RPC messages.\n-The one major exception is ``nova-compute``, where a single process runs on the\n+The one major exception is the compute service, where a single process runs on the\n hypervisor it is managing (except when using the VMware or Ironic drivers).\n The manager also, optionally, has periodic tasks.\n-For more details on our RPC system, please see: :doc:`/reference/rpc`\n+For more details on our RPC system, refer to :doc:`/reference/rpc`.\n \n-Nova also uses a central database that is (logically) shared between all\n-components. However, to aid upgrade, the DB is accessed through an object\n-layer that ensures an upgraded control plane can still communicate with\n-a ``nova-compute`` running the previous release.\n-To make this possible ``nova-compute`` proxies DB requests over RPC to a\n-central manager called ``nova-conductor``.\n+Nova uses traditional SQL databases to store information.\n+These are (logically) shared between multiple components.\n+To aid upgrade, the database is accessed through an object layer that ensures\n+an upgraded control plane can still communicate with a compute nodes running\n+the previous release.\n+To make this possible, services running on the compute node proxy database\n+requests over RPC to a central manager called the conductor.\n \n To horizontally expand Nova deployments, we have a deployment sharding\n-concept called cells. For more information please see: :doc:`/admin/cells`\n+concept called :term:`cells <cell>`.\n+All deployments contain at least one cell.\n+For more information, refer to :doc:`/admin/cells`.\n \n \n Components\n@@ -109,11 +112,9 @@ projects on a shared system, and role-based access assignments. Roles control\n the actions that a user is allowed to perform.\n \n Projects are isolated resource containers that form the principal\n-organizational structure within the Nova service. They typically consist of an\n-individual VLAN, and volumes, instances, images, keys, and users. A user can\n-specify the project by appending ``project_id`` to their access key.  If no\n-project is specified in the API request, Nova attempts to use a project with\n-the same ID as the user.\n+organizational structure within the Nova service. They typically consist of\n+networks, volumes, instances, images, keys, and users. A user can\n+specify the project by appending ``project_id`` to their access key.\n \n For projects, you can use quota controls to limit the number of processor cores\n and the amount of RAM that can be allocated. Other projects also allow quotas\n@@ -142,21 +143,22 @@ consumption across available hardware resources.\n Block storage\n -------------\n \n-OpenStack provides two classes of block storage: ephemeral storage and\n-persistent volume.\n+OpenStack provides two classes of block storage: storage that is provisioned by\n+Nova itself, and storage that is managed by the block storage service, Cinder.\n \n-.. rubric:: Ephemeral storage\n+.. rubric:: Nova-provisioned block storage\n \n-Ephemeral storage includes a root ephemeral volume and an additional ephemeral\n-volume. These are provided by nova itself.\n+Nova provides the ability to create a root disk and an optional \"ephemeral\"\n+volume. The root disk will always be present unless the instance is a\n+:term:`Boot From Volume` instance.\n \n The root disk is associated with an instance, and exists only for the life of\n this very instance. Generally, it is used to store an instance's root file\n system, persists across the guest operating system reboots, and is removed on\n an instance deletion. The amount of the root ephemeral volume is defined by the\n flavor of an instance.\n \n-In addition to the ephemeral root volume, flavors can provide an additional\n+In addition to the root volume, flavors can provide an additional\n ephemeral block device. It is represented as a raw block device with no\n partition table or file system. A cloud-aware operating system can discover,\n format, and mount such a storage device. Nova defines the default file system\n@@ -171,17 +173,17 @@ is possible to configure other filesystem types.\n    mounts it on ``/mnt``. This is a cloud-init feature, and is not an OpenStack\n    mechanism. OpenStack only provisions the raw storage.\n \n-.. rubric:: Persistent volume\n+.. rubric:: Cinder-provisioned block storage\n \n-A persistent volume is represented by a persistent virtualized block device\n-independent of any particular instance. These are provided by the OpenStack\n-Block Storage service, cinder.\n+The OpenStack Block Storage service, Cinder, provides persistent volumes hat\n+are represented by a persistent virtualized block device independent of any\n+particular instance.\n \n Persistent volumes can be accessed by a single instance or attached to multiple\n instances. This type of configuration requires a traditional network file\n system to allow multiple instances accessing the persistent volume. It also\n requires a traditional network file system like NFS, CIFS, or a cluster file\n-system such as GlusterFS. These systems can be built within an OpenStack\n+system such as Ceph. These systems can be built within an OpenStack\n cluster, or provisioned outside of it, but OpenStack software does not provide\n these features.\n \n@@ -194,14 +196,6 @@ if the instance is shut down. For more information about this type of\n configuration, see :cinder-doc:`Introduction to the Block Storage service\n <configuration/block-storage/block-storage-overview.html>`.\n \n-.. note::\n-\n-   A persistent volume does not provide concurrent access from multiple\n-   instances. That type of configuration requires a traditional network file\n-   system like NFS, or CIFS, or a cluster file system such as GlusterFS. These\n-   systems can be built within an OpenStack cluster, or provisioned outside of\n-   it, but OpenStack software does not provide these features.\n-\n \n Building blocks\n ---------------\n@@ -245,7 +239,7 @@ The displayed image attributes are:\n \n Virtual hardware templates are called ``flavors``. By default, these are\n configurable by admin users, however, that behavior can be changed by redefining\n-the access controls ``policy.yaml`` on the ``nova-compute`` server. For more\n+the access controls ``policy.yaml`` on the ``nova-api`` server. For more\n information, refer to :doc:`/configuration/policy`.\n \n For a list of flavors that are available on your system:"
},
{
"sha":"ffe1be06f97d1f7fb7272f5f349b9aeb70575f95",
"filename":"doc/source/admin/availability-zones.rst",
"status":"modified",
"additions":16,
"deletions":9,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/availability-zones.rst",
"raw_url":"https://github.com/openstack/nova/raw/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/availability-zones.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/availability-zones.rst?ref=136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"patch":"@@ -9,15 +9,22 @@ Availability Zones\n     zones, refer to the :doc:`user guide </user/availability-zones>`.\n \n Availability Zones are an end-user visible logical abstraction for partitioning\n-a cloud without knowing the physical infrastructure. Availability zones are not\n-modeled in the database; rather, they are defined by attaching specific\n-metadata information to an :doc:`aggregate </admin/aggregates>` The addition of\n-this specific metadata to an aggregate makes the aggregate visible from an\n-end-user perspective and consequently allows users to schedule instances to a\n-specific set of hosts, the ones belonging to the aggregate.\n-\n-However, despite their similarities, there are a few additional differences to\n-note when comparing availability zones and host aggregates:\n+a cloud without knowing the physical infrastructure. They can be used to\n+partition a cloud on arbitrary factors, such as location (country, datacenter,\n+rack), network layout and/or power source.\n+\n+.. note::\n+\n+   Availability Zones should not be assumed to map to fault domains and provide\n+   no intrinsic HA benefit by themselves.\n+\n+Availability zones are not modeled in the database; rather, they are defined by\n+attaching specific metadata information to an\n+:doc:`aggregate </admin/aggregates>` The addition of this specific metadata to\n+an aggregate makes the aggregate visible from an end-user perspective and\n+consequently allows users to schedule instances to a specific set of hosts, the\n+ones belonging to the aggregate. There are a few additional differences to note\n+when comparing availability zones and host aggregates:\n \n - A host can be part of multiple aggregates but it can only be in one\n   availability zone."
},
{
"sha":"bad3566bd92a7e5c04ccb1297db7e9521b85bd44",
"filename":"doc/source/admin/cells.rst",
"status":"modified",
"additions":50,
"deletions":68,
"changes":118,
"blob_url":"https://github.com/openstack/nova/blob/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/cells.rst",
"raw_url":"https://github.com/openstack/nova/raw/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/cells.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/cells.rst?ref=136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"patch":"@@ -26,9 +26,13 @@ Laski gave at the Austin (Newton) summit which may be worth watching.\n Overview\n --------\n \n-The purpose of the cells functionality in nova is specifically to\n-allow larger deployments to shard their many compute nodes into cells.\n-A basic Nova system consists of the following components:\n+The purpose of the cells functionality in nova is to allow larger deployments\n+to shard their many compute nodes into cells. All nova deployments are by\n+definition cells deployments, even if most will only ever have a single cell.\n+This means a multi-cell deployment will not b radically different from a\n+\"standard\" nova deployment.\n+\n+Consider such a deployment. It will consists of the following components:\n \n - The :program:`nova-api` service which provides the external REST API to\n   users.\n@@ -43,7 +47,7 @@ A basic Nova system consists of the following components:\n   instances being built but not yet scheduled.\n \n - The :program:`nova-conductor` service which offloads long-running tasks for\n-  the API-level service and insulates compute nodes from direct database access\n+  the API-level services and insulates compute nodes from direct database access\n \n - The :program:`nova-compute` service which manages the virt driver and\n   hypervisor host.\n@@ -60,15 +64,19 @@ A basic Nova system consists of the following components:\n - A message queue which allows the services to communicate with each\n   other via RPC.\n \n-All deployments have at least the above components. Smaller deployments\n-likely have a single message queue that all services share and a\n-single database server which hosts the API database, a single cell\n-database, as well as the required cell0 database. This is considered a\n-\"single-cell deployment\" because it only has one \"real\" cell.\n-However, while there will only ever be one global API database, a larger\n-deployments can have many cell databases (where the bulk of the instance\n-information lives), each with a portion of the instances for the entire\n-deployment within, as well as per-cell message queues.\n+In smaller deployments, there will typically be a single message queue that all\n+services share and a single database server which hosts the API database, a\n+single cell database, as well as the required cell0 database. Because we only\n+have one \"real\" cell, we consider this a \"single-cell deployment\".\n+\n+In larger deployments, we can opt to shard the deployment using multiple cells.\n+In this configuration there will still only be one global API database but\n+there will be a cell database (where the bulk of the instance information\n+lives) for each cell, each containing a portion of the instances for the entire\n+deployment within, as well as per-cell message queues and per-cell\n+:program:`nova-conductor` instances. There will also be an additional\n+:program:`nova-conductor` instance, known as a *super conductor*, to handle\n+API-level operations.\n \n In these larger deployments, each of the nova services will use a cell-specific\n configuration file, all of which will at a minimum specify a message queue\n@@ -98,6 +106,9 @@ other cells in the API database, with records called *cell mappings*.\n    lower-level services. See the ``nova-manage`` :ref:`man-page-cells-v2`\n    commands for more information about how to create and examine these records.\n \n+The following section goes into more detail about the difference between\n+single-cell and multi-cell deployments.\n+\n \n Service layout\n --------------\n@@ -242,70 +253,42 @@ any other API-layer services via RPC, nor do they have access to the\n API database for global visibility of resources across the cloud.\n This is intentional and provides security and failure domain\n isolation benefits, but also has impacts on some things that would\n-otherwise require this any-to-any communication style. Check the\n-release notes for the version of Nova you are using for the most\n-up-to-date information about any caveats that may be present due to\n-this limitation.\n+otherwise require this any-to-any communication style. Check :ref:`upcall`\n+below for the most up-to-date information about any caveats that may be present\n+due to this limitation.\n \n \n Database layout\n ---------------\n \n As mentioned previously, there is a split between global data and data that is\n-local to a cell.\n+local to a cell. These databases schema are referred to as the *API* and *main*\n+database schemas, respectively.\n \n-The following is a breakdown of what data can uncontroversially considered\n-global versus local to a cell.  Missing data will be filled in as consensus is\n-reached on the data that is more difficult to cleanly place.  The missing data\n-is mostly concerned with scheduling and networking.\n-\n-.. note::\n+API database\n+~~~~~~~~~~~~\n \n-   This list of tables is accurate as of the 15.0.0 (Pike) release. It's\n-   possible that schema changes may have added additional tables since.\n+The API database is the database used for API-level services, such as\n+:program:`nova-api` and, in a multi-cell deployment, the superconductor.\n+The models and migrations related to this database can be found in\n+``nova.db.api``, and the database can be managed using the\n+:program:`nova-manage api_db` commands.\n \n-Global (API-level) tables\n-~~~~~~~~~~~~~~~~~~~~~~~~~\n+Main (cell-level) database\n+~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n-- ``instance_types``\n-- ``instance_type_projects``\n-- ``instance_type_extra_specs``\n-- ``quotas``\n-- ``project_user_quotas``\n-- ``quota_classes``\n-- ``quota_usages``\n-- ``security_groups``\n-- ``security_group_rules``\n-- ``security_group_default_rules``\n-- ``provider_fw_rules``\n-- ``key_pairs``\n-- ``migrations``\n-- ``networks``\n-- ``tags``\n-\n-Cell-level tables\n-~~~~~~~~~~~~~~~~~\n-\n-- ``instances``\n-- ``instance_info_caches``\n-- ``instance_extra``\n-- ``instance_metadata``\n-- ``instance_system_metadata``\n-- ``instance_faults``\n-- ``instance_actions``\n-- ``instance_actions_events``\n-- ``instance_id_mappings``\n-- ``pci_devices``\n-- ``block_device_mapping``\n-- ``virtual_interfaces``\n+The main database is the database used for cell-level :program:`nova-conductor`\n+instances. The models and migrations related to this database can be found in\n+``nova.db.main``, and the database can be managed using the\n+:program:`nova-manage db` commands.\n \n \n Usage\n -----\n \n As noted previously, all deployments are in effect now cells v2 deployments. As\n-a result, setup of a any nova deployment - even those that intend to only have\n-once cell - will involve some level of cells configuration. These changes are\n+a result, setup of any nova deployment - even those that intend to only have\n+one cell - will involve some level of cells configuration. These changes are\n configuration-related, both in the main nova configuration file as well as some\n extra records in the databases.\n \n@@ -345,11 +328,11 @@ Configuring a new deployment\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n If you are installing Nova for the first time and have no compute hosts in the\n-database yet then it will be necessary to configure cell0 and at least once\n-additional \"real\" cell. To begin, ensure your API database has been created\n-using the :program:`nova-manage api_db sync` command. Ensure the connection\n-information for this database is stored in the ``nova.conf`` file using the\n-:oslo.config:option:`api_database.connection` config option:\n+database yet then it will be necessary to configure cell0 and at least one\n+additional \"real\" cell. To begin, ensure your API database schema has been\n+populated using the :program:`nova-manage api_db sync` command. Ensure the\n+connection information for this database is stored in the ``nova.conf`` file\n+using the :oslo.config:option:`api_database.connection` config option:\n \n .. code-block:: ini\n \n@@ -557,7 +540,6 @@ existing instances to the new cell(s). For example:\n    have been mapped. An exit code of 1 indicates that there are remaining\n    instances that need to be mapped.\n \n-\n Template URLs in Cell Mappings\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n@@ -1152,7 +1134,7 @@ real-world users of the feature.\n - `Rocky Summit Video - Moving from CellsV1 to CellsV2 at CERN`__\n - `Stein Summit Video - Scaling Nova with CellsV2: The Nova Developer and the\n   CERN Operator perspective`__\n-- `Ussuri Summit Video - What's new in Nova Cellsv2?`__\n+- `Train Summit Video - What's new in Nova Cellsv2?`__\n \n .. __: https://www.openstack.org/videos/austin-2016/nova-cells-v2-whats-going-on\n .. __: https://www.openstack.org/videos/boston-2017/scaling-nova-how-cellsv2-affects-your-deployment"
},
{
"sha":"04078f0852c6cb7c547d8078e6a3ddbcb94de2fd",
"filename":"doc/source/admin/index.rst",
"status":"modified",
"additions":1,
"deletions":3,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/admin/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/index.rst?ref=136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"patch":"@@ -101,9 +101,7 @@ the defaults from the :doc:`install guide </install/index>` will be sufficient.\n \n * :doc:`Availablity Zones </admin/availability-zones>`: Availability Zones are\n   an end-user visible logical abstraction for partitioning a cloud without\n-  knowing the physical infrastructure. They can be used to partition a cloud on\n-  arbitrary factors, such as location (country, datacenter, rack), network\n-  layout and/or power source.\n+  knowing the physical infrastructure.\n \n * :placement-doc:`Placement service <>`: Overview of the placement\n   service, including how it fits in with the rest of nova."
},
{
"sha":"e48a4acc2e7d57dc001b00c566fe7e5291e2098e",
"filename":"doc/source/reference/glossary.rst",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/reference/glossary.rst",
"raw_url":"https://github.com/openstack/nova/raw/136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4/doc/source/reference/glossary.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/reference/glossary.rst?ref=136f1deb6ec312c1ddd6a1356e2e2dbf6290a2e4",
"patch":"@@ -23,6 +23,14 @@ Glossary\n         has an empty (\"\") ``image`` parameter in ``GET /servers/{server_id}``\n         responses.\n \n+    Cell\n+        A cell is a shard or horizontal partition in a nova deployment.\n+        A cell mostly consists of a database, queue, and set of compute nodes.\n+        All deployments willl have at least one cell (and one \"fake\" cell).\n+        Larger deployments can have many.\n+\n+        For more information, refer to :doc:`/admin/cells`.\n+\n     Cross-Cell Resize\n         A resize (or cold migrate) operation where the source and destination\n         compute hosts are mapped to different cells. By default, resize and"
}
]
},
{
"commit_sha":"b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"commit_node_id":"C_kwDOAAwOD9oAKGIwNjMzYWM0OWJmYmUyZTBlNTFlZjA1MDZmNjI2ZDJkYmY3YzE3MDU",
"commit_html_url":"https://github.com/openstack/nova/commit/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"commit_date":"2022-02-02T17:01:13Z",
"files":[
{
"sha":"79048f1ee869746d333d48dec001766ab9047d1b",
"filename":"doc/source/_extra/.htaccess",
"status":"modified",
"additions":5,
"deletions":3,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/_extra/.htaccess",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/_extra/.htaccess",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/_extra/.htaccess?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -9,12 +9,12 @@ redirectmatch 301 ^/nova/([^/]+)/api_plugins.html$ /nova/$1/contributor/api.html\n redirectmatch 301 ^/nova/([^/]+)/architecture.html$ /nova/$1/user/architecture.html\n redirectmatch 301 ^/nova/([^/]+)/block_device_mapping.html$ /nova/$1/user/block-device-mapping.html\n redirectmatch 301 ^/nova/([^/]+)/blueprints.html$ /nova/$1/contributor/blueprints.html\n-redirectmatch 301 ^/nova/([^/]+)/cells.html$ /nova/$1/user/cells.html\n+redirectmatch 301 ^/nova/([^/]+)/cells.html$ /nova/$1/admin/cells.html\n redirectmatch 301 ^/nova/([^/]+)/code-review.html$ /nova/$1/contributor/code-review.html\n redirectmatch 301 ^/nova/([^/]+)/conductor.html$ /nova/$1/user/conductor.html\n redirectmatch 301 ^/nova/([^/]+)/development.environment.html$ /nova/$1/contributor/development-environment.html\n redirectmatch 301 ^/nova/([^/]+)/devref/api.html /nova/$1/contributor/api.html\n-redirectmatch 301 ^/nova/([^/]+)/devref/cells.html /nova/$1/user/cells.html\n+redirectmatch 301 ^/nova/([^/]+)/devref/cells.html /nova/$1/admin/cells.html\n redirectmatch 301 ^/nova/([^/]+)/devref/filter_scheduler.html /nova/$1/admin/scheduling.html\n # catch all, if we hit something in devref assume it moved to\n # reference unless we have already triggered a hit above.\n@@ -64,7 +64,9 @@ redirectmatch 301 ^/nova/([^/]+)/testing/zero-downtime-upgrade.html$ /nova/$1/co\n redirectmatch 301 ^/nova/([^/]+)/threading.html$ /nova/$1/reference/threading.html\n redirectmatch 301 ^/nova/([^/]+)/upgrade.html$ /nova/$1/admin/upgrades.html\n redirectmatch 301 ^/nova/([^/]+)/user/aggregates.html$ /nova/$1/admin/aggregates.html\n-redirectmatch 301 ^/nova/([^/]+)/user/cellsv2_layout.html$ /nova/$1/user/cellsv2-layout.html\n+redirectmatch 301 ^/nova/([^/]+)/user/cells.html$ /nova/$1/admin/cells.html\n+redirectmatch 301 ^/nova/([^/]+)/user/cellsv2-layout.html$ /nova/$1/admin/cells.html\n+redirectmatch 301 ^/nova/([^/]+)/user/cellsv2_layout.html$ /nova/$1/admin/cells.html\n redirectmatch 301 ^/nova/([^/]+)/user/config-drive.html$ /nova/$1/user/metadata.html\n redirectmatch 301 ^/nova/([^/]+)/user/filter-scheduler.html$ /nova/$1/admin/scheduling.html\n redirectmatch 301 ^/nova/([^/]+)/user/metadata-service.html$ /nova/$1/user/metadata.html"
},
{
"sha":"87bf81a542a0de6bb42d815ae04ec8ae2181eeaf",
"filename":"doc/source/admin/cells.rst",
"status":"modified",
"additions":1082,
"deletions":12,
"changes":1094,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/cells.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/cells.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/cells.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -1,21 +1,941 @@\n-==================\n-CellsV2 Management\n-==================\n+==========\n+Cells (v2)\n+==========\n+\n+.. versionadded:: 16.0.0 (Pike)\n+\n+This document describes the layout of a deployment with cells v2, including\n+deployment considerations for security and scale and recommended practices and\n+tips for running and maintaining cells v2 for admins and operators. It is\n+focused on code present in Pike and later, and while it is geared towards\n+people who want to have multiple cells for whatever reason, the nature of the\n+cells v2 support in Nova means that it applies in some way to all deployments.\n+\n+Before reading any further, there is a nice overview presentation_ that Andrew\n+Laski gave at the Austin (Newton) summit which may be worth watching.\n+\n+.. _presentation: https://www.openstack.org/videos/summits/austin-2016/nova-cells-v2-whats-going-on\n+\n+.. note::\n+\n+   Cells v2 is different to the cells feature found in earlier versions of\n+   nova, also known as cells v1. Cells v1 was deprecated in 16.0.0 (Pike) and\n+   removed entirely in Train (20.0.0).\n+\n+\n+Overview\n+--------\n+\n+The purpose of the cells functionality in nova is specifically to\n+allow larger deployments to shard their many compute nodes into cells.\n+A basic Nova system consists of the following components:\n+\n+- The :program:`nova-api` service which provides the external REST API to\n+  users.\n+\n+- The :program:`nova-scheduler` and ``placement`` services which are\n+  responsible for tracking resources and deciding which compute node instances\n+  should be on.\n+\n+- An \"API database\" that is used primarily by :program:`nova-api` and\n+  :program:`nova-scheduler` (called *API-level services* below) to track\n+  location information about instances, as well as a temporary location for\n+  instances being built but not yet scheduled.\n+\n+- The :program:`nova-conductor` service which offloads long-running tasks for\n+  the API-level service and insulates compute nodes from direct database access\n+\n+- The :program:`nova-compute` service which manages the virt driver and\n+  hypervisor host.\n+\n+- A \"cell database\" which is used by API, conductor and compute\n+  services, and which houses the majority of the information about\n+  instances.\n+\n+- A \"cell0 database\" which is just like the cell database, but\n+  contains only instances that failed to be scheduled. This database mimics a\n+  regular cell, but has no compute nodes and is used only as a place to put\n+  instances that fail to land on a real compute node (and thus a real cell).\n+\n+- A message queue which allows the services to communicate with each\n+  other via RPC.\n+\n+All deployments have at least the above components. Smaller deployments\n+likely have a single message queue that all services share and a\n+single database server which hosts the API database, a single cell\n+database, as well as the required cell0 database. This is considered a\n+\"single-cell deployment\" because it only has one \"real\" cell.\n+However, while there will only ever be one global API database, a larger\n+deployments can have many cell databases (where the bulk of the instance\n+information lives), each with a portion of the instances for the entire\n+deployment within, as well as per-cell message queues.\n+\n+In these larger deployments, each of the nova services will use a cell-specific\n+configuration file, all of which will at a minimum specify a message queue\n+endpoint (i.e. :oslo.config:option:`transport_url`). Most of the services will\n+also contain database connection configuration information (i.e.\n+:oslo.config:option:`database.connection`), while API-level services that need\n+access to the global routing and placement information will also be configured\n+to reach the API database (i.e. :oslo.config:option:`api_database.connection`).\n+\n+.. note::\n+\n+   The pair of :oslo.config:option:`transport_url` and\n+   :oslo.config:option:`database.connection` configured for a service defines\n+   what cell a service lives in.\n+\n+API-level services need to be able to contact other services in all of\n+the cells. Since they only have one configured\n+:oslo.config:option:`transport_url` and\n+:oslo.config:option:`database.connection`, they look up the information for the\n+other cells in the API database, with records called *cell mappings*.\n+\n+.. note::\n+\n+   The API database must have cell mapping records that match\n+   the :oslo.config:option:`transport_url` and\n+   :oslo.config:option:`database.connection` configuration options of the\n+   lower-level services. See the ``nova-manage`` :ref:`man-page-cells-v2`\n+   commands for more information about how to create and examine these records.\n+\n+\n+Service layout\n+--------------\n+\n+The services generally have a well-defined communication pattern that\n+dictates their layout in a deployment. In a small/simple scenario, the\n+rules do not have much of an impact as all the services can\n+communicate with each other on a single message bus and in a single\n+cell database. However, as the deployment grows, scaling and security\n+concerns may drive separation and isolation of the services.\n+\n+Single cell\n+~~~~~~~~~~~\n+\n+This is a diagram of the basic services that a simple (single-cell) deployment\n+would have, as well as the relationships (i.e. communication paths) between\n+them:\n+\n+.. graphviz::\n+\n+  digraph services {\n+    graph [pad=\"0.35\", ranksep=\"0.65\", nodesep=\"0.55\", concentrate=true];\n+    node [fontsize=10 fontname=\"Monospace\"];\n+    edge [arrowhead=\"normal\", arrowsize=\"0.8\"];\n+    labelloc=bottom;\n+    labeljust=left;\n+\n+    { rank=same\n+      api [label=\"nova-api\"]\n+      apidb [label=\"API Database\" shape=\"box\"]\n+      scheduler [label=\"nova-scheduler\"]\n+    }\n+    { rank=same\n+      mq [label=\"MQ\" shape=\"diamond\"]\n+      conductor [label=\"nova-conductor\"]\n+    }\n+    { rank=same\n+      cell0db [label=\"Cell0 Database\" shape=\"box\"]\n+      celldb [label=\"Cell Database\" shape=\"box\"]\n+      compute [label=\"nova-compute\"]\n+    }\n+\n+    api -> mq -> compute\n+    conductor -> mq -> scheduler\n+\n+    api -> apidb\n+    api -> cell0db\n+    api -> celldb\n+\n+    conductor -> apidb\n+    conductor -> cell0db\n+    conductor -> celldb\n+  }\n+\n+All of the services are configured to talk to each other over the same\n+message bus, and there is only one cell database where live instance\n+data resides. The cell0 database is present (and required) but as no\n+compute nodes are connected to it, this is still a \"single cell\"\n+deployment.\n+\n+Multiple cells\n+~~~~~~~~~~~~~~\n+\n+In order to shard the services into multiple cells, a number of things\n+must happen. First, the message bus must be split into pieces along\n+the same lines as the cell database. Second, a dedicated conductor\n+must be run for the API-level services, with access to the API\n+database and a dedicated message queue. We call this *super conductor*\n+to distinguish its place and purpose from the per-cell conductor nodes.\n+\n+.. graphviz::\n+\n+  digraph services2 {\n+    graph [pad=\"0.35\", ranksep=\"0.65\", nodesep=\"0.55\", concentrate=true];\n+    node [fontsize=10 fontname=\"Monospace\"];\n+    edge [arrowhead=\"normal\", arrowsize=\"0.8\"];\n+    labelloc=bottom;\n+    labeljust=left;\n+\n+    subgraph api {\n+      api [label=\"nova-api\"]\n+      scheduler [label=\"nova-scheduler\"]\n+      conductor [label=\"super conductor\"]\n+      { rank=same\n+        apimq [label=\"API MQ\" shape=\"diamond\"]\n+        apidb [label=\"API Database\" shape=\"box\"]\n+      }\n+\n+      api -> apimq -> conductor\n+      api -> apidb\n+      conductor -> apimq -> scheduler\n+      conductor -> apidb\n+    }\n+\n+    subgraph clustercell0 {\n+      label=\"Cell 0\"\n+      color=green\n+      cell0db [label=\"Cell Database\" shape=\"box\"]\n+    }\n+\n+    subgraph clustercell1 {\n+      label=\"Cell 1\"\n+      color=blue\n+      mq1 [label=\"Cell MQ\" shape=\"diamond\"]\n+      cell1db [label=\"Cell Database\" shape=\"box\"]\n+      conductor1 [label=\"nova-conductor\"]\n+      compute1 [label=\"nova-compute\"]\n+\n+      conductor1 -> mq1 -> compute1\n+      conductor1 -> cell1db\n+\n+    }\n+\n+    subgraph clustercell2 {\n+      label=\"Cell 2\"\n+      color=red\n+      mq2 [label=\"Cell MQ\" shape=\"diamond\"]\n+      cell2db [label=\"Cell Database\" shape=\"box\"]\n+      conductor2 [label=\"nova-conductor\"]\n+      compute2 [label=\"nova-compute\"]\n+\n+      conductor2 -> mq2 -> compute2\n+      conductor2 -> cell2db\n+    }\n+\n+    api -> mq1 -> conductor1\n+    api -> mq2 -> conductor2\n+    api -> cell0db\n+    api -> cell1db\n+    api -> cell2db\n+\n+    conductor -> cell0db\n+    conductor -> cell1db\n+    conductor -> mq1\n+    conductor -> cell2db\n+    conductor -> mq2\n+  }\n+\n+It is important to note that services in the lower cell boxes only\n+have the ability to call back to the placement API but cannot access\n+any other API-layer services via RPC, nor do they have access to the\n+API database for global visibility of resources across the cloud.\n+This is intentional and provides security and failure domain\n+isolation benefits, but also has impacts on some things that would\n+otherwise require this any-to-any communication style. Check the\n+release notes for the version of Nova you are using for the most\n+up-to-date information about any caveats that may be present due to\n+this limitation.\n+\n+\n+Database layout\n+---------------\n+\n+As mentioned previously, there is a split between global data and data that is\n+local to a cell.\n+\n+The following is a breakdown of what data can uncontroversially considered\n+global versus local to a cell.  Missing data will be filled in as consensus is\n+reached on the data that is more difficult to cleanly place.  The missing data\n+is mostly concerned with scheduling and networking.\n+\n+.. note::\n+\n+   This list of tables is accurate as of the 15.0.0 (Pike) release. It's\n+   possible that schema changes may have added additional tables since.\n+\n+Global (API-level) tables\n+~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+- ``instance_types``\n+- ``instance_type_projects``\n+- ``instance_type_extra_specs``\n+- ``quotas``\n+- ``project_user_quotas``\n+- ``quota_classes``\n+- ``quota_usages``\n+- ``security_groups``\n+- ``security_group_rules``\n+- ``security_group_default_rules``\n+- ``provider_fw_rules``\n+- ``key_pairs``\n+- ``migrations``\n+- ``networks``\n+- ``tags``\n+\n+Cell-level tables\n+~~~~~~~~~~~~~~~~~\n+\n+- ``instances``\n+- ``instance_info_caches``\n+- ``instance_extra``\n+- ``instance_metadata``\n+- ``instance_system_metadata``\n+- ``instance_faults``\n+- ``instance_actions``\n+- ``instance_actions_events``\n+- ``instance_id_mappings``\n+- ``pci_devices``\n+- ``block_device_mapping``\n+- ``virtual_interfaces``\n+\n+\n+Usage\n+-----\n+\n+As noted previously, all deployments are in effect now cells v2 deployments. As\n+a result, setup of a any nova deployment - even those that intend to only have\n+once cell - will involve some level of cells configuration. These changes are\n+configuration-related, both in the main nova configuration file as well as some\n+extra records in the databases.\n+\n+All nova deployments must now have the following databases available\n+and configured:\n+\n+1. The \"API\" database\n+2. One special \"cell\" database called \"cell0\"\n+3. One (or eventually more) \"cell\" databases\n+\n+Thus, a small nova deployment will have an API database, a cell0, and\n+what we will call here a \"cell1\" database. High-level tracking\n+information is kept in the API database. Instances that are never\n+scheduled are relegated to the cell0 database, which is effectively a\n+graveyard of instances that failed to start. All successful/running\n+instances are stored in \"cell1\".\n+\n+.. note::\n+\n+   Since Nova services make use of both configuration file and some\n+   databases records, starting or restarting those services with an\n+   incomplete configuration could lead to an incorrect deployment.\n+   Only restart the services once you are done with the described\n+   steps below.\n+\n+.. note::\n+\n+   The following examples show the full expanded command line usage of\n+   the setup commands. This is to make it easier to visualize which of\n+   the various URLs are used by each of the commands. However, you should be\n+   able to put all of that in the config file and :program:`nova-manage` will\n+   use those values. If need be, you can create separate config files and pass\n+   them as ``nova-manage --config-file foo.conf`` to control the behavior\n+   without specifying things on the command lines.\n+\n+Configuring a new deployment\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+If you are installing Nova for the first time and have no compute hosts in the\n+database yet then it will be necessary to configure cell0 and at least once\n+additional \"real\" cell. To begin, ensure your API database has been created\n+using the :program:`nova-manage api_db sync` command. Ensure the connection\n+information for this database is stored in the ``nova.conf`` file using the\n+:oslo.config:option:`api_database.connection` config option:\n+\n+.. code-block:: ini\n+\n+   [api_database]\n+   connection = mysql+pymysql://root:secretmysql@dbserver/nova_api?charset=utf8\n+\n+Since there may be multiple \"cell\" databases (and in fact everyone\n+will have cell0 and cell1 at a minimum), connection info for these is\n+stored in the API database. Thus, the API database must exist and must provide\n+information on how to connect to it before continuing to the steps below, so\n+that :program:`nova-manage` can find your other databases.\n+\n+Next, we will create the necessary records for the cell0 database. To\n+do that we will first use :program:`nova-manage cell_v2 map_cell0` to create\n+and map cell0. For example:\n+\n+.. code-block:: bash\n+\n+   $ nova-manage cell_v2 map_cell0 \\\n+       --database_connection mysql+pymysql://root:secretmysql@dbserver/nova_cell0?charset=utf8\n+\n+.. note::\n+\n+   If you don't specify ``--database_connection`` then the commands will use\n+   the :oslo.config:option:`database.connection` value from your config file\n+   and mangle the database name to have a ``_cell0`` suffix\n+\n+.. warning::\n+\n+   If your databases are on separate hosts then you should specify\n+   ``--database_connection`` or make certain that the :file:`nova.conf`\n+   being used has the :oslo.config:option:`database.connection` value pointing\n+   to the same user/password/host that will work for the cell0 database.\n+   If the cell0 mapping was created incorrectly, it can be deleted\n+   using the :program:`nova-manage cell_v2 delete_cell` command before running\n+   :program:`nova-manage cell_v2 map_cell0` again with the proper database\n+   connection value.\n+\n+We will then use :program:`nova-manage db sync` to apply the database schema to\n+this new database. For example:\n+\n+.. code-block:: bash\n+\n+   $ nova-manage db sync \\\n+       --database_connection mysql+pymysql://root:secretmysql@dbserver/nova_cell0?charset=utf8\n+\n+Since no hosts are ever in cell0, nothing further is required for its setup.\n+Note that all deployments only ever have one cell0, as it is special, so once\n+you have done this step you never need to do it again, even if you add more\n+regular cells.\n+\n+Now, we must create another cell which will be our first \"regular\"\n+cell, which has actual compute hosts in it, and to which instances can\n+actually be scheduled. First, we create the cell record using\n+:program:`nova-manage cell_v2 create_cell`. For example:\n+\n+.. code-block:: bash\n+\n+  $ nova-manage cell_v2 create_cell \\\n+      --name cell1 \\\n+      --database_connection  mysql+pymysql://root:secretmysql@127.0.0.1/nova?charset=utf8 \\\n+      --transport-url rabbit://stackrabbit:secretrabbit@mqserver:5672/\n+\n+.. note::\n+\n+   If you don't specify the database and transport urls then\n+   :program:`nova-manage` will use the :oslo.config:option:`transport_url` and\n+   :oslo.config:option:`database.connection` values from the config file.\n+\n+.. note::\n+\n+   It is a good idea to specify a name for the new cell you create so you can\n+   easily look up cell UUIDs with the :program:`nova-manage cell_v2 list_cells`\n+   command later if needed.\n+\n+.. note::\n+\n+   The :program:`nova-manage cell_v2 create_cell` command will print the UUID\n+   of the newly-created cell if ``--verbose`` is passed, which is useful if you\n+   need to run commands like :program:`nova-manage cell_v2 discover_hosts`\n+   targeted at a specific cell.\n+\n+At this point, the API database can now find the cell database, and further\n+commands will attempt to look inside. If this is a completely fresh database\n+(such as if you're adding a cell, or if this is a new deployment), then you\n+will need to run :program:`nova-manage db sync` on it to initialize the\n+schema.\n+\n+Now we have a cell, but no hosts are in it which means the scheduler will never\n+actually place instances there. The next step is to scan the database for\n+compute node records and add them into the cell we just created. For this step,\n+you must have had a compute node started such that it registers itself as a\n+running service. You can identify this using the :program:`openstack compute\n+service list` command:\n+\n+.. code-block:: bash\n+\n+   $ openstack compute service list --service nova-compute\n+\n+Once that has happened, you can scan and add it to the cell using the\n+:program:`nova-manage cell_v2 discover_hosts` command:\n+\n+.. code-block:: bash\n+\n+   $ nova-manage cell_v2 discover_hosts\n+\n+This command will connect to any databases for which you have created cells (as\n+above), look for hosts that have registered themselves there, and map those\n+hosts in the API database so that they are visible to the scheduler as\n+available targets for instances. Any time you add more compute hosts to a cell,\n+you need to re-run this command to map them from the top-level so they can be\n+utilized. You can also configure a periodic task to have Nova discover new\n+hosts automatically by setting the\n+:oslo.config:option:`scheduler.discover_hosts_in_cells_interval` to a time\n+interval in seconds. The periodic task is run by the :program:`nova-scheduler`\n+service, so you must be sure to configure it on all of your\n+:program:`nova-scheduler` hosts.\n+\n+.. note::\n+\n+   In the future, whenever you add new compute hosts, you will need to run the\n+   :program:`nova-manage cell_v2 discover_hosts` command after starting them to\n+   map them to the cell if you did not configure automatic host discovery using\n+   :oslo.config:option:`scheduler.discover_hosts_in_cells_interval`.\n+\n+Adding a new cell to an existing deployment\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+You can add additional cells to your deployment using the same steps used above\n+to create your first cell. We can create a new cell record using\n+:program:`nova-manage cell_v2 create_cell`. For example:\n+\n+.. code-block:: bash\n+\n+  $ nova-manage cell_v2 create_cell \\\n+      --name cell2 \\\n+      --database_connection  mysql+pymysql://root:secretmysql@127.0.0.1/nova?charset=utf8 \\\n+      --transport-url rabbit://stackrabbit:secretrabbit@mqserver:5672/\n+\n+.. note::\n+\n+   If you don't specify the database and transport urls then\n+   :program:`nova-manage` will use the :oslo.config:option:`transport_url` and\n+   :oslo.config:option:`database.connection` values from the config file.\n+\n+.. note::\n+\n+   It is a good idea to specify a name for the new cell you create so you can\n+   easily look up cell UUIDs with the :program:`nova-manage cell_v2 list_cells`\n+   command later if needed.\n+\n+.. note::\n+\n+   The :program:`nova-manage cell_v2 create_cell` command will print the UUID\n+   of the newly-created cell if ``--verbose`` is passed, which is useful if you\n+   need to run commands like :program:`nova-manage cell_v2 discover_hosts`\n+   targeted at a specific cell.\n+\n+You can repeat this step for each cell you wish to add to your deployment. Your\n+existing cell database will be re-used - this simply informs the top-level API\n+database about your existing cell databases.\n+\n+Once you've created your new cell, use :program:`nova-manage cell_v2\n+discover_hosts` to map compute hosts to cells. This is only necessary if you\n+haven't enabled automatic discovery using the\n+:oslo.config:option:`scheduler.discover_hosts_in_cells_interval` option. For\n+example:\n+\n+.. code-block:: bash\n+\n+   $ nova-manage cell_v2 discover_hosts\n+\n+.. note::\n+\n+   This command will search for compute hosts in each cell database and map\n+   them to the corresponding cell. This can be slow, particularly for larger\n+   deployments. You may wish to specify the ``--cell_uuid`` option, which will\n+   limit the search to a specific cell. You can use the :program:`nova-manage\n+   cell_v2 list_cells` command to look up cell UUIDs if you are going to\n+   specify ``--cell_uuid``.\n+\n+Finally, run the :program:`nova-manage cell_v2 map_instances` command to map\n+existing instances to the new cell(s). For example:\n+\n+.. code-block:: bash\n+\n+   $ nova-manage cell_v2 map_instances\n+\n+.. note::\n+\n+   This command will search for instances in each cell database and map them to\n+   the correct cell. This can be slow, particularly for larger deployments. You\n+   may wish to specify the ``--cell_uuid`` option, which will limit the search\n+   to a specific cell. You can use the :program:`nova-manage cell_v2\n+   list_cells` command to look up cell UUIDs if you are going to specify\n+   ``--cell_uuid``.\n+\n+.. note::\n+\n+   The ``--max-count`` option can be specified if you would like to limit the\n+   number of instances to map in a single run. If ``--max-count`` is not\n+   specified, all instances will be mapped. Repeated runs of the command will\n+   start from where the last run finished so it is not necessary to increase\n+   ``--max-count`` to finish. An exit code of 0 indicates that all instances\n+   have been mapped. An exit code of 1 indicates that there are remaining\n+   instances that need to be mapped.\n+\n+\n+Template URLs in Cell Mappings\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Starting in the 18.0.0 (Rocky) release, the URLs provided in the cell mappings\n+for ``--database_connection`` and ``--transport-url`` can contain\n+variables which are evaluated each time they are loaded from the\n+database, and the values of which are taken from the corresponding\n+base options in the host's configuration file.  The base URL is parsed\n+and the following elements may be substituted into the cell mapping\n+URL (using ``rabbit://bob:s3kret@myhost:123/nova?sync=true#extra``):\n+\n+.. list-table:: Cell Mapping URL Variables\n+   :header-rows: 1\n+   :widths: 15, 50, 15\n+\n+   * - Variable\n+     - Meaning\n+     - Part of example URL\n+   * - ``scheme``\n+     - The part before the `://`\n+     - ``rabbit``\n+   * - ``username``\n+     - The username part of the credentials\n+     - ``bob``\n+   * - ``password``\n+     - The password part of the credentials\n+     - ``s3kret``\n+   * - ``hostname``\n+     - The hostname or address\n+     - ``myhost``\n+   * - ``port``\n+     - The port number (must be specified)\n+     - ``123``\n+   * - ``path``\n+     - The \"path\" part of the URL (without leading slash)\n+     - ``nova``\n+   * - ``query``\n+     - The full query string arguments (without leading question mark)\n+     - ``sync=true``\n+   * - ``fragment``\n+     - Everything after the first hash mark\n+     - ``extra``\n+\n+Variables are provided in curly brackets, like ``{username}``. A simple template\n+of ``rabbit://{username}:{password}@otherhost/{path}`` will generate a full URL\n+of ``rabbit://bob:s3kret@otherhost/nova`` when used with the above example.\n+\n+.. note::\n+\n+   The :oslo.config:option:`database.connection` and\n+   :oslo.config:option:`transport_url` values are not reloaded from the\n+   configuration file during a SIGHUP, which means that a full service restart\n+   will be required to notice changes in a cell mapping record if variables are\n+   changed.\n+\n+.. note::\n+\n+   The :oslo.config:option:`transport_url` option can contain an\n+   extended syntax for the \"netloc\" part of the URL\n+   (i.e. ``userA:passwordA@hostA:portA,userB:passwordB:hostB:portB``). In this\n+   case, substitions of the form ``username1``, ``username2``, etc will be\n+   honored and can be used in the template URL.\n+\n+The templating of these URLs may be helpful in order to provide each service host\n+with its own credentials for, say, the database. Without templating, all hosts\n+will use the same URL (and thus credentials) for accessing services like the\n+database and message queue. By using a URL with a template that results in the\n+credentials being taken from the host-local configuration file, each host will\n+use different values for those connections.\n+\n+Assuming you have two service hosts that are normally configured with the cell0\n+database as their primary connection, their (abbreviated) configurations would\n+look like this:\n+\n+.. code-block:: ini\n+\n+  [database]\n+  connection = mysql+pymysql://service1:foo@myapidbhost/nova_cell0\n+\n+and:\n+\n+.. code-block:: ini\n+\n+   [database]\n+   connection = mysql+pymysql://service2:bar@myapidbhost/nova_cell0\n+\n+Without cell mapping template URLs, they would still use the same credentials\n+(as stored in the mapping) to connect to the cell databases. However, consider\n+template URLs like the following::\n+\n+    mysql+pymysql://{username}:{password}@mycell1dbhost/nova\n+\n+and::\n+\n+    mysql+pymysql://{username}:{password}@mycell2dbhost/nova\n+\n+Using the first service and cell1 mapping, the calculated URL that will actually\n+be used for connecting to that database will be::\n+\n+    mysql+pymysql://service1:foo@mycell1dbhost/nova\n+\n+\n+Design\n+------\n+\n+Prior to the introduction of cells v2, when a request hit the Nova API for a\n+particular instance, the instance information was fetched from the database.\n+The information contained the hostname of the compute node on which the\n+instance was currently located. If the request needed to take action on the\n+instance (which it generally would), the hostname was used to calculate the\n+name of a queue and a message was written there which would eventually find its\n+way to the proper compute node.\n+\n+The meat of the cells v2 feature was to split this hostname lookup into two parts\n+that yielded three pieces of information instead of one. Basically, instead of\n+merely looking up the *name* of the compute node on which an instance was\n+located, we also started obtaining database and queue connection information.\n+Thus, when asked to take action on instance $foo, we now:\n+\n+1. Lookup the three-tuple of (database, queue, hostname) for that instance\n+2. Connect to that database and fetch the instance record\n+3. Connect to the queue and send the message to the proper hostname queue\n+\n+The above differs from the previous organization in two ways. First, we now\n+need to do two database lookups before we know where the instance lives.\n+Second, we need to demand-connect to the appropriate database and queue. Both\n+of these changes had performance implications, but it was possible to mitigate\n+them through the use of things like a memcache of instance mapping information\n+and pooling of connections to database and queue systems. The number of cells\n+will always be much smaller than the number of instances.\n+\n+There were also availability implications with the new feature since something like a\n+instance list which might query multiple cells could end up with a partial result\n+if there is a database failure in a cell. These issues can be mitigated, as\n+discussed in :ref:`handling-cell-failures`. A database failure within a cell\n+would cause larger issues than a partial list result so the expectation is that\n+it would be addressed quickly and cells v2 will handle it by indicating in the\n+response that the data may not be complete.\n+\n+\n+Comparison with cells v1\n+------------------------\n+\n+Prior to the introduction of cells v2, nova had a very similar feature, also\n+called cells or referred to as cells v1 for disambiguation. Cells v2 was an\n+effort to address many of the perceived shortcomings of the cell v1 feature.\n+Benefits of the cells v2 feature over the previous cells v1 feature include:\n+\n+- Native sharding of the database and queue as a first-class-feature in nova.\n+  All of the code paths will go through the lookup procedure and thus we won't\n+  have the same feature parity issues as we do with current cells.\n+\n+- No high-level replication of all the cell databases at the top. The API will\n+  need a database of its own for things like the instance index, but it will\n+  not need to replicate all the data at the top level.\n+\n+- It draws a clear line between global and local data elements. Things like\n+  flavors and keypairs are clearly global concepts that need only live at the\n+  top level. Providing this separation allows compute nodes to become even more\n+  stateless and insulated from things like deleted/changed global data.\n+\n+- Existing non-cells users will suddenly gain the ability to spawn a new \"cell\"\n+  from their existing deployment without changing their architecture. Simply\n+  adding information about the new database and queue systems to the new index\n+  will allow them to consume those resources.\n+\n+- Existing cells users will need to fill out the cells mapping index, shutdown\n+  their existing cells synchronization service, and ultimately clean up their\n+  top level database. However, since the high-level organization is not\n+  substantially different, they will not have to re-architect their systems to\n+  move to cells v2.\n+\n+- Adding new sets of hosts as a new \"cell\" allows them to be plugged into a\n+  deployment and tested before allowing builds to be scheduled to them.\n+\n+\n+.. _cells-v2-caveats:\n+\n+Caveats\n+-------\n+\n+.. note::\n+\n+   Many of these caveats have been addressed since the introduction of cells v2\n+   in the 16.0.0 (Pike) release. These are called out below.\n+\n+Cross-cell move operations\n+~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Support for cross-cell cold migration and resize was introduced in the 21.0.0\n+(Ussuri) release. This is documented in\n+:doc:`/admin/configuration/cross-cell-resize`. Prior to this release, it was\n+not possible to cold migrate or resize an instance from a host in one cell to a\n+host in another cell.\n+\n+It is not currently possible to live migrate, evacuate or unshelve an instance\n+from a host in one cell to a host in another cell.\n+\n+Quota-related quirks\n+~~~~~~~~~~~~~~~~~~~~\n+\n+Quotas are now calculated live at the point at which an operation\n+would consume more resource, instead of being kept statically in the\n+database. This means that a multi-cell environment may incorrectly\n+calculate the usage of a tenant if one of the cells is unreachable, as\n+those resources cannot be counted. In this case, the tenant may be\n+able to consume more resource from one of the available cells, putting\n+them far over quota when the unreachable cell returns.\n+\n+.. note::\n+\n+   Starting in the Train (20.0.0) release, it is possible to configure\n+   counting of quota usage from the placement service and API database\n+   to make quota usage calculations resilient to down or poor-performing\n+   cells in a multi-cell environment. See the :doc:`quotas documentation\n+   </user/quotas>` for more details.\n+\n+Performance of listing instances\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Prior to the 17.0.0 (Queens) release, the instance list operation may not sort\n+and paginate results properly when crossing multiple cell boundaries. Further,\n+the performance of a sorted list operation across multiple cells was\n+considerably slower than with a single cell. This was resolved as part of the\n+`efficient-multi-cell-instance-list-and-sort`__ spec.\n+\n+.. __: https://blueprints.launchpad.net/nova/+spec/efficient-multi-cell-instance-list-and-sort\n+\n+Notifications\n+~~~~~~~~~~~~~\n+\n+With a multi-cell environment with multiple message queues, it is\n+likely that operators will want to configure a separate connection to\n+a unified queue for notifications. This can be done in the configuration file\n+of all nodes. Refer to the :oslo.messaging-doc:`oslo.messaging configuration\n+documentation\n+<configuration/opts.html#oslo_messaging_notifications.transport_url>` for more\n+details.\n+\n+.. _cells-v2-layout-metadata-api:\n+\n+Nova Metadata API service\n+~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+Starting from the 19.0.0 (Stein) release, the :doc:`nova metadata API service\n+</admin/metadata-service>` can be run either globally or per cell using the\n+:oslo.config:option:`api.local_metadata_per_cell` configuration option.\n+\n+.. rubric:: Global\n+\n+If you have networks that span cells, you might need to run Nova metadata API\n+globally. When running globally, it should be configured as an API-level\n+service with access to the :oslo.config:option:`api_database.connection`\n+information. The nova metadata API service **must not** be run as a standalone\n+service, using the :program:`nova-api-metadata` service, in this case.\n+\n+.. rubric:: Local per cell\n+\n+Running Nova metadata API per cell can have better performance and data\n+isolation in a multi-cell deployment. If your networks are segmented along\n+cell boundaries, then you can run Nova metadata API service per cell. If you\n+choose to run it per cell, you should also configure each\n+:neutron-doc:`neutron-metadata-agent\n+<configuration/metadata-agent.html?#DEFAULT.nova_metadata_host>` service to\n+point to the corresponding :program:`nova-api-metadata`. The nova metadata API\n+service **must** be run as a standalone service, using the\n+:program:`nova-api-metadata` service, in this case.\n+\n+Console proxies\n+~~~~~~~~~~~~~~~\n+\n+Starting from the 18.0.0 (Rocky) release, console proxies must be run per cell\n+because console token authorizations are stored in cell databases. This means\n+that each console proxy server must have access to the\n+:oslo.config:option:`database.connection` information for the cell database\n+containing the instances for which it is proxying console access. This\n+functionality was added as part of the `convert-consoles-to-objects`__ spec.\n+\n+.. __: https://specs.openstack.org/openstack/nova-specs/specs/rocky/implemented/convert-consoles-to-objects.html\n+\n+.. _upcall:\n+\n+Operations requiring upcalls\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+If you deploy multiple cells with a superconductor as described above,\n+computes and cell-based conductors will not have the ability to speak\n+to the scheduler as they are not connected to the same MQ. This is by\n+design for isolation, but currently the processes are not in place to\n+implement some features without such connectivity. Thus, anything that\n+requires a so-called \"upcall\" will not function. This impacts the\n+following:\n+\n+#. Instance reschedules during boot and resize (part 1)\n+\n+   .. note::\n+\n+      This has been resolved in the `Queens release`__.\n+\n+      .. __: https://specs.openstack.org/openstack/nova-specs/specs/queens/approved/return-alternate-hosts.html\n+\n+#. Instance affinity reporting from the compute nodes to scheduler\n+#. The late anti-affinity check during server create and evacuate\n+#. Querying host aggregates from the cell\n+\n+   .. note::\n+\n+      This has been resolved in the `Rocky release`__.\n+\n+      .. __: https://blueprints.launchpad.net/nova/+spec/live-migration-in-xapi-pool\n+\n+#. Attaching a volume and ``[cinder] cross_az_attach = False``\n+#. Instance reschedules during boot and resize (part 2)\n+\n+   .. note:: This has been resolved in the `Ussuri release`__.\n+\n+      .. __: https://review.opendev.org/q/topic:bug/1781286\n+\n+The first is simple: if you boot an instance, it gets scheduled to a\n+compute node, fails, it would normally be re-scheduled to another\n+node. That requires scheduler intervention and thus it will not work\n+in Pike with a multi-cell layout. If you do not rely on reschedules\n+for covering up transient compute-node failures, then this will not\n+affect you. To ensure you do not make futile attempts at rescheduling,\n+you should set :oslo.config:option:`scheduler.max_attempts` to ``1`` in\n+``nova.conf``.\n+\n+The second two are related. The summary is that some of the facilities\n+that Nova has for ensuring that affinity/anti-affinity is preserved\n+between instances does not function in Pike with a multi-cell\n+layout. If you don't use affinity operations, then this will not\n+affect you. To make sure you don't make futile attempts at the\n+affinity check, you should set\n+:oslo.config:option:`workarounds.disable_group_policy_check_upcall` to ``True``\n+and :oslo.config:option:`filter_scheduler.track_instance_changes` to ``False``\n+in ``nova.conf``.\n+\n+The fourth was previously only a problem when performing live migrations using\n+the since-removed XenAPI driver and not specifying ``--block-migrate``. The\n+driver would attempt to figure out if block migration should be performed based\n+on source and destination hosts being in the same aggregate. Since aggregates\n+data had migrated to the API database, the cell conductor would not be able to\n+access the aggregate information and would fail.\n+\n+The fifth is a problem because when a volume is attached to an instance\n+in the *nova-compute* service, and ``[cinder]/cross_az_attach=False`` in\n+nova.conf, we attempt to look up the availability zone that the instance is\n+in which includes getting any host aggregates that the ``instance.host`` is in.\n+Since the aggregates are in the API database and the cell conductor cannot\n+access that information, so this will fail. In the future this check could be\n+moved to the *nova-api* service such that the availability zone between the\n+instance and the volume is checked before we reach the cell, except in the\n+case of :term:`boot from volume <Boot From Volume>` where the *nova-compute*\n+service itself creates the volume and must tell Cinder in which availability\n+zone to create the volume. Long-term, volume creation during boot from volume\n+should be moved to the top-level superconductor which would eliminate this AZ\n+up-call check problem.\n+\n+The sixth is detailed in `bug 1781286`__ and is similar to the first issue.\n+The issue is that servers created without a specific availability zone\n+will have their AZ calculated during a reschedule based on the alternate host\n+selected. Determining the AZ for the alternate host requires an \"up call\" to\n+the API DB.\n+\n+.. __: https://bugs.launchpad.net/nova/+bug/1781286\n \n-This section describes the various recommended practices/tips for runnning and\n-maintaining CellsV2 for admins and operators. For more details regarding the\n-basic concept of CellsV2 and its layout please see the main :doc:`/user/cellsv2-layout`\n-page.\n \n .. _handling-cell-failures:\n \n Handling cell failures\n ----------------------\n \n For an explanation on how ``nova-api`` handles cell failures please see the\n-`Handling Down Cells <https://docs.openstack.org/api-guide/compute/down_cells.html>`__\n-section of the Compute API guide. Below, you can find some recommended practices and\n-considerations for effectively tolerating cell failure situations.\n+`Handling Down Cells`__ section of the Compute API guide. Below, you can find\n+some recommended practices and considerations for effectively tolerating cell\n+failure situations.\n+\n+.. __: https://docs.openstack.org/api-guide/compute/down_cells.html\n \n Configuration considerations\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -67,8 +987,8 @@ Known issues\n    information on each of the compute service's version to determine the compute\n    version cap to use. The current workaround is to pin the\n    :oslo.config:option:`upgrade_levels.compute` to a particular version like\n-   \"rocky\" and get the service up under such situations. See `bug 1815697\n-   <https://bugs.launchpad.net/nova/+bug/1815697>`__ for more details. Also note\n+   \"rocky\" and get the service up under such situations. See `bug 1815697`__\n+   for more details. Also note\n    that in general during situations where cells are not reachable certain\n    \"slowness\" may be experienced in operations requiring hitting all the cells\n    because of the aforementioned configurable timeout/retry values.\n@@ -90,3 +1010,153 @@ Known issues\n              API database to make quota usage calculations resilient to down or\n              poor-performing cells in a multi-cell environment. See the\n              :doc:`quotas documentation</user/quotas>` for more details.\n+\n+.. __: https://bugs.launchpad.net/nova/+bug/1815697\n+\n+\n+FAQs\n+----\n+\n+- How do I find out which hosts are bound to which cell?\n+\n+  There are a couple of ways to do this.\n+\n+  #. Run :program:`nova-manage cell_v2 discover_hosts --verbose`.\n+\n+     This does not produce a report but if you are trying to determine if a\n+     host is in a cell you can run this and it will report any hosts that are\n+     not yet mapped to a cell and map them. This command is idempotent.\n+\n+  #. Run :program:`nova-manage cell_v2 list_hosts`.\n+\n+     This will list hosts in all cells. If you want to list hosts in a\n+     specific cell, you can use the ``--cell_uuid`` option.\n+\n+- I updated the ``database_connection`` and/or ``transport_url`` in a cell\n+  using the ``nova-manage cell_v2 update_cell`` command but the API is still\n+  trying to use the old settings.\n+\n+  The cell mappings are cached in the :program:`nova-api` service worker so you\n+  will need to restart the worker process to rebuild the cache. Note that there\n+  is another global cache tied to request contexts, which is used in the\n+  nova-conductor and nova-scheduler services, so you might need to do the same\n+  if you are having the same issue in those services. As of the 16.0.0 (Pike)\n+  release there is no timer on the cache or hook to refresh the cache using a\n+  SIGHUP to the service.\n+\n+- I have upgraded from Newton to Ocata and I can list instances but I get a\n+  HTTP 404 (NotFound) error when I try to get details on a specific instance.\n+\n+  Instances need to be mapped to cells so the API knows which cell an instance\n+  lives in. When upgrading, the :program:`nova-manage cell_v2 simple_cell_setup`\n+  command will automatically map the instances to the single cell which is\n+  backed by the existing nova database. If you have already upgraded and did\n+  not use the :program:`nova-manage cell_v2 simple_cell_setup` command, you can run the\n+  :program:`nova-manage cell_v2 map_instances` command with the ``--cell_uuid``\n+  option to map all instances in the given cell. See the\n+  :ref:`man-page-cells-v2` man page for details on command usage.\n+\n+- Can I create a cell but have it disabled from scheduling?\n+\n+  Yes. It is possible to create a pre-disabled cell such that it does not\n+  become a candidate for scheduling new VMs. This can be done by running the\n+  :program:`nova-manage cell_v2 create_cell` command with the ``--disabled``\n+  option.\n+\n+- How can I disable a cell so that the new server create requests do not go to\n+  it while I perform maintenance?\n+\n+  Existing cells can be disabled by running :program:`nova-manage cell_v2\n+  update_cell` with the ``--disable`` option and can be re-enabled once the\n+  maintenance period is over by running this command with the ``--enable``\n+  option.\n+\n+- I disabled (or enabled) a cell using the :program:`nova-manage cell_v2\n+  update_cell` or I created a new (pre-disabled) cell(mapping) using the\n+  :program:`nova-manage cell_v2 create_cell` command but the scheduler is still\n+  using the old settings.\n+\n+  The cell mappings are cached in the scheduler worker so you will either need\n+  to restart the scheduler process to refresh the cache, or send a SIGHUP\n+  signal to the scheduler by which it will automatically refresh the cells\n+  cache and the changes will take effect.\n+\n+- Why was the cells REST API not implemented for cells v2? Why are there no\n+  CRUD operations for cells in the API?\n+\n+  One of the deployment challenges that cells v1 had was the requirement for\n+  the API and control services to be up before a new cell could be deployed.\n+  This was not a problem for large-scale public clouds that never shut down,\n+  but is not a reasonable requirement for smaller clouds that do offline\n+  upgrades and/or clouds which could be taken completely offline by something\n+  like a power outage. Initial devstack and gate testing for cells v1 was\n+  delayed by the need to engineer a solution for bringing the services\n+  partially online in order to deploy the rest, and this continues to be a gap\n+  for other deployment tools. Consider also the FFU case where the control\n+  plane needs to be down for a multi-release upgrade window where changes to\n+  cell records have to be made. This would be quite a bit harder if the way\n+  those changes are made is via the API, which must remain down during the\n+  process.\n+\n+  Further, there is a long-term goal to move cell configuration (i.e.\n+  cell_mappings and the associated URLs and credentials) into config and get\n+  away from the need to store and provision those things in the database.\n+  Obviously a CRUD interface in the API would prevent us from making that move.\n+\n+- Why are cells not exposed as a grouping mechanism in the API for listing\n+  services, instances, and other resources?\n+\n+  Early in the design of cells v2 we set a goal to not let the cell concept\n+  leak out of the API, even for operators. Aggregates are the way nova supports\n+  grouping of hosts for a variety of reasons, and aggregates can cut across\n+  cells, and/or be aligned with them if desired. If we were to support cells as\n+  another grouping mechanism, we would likely end up having to implement many\n+  of the same features for them as aggregates, such as scheduler features,\n+  metadata, and other searching/filtering operations. Since aggregates are how\n+  Nova supports grouping, we expect operators to use aggregates any time they\n+  need to refer to a cell as a group of hosts from the API, and leave actual\n+  cells as a purely architectural detail.\n+\n+  The need to filter instances by cell in the API can and should be solved by\n+  adding a generic by-aggregate filter, which would allow listing instances on\n+  hosts contained within any aggregate, including one that matches the cell\n+  boundaries if so desired.\n+\n+- Why are the API responses for ``GET /servers``, ``GET /servers/detail``,\n+  ``GET /servers/{server_id}`` and ``GET /os-services`` missing some\n+  information for certain cells at certain times? Why do I see the status as\n+  \"UNKNOWN\" for the servers in those cells at those times when I run\n+  ``openstack server list`` or ``openstack server show``?\n+\n+  Starting from microversion 2.69 the API responses of ``GET /servers``, ``GET\n+  /servers/detail``, ``GET /servers/{server_id}`` and ``GET /os-services`` may\n+  contain missing keys during down cell situations. See the `Handling Down\n+  Cells`__ section of the Compute API guide for more information on the partial\n+  constructs.\n+\n+  For administrative considerations, see :ref:`handling-cell-failures`.\n+\n+.. __: https://docs.openstack.org/api-guide/compute/down_cells.html\n+\n+References\n+----------\n+\n+A large number of cells v2-related presentations have been given at various\n+OpenStack and OpenInfra Summits over the years. These provide an excellent\n+reference on the history and development of the feature along with details from\n+real-world users of the feature.\n+\n+- `Newton Summit Video - Nova Cells V2: What's Going On?`__\n+- `Pike Summit Video - Scaling Nova: How CellsV2 Affects Your Deployment`__\n+- `Queens Summit Video - Add Cellsv2 to your existing Nova deployment`__\n+- `Rocky Summit Video - Moving from CellsV1 to CellsV2 at CERN`__\n+- `Stein Summit Video - Scaling Nova with CellsV2: The Nova Developer and the\n+  CERN Operator perspective`__\n+- `Ussuri Summit Video - What's new in Nova Cellsv2?`__\n+\n+.. __: https://www.openstack.org/videos/austin-2016/nova-cells-v2-whats-going-on\n+.. __: https://www.openstack.org/videos/boston-2017/scaling-nova-how-cellsv2-affects-your-deployment\n+.. __: https://www.openstack.org/videos/sydney-2017/adding-cellsv2-to-your-existing-nova-deployment\n+.. __: https://www.openstack.org/videos/summits/vancouver-2018/moving-from-cellsv1-to-cellsv2-at-cern\n+.. __: https://www.openstack.org/videos/summits/berlin-2018/scaling-nova-with-cellsv2-the-nova-developer-and-the-cern-operator-perspective\n+.. __: https://www.openstack.org/videos/summits/denver-2019/whats-new-in-nova-cellsv2"
},
{
"sha":"e51e42577484e5991ebcc6d2260bf0d0ba2c5753",
"filename":"doc/source/admin/configuration/cross-cell-resize.rst",
"status":"modified",
"additions":37,
"deletions":24,
"changes":61,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/configuration/cross-cell-resize.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/configuration/cross-cell-resize.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/configuration/cross-cell-resize.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -2,21 +2,25 @@\n Cross-cell resize\n =================\n \n-This document describes how to configure nova for cross-cell resize.\n-For information on :term:`same-cell resize <Same-Cell Resize>`, refer to\n-:doc:`/admin/configuration/resize`.\n+.. note::\n+\n+   This document describes how to configure nova for cross-cell resize.\n+   For information on :term:`same-cell resize <Same-Cell Resize>`, refer to\n+   :doc:`/admin/configuration/resize`. For information on the cells v2 feature,\n+   refer to :doc:`/admin/cells`.\n \n Historically resizing and cold migrating a server has been explicitly\n-`restricted`_ to within the same cell in which the server already exists.\n+`restricted`__ to within the same cell in which the server already exists.\n The cross-cell resize feature allows configuring nova to allow resizing\n and cold migrating servers across cells.\n \n-The full design details are in the `Ussuri spec`_ and there is a `video`_ from\n-a summit talk with a high-level overview.\n+The full design details are in the `Ussuri spec`__ and there is a `video`__\n+from a summit talk with a high-level overview.\n+\n+.. __: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/conductor/tasks/migrate.py#L164\n+.. __: https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/cross-cell-resize.html\n+.. __: https://www.openstack.org/videos/summits/denver-2019/whats-new-in-nova-cellsv2\n \n-.. _restricted: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/conductor/tasks/migrate.py#L164\n-.. _Ussuri spec: https://specs.openstack.org/openstack/nova-specs/specs/ussuri/approved/cross-cell-resize.html\n-.. _video: https://www.openstack.org/videos/summits/denver-2019/whats-new-in-nova-cellsv2\n \n Use case\n --------\n@@ -32,6 +36,7 @@ migrate their servers to the new cell with newer hardware. Administrators\n could also just cold migrate the servers during a maintenance window to the\n new cell.\n \n+\n Requirements\n ------------\n \n@@ -70,6 +75,7 @@ Networking\n The networking API must expose the ``Port Bindings Extended`` API extension\n which was added in the 13.0.0 (Rocky) release for Neutron.\n \n+\n Notifications\n -------------\n \n@@ -78,13 +84,14 @@ from same-cell resize is the *publisher_id* may be different in some cases\n since some events are sent from the conductor service rather than a compute\n service. For example, with same-cell resize the\n ``instance.resize_revert.start`` notification is sent from the source compute\n-host in the `finish_revert_resize`_ method but with cross-cell resize that\n+host in the `finish_revert_resize`__ method but with cross-cell resize that\n same notification is sent from the conductor service.\n \n Obviously the actual message queue sending the notifications would be different\n for the source and target cells assuming they use separate transports.\n \n-.. _finish_revert_resize: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/compute/manager.py#L4326\n+.. __: https://opendev.org/openstack/nova/src/tag/20.0.0/nova/compute/manager.py#L4326\n+\n \n Instance actions\n ----------------\n@@ -96,6 +103,7 @@ names are generated based on the compute service methods involved in the\n operation and there are different methods involved in a cross-cell resize.\n This is important for triage when a cross-cell resize operation fails.\n \n+\n Scheduling\n ----------\n \n@@ -107,19 +115,20 @@ cell. However, this behavior is configurable using the\n configuration option if, for example, you want to drain old cells when resizing\n or cold migrating.\n \n+\n Code flow\n ---------\n \n The end user experience is meant to not change, i.e. status transitions. A\n successfully cross-cell resized server will go to ``VERIFY_RESIZE`` status\n and from there the user can either confirm or revert the resized server using\n-the normal `confirmResize`_ and `revertResize`_ server action APIs.\n+the normal `confirmResize`__ and `revertResize`__ server action APIs.\n \n Under the covers there are some differences from a traditional same-cell\n resize:\n \n * There is no inter-compute interaction. Everything is synchronously\n-  `orchestrated`_ from the (super)conductor service. This uses the\n+  `orchestrated`__ from the (super)conductor service. This uses the\n   :oslo.config:option:`long_rpc_timeout` configuration option.\n \n * The orchestration tasks in the (super)conductor service are in charge of\n@@ -129,15 +138,16 @@ resize:\n   ``instance_mappings`` table record in the API database.\n \n * Non-volume-backed servers will have their root disk uploaded to the image\n-  service as a temporary snapshot image just like during the `shelveOffload`_\n+  service as a temporary snapshot image just like during the `shelveOffload`__\n   operation. When finishing the resize on the destination host in the target\n   cell that snapshot image will be used to spawn the guest and then the\n   snapshot image will be deleted.\n \n-.. _confirmResize: https://docs.openstack.org/api-ref/compute/#confirm-resized-server-confirmresize-action\n-.. _revertResize: https://docs.openstack.org/api-ref/compute/#revert-resized-server-revertresize-action\n-.. _orchestrated: https://opendev.org/openstack/nova/src/branch/master/nova/conductor/tasks/cross_cell_migrate.py\n-.. _shelveOffload: https://docs.openstack.org/api-ref/compute/#shelf-offload-remove-server-shelveoffload-action\n+.. __: https://docs.openstack.org/api-ref/compute/#confirm-resized-server-confirmresize-action\n+.. __: https://docs.openstack.org/api-ref/compute/#revert-resized-server-revertresize-action\n+.. __: https://opendev.org/openstack/nova/src/branch/master/nova/conductor/tasks/cross_cell_migrate.py\n+.. __: https://docs.openstack.org/api-ref/compute/#shelf-offload-remove-server-shelveoffload-action\n+\n \n Sequence diagram\n ----------------\n@@ -230,6 +240,7 @@ status.\n \n     }\n \n+\n Limitations\n -----------\n \n@@ -251,19 +262,21 @@ Other limitations:\n \n * The config drive associated with the server, if there is one, will be\n   re-generated on the destination host in the target cell. Therefore if the\n-  server was created with `personality files`_ they will be lost. However, this\n-  is no worse than `evacuating`_ a server that had a config drive when the\n+  server was created with `personality files`__ they will be lost. However, this\n+  is no worse than `evacuating`__ a server that had a config drive when the\n   source and destination compute host are not on shared storage or when\n   shelve offloading and unshelving a server with a config drive. If necessary,\n   the resized server can be rebuilt to regain the personality files.\n+\n * The ``_poll_unconfirmed_resizes`` periodic task, which can be\n   :oslo.config:option:`configured <resize_confirm_window>` to automatically\n   confirm pending resizes on the target host, *might* not support cross-cell\n   resizes because doing so would require an :ref:`up-call <upcall>` to the\n   API to confirm the resize and cleanup the source cell database.\n \n-.. _personality files: https://docs.openstack.org/api-guide/compute/server_concepts.html#server-personality\n-.. _evacuating: https://docs.openstack.org/api-ref/compute/#evacuate-server-evacuate-action\n+.. __: https://docs.openstack.org/api-guide/compute/server_concepts.html#server-personality\n+.. __: https://docs.openstack.org/api-ref/compute/#evacuate-server-evacuate-action\n+\n \n Troubleshooting\n ---------------\n@@ -301,9 +314,9 @@ manually recovered, for example volume attachments or port bindings, and also\n check the (super)conductor service logs. Assuming volume attachments and\n port bindings are OK (current and pointing at the correct host), then try hard\n rebooting the server to get it back to ``ACTIVE`` status. If that fails, you\n-may need to `rebuild`_ the server on the source host. Note that the guest's\n+may need to `rebuild`__ the server on the source host. Note that the guest's\n disks on the source host are not deleted until the resize is confirmed so if\n there is an issue prior to confirm or confirm itself fails, the guest disks\n should still be available for rebuilding the instance if necessary.\n \n-.. _rebuild: https://docs.openstack.org/api-ref/compute/#rebuild-server-rebuild-action\n+.. __: https://docs.openstack.org/api-ref/compute/#rebuild-server-rebuild-action"
},
{
"sha":"4de7fe36aa5fccc381593d7768e1bb42ecc347f4",
"filename":"doc/source/admin/configuring-migrations.rst",
"status":"modified",
"additions":2,
"deletions":1,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/configuring-migrations.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/configuring-migrations.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/configuring-migrations.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -63,7 +63,8 @@ The migration types are:\n .. note::\n \n    In a multi-cell cloud, instances can be live migrated to a\n-   different host in the same cell, but not across cells.\n+   different host in the same cell, but not across cells. Refer to the\n+   :ref:`cells v2 documentation <cells-v2-caveats>`. for more information.\n \n The following sections describe how to configure your hosts for live migrations\n using the libvirt virt driver and KVM hypervisor."
},
{
"sha":"f93a256660c481f4b167242f8ca37acd0c98c94e",
"filename":"doc/source/admin/troubleshooting/affinity-policy-violated.rst",
"status":"modified",
"additions":3,
"deletions":6,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/troubleshooting/affinity-policy-violated.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/troubleshooting/affinity-policy-violated.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/troubleshooting/affinity-policy-violated.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -43,9 +43,9 @@ reschedule of the server create request.  Note that this means the deployment\n must have :oslo.config:option:`scheduler.max_attempts` set greater than ``1``\n (default is ``3``) to handle races.\n \n-An ideal configuration for multiple cells will minimize `upcalls`_ from the\n-cells to the API database. This is how devstack, for example, is configured in\n-the CI gate. The cell conductors do not set\n+An ideal configuration for multiple cells will minimize :ref:`upcalls <upcall>`\n+from the cells to the API database. This is how devstack, for example, is\n+configured in the CI gate. The cell conductors do not set\n :oslo.config:option:`api_database.connection` and ``nova-compute`` sets\n :oslo.config:option:`workarounds.disable_group_policy_check_upcall` to\n ``True``.\n@@ -73,6 +73,3 @@ parallel server create requests are racing.\n \n Future work is needed to add anti-/affinity support to the placement service in\n order to eliminate the need for the late affinity check in ``nova-compute``.\n-\n-.. _upcalls: https://docs.openstack.org/nova/latest/user/cellsv2-layout.html#operations-requiring-upcalls\n-"
},
{
"sha":"00a714970b200c8d306b07e02b511dc0b218722d",
"filename":"doc/source/admin/upgrades.rst",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/upgrades.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/admin/upgrades.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/admin/upgrades.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -53,8 +53,8 @@ same time.\n     deployment. The `nova-conductor`` service will fail to start when a\n     ``nova-compute`` service that is older than the previous release (N-2 or\n     greater) is detected. Similarly, in a :doc:`deployment with multiple cells\n-    </user/cellsv2-layout>`, neither the super conductor service nor any\n-    per-cell conductor service will start if any other conductor service in the\n+    </admin/cells>`, neither the super conductor service nor any per-cell\n+    conductor service will start if any other conductor service in the\n     deployment is older than the previous release.\n \n #. Before maintenance window:"
},
{
"sha":"80bd8bbc353699277b88853dcc420bd60fbf91d7",
"filename":"doc/source/index.rst",
"status":"modified",
"additions":5,
"deletions":4,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/index.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -153,9 +153,10 @@ the defaults from the :doc:`install guide </install/index>` will be sufficient.\n   * :doc:`Feature Support full list </user/support-matrix>`: A detailed dive through\n     features in each compute driver backend.\n \n-* :doc:`Cells v2 Planning </user/cellsv2-layout>`: For large deployments, Cells v2\n-  allows sharding of your compute environment. Upfront planning is key to a\n-  successful Cells v2 layout.\n+* :doc:`Cells v2 configuration </admin/cells>`: For large deployments, cells v2\n+  cells allow sharding of your compute environment. Upfront planning is key to\n+  a successful cells v2 layout.\n+\n * :doc:`Running nova-api on wsgi <user/wsgi>`: Considerations for using a real\n   WSGI container instead of the baked-in eventlet web server.\n \n@@ -166,7 +167,7 @@ the defaults from the :doc:`install guide </install/index>` will be sufficient.\n \n    user/feature-classification\n    user/support-matrix\n-   user/cellsv2-layout\n+   admin/cells\n    user/wsgi\n \n Maintenance"
},
{
"sha":"d162157ac470c35a3e5295978a0750816ae0f7bf",
"filename":"doc/source/reference/index.rst",
"status":"modified",
"additions":1,
"deletions":3,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/reference/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/reference/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/reference/index.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -92,10 +92,9 @@ these documents will move into the \"Internals\" section.\n If you want to get involved in shaping the future of nova's architecture,\n these are a great place to start reading up on the current plans.\n \n-* :doc:`/user/cells`: How cells v2 is evolving\n * :doc:`/reference/policy-enforcement`: How we want policy checks on API actions\n   to work in the future\n-* :doc:`/reference/stable-api`: What stable api means to nova\n+* :doc:`/reference/stable-api`: What stable API means to nova\n * :doc:`/reference/scheduler-evolution`: Motivation behind the scheduler /\n   placement evolution\n \n@@ -104,7 +103,6 @@ these are a great place to start reading up on the current plans.\n .. toctree::\n    :hidden:\n \n-   /user/cells\n    policy-enforcement\n    stable-api\n    scheduler-evolution"
},
{
"sha":"2841cc0001783e9350cb0267b5cf33f76e7335bd",
"filename":"doc/source/user/architecture.rst",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/architecture.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/architecture.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/architecture.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -42,7 +42,7 @@ To make this possible nova-compute proxies DB requests over RPC to a\n central manager called ``nova-conductor``.\n \n To horizontally expand Nova deployments, we have a deployment sharding\n-concept called cells. For more information please see: :doc:`cells`\n+concept called cells. For more information please see: :doc:`/admin/cells`\n \n Components\n ----------"
},
{
"sha":"74d6fc1a3c0ae831968ff10cb0c5b264e3595103",
"filename":"doc/source/user/cells.rst",
"status":"removed",
"additions":0,
"deletions":759,
"changes":759,
"blob_url":"https://github.com/openstack/nova/blob/e8feef747f128a4cc6033a09c9a1059110534950/doc/source/user/cells.rst",
"raw_url":"https://github.com/openstack/nova/raw/e8feef747f128a4cc6033a09c9a1059110534950/doc/source/user/cells.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/cells.rst?ref=e8feef747f128a4cc6033a09c9a1059110534950",
"patch":"@@ -1,759 +0,0 @@\n-..\n-      Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n-      not use this file except in compliance with the License. You may obtain\n-      a copy of the License at\n-\n-          http://www.apache.org/licenses/LICENSE-2.0\n-\n-      Unless required by applicable law or agreed to in writing, software\n-      distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n-      WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n-      License for the specific language governing permissions and limitations\n-      under the License.\n-\n-.. _cells:\n-\n-=======\n- Cells\n-=======\n-\n-Before reading further, there is a nice overview presentation_ that\n-Andrew Laski gave at the Austin (Newton) summit which is worth watching.\n-\n-.. _presentation: https://www.openstack.org/videos/summits/austin-2016/nova-cells-v2-whats-going-on\n-\n-.. _cells-v2:\n-\n-Cells V2\n-========\n-\n-* `Newton Summit Video - Nova Cells V2: What's Going On? <https://www.openstack.org/videos/austin-2016/nova-cells-v2-whats-going-on>`_\n-* `Pike Summit Video - Scaling Nova: How CellsV2 Affects Your Deployment <https://www.openstack.org/videos/boston-2017/scaling-nova-how-cellsv2-affects-your-deployment>`_\n-* `Queens Summit Video - Add Cellsv2 to your existing Nova deployment <https://www.openstack.org/videos/sydney-2017/adding-cellsv2-to-your-existing-nova-deployment>`_\n-* `Rocky Summit Video - Moving from CellsV1 to CellsV2 at CERN\n-  <https://www.openstack.org/videos/summits/vancouver-2018/moving-from-cellsv1-to-cellsv2-at-cern>`_\n-* `Stein Summit Video - Scaling Nova with CellsV2: The Nova Developer and the CERN Operator perspective\n-  <https://www.openstack.org/videos/summits/berlin-2018/scaling-nova-with-cellsv2-the-nova-developer-and-the-cern-operator-perspective>`_\n-\n-Manifesto\n-~~~~~~~~~\n-\n-Proposal\n---------\n-\n-Right now, when a request hits the Nova API for a particular instance, the\n-instance information is fetched from the database, which contains the hostname\n-of the compute node on which the instance currently lives. If the request needs\n-to take action on the instance (which is most of them), the hostname is used to\n-calculate the name of a queue, and a message is written there which finds its\n-way to the proper compute node.\n-\n-The meat of this proposal is changing the above hostname lookup into two parts\n-that yield three pieces of information instead of one. Basically, instead of\n-merely looking up the *name* of the compute node on which an instance lives, we\n-will also obtain database and queue connection information. Thus, when asked to\n-take action on instance $foo, we will:\n-\n-1. Lookup the three-tuple of (database, queue, hostname) for that instance\n-2. Connect to that database and fetch the instance record\n-3. Connect to the queue and send the message to the proper hostname queue\n-\n-The above differs from the current organization in two ways. First, we need to\n-do two database lookups before we know where the instance lives. Second, we\n-need to demand-connect to the appropriate database and queue. Both of these\n-have performance implications, but we believe we can mitigate the impacts\n-through the use of things like a memcache of instance mapping information and\n-pooling of connections to database and queue systems. The number of cells will\n-always be much smaller than the number of instances.\n-\n-There are availability implications with this change since something like a\n-'nova list' which might query multiple cells could end up with a partial result\n-if there is a database failure in a cell. See :doc:`/admin/cells` for knowing\n-more about the recommended practices under such situations. A database failure\n-within a cell would cause larger issues than a partial list result so the\n-expectation is that it would be addressed quickly and cellsv2 will handle it by\n-indicating in the response that the data may not be complete.\n-\n-Since this is very similar to what we have with current cells, in terms of\n-organization of resources, we have decided to call this \"cellsv2\" for\n-disambiguation.\n-\n-After this work is complete there will no longer be a \"no cells\" deployment.\n-The default installation of Nova will be a single cell setup.\n-\n-Benefits\n---------\n-\n-The benefits of this new organization are:\n-\n-* Native sharding of the database and queue as a first-class-feature in nova.\n-  All of the code paths will go through the lookup procedure and thus we won't\n-  have the same feature parity issues as we do with current cells.\n-\n-* No high-level replication of all the cell databases at the top. The API will\n-  need a database of its own for things like the instance index, but it will\n-  not need to replicate all the data at the top level.\n-\n-* It draws a clear line between global and local data elements. Things like\n-  flavors and keypairs are clearly global concepts that need only live at the\n-  top level. Providing this separation allows compute nodes to become even more\n-  stateless and insulated from things like deleted/changed global data.\n-\n-* Existing non-cells users will suddenly gain the ability to spawn a new \"cell\"\n-  from their existing deployment without changing their architecture. Simply\n-  adding information about the new database and queue systems to the new index\n-  will allow them to consume those resources.\n-\n-* Existing cells users will need to fill out the cells mapping index, shutdown\n-  their existing cells synchronization service, and ultimately clean up their\n-  top level database. However, since the high-level organization is not\n-  substantially different, they will not have to re-architect their systems to\n-  move to cellsv2.\n-\n-* Adding new sets of hosts as a new \"cell\" allows them to be plugged into a\n-  deployment and tested before allowing builds to be scheduled to them.\n-\n-\n-Database split\n-~~~~~~~~~~~~~~\n-\n-As mentioned above there is a split between global data and data that is local\n-to a cell.\n-\n-The following is a breakdown of what data can uncontroversially considered\n-global versus local to a cell.  Missing data will be filled in as consensus is\n-reached on the data that is more difficult to cleanly place.  The missing data\n-is mostly concerned with scheduling and networking.\n-\n-Global (API-level) Tables\n--------------------------\n-\n-instance_types\n-instance_type_projects\n-instance_type_extra_specs\n-quotas\n-project_user_quotas\n-quota_classes\n-quota_usages\n-security_groups\n-security_group_rules\n-security_group_default_rules\n-provider_fw_rules\n-key_pairs\n-migrations\n-networks\n-tags\n-\n-Cell-level Tables\n------------------\n-\n-instances\n-instance_info_caches\n-instance_extra\n-instance_metadata\n-instance_system_metadata\n-instance_faults\n-instance_actions\n-instance_actions_events\n-instance_id_mappings\n-pci_devices\n-block_device_mapping\n-virtual_interfaces\n-\n-Setup of Cells V2\n-=================\n-\n-Overview\n-~~~~~~~~\n-\n-As more of the CellsV2 implementation is finished, all operators are\n-required to make changes to their deployment. For all deployments\n-(even those that only intend to have one cell), these changes are\n-configuration-related, both in the main nova configuration file as\n-well as some extra records in the databases.\n-\n-All nova deployments must now have the following databases available\n-and configured:\n-\n-1. The \"API\" database\n-2. One special \"cell\" database called \"cell0\"\n-3. One (or eventually more) \"cell\" databases\n-\n-Thus, a small nova deployment will have an API database, a cell0, and\n-what we will call here a \"cell1\" database. High-level tracking\n-information is kept in the API database. Instances that are never\n-scheduled are relegated to the cell0 database, which is effectively a\n-graveyard of instances that failed to start. All successful/running\n-instances are stored in \"cell1\".\n-\n-\n-.. note:: Since Nova services make use of both configuration file and some\n-          databases records, starting or restarting those services with an\n-          incomplete configuration could lead to an incorrect deployment.\n-          Please only restart the services once you are done with the described\n-          steps below.\n-\n-\n-First Time Setup\n-~~~~~~~~~~~~~~~~\n-\n-Since there is only one API database, the connection information for\n-it is stored in the nova.conf file.\n-::\n-\n-  [api_database]\n-  connection = mysql+pymysql://root:secretmysql@dbserver/nova_api?charset=utf8\n-\n-Since there may be multiple \"cell\" databases (and in fact everyone\n-will have cell0 and cell1 at a minimum), connection info for these is\n-stored in the API database. Thus, you must have connection information\n-in your config file for the API database before continuing to the\n-steps below, so that `nova-manage` can find your other databases.\n-\n-The following examples show the full expanded command line usage of\n-the setup commands. This is to make it easier to visualize which of\n-the various URLs are used by each of the commands. However, you should\n-be able to put all of that in the config file and `nova-manage` will\n-use those values. If need be, you can create separate config files and\n-pass them as `nova-manage --config-file foo.conf` to control the\n-behavior without specifying things on the command lines.\n-\n-The commands below use the API database so remember to run\n-`nova-manage api_db sync` first.\n-\n-First we will create the necessary records for the cell0 database. To\n-do that we use `nova-manage` like this::\n-\n-  nova-manage cell_v2 map_cell0 --database_connection \\\n-    mysql+pymysql://root:secretmysql@dbserver/nova_cell0?charset=utf8\n-\n-.. note:: If you don't specify `--database_connection` then\n-          `nova-manage` will use the `[database]/connection` value\n-          from your config file, and mangle the database name to have\n-          a `_cell0` suffix.\n-.. warning:: If your databases are on separate hosts then you should specify\n-             `--database_connection` or make certain that the nova.conf\n-             being used has the `[database]/connection` value pointing to the\n-             same user/password/host that will work for the cell0 database.\n-             If the cell0 mapping was created incorrectly, it can be deleted\n-             using the `nova-manage cell_v2 delete_cell` command and then run\n-             `map_cell0` again with the proper database connection value.\n-\n-Since no hosts are ever in cell0, nothing further is required for its\n-setup. Note that all deployments only ever have one cell0, as it is\n-special, so once you have done this step you never need to do it\n-again, even if you add more regular cells.\n-\n-Now, we must create another cell which will be our first \"regular\"\n-cell, which has actual compute hosts in it, and to which instances can\n-actually be scheduled. First, we create the cell record like this::\n-\n-  nova-manage cell_v2 create_cell --verbose --name cell1 \\\n-    --database_connection  mysql+pymysql://root:secretmysql@127.0.0.1/nova?charset=utf8\n-    --transport-url rabbit://stackrabbit:secretrabbit@mqserver:5672/\n-\n-.. note:: If you don't specify the database and transport urls then\n-          `nova-manage` will use the\n-          `[database]/connection` and `[DEFAULT]/transport_url` values\n-          from the config file.\n-\n-.. note:: At this point, the API database can now find the cell\n-          database, and further commands will attempt to look\n-          inside. If this is a completely fresh database (such as if\n-          you're adding a cell, or if this is a new deployment), then\n-          you will need to run `nova-manage db sync` on it to\n-          initialize the schema.\n-\n-The `nova-manage cell_v2 create_cell` command will print the UUID of the\n-newly-created cell if `--verbose` is passed, which is useful if you\n-need to run commands like `discover_hosts` targeted at a specific\n-cell.\n-\n-Now we have a cell, but no hosts are in it which means the scheduler\n-will never actually place instances there. The next step is to scan\n-the database for compute node records and add them into the cell we\n-just created. For this step, you must have had a compute node started\n-such that it registers itself as a running service. Once that has\n-happened, you can scan and add it to the cell::\n-\n-  nova-manage cell_v2 discover_hosts\n-\n-This command will connect to any databases for which you have created\n-cells (as above), look for hosts that have registered themselves\n-there, and map those hosts in the API database so that\n-they are visible to the scheduler as available targets for\n-instances. Any time you add more compute hosts to a cell, you need to\n-re-run this command to map them from the top-level so they can be\n-utilized.\n-\n-Template URLs in Cell Mappings\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-Starting in the Rocky release, the URLs provided in the cell mappings\n-for ``--database_connection`` and ``--transport-url`` can contain\n-variables which are evaluated each time they are loaded from the\n-database, and the values of which are taken from the corresponding\n-base options in the host's configuration file.  The base URL is parsed\n-and the following elements may be substituted into the cell mapping\n-URL (using ``rabbit://bob:s3kret@myhost:123/nova?sync=true#extra``):\n-\n-.. list-table:: Cell Mapping URL Variables\n-   :header-rows: 1\n-   :widths: 15, 50, 15\n-\n-   * - Variable\n-     - Meaning\n-     - Part of example URL\n-   * - ``scheme``\n-     - The part before the `://`\n-     - ``rabbit``\n-   * - ``username``\n-     - The username part of the credentials\n-     - ``bob``\n-   * - ``password``\n-     - The password part of the credentials\n-     - ``s3kret``\n-   * - ``hostname``\n-     - The hostname or address\n-     - ``myhost``\n-   * - ``port``\n-     - The port number (must be specified)\n-     - ``123``\n-   * - ``path``\n-     - The \"path\" part of the URL (without leading slash)\n-     - ``nova``\n-   * - ``query``\n-     - The full query string arguments (without leading question mark)\n-     - ``sync=true``\n-   * - ``fragment``\n-     - Everything after the first hash mark\n-     - ``extra``\n-\n-Variables are provided in curly brackets, like ``{username}``. A simple template\n-of ``rabbit://{username}:{password}@otherhost/{path}`` will generate a full URL\n-of ``rabbit://bob:s3kret@otherhost/nova`` when used with the above example.\n-\n-.. note:: The ``[database]/connection`` and\n-   ``[DEFAULT]/transport_url`` values are not reloaded from the\n-   configuration file during a SIGHUP, which means that a full service\n-   restart will be required to notice changes in a cell mapping record\n-   if variables are changed.\n-\n-.. note:: The ``[DEFAULT]/transport_url`` option can contain an\n-   extended syntax for the \"netloc\" part of the url\n-   (i.e. `userA:passwordA@hostA:portA,userB:passwordB:hostB:portB`). In this\n-   case, substitions of the form ``username1``, ``username2``, etc will be\n-   honored and can be used in the template URL.\n-\n-The templating of these URLs may be helpful in order to provide each service host\n-with its own credentials for, say, the database. Without templating, all hosts\n-will use the same URL (and thus credentials) for accessing services like the\n-database and message queue. By using a URL with a template that results in the\n-credentials being taken from the host-local configuration file, each host will\n-use different values for those connections.\n-\n-Assuming you have two service hosts that are normally configured with the cell0\n-database as their primary connection, their (abbreviated) configurations would\n-look like this::\n-\n- [database]\n- connection = mysql+pymysql://service1:foo@myapidbhost/nova_cell0\n-\n-and::\n-\n- [database]\n- connection = mysql+pymysql://service2:bar@myapidbhost/nova_cell0\n-\n-Without cell mapping template URLs, they would still use the same credentials\n-(as stored in the mapping) to connect to the cell databases. However, consider\n-template URLs like the following::\n-\n- mysql+pymysql://{username}:{password}@mycell1dbhost/nova\n-\n-and::\n-\n- mysql+pymysql://{username}:{password}@mycell2dbhost/nova\n-\n-Using the first service and cell1 mapping, the calculated URL that will actually\n-be used for connecting to that database will be::\n-\n- mysql+pymysql://service1:foo@mycell1dbhost/nova\n-\n-\n-References\n-~~~~~~~~~~\n-\n-* :doc:`nova-manage man page </cli/nova-manage>`\n-\n-Step-By-Step for Common Use Cases\n-=================================\n-\n-The following are step-by-step examples for common use cases setting\n-up Cells V2. This is intended as a quick reference that puts together\n-everything explained in `Setup of Cells V2`_. It is assumed that you have\n-followed all other install steps for Nova and are setting up Cells V2\n-specifically at this point.\n-\n-Fresh Install\n-~~~~~~~~~~~~~\n-\n-You are installing Nova for the first time and have no compute hosts in the\n-database yet. This will set up a single cell Nova deployment.\n-\n-1. Reminder: You should have already created and synced the Nova API database\n-   by creating a database, configuring its connection in the\n-   ``[api_database]/connection`` setting in the Nova configuration file, and\n-   running ``nova-manage api_db sync``.\n-\n-2. Create a database for cell0. If you are going to pass the database\n-   connection url on the command line in step 3, you can name the cell0\n-   database whatever you want. If you are not going to pass the database url on\n-   the command line in step 3, you need to name the cell0 database based on the\n-   name of your existing Nova database: <Nova database name>_cell0. For\n-   example, if your Nova database is named ``nova``, then your cell0 database\n-   should be named ``nova_cell0``.\n-\n-3. Run the ``map_cell0`` command to create and map cell0::\n-\n-     nova-manage cell_v2 map_cell0 \\\n-       --database_connection <database connection url>\n-\n-   The database connection url is generated based on the\n-   ``[database]/connection`` setting in the Nova configuration file if not\n-   specified on the command line.\n-\n-4. Run ``nova-manage db sync`` to populate the cell0 database with a schema.\n-   The ``db sync`` command reads the database connection for cell0 that was\n-   created in step 3.\n-\n-5. Run the ``create_cell`` command to create the single cell which will contain\n-   your compute hosts::\n-\n-     nova-manage cell_v2 create_cell --name <name> \\\n-       --transport-url <transport url for message queue> \\\n-       --database_connection <database connection url>\n-\n-   The transport url is taken from the ``[DEFAULT]/transport_url`` setting in\n-   the Nova configuration file if not specified on the command line. The\n-   database url is taken from the ``[database]/connection`` setting in the Nova\n-   configuration file if not specified on the command line.\n-\n-6. Configure your compute host(s), making sure ``[DEFAULT]/transport_url``\n-   matches the transport URL for the cell created in step 5, and start the\n-   nova-compute service. Before step 7, make sure you have compute hosts in the\n-   database by running::\n-\n-     nova service-list --binary nova-compute\n-\n-7. Run the ``discover_hosts`` command to map compute hosts to the single cell\n-   by running::\n-\n-     nova-manage cell_v2 discover_hosts\n-\n-   The command will search for compute hosts in the database of the cell you\n-   created in step 5 and map them to the cell. You can also configure a\n-   periodic task to have Nova discover new hosts automatically by setting\n-   the ``[scheduler]/discover_hosts_in_cells_interval`` to a time interval in\n-   seconds. The periodic task is run by the nova-scheduler service, so you must\n-   be sure to configure it on all of your nova-scheduler hosts.\n-\n-.. note:: Remember: In the future, whenever you add new compute hosts, you\n-          will need to run the ``discover_hosts`` command after starting them\n-          to map them to the cell if you did not configure the automatic host\n-          discovery in step 7.\n-\n-Upgrade (minimal)\n-~~~~~~~~~~~~~~~~~\n-\n-You are upgrading an existing Nova install and have compute hosts in the\n-database. This will set up a single cell Nova deployment.\n-\n-1. If you haven't already created a cell0 database in a prior release,\n-   create a database for cell0 with a name based on the name of your Nova\n-   database: <Nova database name>_cell0. If your Nova database is named\n-   ``nova``, then your cell0 database should be named ``nova_cell0``.\n-\n-.. warning:: In Newton, the ``simple_cell_setup`` command expects the name of\n-             the cell0 database to be based on the name of the Nova API\n-             database: <Nova API database name>_cell0 and the database\n-             connection url is taken from the ``[api_database]/connection``\n-             setting in the Nova configuration file.\n-\n-2. Run the ``simple_cell_setup`` command to create and map cell0, create and\n-   map the single cell, and map existing compute hosts and instances to the\n-   single cell::\n-\n-     nova-manage cell_v2 simple_cell_setup \\\n-       --transport-url <transport url for message queue>\n-\n-   The transport url is taken from the ``[DEFAULT]/transport_url`` setting in\n-   the Nova configuration file if not specified on the command line. The\n-   database connection url will be generated based on the\n-   ``[database]/connection`` setting in the Nova configuration file.\n-\n-.. note:: Remember: In the future, whenever you add new compute hosts, you\n-          will need to run the ``discover_hosts`` command after starting them\n-          to map them to the cell. You can also configure a periodic task to\n-          have Nova discover new hosts automatically by setting the\n-          ``[scheduler]/discover_hosts_in_cells_interval`` to a time interval\n-          in seconds. The periodic task is run by the nova-scheduler service,\n-          so you must be sure to configure it on all of your nova-scheduler\n-          hosts.\n-\n-Upgrade with Cells V1\n-~~~~~~~~~~~~~~~~~~~~~\n-\n-.. todo:: This needs to be removed but `Adding a new cell to an existing deployment`_\n-          is still using it.\n-\n-You are upgrading an existing Nova install that has Cells V1 enabled and have\n-compute hosts in your databases. This will set up a multiple cell Nova\n-deployment. At this time, it is recommended to keep Cells V1 enabled during and\n-after the upgrade as multiple Cells V2 cell support is not fully finished and\n-may not work properly in all scenarios. These upgrade steps will help ensure a\n-simple cutover from Cells V1 to Cells V2 in the future.\n-\n-.. note:: There is a Rocky summit video from CERN about how they did their\n-          upgrade from cells v1 to v2 here:\n-\n-          https://www.openstack.org/videos/vancouver-2018/moving-from-cellsv1-to-cellsv2-at-cern\n-\n-1. If you haven't already created a cell0 database in a prior release,\n-   create a database for cell0. If you are going to pass the database\n-   connection url on the command line in step 2, you can name the cell0\n-   database whatever you want. If you are not going to pass the database url on\n-   the command line in step 2, you need to name the cell0 database based on the\n-   name of your existing Nova database: <Nova database name>_cell0. For\n-   example, if your Nova database is named ``nova``, then your cell0 database\n-   should be named ``nova_cell0``.\n-\n-2. Run the ``map_cell0`` command to create and map cell0::\n-\n-     nova-manage cell_v2 map_cell0 \\\n-       --database_connection <database connection url>\n-\n-   The database connection url is generated based on the\n-   ``[database]/connection`` setting in the Nova configuration file if not\n-   specified on the command line.\n-\n-3. Run ``nova-manage db sync`` to populate the cell0 database with a schema.\n-   The ``db sync`` command reads the database connection for cell0 that was\n-   created in step 2.\n-\n-4. Run the ``create_cell`` command to create cells which will contain your\n-   compute hosts::\n-\n-     nova-manage cell_v2 create_cell --name <cell name> \\\n-       --transport-url <transport url for message queue> \\\n-       --database_connection <database connection url>\n-\n-   You will need to repeat this step for each cell in your deployment. Your\n-   existing cell database will be re-used -- this simply informs the top-level\n-   API database about your existing cell databases.\n-\n-   It is a good idea to specify a name for the new cell you create so you can\n-   easily look up cell uuids with the ``list_cells`` command later if needed.\n-\n-   The transport url is taken from the ``[DEFAULT]/transport_url`` setting in\n-   the Nova configuration file if not specified on the command line. The\n-   database url is taken from the ``[database]/connection`` setting in the Nova\n-   configuration file if not specified on the command line. If you are not\n-   going to specify ``--database_connection`` and ``--transport-url`` on the\n-   command line, be sure to specify your existing cell Nova configuration\n-   file::\n-\n-     nova-manage --config-file <cell nova.conf> cell_v2 create_cell \\\n-       --name <cell name>\n-\n-5. Run the ``discover_hosts`` command to map compute hosts to cells::\n-\n-     nova-manage cell_v2 discover_hosts --cell_uuid <cell uuid>\n-\n-   You will need to repeat this step for each cell in your deployment unless\n-   you omit the ``--cell_uuid`` option. If the cell uuid is not specified on\n-   the command line, ``discover_hosts`` will search for compute hosts in each\n-   cell database and map them to the corresponding cell. You can use the\n-   ``list_cells`` command to look up cell uuids if you are going to specify\n-   ``--cell_uuid``.\n-\n-   You can also configure a periodic task to have Nova discover new hosts\n-   automatically by setting the\n-   ``[scheduler]/discover_hosts_in_cells_interval`` to a time interval in\n-   seconds. The periodic task is run by the nova-scheduler service, so you must\n-   be sure to configure it on all of your nova-scheduler hosts.\n-\n-6. Run the ``map_instances`` command to map instances to cells::\n-\n-     nova-manage cell_v2 map_instances --cell_uuid <cell uuid> \\\n-       --max-count <max count>\n-\n-   You will need to repeat this step for each cell in your deployment. You can\n-   use the ``list_cells`` command to look up cell uuids.\n-\n-   The ``--max-count`` option can be specified if you would like to limit the\n-   number of instances to map in a single run. If ``--max-count`` is not\n-   specified, all instances will be mapped. Repeated runs of the command will\n-   start from where the last run finished so it is not necessary to increase\n-   ``--max-count`` to finish. An exit code of 0 indicates that all instances\n-   have been mapped. An exit code of 1 indicates that there are remaining\n-   instances that need to be mapped.\n-\n-.. note:: Remember: In the future, whenever you add new compute hosts, you\n-          will need to run the ``discover_hosts`` command after starting them\n-          to map them to a cell if you did not configure the automatic host\n-          discovery in step 5.\n-\n-Adding a new cell to an existing deployment\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-To expand your deployment with a new cell, first follow the usual steps for\n-standing up a new Cells V1 cell. After that is finished, follow step 4 in\n-`Upgrade with Cells V1`_ to create a new Cells V2 cell for it. If you have\n-added new compute hosts for the new cell, you will also need to run the\n-``discover_hosts`` command after starting them to map them to the new cell if\n-you did not configure the automatic host discovery as described in step 5 in\n-`Upgrade with Cells V1`_.\n-\n-References\n-~~~~~~~~~~\n-\n-* :doc:`nova-manage man page </cli/nova-manage>`\n-\n-FAQs\n-====\n-\n-#. How do I find out which hosts are bound to which cell?\n-\n-   There are a couple of ways to do this.\n-\n-   1. Run ``nova-manage --config-file <cell config> host list``. This will\n-      only lists hosts in the provided cell nova.conf.\n-\n-      .. deprecated:: 16.0.0\n-         The ``nova-manage host list`` command is deprecated as of the\n-         16.0.0 Pike release.\n-\n-   2. Run ``nova-manage cell_v2 discover_hosts --verbose``. This does not\n-      produce a report but if you are trying to determine if a host is in a\n-      cell you can run this and it will report any hosts that are not yet\n-      mapped to a cell and map them. This command is idempotent.\n-\n-   3. Run ``nova-manage cell_v2 list_hosts``. This will list hosts in all\n-      cells. If you want to list hosts in a specific cell, you can run\n-      ``nova-manage cell_v2 list_hosts --cell_uuid <cell_uuid>``.\n-\n-#. I updated the database_connection and/or transport_url in a cell using the\n-   ``nova-manage cell_v2 update_cell`` command but the API is still trying to\n-   use the old settings.\n-\n-   The cell mappings are cached in the nova-api service worker so you will need\n-   to restart the worker process to rebuild the cache. Note that there is\n-   another global cache tied to request contexts, which is used in the\n-   nova-conductor and nova-scheduler services, so you might need to do the same\n-   if you are having the same issue in those services. As of the 16.0.0 Pike\n-   release there is no timer on the cache or hook to refresh the cache using a\n-   SIGHUP to the service.\n-\n-#. I have upgraded from Newton to Ocata and I can list instances but I get a\n-   404 NotFound error when I try to get details on a specific instance.\n-\n-   Instances need to be mapped to cells so the API knows which cell an instance\n-   lives in. When upgrading, the ``nova-manage cell_v2 simple_cell_setup``\n-   command will automatically map the instances to the single cell which is\n-   backed by the existing nova database. If you have already upgraded\n-   and did not use the ``simple_cell_setup`` command, you can run the\n-   ``nova-manage cell_v2 map_instances --cell_uuid <cell_uuid>`` command to\n-   map all instances in the given cell. See the :ref:`man-page-cells-v2` man\n-   page for details on command usage.\n-\n-#. Should I change any of the ``[cells]`` configuration options for Cells v2?\n-\n-   **NO**. Those options are for Cells v1 usage only and are not used at all\n-   for Cells v2. That includes the ``nova-cells`` service - it has nothing\n-   to do with Cells v2.\n-\n-#. Can I create a cell but have it disabled from scheduling?\n-\n-   Yes. It is possible to create a pre-disabled cell such that it does not\n-   become a candidate for scheduling new VMs. This can be done by running the\n-   ``nova-manage cell_v2 create_cell`` command with the ``--disabled`` option.\n-\n-#. How can I disable a cell so that the new server create requests do not go to\n-   it while I perform maintenance?\n-\n-   Existing cells can be disabled by running ``nova-manage cell_v2 update_cell\n-   --cell_uuid <cell_uuid> --disable`` and can be re-enabled once the\n-   maintenance period is over by running ``nova-manage cell_v2 update_cell\n-   --cell_uuid <cell_uuid> --enable``\n-\n-#. I disabled (or enabled) a cell using the ``nova-manage cell_v2 update_cell``\n-   or I created a new (pre-disabled) cell(mapping) using the\n-   ``nova-manage cell_v2 create_cell`` command but the scheduler is still using\n-   the old settings.\n-\n-   The cell mappings are cached in the scheduler worker so you will either need\n-   to restart the scheduler process to refresh the cache, or send a SIGHUP\n-   signal to the scheduler by which it will automatically refresh the cells\n-   cache and the changes will take effect.\n-\n-#. Why was the cells REST API not implemented for CellsV2? Why are\n-   there no CRUD operations for cells in the API?\n-\n-   One of the deployment challenges that CellsV1 had was the\n-   requirement for the API and control services to be up before a new\n-   cell could be deployed. This was not a problem for large-scale\n-   public clouds that never shut down, but is not a reasonable\n-   requirement for smaller clouds that do offline upgrades and/or\n-   clouds which could be taken completely offline by something like a\n-   power outage. Initial devstack and gate testing for CellsV1 was\n-   delayed by the need to engineer a solution for bringing the services\n-   partially online in order to deploy the rest, and this continues to\n-   be a gap for other deployment tools. Consider also the FFU case\n-   where the control plane needs to be down for a multi-release\n-   upgrade window where changes to cell records have to be made. This\n-   would be quite a bit harder if the way those changes are made is\n-   via the API, which must remain down during the process.\n-\n-   Further, there is a long-term goal to move cell configuration\n-   (i.e. cell_mappings and the associated URLs and credentials) into\n-   config and get away from the need to store and provision those\n-   things in the database. Obviously a CRUD interface in the API would\n-   prevent us from making that move.\n-\n-#. Why are cells not exposed as a grouping mechanism in the API for\n-   listing services, instances, and other resources?\n-\n-   Early in the design of CellsV2 we set a goal to not let the cell\n-   concept leak out of the API, even for operators. Aggregates are the\n-   way nova supports grouping of hosts for a variety of reasons, and\n-   aggregates can cut across cells, and/or be aligned with them if\n-   desired. If we were to support cells as another grouping mechanism,\n-   we would likely end up having to implement many of the same\n-   features for them as aggregates, such as scheduler features,\n-   metadata, and other searching/filtering operations. Since\n-   aggregates are how Nova supports grouping, we expect operators to\n-   use aggregates any time they need to refer to a cell as a group of\n-   hosts from the API, and leave actual cells as a purely\n-   architectural detail.\n-\n-   The need to filter instances by cell in the API can and should be\n-   solved by adding a generic by-aggregate filter, which would allow\n-   listing instances on hosts contained within any aggregate,\n-   including one that matches the cell boundaries if so desired.\n-\n-#. Why are the API responses for ``GET /servers``, ``GET /servers/detail``,\n-   ``GET /servers/{server_id}`` and ``GET /os-services`` missing some\n-   information for certain cells at certain times? Why do I see the status as\n-   \"UNKNOWN\" for the servers in those cells at those times when I run\n-   ``openstack server list`` or ``openstack server show``?\n-\n-   Starting from microversion 2.69 the API responses of ``GET /servers``,\n-   ``GET /servers/detail``, ``GET /servers/{server_id}`` and\n-   ``GET /os-services`` may contain missing keys during down cell situations.\n-   See the `Handling Down Cells\n-   <https://docs.openstack.org/api-guide/compute/down_cells.html>`__\n-   section of the Compute API guide for more information on the partial\n-   constructs.\n-\n-   For administrative considerations, see\n-   :ref:`Handling cell failures <handling-cell-failures>`."
},
{
"sha":"945770c6658a883c06d5643a32bcb80726ae25a0",
"filename":"doc/source/user/cellsv2-layout.rst",
"status":"removed",
"additions":0,
"deletions":412,
"changes":412,
"blob_url":"https://github.com/openstack/nova/blob/e8feef747f128a4cc6033a09c9a1059110534950/doc/source/user/cellsv2-layout.rst",
"raw_url":"https://github.com/openstack/nova/raw/e8feef747f128a4cc6033a09c9a1059110534950/doc/source/user/cellsv2-layout.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/cellsv2-layout.rst?ref=e8feef747f128a4cc6033a09c9a1059110534950",
"patch":"@@ -1,412 +0,0 @@\n-..\n-      Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n-      not use this file except in compliance with the License. You may obtain\n-      a copy of the License at\n-\n-          http://www.apache.org/licenses/LICENSE-2.0\n-\n-      Unless required by applicable law or agreed to in writing, software\n-      distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n-      WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n-      License for the specific language governing permissions and limitations\n-      under the License.\n-\n-===================\n- Cells Layout (v2)\n-===================\n-\n-This document describes the layout of a deployment with Cells\n-version 2, including deployment considerations for security and\n-scale. It is focused on code present in Pike and later, and while it\n-is geared towards people who want to have multiple cells for whatever\n-reason, the nature of the cellsv2 support in Nova means that it\n-applies in some way to all deployments.\n-\n-Concepts\n-========\n-\n-A basic Nova system consists of the following components:\n-\n-* The nova-api service which provides the external REST API to users.\n-* The nova-scheduler and placement services which are responsible\n-  for tracking resources and deciding which compute node instances\n-  should be on.\n-* An \"API database\" that is used primarily by nova-api and\n-  nova-scheduler (called *API-level services* below) to track location\n-  information about instances, as well as a temporary location for\n-  instances being built but not yet scheduled.\n-* The nova-conductor service which offloads long-running tasks for the\n-  API-level service, as well as insulates compute nodes from direct\n-  database access\n-* The nova-compute service which manages the virt driver and\n-  hypervisor host.\n-* A \"cell database\" which is used by API, conductor and compute\n-  services, and which houses the majority of the information about\n-  instances.\n-* A \"cell0 database\" which is just like the cell database, but\n-  contains only instances that failed to be scheduled.\n-* A message queue which allows the services to communicate with each\n-  other via RPC.\n-\n-All deployments have at least the above components. Small deployments\n-likely have a single message queue that all services share, and a\n-single database server which hosts the API database, a single cell\n-database, as well as the required cell0 database. This is considered a\n-\"single-cell deployment\" because it only has one \"real\" cell. The\n-cell0 database mimics a regular cell, but has no compute nodes and is\n-used only as a place to put instances that fail to land on a real\n-compute node (and thus a real cell).\n-\n-The purpose of the cells functionality in nova is specifically to\n-allow larger deployments to shard their many compute nodes into cells,\n-each of which has a database and message queue. The API database is\n-always and only global, but there can be many cell databases (where\n-the bulk of the instance information lives), each with a portion of\n-the instances for the entire deployment within.\n-\n-All of the nova services use a configuration file, all of which will\n-at a minimum specify a message queue endpoint\n-(i.e. ``[DEFAULT]/transport_url``). Most of the services also require\n-configuration of database connection information\n-(i.e. ``[database]/connection``). API-level services that need access\n-to the global routing and placement information will also be\n-configured to reach the API database\n-(i.e. ``[api_database]/connection``).\n-\n-.. note:: The pair of ``transport_url`` and ``[database]/connection``\n-          configured for a service defines what cell a service lives\n-          in.\n-\n-API-level services need to be able to contact other services in all of\n-the cells. Since they only have one configured ``transport_url`` and\n-``[database]/connection`` they look up the information for the other\n-cells in the API database, with records called *cell mappings*.\n-\n-.. note:: The API database must have cell mapping records that match\n-          the ``transport_url`` and ``[database]/connection``\n-          configuration elements of the lower-level services. See the\n-          ``nova-manage`` :ref:`man-page-cells-v2` commands for more\n-          information about how to create and examine these records.\n-\n-Service Layout\n-==============\n-\n-The services generally have a well-defined communication pattern that\n-dictates their layout in a deployment. In a small/simple scenario, the\n-rules do not have much of an impact as all the services can\n-communicate with each other on a single message bus and in a single\n-cell database. However, as the deployment grows, scaling and security\n-concerns may drive separation and isolation of the services.\n-\n-Simple\n-------\n-\n-This is a diagram of the basic services that a simple (single-cell)\n-deployment would have, as well as the relationships\n-(i.e. communication paths) between them:\n-\n-.. graphviz::\n-\n-  digraph services {\n-    graph [pad=\"0.35\", ranksep=\"0.65\", nodesep=\"0.55\", concentrate=true];\n-    node [fontsize=10 fontname=\"Monospace\"];\n-    edge [arrowhead=\"normal\", arrowsize=\"0.8\"];\n-    labelloc=bottom;\n-    labeljust=left;\n-\n-    { rank=same\n-      api [label=\"nova-api\"]\n-      apidb [label=\"API Database\" shape=\"box\"]\n-      scheduler [label=\"nova-scheduler\"]\n-    }\n-    { rank=same\n-      mq [label=\"MQ\" shape=\"diamond\"]\n-      conductor [label=\"nova-conductor\"]\n-    }\n-    { rank=same\n-      cell0db [label=\"Cell0 Database\" shape=\"box\"]\n-      celldb [label=\"Cell Database\" shape=\"box\"]\n-      compute [label=\"nova-compute\"]\n-    }\n-\n-    api -> mq -> compute\n-    conductor -> mq -> scheduler\n-\n-    api -> apidb\n-    api -> cell0db\n-    api -> celldb\n-\n-    conductor -> apidb\n-    conductor -> cell0db\n-    conductor -> celldb\n-  }\n-\n-All of the services are configured to talk to each other over the same\n-message bus, and there is only one cell database where live instance\n-data resides. The cell0 database is present (and required) but as no\n-compute nodes are connected to it, this is still a \"single cell\"\n-deployment.\n-\n-Multiple Cells\n---------------\n-\n-In order to shard the services into multiple cells, a number of things\n-must happen. First, the message bus must be split into pieces along\n-the same lines as the cell database. Second, a dedicated conductor\n-must be run for the API-level services, with access to the API\n-database and a dedicated message queue. We call this *super conductor*\n-to distinguish its place and purpose from the per-cell conductor nodes.\n-\n-.. graphviz::\n-\n-  digraph services2 {\n-    graph [pad=\"0.35\", ranksep=\"0.65\", nodesep=\"0.55\", concentrate=true];\n-    node [fontsize=10 fontname=\"Monospace\"];\n-    edge [arrowhead=\"normal\", arrowsize=\"0.8\"];\n-    labelloc=bottom;\n-    labeljust=left;\n-\n-    subgraph api {\n-      api [label=\"nova-api\"]\n-      scheduler [label=\"nova-scheduler\"]\n-      conductor [label=\"super conductor\"]\n-      { rank=same\n-        apimq [label=\"API MQ\" shape=\"diamond\"]\n-        apidb [label=\"API Database\" shape=\"box\"]\n-      }\n-\n-      api -> apimq -> conductor\n-      api -> apidb\n-      conductor -> apimq -> scheduler\n-      conductor -> apidb\n-    }\n-\n-    subgraph clustercell0 {\n-      label=\"Cell 0\"\n-      color=green\n-      cell0db [label=\"Cell Database\" shape=\"box\"]\n-    }\n-\n-    subgraph clustercell1 {\n-      label=\"Cell 1\"\n-      color=blue\n-      mq1 [label=\"Cell MQ\" shape=\"diamond\"]\n-      cell1db [label=\"Cell Database\" shape=\"box\"]\n-      conductor1 [label=\"nova-conductor\"]\n-      compute1 [label=\"nova-compute\"]\n-\n-      conductor1 -> mq1 -> compute1\n-      conductor1 -> cell1db\n-\n-    }\n-\n-    subgraph clustercell2 {\n-      label=\"Cell 2\"\n-      color=red\n-      mq2 [label=\"Cell MQ\" shape=\"diamond\"]\n-      cell2db [label=\"Cell Database\" shape=\"box\"]\n-      conductor2 [label=\"nova-conductor\"]\n-      compute2 [label=\"nova-compute\"]\n-\n-      conductor2 -> mq2 -> compute2\n-      conductor2 -> cell2db\n-    }\n-\n-    api -> mq1 -> conductor1\n-    api -> mq2 -> conductor2\n-    api -> cell0db\n-    api -> cell1db\n-    api -> cell2db\n-\n-    conductor -> cell0db\n-    conductor -> cell1db\n-    conductor -> mq1\n-    conductor -> cell2db\n-    conductor -> mq2\n-  }\n-\n-It is important to note that services in the lower cell boxes only\n-have the ability to call back to the placement API but cannot access\n-any other API-layer services via RPC, nor do they have access to the\n-API database for global visibility of resources across the cloud.\n-This is intentional and provides security and failure domain\n-isolation benefits, but also has impacts on some things that would\n-otherwise require this any-to-any communication style. Check the\n-release notes for the version of Nova you are using for the most\n-up-to-date information about any caveats that may be present due to\n-this limitation.\n-\n-Caveats of a Multi-Cell deployment\n-----------------------------------\n-\n-.. note:: This information is correct as of the Pike release. Where\n-          improvements have been made or issues fixed, they are noted per\n-          item.\n-\n-Cross-cell instance migrations\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-Currently it is not possible to migrate an instance from a host in one\n-cell to a host in another cell. This may be possible in the future,\n-but it is currently unsupported. This impacts cold migration,\n-resizes, live migrations, evacuate, and unshelve operations.\n-\n-Quota-related quirks\n-~~~~~~~~~~~~~~~~~~~~\n-\n-Quotas are now calculated live at the point at which an operation\n-would consume more resource, instead of being kept statically in the\n-database. This means that a multi-cell environment may incorrectly\n-calculate the usage of a tenant if one of the cells is unreachable, as\n-those resources cannot be counted. In this case, the tenant may be\n-able to consume more resource from one of the available cells, putting\n-them far over quota when the unreachable cell returns.\n-\n-.. note:: Starting in the Train (20.0.0) release, it is possible to configure\n-          counting of quota usage from the placement service and API database\n-          to make quota usage calculations resilient to down or poor-performing\n-          cells in a multi-cell environment. See the\n-          :doc:`quotas documentation<quotas>` for more details.\n-\n-Performance of listing instances\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-.. note:: This has been resolved in the Queens release [#]_.\n-\n-With multiple cells, the instance list operation may not sort and\n-paginate results properly when crossing multiple cell\n-boundaries. Further, the performance of a sorted list operation will\n-be considerably slower than with a single cell.\n-\n-Notifications\n-~~~~~~~~~~~~~\n-\n-With a multi-cell environment with multiple message queues, it is\n-likely that operators will want to configure a separate connection to\n-a unified queue for notifications. This can be done in the configuration file\n-of all nodes. Refer to the :oslo.messaging-doc:`oslo.messaging configuration\n-documentation\n-<configuration/opts.html#oslo_messaging_notifications.transport_url>` for more\n-details.\n-\n-.. _cells-v2-layout-metadata-api:\n-\n-Nova Metadata API service\n-~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-Starting from the Stein release, the :doc:`nova metadata API service\n-</admin/metadata-service>` can be run either globally or per cell using the\n-:oslo.config:option:`api.local_metadata_per_cell` configuration option.\n-\n-**Global**\n-\n-If you have networks that span cells, you might need to run Nova metadata API\n-globally. When running globally, it should be configured as an API-level\n-service with access to the :oslo.config:option:`api_database.connection`\n-information. The nova metadata API service **must not** be run as a standalone\n-service, using the :program:`nova-api-metadata` service, in this case.\n-\n-**Local per cell**\n-\n-Running Nova metadata API per cell can have better performance and data\n-isolation in a multi-cell deployment. If your networks are segmented along\n-cell boundaries, then you can run Nova metadata API service per cell. If you\n-choose to run it per cell, you should also configure each\n-:neutron-doc:`neutron-metadata-agent\n-<configuration/metadata-agent.html?#DEFAULT.nova_metadata_host>` service to\n-point to the corresponding :program:`nova-api-metadata`. The nova metadata API\n-service **must** be run as a standalone service, using the\n-:program:`nova-api-metadata` service, in this case.\n-\n-\n-Console proxies\n-~~~~~~~~~~~~~~~\n-\n-`Starting from the Rocky release`__, console proxies must be run per cell\n-because console token authorizations are stored in cell databases. This means\n-that each console proxy server must have access to the\n-:oslo.config:option:`database.connection` information for the cell database\n-containing the instances for which it is proxying console access.\n-\n-.. __: https://specs.openstack.org/openstack/nova-specs/specs/rocky/implemented/convert-consoles-to-objects.html\n-\n-\n-.. _upcall:\n-\n-Operations Requiring upcalls\n-~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n-\n-If you deploy multiple cells with a superconductor as described above,\n-computes and cell-based conductors will not have the ability to speak\n-to the scheduler as they are not connected to the same MQ. This is by\n-design for isolation, but currently the processes are not in place to\n-implement some features without such connectivity. Thus, anything that\n-requires a so-called \"upcall\" will not function. This impacts the\n-following:\n-\n-#. Instance reschedules during boot and resize (part 1)\n-\n-   .. note:: This has been resolved in the Queens release [#]_.\n-\n-#. Instance affinity reporting from the compute nodes to scheduler\n-#. The late anti-affinity check during server create and evacuate\n-#. Querying host aggregates from the cell\n-\n-   .. note:: This has been resolved in the Rocky release [#]_.\n-\n-#. Attaching a volume and ``[cinder]/cross_az_attach=False``\n-#. Instance reschedules during boot and resize (part 2)\n-\n-   .. note:: This has been resolved in the Ussuri release [#]_ [#]_.\n-\n-The first is simple: if you boot an instance, it gets scheduled to a\n-compute node, fails, it would normally be re-scheduled to another\n-node. That requires scheduler intervention and thus it will not work\n-in Pike with a multi-cell layout. If you do not rely on reschedules\n-for covering up transient compute-node failures, then this will not\n-affect you. To ensure you do not make futile attempts at rescheduling,\n-you should set ``[scheduler]/max_attempts=1`` in ``nova.conf``.\n-\n-The second two are related. The summary is that some of the facilities\n-that Nova has for ensuring that affinity/anti-affinity is preserved\n-between instances does not function in Pike with a multi-cell\n-layout. If you don't use affinity operations, then this will not\n-affect you. To make sure you don't make futile attempts at the\n-affinity check, you should set\n-``[workarounds]/disable_group_policy_check_upcall=True`` and\n-``[filter_scheduler]/track_instance_changes=False`` in ``nova.conf``.\n-\n-The fourth was previously only a problem when performing live migrations using\n-the since-removed XenAPI driver and not specifying ``--block-migrate``. The\n-driver would attempt to figure out if block migration should be performed based\n-on source and destination hosts being in the same aggregate. Since aggregates\n-data had migrated to the API database, the cell conductor would not be able to\n-access the aggregate information and would fail.\n-\n-The fifth is a problem because when a volume is attached to an instance\n-in the *nova-compute* service, and ``[cinder]/cross_az_attach=False`` in\n-nova.conf, we attempt to look up the availability zone that the instance is\n-in which includes getting any host aggregates that the ``instance.host`` is in.\n-Since the aggregates are in the API database and the cell conductor cannot\n-access that information, so this will fail. In the future this check could be\n-moved to the *nova-api* service such that the availability zone between the\n-instance and the volume is checked before we reach the cell, except in the\n-case of :term:`boot from volume <Boot From Volume>` where the *nova-compute*\n-service itself creates the volume and must tell Cinder in which availability\n-zone to create the volume. Long-term, volume creation during boot from volume\n-should be moved to the top-level superconductor which would eliminate this AZ\n-up-call check problem.\n-\n-The sixth is detailed in `bug 1781286`_ and similar to the first issue.\n-The issue is that servers created without a specific availability zone\n-will have their AZ calculated during a reschedule based on the alternate host\n-selected. Determining the AZ for the alternate host requires an \"up call\" to\n-the API DB.\n-\n-.. _bug 1781286: https://bugs.launchpad.net/nova/+bug/1781286\n-\n-.. [#] https://blueprints.launchpad.net/nova/+spec/efficient-multi-cell-instance-list-and-sort\n-.. [#] https://specs.openstack.org/openstack/nova-specs/specs/queens/approved/return-alternate-hosts.html\n-.. [#] https://blueprints.launchpad.net/nova/+spec/live-migration-in-xapi-pool\n-.. [#] https://review.opendev.org/686047/\n-.. [#] https://review.opendev.org/686050/"
},
{
"sha":"743519a86ebd9eb9624365a9fa1d03dcb87aef54",
"filename":"doc/source/user/index.rst",
"status":"modified",
"additions":3,
"deletions":3,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/index.rst",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/source/user/index.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/index.rst?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -54,9 +54,9 @@ the defaults from the :doc:`install guide </install/index>` will be sufficient.\n   * :doc:`Feature Support full list </user/support-matrix>`: A detailed dive through\n     features in each compute driver backend.\n \n-* :doc:`Cells v2 Planning </user/cellsv2-layout>`: For large deployments, Cells v2\n-  allows sharding of your compute environment. Upfront planning is key to a\n-  successful Cells v2 layout.\n+* :doc:`Cells v2 configuration </admin/cells>`: For large deployments, cells v2\n+  cells allow sharding of your compute environment. Upfront planning is key to\n+  a successful cells v2 layout.\n \n * :placement-doc:`Placement service <>`: Overview of the placement\n   service, including how it fits in with the rest of nova."
},
{
"sha":"012ddfe7bc1575be4e6b8e4a8a0a05cd17e9fb7d",
"filename":"doc/test/redirect-tests.txt",
"status":"modified",
"additions":5,
"deletions":3,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/test/redirect-tests.txt",
"raw_url":"https://github.com/openstack/nova/raw/b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705/doc/test/redirect-tests.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/test/redirect-tests.txt?ref=b0633ac49bfbe2e0e51ef0506f626d2dbf7c1705",
"patch":"@@ -9,12 +9,12 @@\n /nova/latest/architecture.html 301 /nova/latest/user/architecture.html\n /nova/latest/block_device_mapping.html 301 /nova/latest/user/block-device-mapping.html\n /nova/latest/blueprints.html 301 /nova/latest/contributor/blueprints.html\n-/nova/latest/cells.html 301 /nova/latest/user/cells.html\n+/nova/latest/cells.html 301 /nova/latest/admin/cells.html\n /nova/latest/code-review.html 301 /nova/latest/contributor/code-review.html\n /nova/latest/conductor.html 301 /nova/latest/user/conductor.html\n /nova/latest/development.environment.html 301 /nova/latest/contributor/development-environment.html\n /nova/latest/devref/api.html 301 /nova/latest/contributor/api.html\n-/nova/latest/devref/cells.html 301 /nova/latest/user/cells.html\n+/nova/latest/devref/cells.html 301 /nova/latest/admin/cells.html\n /nova/latest/devref/filter_scheduler.html 301 /nova/latest/admin/scheduling.html\n # catch all, if we hit something in devref assume it moved to\n # reference unless we have already triggered a hit above.\n@@ -64,7 +64,9 @@\n /nova/latest/threading.html 301 /nova/latest/reference/threading.html\n /nova/latest/upgrade.html 301 /nova/latest/admin/upgrades.html\n /nova/latest/user/aggregates.html 301 /nova/latest/admin/aggregates.html\n-/nova/latest/user/cellsv2_layout.html 301 /nova/latest/user/cellsv2-layout.html\n+/nova/latest/user/cells.html 301 /nova/latest/admin/cells.html\n+/nova/latest/user/cellsv2_layout.html 301 /nova/latest/admin/cells.html\n+/nova/latest/user/cellsv2-layout.html 301 /nova/latest/admin/cells.html\n /nova/latest/user/config-drive.html 301 /nova/latest/user/metadata.html\n /nova/latest/user/filter-scheduler.html 301 /nova/latest/admin/scheduling.html\n /nova/latest/user/metadata-service.html 301 /nova/latest/user/metadata.html"
}
]
},
{
"commit_sha":"ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"commit_node_id":"C_kwDOAAwOD9oAKGFiNDlmOTdiMmMwODI5NDIzNGM3YmZkM2RlZGI3NTc4MGNhNTE5ZTY",
"commit_html_url":"https://github.com/openstack/nova/commit/ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"commit_date":"2021-09-30T19:36:47Z",
"files":[
{
"sha":"294ccaebbecb0b5e8a9292c691efc41280e14739",
"filename":"nova/network/neutron.py",
"status":"modified",
"additions":18,
"deletions":6,
"changes":24,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/network/neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/network/neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/neutron.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -667,7 +667,8 @@ def _unbind_ports(self, context, ports,\n             # for the physical device but don't want to overwrite the other\n             # information in the binding profile.\n             for profile_key in ('pci_vendor_info', 'pci_slot',\n-                                constants.ALLOCATION, 'arq_uuid'):\n+                                constants.ALLOCATION, 'arq_uuid',\n+                                'physical_network', 'card_serial_number'):\n                 if profile_key in port_profile:\n                     del port_profile[profile_key]\n             port_req_body['port'][constants.BINDING_PROFILE] = port_profile\n@@ -1506,11 +1507,22 @@ def delete_port_binding(self, context, port_id, host):\n     def _get_pci_device_profile(self, pci_dev):\n         dev_spec = self.pci_whitelist.get_devspec(pci_dev)\n         if dev_spec:\n-            return {'pci_vendor_info': \"%s:%s\" %\n-                        (pci_dev.vendor_id, pci_dev.product_id),\n-                    'pci_slot': pci_dev.address,\n-                    'physical_network':\n-                        dev_spec.get_tags().get('physical_network')}\n+            dev_profile = {\n+                'pci_vendor_info': \"%s:%s\"\n+                % (pci_dev.vendor_id, pci_dev.product_id),\n+                'pci_slot': pci_dev.address,\n+                'physical_network': dev_spec.get_tags().get(\n+                    'physical_network'\n+                ),\n+            }\n+            if pci_dev.dev_type == obj_fields.PciDeviceType.SRIOV_VF:\n+                card_serial_number = pci_dev.card_serial_number\n+                if card_serial_number:\n+                    dev_profile.update({\n+                        'card_serial_number': card_serial_number\n+                    })\n+            return dev_profile\n+\n         raise exception.PciDeviceNotFound(node_id=pci_dev.compute_node_id,\n                                           address=pci_dev.address)\n "
},
{
"sha":"275d5da3564aa0540829c3a6e7439d1655c49886",
"filename":"nova/objects/pci_device.py",
"status":"modified",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/objects/pci_device.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/objects/pci_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/pci_device.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -511,6 +511,12 @@ def free(self, instance=None):\n     def is_available(self):\n         return self.status == fields.PciDeviceStatus.AVAILABLE\n \n+    @property\n+    def card_serial_number(self):\n+        caps_json = self.extra_info.get('capabilities', \"{}\")\n+        caps = jsonutils.loads(caps_json)\n+        return caps.get('vpd', {}).get('card_serial_number')\n+\n \n @base.NovaObjectRegistry.register\n class PciDeviceList(base.ObjectListBase, base.NovaObject):"
},
{
"sha":"43fcc8c950aee71c2ea14b7734ceb43543af31c1",
"filename":"nova/tests/fixtures/libvirt_data.py",
"status":"modified",
"additions":162,
"deletions":0,
"changes":162,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/fixtures/libvirt_data.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/fixtures/libvirt_data.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/libvirt_data.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -2002,6 +2002,168 @@ def fake_kvm_guest():\n       </capability>\n     </device>\n     \"\"\",\n+    # A PF with the VPD capability.\n+    \"pci_0000_82_00_0\": \"\"\"\n+    <device>\n+      <name>pci_0000_82_00_0</name>\n+      <path>/sys/devices/pci0000:80/0000:80:03.0/0000:82:00.0</path>\n+      <parent>pci_0000_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>0</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>0</function>\n+        <product id='0xa2d6'>MT42822 BlueField-2 integrated ConnectX-6 Dx network controller</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='virt_functions' maxCount='8'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x3'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x4'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x5'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x6'/>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x7'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x0'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x1'/>\n+          <address domain='0x0000' bus='0x82' slot='0x01' function='0x2'/>\n+        </capability>\n+        <capability type='vpd'>\n+          <name>BlueField-2 DPU 25GbE Dual-Port SFP56, Crypto Enabled, 16GB on-board DDR, 1GbE OOB management, Tall Bracket</name>\n+          <fields access='readonly'>\n+            <change_level>B1</change_level>\n+            <manufacture_id>foobar</manufacture_id>\n+            <part_number>MBF2H332A-AEEOT</part_number>\n+            <serial_number>MT2113X00000</serial_number>\n+            <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+            <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+            <vendor_field index='3'>3c53d07eec484d8aab34dabd24fe575aa</vendor_field>\n+            <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+          </fields>\n+          <fields access='readwrite'>\n+            <asset_tag>fooasset</asset_tag>\n+            <vendor_field index='0'>vendorfield0</vendor_field>\n+            <vendor_field index='2'>vendorfield2</vendor_field>\n+            <vendor_field index='A'>vendorfieldA</vendor_field>\n+            <system_field index='B'>systemfieldB</system_field>\n+            <system_field index='0'>systemfield0</system_field>\n+          </fields>\n+        </capability>\n+        <iommuGroup number='65'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x0'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' speed='8' width='8'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n+    # A VF without the VPD capability with a PF that has a VPD capability.\n+    \"pci_0000_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0000_82_00_3</name>\n+      <path>/sys/devices/pci0000:80/0000:80:03.0/0000:82:00.3</path>\n+      <parent>pci_0000_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>0</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0000' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",\n+    # A VF with the VPD capability but without a parent defined in test data\n+    # so that the VPD cap is extracted from the VF directly.\n+    \"pci_0001_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0001_82_00_3</name>\n+      <path>/sys/devices/pci0001:80/0001:80:03.0/0001:82:00.3</path>\n+      <parent>pci_0001_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>1</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0001' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <capability type='vpd'>\n+          <name>BlueField-2 DPU 25GbE Dual-Port SFP56, Crypto Enabled, 16GB on-board DDR, 1GbE OOB management, Tall Bracket</name>\n+          <fields access='readonly'>\n+            <change_level>B1</change_level>\n+            <part_number>MBF2H332A-AEEOT</part_number>\n+            <serial_number>MT2113XBEEF0</serial_number>\n+            <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+            <vendor_field index='3'>9644e3586190eb118000b8cef671bf3e</vendor_field>\n+            <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+            <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+          </fields>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0001' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n+    # A VF without the VPD capability and without a parent PF defined\n+    # in the test data.\n+    \"pci_0002_82_00_3\": \"\"\"\n+    <device>\n+      <name>pci_0002_82_00_3</name>\n+      <path>/sys/devices/pci0002:80/0002:80:03.0/0002:82:00.3</path>\n+      <parent>pci_0002_80_03_0</parent>\n+      <driver>\n+        <name>mlx5_core</name>\n+      </driver>\n+      <capability type='pci'>\n+        <class>0x020000</class>\n+        <domain>2</domain>\n+        <bus>130</bus>\n+        <slot>0</slot>\n+        <function>3</function>\n+        <product id='0x101e'>ConnectX Family mlx5Gen Virtual Function</product>\n+        <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+        <capability type='phys_function'>\n+          <address domain='0x0002' bus='0x82' slot='0x00' function='0x0'/>\n+        </capability>\n+        <iommuGroup number='99'>\n+          <address domain='0x0002' bus='0x82' slot='0x00' function='0x3'/>\n+        </iommuGroup>\n+        <numa node='1'/>\n+        <pci-express>\n+          <link validity='cap' port='0' speed='16' width='8'/>\n+          <link validity='sta' width='0'/>\n+        </pci-express>\n+      </capability>\n+    </device>\"\"\",  # noqa:E501\n }\n \n _fake_NodeDevXml_parents = {"
},
{
"sha":"a06549b609c6ba5ccce566bb732f6acdf52b59e8",
"filename":"nova/tests/unit/network/test_neutron.py",
"status":"modified",
"additions":63,
"deletions":14,
"changes":77,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/network/test_neutron.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/network/test_neutron.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_neutron.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -39,6 +39,7 @@\n from nova.network import model\n from nova.network import neutron as neutronapi\n from nova import objects\n+from nova.objects import fields as obj_fields\n from nova.objects import network_request as net_req_obj\n from nova.objects import virtual_interface as obj_vif\n from nova.pci import manager as pci_manager\n@@ -4494,17 +4495,21 @@ def test_update_port_bindings_for_instance_with_pci(self,\n         instance = fake_instance.fake_instance_obj(self.context)\n         instance.migration_context = objects.MigrationContext()\n         instance.migration_context.old_pci_devices = objects.PciDeviceList(\n-            objects=[objects.PciDevice(vendor_id='1377',\n-                                       product_id='0047',\n-                                       address='0000:0a:00.1',\n-                                       compute_node_id=1,\n-                                       request_id='1234567890')])\n+            objects=[objects.PciDevice(\n+                vendor_id='1377',\n+                product_id='0047',\n+                address='0000:0a:00.1',\n+                compute_node_id=1,\n+                request_id='1234567890',\n+                dev_type=obj_fields.PciDeviceType.SRIOV_VF)])\n         instance.migration_context.new_pci_devices = objects.PciDeviceList(\n-            objects=[objects.PciDevice(vendor_id='1377',\n-                                       product_id='0047',\n-                                       address='0000:0b:00.1',\n-                                       compute_node_id=2,\n-                                       request_id='1234567890')])\n+            objects=[objects.PciDevice(\n+                vendor_id='1377',\n+                product_id='0047',\n+                address='0000:0b:00.1',\n+                compute_node_id=2,\n+                request_id='1234567890',\n+                dev_type=obj_fields.PciDeviceType.SRIOV_VF)])\n         instance.pci_devices = instance.migration_context.old_pci_devices\n \n         # Validate that non-direct port aren't updated (fake-port-2).\n@@ -5928,14 +5933,14 @@ def test_unbind_ports_reset_binding_profile(self, mock_show):\n             'id': uuids.port,\n             'binding:profile': {'pci_vendor_info': '1377:0047',\n                                 'pci_slot': '0000:0a:00.1',\n+                                'card_serial_number': 'MT2113X00000',\n                                 'physical_network': 'physnet1',\n                                 'capabilities': ['switchdev']}\n             }\n         self.api._unbind_ports(self.context, ports, neutron, port_client)\n         port_req_body = {'port': {'binding:host_id': None,\n                                   'binding:profile':\n-                                    {'physical_network': 'physnet1',\n-                                     'capabilities': ['switchdev']},\n+                                    {'capabilities': ['switchdev']},\n                                   'device_id': '',\n                                   'device_owner': ''}\n                         }\n@@ -7402,9 +7407,12 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'card_serial_number': None,\n+                   'dev_type': 'TEST_TYPE',\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n-                               ['vendor_id', 'product_id', 'address'])\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n@@ -7422,6 +7430,43 @@ def test_populate_neutron_extension_values_binding_sriov(self,\n                          port_req_body['port'][\n                              constants.BINDING_PROFILE])\n \n+    @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec')\n+    @mock.patch.object(pci_manager, 'get_instance_pci_devs')\n+    def test_populate_neutron_extension_values_binding_sriov_card_serial(\n+        self, mock_get_instance_pci_devs, mock_get_pci_device_devspec):\n+        host_id = 'my_host_id'\n+        instance = {'host': host_id}\n+        port_req_body = {'port': {}}\n+        pci_req_id = 'my_req_id'\n+        pci_dev = {'vendor_id': 'a2d6',\n+                   'product_id': '15b3',\n+                   'address': '0000:82:00.1',\n+                   'card_serial_number': 'MT2113X00000',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n+                  }\n+        PciDevice = collections.namedtuple('PciDevice',\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n+        mydev = PciDevice(**pci_dev)\n+        profile = {'pci_vendor_info': 'a2d6:15b3',\n+                   'pci_slot': '0000:82:00.1',\n+                   'physical_network': 'physnet1',\n+                   # card_serial_number is a property of the object obtained\n+                   # from extra_info.\n+                   'card_serial_number': 'MT2113X00000',\n+                  }\n+\n+        mock_get_instance_pci_devs.return_value = [mydev]\n+        devspec = mock.Mock()\n+        devspec.get_tags.return_value = {'physical_network': 'physnet1'}\n+        mock_get_pci_device_devspec.return_value = devspec\n+        self.api._populate_neutron_binding_profile(\n+            instance, pci_req_id, port_req_body, None)\n+\n+        self.assertEqual(profile,\n+                         port_req_body['port'][\n+                             constants.BINDING_PROFILE])\n+\n     def test_populate_neutron_extension_values_binding_arq(self):\n         host_id = 'my_host_id'\n         instance = {'host': host_id}\n@@ -7474,9 +7519,12 @@ def test_populate_neutron_extension_values_binding_sriov_with_cap(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'card_serial_number': None,\n+                   'dev_type': 'TEST_TYPE',\n                   }\n         PciDevice = collections.namedtuple('PciDevice',\n-                               ['vendor_id', 'product_id', 'address'])\n+                               ['vendor_id', 'product_id', 'address',\n+                                'card_serial_number', 'dev_type'])\n         mydev = PciDevice(**pci_dev)\n         profile = {'pci_vendor_info': '1377:0047',\n                    'pci_slot': '0000:0a:00.1',\n@@ -7547,6 +7595,7 @@ def test_pci_parse_whitelist_called_once(self,\n         pci_dev = {'vendor_id': '1377',\n                    'product_id': '0047',\n                    'address': '0000:0a:00.1',\n+                   'dev_type': obj_fields.PciDeviceType.SRIOV_VF,\n                   }\n \n         whitelist = pci_whitelist.Whitelist(CONF.pci.passthrough_whitelist)"
},
{
"sha":"4087b89800923d89a2e5936b657aa0a0ca54288a",
"filename":"nova/tests/unit/objects/test_pci_device.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/objects/test_pci_device.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/objects/test_pci_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_pci_device.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -161,6 +161,16 @@ def test_pci_device_extra_info_with_dict(self):\n                               'vendor_id', 'numa_node', 'status', 'uuid',\n                               'extra_info', 'dev_type', 'parent_addr']))\n \n+    def test_pci_device_extra_info_card_serial_number(self):\n+        self.dev_dict = copy.copy(dev_dict)\n+        self.pci_device = pci_device.PciDevice.create(None, self.dev_dict)\n+        self.assertIsNone(self.pci_device.card_serial_number)\n+\n+        self.dev_dict = copy.copy(dev_dict)\n+        self.dev_dict['capabilities'] = {'vpd': {'card_serial_number': '42'}}\n+        self.pci_device = pci_device.PciDevice.create(None, self.dev_dict)\n+        self.assertEqual(self.pci_device.card_serial_number, '42')\n+\n     def test_update_device(self):\n         self.pci_device = pci_device.PciDevice.create(None, dev_dict)\n         self.pci_device.obj_reset_changes()"
},
{
"sha":"396edfd0248292385b9ed8c19b166a4bb085da60",
"filename":"nova/tests/unit/virt/libvirt/test_config.py",
"status":"modified",
"additions":80,
"deletions":0,
"changes":80,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/virt/libvirt/test_config.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/virt/libvirt/test_config.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_config.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -3273,6 +3273,86 @@ def test_config_device_pci_mdev_capable(self):\n             'name': 'GRID M60-0B',\n             'type': 'nvidia-11'}], obj.mdev_capability[0].mdev_types)\n \n+    def test_config_device_pci_vpd(self):\n+        xmlin = \"\"\"\n+    <capability type='pci'>\n+      <class>0x020000</class>\n+      <domain>0</domain>\n+      <bus>130</bus>\n+      <slot>0</slot>\n+      <function>1</function>\n+      <product id='0xa2d6'>MT42822 BlueField-2</product>\n+      <vendor id='0x15b3'>Mellanox Technologies</vendor>\n+      <capability type='virt_functions' maxCount='16'/>\n+      <capability type='vpd'>\n+        <name>BlueField-2 DPU 25GbE</name>\n+        <fields access='readonly'>\n+          <change_level>B1</change_level>\n+          <manufacture_id>foobar</manufacture_id>\n+          <part_number>MBF2H332A-AEEOT</part_number>\n+          <serial_number>MT2113X00000</serial_number>\n+          <vendor_field index='0'>PCIeGen4 x8</vendor_field>\n+          <vendor_field index='2'>MBF2H332A-AEEOT</vendor_field>\n+          <vendor_field index='3'>3c53d07eec484d8aab34dabd24fe575aa</vendor_field>\n+          <vendor_field index='A'>MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A</vendor_field>\n+        </fields>\n+        <fields access='readwrite'>\n+          <asset_tag>fooasset</asset_tag>\n+          <vendor_field index='0'>vendorfield0</vendor_field>\n+          <vendor_field index='2'>vendorfield2</vendor_field>\n+          <vendor_field index='A'>vendorfieldA</vendor_field>\n+          <system_field index='B'>systemfieldB</system_field>\n+          <system_field index='0'>systemfield0</system_field>\n+        </fields>\n+      </capability>\n+      <iommuGroup number='66'>\n+        <address domain='0x0000' bus='0x82' slot='0x00' function='0x1'/>\n+      </iommuGroup>\n+      <numa node='1'/>\n+      <pci-express>\n+        <link validity='cap' port='0' speed='16' width='8'/>\n+        <link validity='sta' speed='8' width='8'/>\n+      </pci-express>\n+    </capability>\"\"\"  # noqa: E501\n+        obj = config.LibvirtConfigNodeDevicePciCap()\n+        obj.parse_str(xmlin)\n+\n+        # Asserting common PCI attribute parsing.\n+        self.assertEqual(0, obj.domain)\n+        self.assertEqual(130, obj.bus)\n+        self.assertEqual(0, obj.slot)\n+        self.assertEqual(1, obj.function)\n+        # Asserting vpd capability parsing.\n+        self.assertEqual(\"MT42822 BlueField-2\", obj.product)\n+        self.assertEqual(0xA2D6, obj.product_id)\n+        self.assertEqual(\"Mellanox Technologies\", obj.vendor)\n+        self.assertEqual(0x15B3, obj.vendor_id)\n+        self.assertEqual(obj.numa_node, 1)\n+        self.assertIsInstance(obj.vpd_capability,\n+                              config.LibvirtConfigNodeDeviceVpdCap)\n+        self.assertEqual(obj.vpd_capability.card_name, 'BlueField-2 DPU 25GbE')\n+\n+        self.assertEqual(obj.vpd_capability.change_level, 'B1')\n+        self.assertEqual(obj.vpd_capability.manufacture_id, 'foobar')\n+        self.assertEqual(obj.vpd_capability.part_number, 'MBF2H332A-AEEOT')\n+        self.assertEqual(obj.vpd_capability.card_serial_number, 'MT2113X00000')\n+        self.assertEqual(obj.vpd_capability.asset_tag, 'fooasset')\n+        self.assertEqual(obj.vpd_capability.ro_vendor_fields, {\n+            '0': 'PCIeGen4 x8',\n+            '2': 'MBF2H332A-AEEOT',\n+            '3': '3c53d07eec484d8aab34dabd24fe575aa',\n+            'A': 'MLX:MN=MLNX:CSKU=V2:UUID=V3:PCI=V0:MODL=BF2H332A',\n+        })\n+        self.assertEqual(obj.vpd_capability.rw_vendor_fields, {\n+            '0': 'vendorfield0',\n+            '2': 'vendorfield2',\n+            'A': 'vendorfieldA',\n+        })\n+        self.assertEqual(obj.vpd_capability.rw_system_fields, {\n+            '0': 'systemfield0',\n+            'B': 'systemfieldB',\n+        })\n+\n \n class LibvirtConfigNodeDevicePciSubFunctionCap(LibvirtConfigBaseTest):\n "
},
{
"sha":"a33ffef7024bb9a1ffad0063a74a98a7680e5989",
"filename":"nova/tests/unit/virt/libvirt/test_host.py",
"status":"modified",
"additions":87,
"deletions":8,
"changes":95,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/virt/libvirt/test_host.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/tests/unit/virt/libvirt/test_host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_host.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -1119,7 +1119,7 @@ def test_get_pcidev_info_non_nic(self, mock_get_ifname):\n         pci_dev = fakelibvirt.NodeDevice(\n             self.host._get_connection(),\n             xml=fake_libvirt_data._fake_NodeDevXml[dev_name])\n-        actual_vf = self.host._get_pcidev_info(dev_name, pci_dev, [], [])\n+        actual_vf = self.host._get_pcidev_info(dev_name, pci_dev, [], [], [])\n         expect_vf = {\n             \"dev_id\": dev_name, \"address\": \"0000:04:11.7\",\n             \"product_id\": '1520', \"numa_node\": 0,\n@@ -1135,7 +1135,9 @@ def test_get_pcidev_info_non_nic(self, mock_get_ifname):\n     def test_get_pcidev_info(self, mock_get_ifname):\n         devs = {\n             \"pci_0000_04_00_3\", \"pci_0000_04_10_7\", \"pci_0000_04_11_7\",\n-            \"pci_0000_04_00_1\", \"pci_0000_03_00_0\", \"pci_0000_03_00_1\"\n+            \"pci_0000_04_00_1\", \"pci_0000_03_00_0\", \"pci_0000_03_00_1\",\n+            \"pci_0000_82_00_0\", \"pci_0000_82_00_3\", \"pci_0001_82_00_3\",\n+            \"pci_0002_82_00_3\",\n         }\n         node_devs = {}\n         for dev_name in devs:\n@@ -1150,10 +1152,12 @@ def test_get_pcidev_info(self, mock_get_ifname):\n                         xml=fake_libvirt_data._fake_NodeDevXml[child]))\n         net_devs = [\n             dev for dev in node_devs.values() if dev.name() not in devs]\n+        pci_devs = [\n+            dev for dev in node_devs.values() if dev.name() in devs]\n \n         name = \"pci_0000_04_00_3\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_00_3\",\n             \"address\": \"0000:04:00.3\",\n@@ -1167,7 +1171,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_10_7\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_10_7\",\n             \"address\": \"0000:04:10.7\",\n@@ -1186,7 +1190,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_11_7\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_11_7\",\n             \"address\": \"0000:04:11.7\",\n@@ -1205,7 +1209,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_04_00_1\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_04_00_1\",\n             \"address\": \"0000:04:00.1\",\n@@ -1219,7 +1223,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_03_00_0\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_03_00_0\",\n             \"address\": \"0000:03:00.0\",\n@@ -1233,7 +1237,7 @@ def test_get_pcidev_info(self, mock_get_ifname):\n \n         name = \"pci_0000_03_00_1\"\n         actual_vf = self.host._get_pcidev_info(\n-            name, node_devs[name], net_devs, [])\n+            name, node_devs[name], net_devs, [], [])\n         expect_vf = {\n             \"dev_id\": \"pci_0000_03_00_1\",\n             \"address\": \"0000:03:00.1\",\n@@ -1245,6 +1249,81 @@ def test_get_pcidev_info(self, mock_get_ifname):\n             }\n         self.assertEqual(expect_vf, actual_vf)\n \n+        # Parent PF with a VPD cap.\n+        name = \"pci_0000_82_00_0\"\n+        actual_pf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_pf = {\n+            \"dev_id\": \"pci_0000_82_00_0\",\n+            \"address\": \"0000:82:00.0\",\n+            \"product_id\": \"a2d6\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_a2d6\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_PF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        self.assertEqual(expect_pf, actual_pf)\n+\n+        # A VF without a VPD cap with a parent PF that has a VPD cap.\n+        name = \"pci_0000_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0000_82_00_3\",\n+            \"address\": \"0000:82:00.3\",\n+            \"parent_addr\": \"0000:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113X00000\"}},\n+        }\n+        self.assertEqual(expect_vf, actual_vf)\n+\n+        # A VF with a VPD cap without a test parent dev (used to check the\n+        # VPD code path when a VF's own VPD capability is used).\n+        name = \"pci_0001_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0001_82_00_3\",\n+            \"address\": \"0001:82:00.3\",\n+            \"parent_addr\": \"0001:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+            \"capabilities\": {\n+                # Should be obtained from the parent PF in this case.\n+                \"vpd\": {\"card_serial_number\": \"MT2113XBEEF0\"}},\n+        }\n+\n+        # A VF without a VPD cap and without a test parent dev\n+        # (used to check the code path where a VF VPD capability is\n+        # checked but is not present and a parent PF info is not available).\n+        name = \"pci_0002_82_00_3\"\n+        actual_vf = self.host._get_pcidev_info(\n+            name, node_devs[name], net_devs, [], pci_devs)\n+        expect_vf = {\n+            \"dev_id\": \"pci_0002_82_00_3\",\n+            \"address\": \"0002:82:00.3\",\n+            \"parent_addr\": \"0002:82:00.0\",\n+            \"product_id\": \"101e\",\n+            \"numa_node\": 1,\n+            \"vendor_id\": \"15b3\",\n+            \"label\": \"label_15b3_101e\",\n+            \"dev_type\": obj_fields.PciDeviceType.SRIOV_VF,\n+        }\n+\n+        self.assertEqual(expect_vf, actual_vf)\n+\n     def test_list_pci_devices(self):\n         with mock.patch.object(self.host, \"_list_devices\") as mock_listDevices:\n             self.host.list_pci_devices(8)"
},
{
"sha":"b1179b3d1fdf7c12eb7bf80780b95fb494ec98e1",
"filename":"nova/virt/libvirt/config.py",
"status":"modified",
"additions":101,
"deletions":0,
"changes":101,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/config.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/config.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/config.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -3130,6 +3130,7 @@ def __init__(self, **kwargs):\n         self.pci_capability = None\n         self.mdev_information = None\n         self.vdpa_capability = None\n+        self.vpd_capability = None\n \n     def parse_dom(self, xmldoc):\n         super(LibvirtConfigNodeDevice, self).parse_dom(xmldoc)\n@@ -3183,6 +3184,7 @@ def __init__(self, **kwargs):\n         self.numa_node = None\n         self.fun_capability = []\n         self.mdev_capability = []\n+        self.vpd_capability = None\n         self.interface = None\n         self.address = None\n         self.link_state = None\n@@ -3225,6 +3227,10 @@ def parse_dom(self, xmldoc):\n                 mdevcap = LibvirtConfigNodeDeviceMdevCapableSubFunctionCap()\n                 mdevcap.parse_dom(c)\n                 self.mdev_capability.append(mdevcap)\n+            elif c.tag == \"capability\" and c.get('type') in ('vpd',):\n+                vpdcap = LibvirtConfigNodeDeviceVpdCap()\n+                vpdcap.parse_dom(c)\n+                self.vpd_capability = vpdcap\n \n     def pci_address(self):\n         return \"%04x:%02x:%02x.%01x\" % (\n@@ -3288,6 +3294,101 @@ def parse_dom(self, xmldoc):\n                 self.iommu_group = int(c.get('number'))\n \n \n+class LibvirtConfigNodeDeviceVpdCap(LibvirtConfigObject):\n+\n+    def __init__(self, **kwargs):\n+        super().__init__(\n+            root_name=\"capability\", **kwargs)\n+        self._card_name = None\n+        self._change_level = None\n+        self._manufacture_id = None\n+        self._part_number = None\n+        self._serial_number = None\n+        self._asset_tag = None\n+        self._ro_vendor_fields = {}\n+        self._rw_vendor_fields = {}\n+        self._rw_system_fields = {}\n+\n+    @staticmethod\n+    def _process_custom_field(fields_dict, field_element):\n+        index = field_element.get('index')\n+        if index:\n+            fields_dict[index] = field_element.text\n+\n+    def _parse_ro_fields(self, fields_element):\n+        for e in fields_element:\n+            if e.tag == 'change_level':\n+                self._change_level = e.text\n+            elif e.tag == 'manufacture_id':\n+                self._manufacture_id = e.text\n+            elif e.tag == 'part_number':\n+                self._part_number = e.text\n+            elif e.tag == 'serial_number':\n+                self._serial_number = e.text\n+            elif e.tag == 'vendor_field':\n+                self._process_custom_field(self._ro_vendor_fields, e)\n+\n+    def _parse_rw_fields(self, fields_element):\n+        for e in fields_element:\n+            if e.tag == 'asset_tag':\n+                self._asset_tag = e.text\n+            elif e.tag == 'vendor_field':\n+                self._process_custom_field(self._rw_vendor_fields, e)\n+            elif e.tag == 'system_field':\n+                self._process_custom_field(self._rw_system_fields, e)\n+\n+    def parse_dom(self, xmldoc):\n+        super(LibvirtConfigNodeDeviceVpdCap, self).parse_dom(xmldoc)\n+        for c in xmldoc:\n+            if c.tag == \"name\":\n+                self._card_name = c.text\n+            if c.tag == \"fields\":\n+                access = c.get('access')\n+                if access:\n+                    if access == 'readonly':\n+                        self._parse_ro_fields(c)\n+                    elif access == 'readwrite':\n+                        self._parse_rw_fields(c)\n+                    else:\n+                        continue\n+\n+    @property\n+    def card_name(self):\n+        return self._card_name\n+\n+    @property\n+    def change_level(self):\n+        return self._change_level\n+\n+    @property\n+    def manufacture_id(self):\n+        return self._manufacture_id\n+\n+    @property\n+    def part_number(self):\n+        return self._part_number\n+\n+    @property\n+    def card_serial_number(self):\n+        return self._serial_number\n+\n+    @property\n+    def asset_tag(self):\n+        return self._asset_tag\n+\n+    @property\n+    def ro_vendor_fields(self):\n+        return self._ro_vendor_fields\n+\n+    @property\n+    def rw_vendor_fields(self):\n+        return self._rw_vendor_fields\n+\n+    @property\n+    def rw_system_fields(self):\n+        return self._rw_system_fields\n+\n+\n class LibvirtConfigGuestRng(LibvirtConfigGuestDevice):\n \n     def __init__(self, **kwargs):"
},
{
"sha":"c8fd7e22ed3829be8238e5e20586fc68dbcb2d8e",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":8,
"deletions":2,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -7742,9 +7742,15 @@ def _get_pci_passthrough_devices(self):\n         vdpa_devs = [\n             dev for dev in devices.values() if \"vdpa\" in dev.listCaps()\n         ]\n+        pci_devs = {\n+            name: dev for name, dev in devices.items()\n+                    if \"pci\" in dev.listCaps()}\n         pci_info = [\n-            self._host._get_pcidev_info(name, dev, net_devs, vdpa_devs)\n-            for name, dev in devices.items() if \"pci\" in dev.listCaps()\n+            self._host._get_pcidev_info(\n+                name, dev, net_devs,\n+                vdpa_devs, list(pci_devs.values())\n+            )\n+            for name, dev in pci_devs.items()\n         ]\n         return jsonutils.dumps(pci_info)\n "
},
{
"sha":"80663ab1dc43be5ea3f30a0f93c4c93dc31c4715",
"filename":"nova/virt/libvirt/host.py",
"status":"modified",
"additions":87,
"deletions":1,
"changes":88,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/host.py",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/nova/virt/libvirt/host.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/host.py?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -1229,12 +1229,51 @@ def _get_pcinet_info(\n         cfgdev.parse_str(xmlstr)\n         return cfgdev.pci_capability.features\n \n+    def _get_vf_parent_pci_vpd_info(\n+        self,\n+        vf_device: 'libvirt.virNodeDevice',\n+        parent_pf_name: str,\n+        candidate_devs: ty.List['libvirt.virNodeDevice']\n+    ) -> ty.Optional[vconfig.LibvirtConfigNodeDeviceVpdCap]:\n+        \"\"\"Returns PCI VPD info of a parent device of a PCI VF.\n+\n+        :param vf_device: a VF device object to use for lookup.\n+        :param str parent_pf_name: parent PF name formatted as pci_dddd_bb_ss_f\n+        :param candidate_devs: devices that could be parent devs for the VF.\n+        :returns: A VPD capability object of a parent device.\n+        \"\"\"\n+        parent_dev = next(\n+            (dev for dev in candidate_devs if dev.name() == parent_pf_name),\n+            None\n+        )\n+        if parent_dev is None:\n+            return None\n+\n+        xmlstr = parent_dev.XMLDesc(0)\n+        cfgdev = vconfig.LibvirtConfigNodeDevice()\n+        cfgdev.parse_str(xmlstr)\n+        return cfgdev.pci_capability.vpd_capability\n+\n+    @staticmethod\n+    def _get_vpd_card_serial_number(\n+        dev: 'libvirt.virNodeDevice',\n+    ) -> ty.Optional[ty.List[str]]:\n+        \"\"\"Returns a card serial number stored in PCI VPD (if present).\"\"\"\n+        xmlstr = dev.XMLDesc(0)\n+        cfgdev = vconfig.LibvirtConfigNodeDevice()\n+        cfgdev.parse_str(xmlstr)\n+        vpd_cap = cfgdev.pci_capability.vpd_capability\n+        if not vpd_cap:\n+            return None\n+        return vpd_cap.card_serial_number\n+\n     def _get_pcidev_info(\n         self,\n         devname: str,\n         dev: 'libvirt.virNodeDevice',\n         net_devs: ty.List['libvirt.virNodeDevice'],\n         vdpa_devs: ty.List['libvirt.virNodeDevice'],\n+        pci_devs: ty.List['libvirt.virNodeDevice'],\n     ) -> ty.Dict[str, ty.Union[str, dict]]:\n         \"\"\"Returns a dict of PCI device.\"\"\"\n \n@@ -1314,6 +1353,52 @@ def _get_device_capabilities(\n                 pcinet_info = self._get_pcinet_info(device, net_devs)\n                 if pcinet_info:\n                     return {'capabilities': {'network': pcinet_info}}\n+\n+            return caps\n+\n+        def _get_vpd_details(\n+            device_dict: dict,\n+            device: 'libvirt.virNodeDevice',\n+            pci_devs: ty.List['libvirt.virNodeDevice']\n+        ) -> ty.Dict[str, ty.Dict[str, ty.Any]]:\n+            \"\"\"Get information from PCI VPD (if present).\n+\n+            PCI/PCIe devices may include the optional VPD capability. It may\n+            contain useful information such as the unique serial number\n+            uniquely assigned at a factory.\n+\n+            If a device is a VF and it does not contain the VPD capability,\n+            a parent device's VPD is used (if present) as a fallback to\n+            retrieve the unique add-in card number. Whether a VF exposes\n+            the VPD capability or not may be controlled via a vendor-specific\n+            firmware setting.\n+            \"\"\"\n+            caps: ty.Dict[str, ty.Dict[str, ty.Any]] = {}\n+            # At the time of writing only the serial number had a clear\n+            # use-case. However, the set of fields may be extended.\n+            card_serial_number = self._get_vpd_card_serial_number(device)\n+\n+            if (not card_serial_number and\n+               device_dict.get('dev_type') == fields.PciDeviceType.SRIOV_VF\n+            ):\n+                # Format the address of a physical function to use underscores\n+                # since that's how Libvirt formats the <name> element content.\n+                pf_addr = device_dict.get('parent_addr')\n+                if not pf_addr:\n+                    LOG.warning(\"A VF device dict does not have a parent PF \"\n+                                \"address in it which is unexpected. Skipping \"\n+                                \"serial number retrieval\")\n+                    return caps\n+\n+                formatted_addr = pf_addr.replace('.', '_').replace(':', '_')\n+                vpd_cap = self._get_vf_parent_pci_vpd_info(\n+                    device, f'pci_{formatted_addr}', pci_devs)\n+                if vpd_cap is not None:\n+                    card_serial_number = vpd_cap.card_serial_number\n+\n+            if card_serial_number:\n+                caps = {'capabilities': {\n+                    'vpd': {\"card_serial_number\": card_serial_number}}}\n             return caps\n \n         xmlstr = dev.XMLDesc(0)\n@@ -1340,6 +1425,7 @@ def _get_device_capabilities(\n         device.update(\n             _get_device_type(cfgdev, address, dev, net_devs, vdpa_devs))\n         device.update(_get_device_capabilities(device, dev, net_devs))\n+        device.update(_get_vpd_details(device, dev, pci_devs))\n         return device\n \n     def get_vdpa_nodedev_by_address(\n@@ -1361,7 +1447,7 @@ def get_vdpa_nodedev_by_address(\n         vdpa_devs = [\n             dev for dev in devices.values() if \"vdpa\" in dev.listCaps()]\n         pci_info = [\n-            self._get_pcidev_info(name, dev, [], vdpa_devs) for name, dev\n+            self._get_pcidev_info(name, dev, [], vdpa_devs, []) for name, dev\n             in devices.items() if \"pci\" in dev.listCaps()]\n         parent_dev = next(\n             dev for dev in pci_info if dev['address'] == pci_address)"
},
{
"sha":"0ca3518351604a5e61847b8b64bb3dc7c7e79f99",
"filename":"releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"status":"added",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/ab49f97b2c08294234c7bfd3dedb75780ca519e6/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"raw_url":"https://github.com/openstack/nova/raw/ab49f97b2c08294234c7bfd3dedb75780ca519e6/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/pci-vpd-capability-0d8039629db4afb8.yaml?ref=ab49f97b2c08294234c7bfd3dedb75780ca519e6",
"patch":"@@ -0,0 +1,20 @@\n+---\n+features:\n+  - |\n+    Add VPD capability parsing support when a PCI VPD capability is exposed\n+    via node device XML in Libvirt. The XML data from Libvirt is parsed and\n+    formatted into PCI device JSON dict that is sent to Nova API and is stored\n+    in the extra_info column of a PciDevice.\n+\n+    The code gracefully handles the lack of the capability since it is optional\n+    or Libvirt may not support it in a particular release.\n+\n+    A serial number is extracted from PCI VPD of network devices (if present)\n+    and is sent to Neutron in port updates.\n+\n+    Libvirt supports parsing the VPD capability from PCI/PCIe devices and\n+    exposing it via nodedev XML as of 7.9.0.\n+\n+    - https://libvirt.org/news.html#v7-9-0-2021-11-01\n+    - https://libvirt.org/drvnodedev.html#VPDCap\n+"
}
]
},
{
"commit_sha":"e8feef747f128a4cc6033a09c9a1059110534950",
"commit_node_id":"C_kwDOAAwOD9oAKGU4ZmVlZjc0N2YxMjhhNGNjNjAzM2EwOWM5YTEwNTkxMTA1MzQ5NTA",
"commit_html_url":"https://github.com/openstack/nova/commit/e8feef747f128a4cc6033a09c9a1059110534950",
"commit_date":"2022-01-31T19:35:25Z",
"files":[
{
"sha":"0f94a3b75b2c4e097a6484940e603cb35c72fa8e",
"filename":"nova/virt/powervm/driver.py",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/e8feef747f128a4cc6033a09c9a1059110534950/nova/virt/powervm/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/e8feef747f128a4cc6033a09c9a1059110534950/nova/virt/powervm/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/powervm/driver.py?ref=e8feef747f128a4cc6033a09c9a1059110534950",
"patch":"@@ -103,6 +103,14 @@ def init_host(self, host):\n \n         Includes catching up with currently running VMs on the given host.\n         \"\"\"\n+        LOG.warning(\n+            'The powervm virt driver is deprecated and may be removed in a '\n+            'future release. The driver is not tested by the OpenStack '\n+            'project nor does it have clear maintainers and thus its quality'\n+            'can not be ensured. If you are using the driver in production '\n+            'please let us know the openstack-discuss mailing list or on IRC'\n+        )\n+\n         # Build the adapter. May need to attempt the connection multiple times\n         # in case the PowerVM management API service is starting.\n         # TODO(efried): Implement async compute service enable/disable like"
},
{
"sha":"a526c01c06d0749f0c17906755e1bb9603da2fc5",
"filename":"releasenotes/notes/deprecate-powervm-yoga-d368b43ba86eb830.yaml",
"status":"added",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/e8feef747f128a4cc6033a09c9a1059110534950/releasenotes/notes/deprecate-powervm-yoga-d368b43ba86eb830.yaml",
"raw_url":"https://github.com/openstack/nova/raw/e8feef747f128a4cc6033a09c9a1059110534950/releasenotes/notes/deprecate-powervm-yoga-d368b43ba86eb830.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/deprecate-powervm-yoga-d368b43ba86eb830.yaml?ref=e8feef747f128a4cc6033a09c9a1059110534950",
"patch":"@@ -0,0 +1,6 @@\n+---\n+deprecations:\n+  - |\n+    The powervm virt driver is deprecated and may be removed in a future\n+    release. The driver is not tested by the OpenStack project nor does it have\n+    clear maintainers and thus its quality can not be ensured."
}
]
},
{
"commit_sha":"55566b90aaf33a959e73e69cf9c75ff86bfba4b2",
"commit_node_id":"C_kwDOAAwOD9oAKDU1NTY2YjkwYWFmMzNhOTU5ZTczZTY5Y2Y5Yzc1ZmY4NmJmYmE0YjI",
"commit_html_url":"https://github.com/openstack/nova/commit/55566b90aaf33a959e73e69cf9c75ff86bfba4b2",
"commit_date":"2022-01-31T18:49:51Z",
"files":[
{
"sha":"74658ed1a905d39035082c0eb92682b2ed3b82b6",
"filename":".zuul.yaml",
"status":"modified",
"additions":62,
"deletions":0,
"changes":62,
"blob_url":"https://github.com/openstack/nova/blob/55566b90aaf33a959e73e69cf9c75ff86bfba4b2/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/55566b90aaf33a959e73e69cf9c75ff86bfba4b2/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=55566b90aaf33a959e73e69cf9c75ff86bfba4b2",
"patch":"@@ -121,6 +121,66 @@\n               block_migrate_cinder_iscsi: false\n     post-run: playbooks/nova-live-migration/post-run.yaml\n \n+- job:\n+    name: nova-ovs-hybrid-plug\n+    parent: tempest-multinode-full-py3\n+    description: |\n+      Run move operations, reboot, and evacuation (via the same post-run hook\n+      as the nova-live-migration job) tests with the OVS network backend and\n+      the \"iptables_hybrid\" securitygroup firewall driver, aka \"hybrid plug\".\n+      The external events interactions between Nova and Neutron in these\n+      situations has historically been fragile. This job exercises them.\n+    irrelevant-files: *nova-base-irrelevant-files\n+    vars:\n+      tox_envlist: all\n+      tempest_test_regex: (^tempest\\..*compute\\..*(migration|resize|reboot).*)\n+      devstack_localrc:\n+        Q_AGENT: openvswitch\n+        Q_ML2_TENANT_NETWORK_TYPE: vxlan\n+        Q_ML2_PLUGIN_MECHANISM_DRIVERS: openvswitch,linuxbridge\n+        ML2_L3_PLUGIN: router\n+      devstack_services:\n+        # Disable OVN services\n+        br-ex-tcpdump: false\n+        br-int-flows: false\n+        ovn-controller: false\n+        ovn-northd: false\n+        q-ovn-metadata-agent: false\n+        # Neutron services\n+        q-agt: true\n+        q-dhcp: true\n+        q-l3: true\n+        q-meta: true\n+      devstack_local_conf:\n+        post-config:\n+          \"/$NEUTRON_CORE_PLUGIN_CONF\":\n+            securitygroup:\n+              firewall_driver: iptables_hybrid\n+    group-vars:\n+      subnode:\n+        devstack_localrc:\n+          Q_AGENT: openvswitch\n+          Q_ML2_TENANT_NETWORK_TYPE: vxlan\n+          Q_ML2_PLUGIN_MECHANISM_DRIVERS: openvswitch,linuxbridge\n+          ML2_L3_PLUGIN: router\n+        devstack_services:\n+          # Disable OVN services\n+          br-ex-tcpdump: false\n+          br-int-flows: false\n+          ovn-controller: false\n+          ovn-northd: false\n+          ovs-vswitchd: false\n+          ovsdb-server: false\n+          q-ovn-metadata-agent: false\n+          # Neutron services\n+          q-agt: true\n+        devstack_local_conf:\n+          post-config:\n+            \"/$NEUTRON_CORE_PLUGIN_CONF\":\n+              securitygroup:\n+                firewall_driver: iptables_hybrid\n+    post-run: playbooks/nova-live-migration/post-run.yaml\n+\n - job:\n     name: nova-live-migration-ceph\n     parent: devstack-plugin-ceph-multinode-tempest-py3\n@@ -545,6 +605,8 @@\n         - nova-lvm\n         - nova-multi-cell\n         - nova-next\n+        - nova-ovs-hybrid-plug:\n+            voting: false\n         - nova-tox-validate-backport:\n             voting: false\n         - nova-tox-functional-centos8-py36"
}
]
},
{
"commit_sha":"9fe465427310f8215890d26bf169617653605e23",
"commit_node_id":"C_kwDOAAwOD9oAKDlmZTQ2NTQyNzMxMGY4MjE1ODkwZDI2YmYxNjk2MTc2NTM2MDVlMjM",
"commit_html_url":"https://github.com/openstack/nova/commit/9fe465427310f8215890d26bf169617653605e23",
"commit_date":"2022-01-31T12:56:57Z",
"files":[
{
"sha":"1d6d29b45f6063d69918aa0ffc16b59c7e8a9257",
"filename":"nova/api/openstack/compute/servers.py",
"status":"modified",
"additions":21,
"deletions":7,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/9fe465427310f8215890d26bf169617653605e23/nova/api/openstack/compute/servers.py",
"raw_url":"https://github.com/openstack/nova/raw/9fe465427310f8215890d26bf169617653605e23/nova/api/openstack/compute/servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/compute/servers.py?ref=9fe465427310f8215890d26bf169617653605e23",
"patch":"@@ -409,6 +409,7 @@ def _get_requested_networks(self, requested_networks):\n \n         networks = []\n         network_uuids = []\n+        port_uuids = []\n         for network in requested_networks:\n             request = objects.NetworkRequest()\n             try:\n@@ -417,18 +418,31 @@ def _get_requested_networks(self, requested_networks):\n                 # it will use one of the available IP address from the network\n                 request.address = network.get('fixed_ip', None)\n                 request.port_id = network.get('port', None)\n-\n                 request.tag = network.get('tag', None)\n \n                 if request.port_id:\n-                    request.network_id = None\n+                    if request.port_id in port_uuids:\n+                        msg = _(\n+                            \"Port ID '%(port)s' was specified twice: you \"\n+                            \"cannot attach a port multiple times.\"\n+                        ) % {\n+                            \"port\": request.port_id,\n+                        }\n+                        raise exc.HTTPBadRequest(explanation=msg)\n+\n                     if request.address is not None:\n-                        msg = _(\"Specified Fixed IP '%(addr)s' cannot be used \"\n-                                \"with port '%(port)s': the two cannot be \"\n-                                \"specified together.\") % {\n-                                    \"addr\": request.address,\n-                                    \"port\": request.port_id}\n+                        msg = _(\n+                            \"Specified Fixed IP '%(addr)s' cannot be used \"\n+                            \"with port '%(port)s': the two cannot be \"\n+                            \"specified together.\"\n+                        ) % {\n+                            \"addr\": request.address,\n+                            \"port\": request.port_id,\n+                        }\n                         raise exc.HTTPBadRequest(explanation=msg)\n+\n+                    request.network_id = None\n+                    port_uuids.append(request.port_id)\n                 else:\n                     request.network_id = network['uuid']\n                     self._validate_network_id("
},
{
"sha":"31739ed7ab20349dfcd8f3b624c389e0fccd8750",
"filename":"nova/tests/unit/api/openstack/compute/test_servers.py",
"status":"modified",
"additions":26,
"deletions":7,
"changes":33,
"blob_url":"https://github.com/openstack/nova/blob/9fe465427310f8215890d26bf169617653605e23/nova/tests/unit/api/openstack/compute/test_servers.py",
"raw_url":"https://github.com/openstack/nova/raw/9fe465427310f8215890d26bf169617653605e23/nova/tests/unit/api/openstack/compute/test_servers.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/api/openstack/compute/test_servers.py?ref=9fe465427310f8215890d26bf169617653605e23",
"patch":"@@ -389,17 +389,36 @@ def test_requested_networks_with_and_duplicate_networks(self):\n                           (network, None, None, None, None, None)],\n                           res.as_tuples())\n \n-    def test_requested_networks_enabled_conflict_on_fixed_ip(self):\n-        network = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa'\n+    def test_requested_networks_duplicate_ports(self):\n+        \"\"\"The same port can't be specified twice.\"\"\"\n+        port = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee'\n+        requested_networks = [{'port': port}, {'port': port}]\n+        exc = self.assertRaises(\n+            webob.exc.HTTPBadRequest,\n+            self.controller._get_requested_networks,\n+            requested_networks,\n+        )\n+        self.assertIn(\n+            \"Port ID 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee' was specified \"\n+            \"twice\",\n+            str(exc),\n+        )\n+\n+    def test_requested_networks_conflict_on_fixed_ip(self):\n+        \"\"\"A fixed IP can't be specified at the same as a port ID.\"\"\"\n         port = 'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee'\n         addr = '10.0.0.1'\n-        requested_networks = [{'uuid': network,\n-                               'fixed_ip': addr,\n-                               'port': port}]\n-        self.assertRaises(\n+        requested_networks = [{'fixed_ip': addr, 'port': port}]\n+        exc = self.assertRaises(\n             webob.exc.HTTPBadRequest,\n             self.controller._get_requested_networks,\n-            requested_networks)\n+            requested_networks,\n+        )\n+        self.assertIn(\n+            \"Specified Fixed IP '10.0.0.1' cannot be used with port \"\n+            \"'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee'\",\n+            str(exc),\n+        )\n \n     def test_requested_networks_api_enabled_with_v2_subclass(self):\n         network = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa'"
},
{
"sha":"2a9a707bcac4ee64e070d06487b2d15a36d1ad7c",
"filename":"releasenotes/notes/bug-1821088-reject-duplicate-port-ids-a38739d67d5d7c5d.yaml",
"status":"added",
"additions":7,
"deletions":0,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/9fe465427310f8215890d26bf169617653605e23/releasenotes/notes/bug-1821088-reject-duplicate-port-ids-a38739d67d5d7c5d.yaml",
"raw_url":"https://github.com/openstack/nova/raw/9fe465427310f8215890d26bf169617653605e23/releasenotes/notes/bug-1821088-reject-duplicate-port-ids-a38739d67d5d7c5d.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/bug-1821088-reject-duplicate-port-ids-a38739d67d5d7c5d.yaml?ref=9fe465427310f8215890d26bf169617653605e23",
"patch":"@@ -0,0 +1,7 @@\n+---\n+fixes:\n+  - |\n+    The ``POST /servers`` (create server) API will now reject attempts to\n+    create a server with the same port specified multiple times. This was\n+    previously accepted by the API but the instance would fail to spawn and\n+    would instead transition to the error state."
}
]
},
{
"commit_sha":"0b0f40d1b308b29da537859b72080488560c23d4",
"commit_node_id":"C_kwDOAAwOD9oAKDBiMGY0MGQxYjMwOGIyOWRhNTM3ODU5YjcyMDgwNDg4NTYwYzIzZDQ",
"commit_html_url":"https://github.com/openstack/nova/commit/0b0f40d1b308b29da537859b72080488560c23d4",
"commit_date":"2021-11-26T19:36:09Z",
"files":[
{
"sha":"1c3d13d5dd93747da89a37f90809ccaa46dbc195",
"filename":".zuul.yaml",
"status":"modified",
"additions":1,
"deletions":2,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -605,8 +605,7 @@\n         - nova-lvm\n         - nova-multi-cell\n         - nova-next\n-        - nova-ovs-hybrid-plug:\n-            voting: false\n+        - nova-ovs-hybrid-plug\n         - nova-tox-validate-backport:\n             voting: false\n         - nova-tox-functional-centos8-py36"
},
{
"sha":"b066b6cc011de43741cdaa75120c4f989588982a",
"filename":"nova/compute/manager.py",
"status":"modified",
"additions":28,
"deletions":53,
"changes":81,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/compute/manager.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/compute/manager.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/compute/manager.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -4809,8 +4809,18 @@ def _finish_revert_snapshot_based_resize_at_source(\n                   self.host, instance=instance)\n         # TODO(mriedem): Calculate provider mappings when we support\n         # cross-cell resize/migrate with ports having resource requests.\n-        self._finish_revert_resize_network_migrate_finish(\n-            ctxt, instance, migration, provider_mappings=None)\n+        # NOTE(hanrong): we need to change migration.dest_compute to\n+        # source host temporarily.\n+        # \"network_api.migrate_instance_finish\" will setup the network\n+        # for the instance on the destination host. For revert resize,\n+        # the instance will back to the source host, the setup of the\n+        # network for instance should be on the source host. So set\n+        # the migration.dest_compute to source host at here.\n+        with utils.temporary_mutation(\n+            migration, dest_compute=migration.source_compute\n+        ):\n+            self.network_api.migrate_instance_finish(\n+                ctxt, instance, migration, provider_mappings=None)\n         network_info = self.network_api.get_instance_nw_info(ctxt, instance)\n \n         # Remember that prep_snapshot_based_resize_at_source destroyed the\n@@ -4902,50 +4912,6 @@ def revert_resize(self, context, instance, migration, request_spec):\n             self.compute_rpcapi.finish_revert_resize(context, instance,\n                     migration, migration.source_compute, request_spec)\n \n-    def _finish_revert_resize_network_migrate_finish(\n-            self, context, instance, migration, provider_mappings):\n-        \"\"\"Causes port binding to be updated. In some Neutron or port\n-        configurations - see NetworkModel.get_bind_time_events() - we\n-        expect the vif-plugged event from Neutron immediately and wait for it.\n-        The rest of the time, the event is expected further along in the\n-        virt driver, so we don't wait here.\n-\n-        :param context: The request context.\n-        :param instance: The instance undergoing the revert resize.\n-        :param migration: The Migration object of the resize being reverted.\n-        :param provider_mappings: a dict of list of resource provider uuids\n-            keyed by port uuid\n-        :raises: eventlet.timeout.Timeout or\n-                 exception.VirtualInterfacePlugException.\n-        \"\"\"\n-        network_info = instance.get_network_info()\n-        events = []\n-        deadline = CONF.vif_plugging_timeout\n-        if deadline and network_info:\n-            events = network_info.get_bind_time_events(migration)\n-            if events:\n-                LOG.debug('Will wait for bind-time events: %s', events)\n-        error_cb = self._neutron_failed_migration_callback\n-        try:\n-            with self.virtapi.wait_for_instance_event(instance, events,\n-                                                      deadline=deadline,\n-                                                      error_callback=error_cb):\n-                # NOTE(hanrong): we need to change migration.dest_compute to\n-                # source host temporarily.\n-                # \"network_api.migrate_instance_finish\" will setup the network\n-                # for the instance on the destination host. For revert resize,\n-                # the instance will back to the source host, the setup of the\n-                # network for instance should be on the source host. So set\n-                # the migration.dest_compute to source host at here.\n-                with utils.temporary_mutation(\n-                        migration, dest_compute=migration.source_compute):\n-                    self.network_api.migrate_instance_finish(\n-                        context, instance, migration, provider_mappings)\n-        except eventlet.timeout.Timeout:\n-            with excutils.save_and_reraise_exception():\n-                LOG.error('Timeout waiting for Neutron events: %s', events,\n-                          instance=instance)\n-\n     @wrap_exception()\n     @reverts_task_state\n     @wrap_instance_event(prefix='compute')\n@@ -5003,8 +4969,18 @@ def _finish_revert_resize(\n \n             self.network_api.setup_networks_on_host(context, instance,\n                                                     migration.source_compute)\n-            self._finish_revert_resize_network_migrate_finish(\n-                context, instance, migration, provider_mappings)\n+            # NOTE(hanrong): we need to change migration.dest_compute to\n+            # source host temporarily. \"network_api.migrate_instance_finish\"\n+            # will setup the network for the instance on the destination host.\n+            # For revert resize, the instance will back to the source host, the\n+            # setup of the network for instance should be on the source host.\n+            # So set the migration.dest_compute to source host at here.\n+            with utils.temporary_mutation(\n+                    migration, dest_compute=migration.source_compute):\n+                self.network_api.migrate_instance_finish(context,\n+                                                         instance,\n+                                                         migration,\n+                                                         provider_mappings)\n             network_info = self.network_api.get_instance_nw_info(context,\n                                                                  instance)\n \n@@ -5081,8 +5057,7 @@ def _fill_provider_mapping_based_on_allocs(\n             # the provider mappings. If the instance has ports with\n             # resource request then the port update will fail in\n             # _update_port_binding_for_instance() called via\n-            # _finish_revert_resize_network_migrate_finish() in\n-            # finish_revert_resize.\n+            # migrate_instance_finish() in finish_revert_resize.\n             provider_mappings = None\n         return provider_mappings\n \n@@ -8306,8 +8281,8 @@ def pre_live_migration(self, context, instance, disk, migrate_data):\n         return migrate_data\n \n     @staticmethod\n-    def _neutron_failed_migration_callback(event_name, instance):\n-        msg = ('Neutron reported failure during migration '\n+    def _neutron_failed_live_migration_callback(event_name, instance):\n+        msg = ('Neutron reported failure during live migration '\n                'with %(event)s for instance %(uuid)s')\n         msg_args = {'event': event_name, 'uuid': instance.uuid}\n         if CONF.vif_plugging_is_fatal:\n@@ -8403,7 +8378,7 @@ class _BreakWaitForInstanceEvent(Exception):\n                 disk = None\n \n             deadline = CONF.vif_plugging_timeout\n-            error_cb = self._neutron_failed_migration_callback\n+            error_cb = self._neutron_failed_live_migration_callback\n             # In order to avoid a race with the vif plugging that the virt\n             # driver does on the destination host, we register our events\n             # to wait for before calling pre_live_migration. Then if the"
},
{
"sha":"64995c95274677b7701694a839032031a9c88f71",
"filename":"nova/network/model.py",
"status":"modified",
"additions":0,
"deletions":25,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/network/model.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/network/model.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/network/model.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -485,17 +485,6 @@ def labeled_ips(self):\n                     'ips': ips}\n         return []\n \n-    def has_bind_time_event(self, migration):\n-        \"\"\"Returns whether this VIF's network-vif-plugged external event will\n-        be sent by Neutron at \"bind-time\" - in other words, as soon as the port\n-        binding is updated. This is in the context of updating the port binding\n-        to a host that already has the instance in a shutoff state - in\n-        practice, this means reverting either a cold migration or a\n-        non-same-host resize.\n-        \"\"\"\n-        return (self.is_hybrid_plug_enabled() and not\n-                migration.is_same_host())\n-\n     @property\n     def has_live_migration_plug_time_event(self):\n         \"\"\"Returns whether this VIF's network-vif-plugged external event will\n@@ -564,27 +553,13 @@ def wait(self, do_raise=True):\n     def json(self):\n         return jsonutils.dumps(self)\n \n-    def get_bind_time_events(self, migration):\n-        \"\"\"Returns a list of external events for any VIFs that have\n-        \"bind-time\" events during cold migration.\n-        \"\"\"\n-        return [('network-vif-plugged', vif['id'])\n-                for vif in self if vif.has_bind_time_event(migration)]\n-\n     def get_live_migration_plug_time_events(self):\n         \"\"\"Returns a list of external events for any VIFs that have\n         \"plug-time\" events during live migration.\n         \"\"\"\n         return [('network-vif-plugged', vif['id'])\n                 for vif in self if vif.has_live_migration_plug_time_event]\n \n-    def get_plug_time_events(self, migration):\n-        \"\"\"Returns a list of external events for any VIFs that have\n-        \"plug-time\" events during cold migration.\n-        \"\"\"\n-        return [('network-vif-plugged', vif['id'])\n-                for vif in self if not vif.has_bind_time_event(migration)]\n-\n     def has_port_with_allocation(self):\n         return any(vif.has_allocation() for vif in self)\n "
},
{
"sha":"cacb636ccc8bb82096af7abc2963d53731d36262",
"filename":"nova/objects/migration.py",
"status":"modified",
"additions":0,
"deletions":3,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/objects/migration.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/objects/migration.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/objects/migration.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -202,9 +202,6 @@ def instance(self):\n     def instance(self, instance):\n         self._cached_instance = instance\n \n-    def is_same_host(self):\n-        return self.source_compute == self.dest_compute\n-\n     @property\n     def is_live_migration(self):\n         return self.migration_type == fields.MigrationType.LIVE_MIGRATION"
},
{
"sha":"f65f1abdb740a6c2ef26c71494f6b7f537708ea1",
"filename":"nova/tests/unit/compute/test_compute.py",
"status":"modified",
"additions":2,
"deletions":6,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/compute/test_compute.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/compute/test_compute.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -5801,9 +5801,7 @@ def fake_finish_revert_migration_driver(*args, **kwargs):\n             old_vm_state = vm_states.ACTIVE\n         else:\n             old_vm_state = vm_states.STOPPED\n-        params = {'vm_state': old_vm_state,\n-                  'info_cache': objects.InstanceInfoCache(\n-                      network_info=network_model.NetworkInfo([]))}\n+        params = {'vm_state': old_vm_state}\n         instance = self._create_fake_instance_obj(params)\n         request_spec = objects.RequestSpec()\n \n@@ -5956,9 +5954,7 @@ def test_finish_revert_resize_validate_source_compute(self):\n         def fake(*args, **kwargs):\n             pass\n \n-        params = {'info_cache': objects.InstanceInfoCache(\n-                      network_info=network_model.NetworkInfo([]))}\n-        instance = self._create_fake_instance_obj(params)\n+        instance = self._create_fake_instance_obj()\n         request_spec = objects.RequestSpec()\n \n         self.stub_out('nova.virt.fake.FakeDriver.finish_migration', fake)"
},
{
"sha":"4d7967b37e487733e873392952efc107ba75c3b8",
"filename":"nova/tests/unit/compute/test_compute_mgr.py",
"status":"modified",
"additions":11,
"deletions":95,
"changes":106,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/compute/test_compute_mgr.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/compute/test_compute_mgr.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/compute/test_compute_mgr.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -6051,86 +6051,6 @@ def test_notify_volume_usage_detach_no_block_stats(self):\n                     self.context, fake_instance, fake_bdm)\n         block_stats.assert_called_once_with(fake_instance, 'vda')\n \n-    def _test_finish_revert_resize_network_migrate_finish(\n-            self, vifs, events, migration=None):\n-        instance = fake_instance.fake_instance_obj(self.context)\n-        instance.info_cache = objects.InstanceInfoCache(\n-            network_info=network_model.NetworkInfo(vifs))\n-        if migration is None:\n-            migration = objects.Migration(\n-                source_compute='fake-source',\n-                dest_compute='fake-dest')\n-\n-        def fake_migrate_instance_finish(\n-                context, instance, migration, mapping):\n-            # NOTE(artom) This looks weird, but it's checking that the\n-            # temporaty_mutation() context manager did its job.\n-            self.assertEqual(migration.dest_compute, migration.source_compute)\n-\n-        with test.nested(\n-            mock.patch.object(self.compute.virtapi,\n-                              'wait_for_instance_event'),\n-            mock.patch.object(self.compute.network_api,\n-                              'migrate_instance_finish',\n-                              side_effect=fake_migrate_instance_finish)\n-        ) as (mock_wait, mock_migrate_instance_finish):\n-            self.compute._finish_revert_resize_network_migrate_finish(\n-                self.context, instance, migration, mock.sentinel.mapping)\n-            mock_wait.assert_called_once_with(\n-                instance, events, deadline=CONF.vif_plugging_timeout,\n-                error_callback=self.compute._neutron_failed_migration_callback)\n-            mock_migrate_instance_finish.assert_called_once_with(\n-                self.context, instance, migration, mock.sentinel.mapping)\n-\n-    def test_finish_revert_resize_network_migrate_finish_wait(self):\n-        \"\"\"Test that we wait for bind-time events if we have a hybrid-plugged\n-        VIF.\n-        \"\"\"\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [('network-vif-plugged', uuids.hybrid_vif)])\n-\n-    def test_finish_revert_resize_network_migrate_finish_same_host(self):\n-        \"\"\"Test that we're not waiting for any events if its a same host\n-        resize revert.\n-        \"\"\"\n-        migration = objects.Migration(\n-            source_compute='fake-source', dest_compute='fake-source')\n-\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [], migration=migration\n-        )\n-\n-    def test_finish_revert_resize_network_migrate_finish_dont_wait(self):\n-        \"\"\"Test that we're not waiting for any events if we don't have any\n-        hybrid-plugged VIFs.\n-        \"\"\"\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': False}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': False})],\n-            [])\n-\n-    def test_finish_revert_resize_network_migrate_finish_no_vif_timeout(self):\n-        \"\"\"Test that we're not waiting for any events if vif_plugging_timeout\n-        is 0.\n-        \"\"\"\n-        self.flags(vif_plugging_timeout=0)\n-        self._test_finish_revert_resize_network_migrate_finish(\n-            [network_model.VIF(id=uuids.hybrid_vif,\n-                               details={'ovs_hybrid_plug': True}),\n-             network_model.VIF(id=uuids.normal_vif,\n-                               details={'ovs_hybrid_plug': True})],\n-            [])\n-\n     @mock.patch('nova.compute.manager.LOG')\n     def test_cache_images_unsupported(self, mock_log):\n         r = self.compute.cache_images(self.context, ['an-image'])\n@@ -8877,8 +8797,7 @@ def do_finish_revert_resize(mock_attachment_complete,\n         do_finish_revert_resize()\n \n     @mock.patch.object(objects.Instance, 'drop_migration_context')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.scheduler.utils.'\n                 'fill_provider_mapping_based_on_allocation')\n     @mock.patch('nova.compute.manager.ComputeManager._revert_allocation')\n@@ -8892,7 +8811,7 @@ def do_finish_revert_resize(mock_attachment_complete,\n     def test_finish_revert_resize_recalc_group_rp_mapping(\n             self, mock_get_bdms, mock_notify_action, mock_notify_usage,\n             mock_set_instance_info, mock_instance_save, mock_revert_allocation,\n-            mock_fill_provider_mapping, mock_network_migrate_finish,\n+            mock_fill_provider_mapping, mock_migrate_instance_finish,\n             mock_drop_migration_context):\n \n         mock_get_bdms.return_value = objects.BlockDeviceMappingList()\n@@ -8909,8 +8828,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping(\n             mock.sentinel.allocation)\n \n     @mock.patch.object(objects.Instance, 'drop_migration_context')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.scheduler.utils.'\n                 'fill_provider_mapping_based_on_allocation')\n     @mock.patch('nova.scheduler.client.report.SchedulerReportClient.'\n@@ -8927,7 +8845,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping_missing_request_spec(\n             self, mock_get_bdms, mock_notify_action, mock_notify_usage,\n             mock_set_instance_info, mock_instance_save, mock_revert_allocation,\n             mock_get_allocations, mock_fill_provider_mapping,\n-            mock_network_migrate_finish, mock_drop_migration_context):\n+            mock_migrate_instance_finish, mock_drop_migration_context):\n \n         mock_get_bdms.return_value = objects.BlockDeviceMappingList()\n         mock_get_allocations.return_value = mock.sentinel.allocation\n@@ -8941,7 +8859,7 @@ def test_finish_revert_resize_recalc_group_rp_mapping_missing_request_spec(\n \n         mock_get_allocations.assert_not_called()\n         mock_fill_provider_mapping.assert_not_called()\n-        mock_network_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration, None)\n \n     def test_confirm_resize_deletes_allocations_and_update_scheduler(self):\n@@ -12126,8 +12044,7 @@ def test_finish_revert_snapshot_based_resize_at_source_error_handling(\n     @mock.patch('nova.objects.BlockDeviceMappingList.get_by_instance_uuid')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_update_volume_attachments')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_get_instance_block_device_info')\n     @mock.patch('nova.objects.Instance.drop_migration_context')\n@@ -12137,7 +12054,7 @@ def test_finish_revert_snapshot_based_resize_at_source_error_handling(\n                 '_complete_volume_attachments')\n     def test_finish_revert_snapshot_based_resize_at_source(\n             self, mock_complete_attachments, mock_update_after_spawn,\n-            mock_drop_mig_context, mock_get_bdi, mock_net_migrate_finish,\n+            mock_drop_mig_context, mock_get_bdi, mock_migrate_instance_finish,\n             mock_update_attachments, mock_get_bdms, mock_revert_allocs,\n             mock_inst_save):\n         \"\"\"Happy path test for finish_revert_snapshot_based_resize_at_source.\n@@ -12177,7 +12094,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n         mock_update_attachments.assert_called_once_with(\n             self.context, self.instance, mock_get_bdms.return_value)\n         # Assert that port bindings were updated to point at the source host.\n-        mock_net_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration,\n             provider_mappings=None)\n         # Assert the driver finished reverting the migration.\n@@ -12202,8 +12119,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n     @mock.patch('nova.objects.BlockDeviceMappingList.get_by_instance_uuid')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_update_volume_attachments')\n-    @mock.patch('nova.compute.manager.ComputeManager.'\n-                '_finish_revert_resize_network_migrate_finish')\n+    @mock.patch('nova.network.neutron.API.migrate_instance_finish')\n     @mock.patch('nova.compute.manager.ComputeManager.'\n                 '_get_instance_block_device_info')\n     @mock.patch('nova.objects.Instance.drop_migration_context')\n@@ -12214,7 +12130,7 @@ def test_finish_revert_snapshot_based_resize_at_source(\n                 side_effect=test.TestingException('vol complete failed'))\n     def test_finish_revert_snapshot_based_resize_at_source_driver_fails(\n             self, mock_complete_attachments, mock_update_after_spawn,\n-            mock_drop_mig_context, mock_get_bdi, mock_net_migrate_finish,\n+            mock_drop_mig_context, mock_get_bdi, mock_migrate_instance_finish,\n             mock_update_attachments, mock_get_bdms, mock_revert_allocs,\n             mock_inst_save):\n         \"\"\"Test for _finish_revert_snapshot_based_resize_at_source where the\n@@ -12268,7 +12184,7 @@ def test_finish_revert_snapshot_based_resize_at_source_driver_fails(\n         mock_update_attachments.assert_called_once_with(\n             self.context, self.instance, mock_get_bdms.return_value)\n         # Assert that port bindings were updated to point at the source host.\n-        mock_net_migrate_finish.assert_called_once_with(\n+        mock_migrate_instance_finish.assert_called_once_with(\n             self.context, self.instance, self.migration,\n             provider_mappings=None)\n         # Assert final DB cleanup for the instance did not happen."
},
{
"sha":"0420e2d79198c7f3fbeccc465f008dbaef063e80",
"filename":"nova/tests/unit/network/test_network_info.py",
"status":"modified",
"additions":0,
"deletions":29,
"changes":29,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/network/test_network_info.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/network/test_network_info.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/network/test_network_info.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -19,7 +19,6 @@\n \n from nova import exception\n from nova.network import model\n-from nova import objects\n from nova import test\n from nova.tests.unit import fake_network_cache_model\n from nova.virt import netutils\n@@ -855,34 +854,6 @@ def test_injection_ipv6_with_lxc_no_gateway(self):\n                 libvirt_virt_type='lxc')\n         self.assertEqual(expected, template)\n \n-    def test_get_events(self):\n-        network_info = model.NetworkInfo([\n-            model.VIF(\n-                id=uuids.hybrid_vif,\n-                details={'ovs_hybrid_plug': True}),\n-            model.VIF(\n-                id=uuids.normal_vif,\n-                details={'ovs_hybrid_plug': False})])\n-        same_host = objects.Migration(source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        diff_host = objects.Migration(source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        # Same-host migrations will have all events be plug-time.\n-        self.assertCountEqual(\n-            [('network-vif-plugged', uuids.normal_vif),\n-             ('network-vif-plugged', uuids.hybrid_vif)],\n-            network_info.get_plug_time_events(same_host))\n-        # Same host migration will have no plug-time events.\n-        self.assertEqual([], network_info.get_bind_time_events(same_host))\n-        # Diff-host migration + OVS hybrid plug = bind-time events\n-        self.assertEqual(\n-            [('network-vif-plugged', uuids.hybrid_vif)],\n-            network_info.get_bind_time_events(diff_host))\n-        # Diff-host migration + normal OVS = plug-time events\n-        self.assertEqual(\n-            [('network-vif-plugged', uuids.normal_vif)],\n-            network_info.get_plug_time_events(diff_host))\n-\n     def test_has_port_with_allocation(self):\n         network_info = model.NetworkInfo([])\n         self.assertFalse(network_info.has_port_with_allocation())"
},
{
"sha":"970122a4094f9a3f33257e43e0a0912b9f4278cb",
"filename":"nova/tests/unit/objects/test_migration.py",
"status":"modified",
"additions":0,
"deletions":8,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/objects/test_migration.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/objects/test_migration.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/objects/test_migration.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -359,14 +359,6 @@ def test_get_by_uuid(self, mock_db_get):\n         mig = objects.Migration.get_by_uuid(self.context, uuidsentinel.mig)\n         self.assertEqual(uuidsentinel.mig, mig.uuid)\n \n-    def test_is_same_host(self):\n-        same_host = objects.Migration(source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        diff_host = objects.Migration(source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self.assertTrue(same_host.is_same_host())\n-        self.assertFalse(diff_host.is_same_host())\n-\n \n class TestMigrationObject(test_objects._LocalTest,\n                           _TestMigrationObject):"
},
{
"sha":"50cb5536ef92e7339acde990f2c5fd977df40567",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":9,
"deletions":55,
"changes":64,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -19169,10 +19169,9 @@ def fake_lxc_disk_handler(*args, **kwargs):\n             self.assertEqual(0, domain.resume.call_count)\n \n     def _test_create_guest_with_network__events(\n-        self, neutron_failure=None, power_on=True, events=None,\n+        self, neutron_failure=None, power_on=True,\n     ):\n         generated_events = []\n-        events_passed_to_prepare = []\n \n         def wait_timeout():\n             event = mock.MagicMock()\n@@ -19190,7 +19189,6 @@ def fake_prepare(instance, name, tag):\n             m.event_name = '%s-%s' % (name, tag)\n             m.wait.side_effect = wait_timeout\n             generated_events.append(m)\n-            events_passed_to_prepare.append((name, tag))\n             return m\n \n         virtapi = manager.ComputeVirtAPI(mock.MagicMock())\n@@ -19209,8 +19207,7 @@ def fake_prepare(instance, name, tag):\n         def test_create(cleanup, create, plug_vifs):\n             domain = drvr._create_guest_with_network(self.context, 'xml',\n                                                      instance, vifs, None,\n-                                                     power_on=power_on,\n-                                                     external_events=events)\n+                                                     power_on=power_on)\n             plug_vifs.assert_called_with(instance, vifs)\n \n             pause = self._get_pause_flag(drvr, vifs, power_on=power_on)\n@@ -19225,9 +19222,7 @@ def test_create(cleanup, create, plug_vifs):\n \n         test_create()\n \n-        if events and CONF.vif_plugging_timeout:\n-            self.assertEqual(events_passed_to_prepare, events)\n-        elif CONF.vif_plugging_timeout and power_on:\n+        if CONF.vif_plugging_timeout and power_on:\n             prepare.assert_has_calls([\n                 mock.call(instance, 'network-vif-plugged', uuids.vif_1),\n                 mock.call(instance, 'network-vif-plugged', uuids.vif_2)])\n@@ -19243,15 +19238,6 @@ def test_create(cleanup, create, plug_vifs):\n     def test_create_guest_with_network__events_neutron(self):\n         self._test_create_guest_with_network__events()\n \n-    def test_create_guest_with_network__events_passed_in(self):\n-        self._test_create_guest_with_network__events(\n-            events=[('network-vif-plugged', uuids.fake_vif)])\n-\n-    def test_create_guest_with_network__events_passed_in_0_timeout(self):\n-        self.flags(vif_plugging_timeout=0)\n-        self._test_create_guest_with_network__events(\n-            events=[('network-vif-plugged', uuids.fake_vif)])\n-\n     def test_create_guest_with_network_events_neutron_power_off(self):\n         # Tests that we don't wait for events if we don't start the instance.\n         self._test_create_guest_with_network__events(power_on=False)\n@@ -22241,7 +22227,7 @@ def test_finish_revert_migration_vtpm__no_vtpm(\n         mock_restore_vtpm.assert_not_called()\n         mock_delete_vtpm.assert_not_called()\n \n-    def _test_finish_revert_migration(self, power_on, migration):\n+    def _test_finish_revert_migration(self, power_on):\n         \"\"\"Test for nova.virt.libvirt.libvirt_driver.LivirtConnection\n         .finish_revert_migration.\n         \"\"\"\n@@ -22258,14 +22244,11 @@ def fake_plug_vifs(self, instance, network_info):\n         def fake_create_guest_with_network(\n             _self, context, xml, instance, network_info, block_device_info,\n             power_on=None, vifs_already_plugged=None, post_xml_callback=None,\n-            external_events=None, cleanup_instance_dir=False,\n-            cleanup_instance_disks=False,\n+            cleanup_instance_dir=False, cleanup_instance_disks=False,\n         ):\n             self.fake_create_guest_called = True\n             self.assertEqual(powered_on, power_on)\n             self.assertFalse(vifs_already_plugged)\n-            self.assertEqual(self.events_passed_to_fake_create,\n-                             external_events)\n             return mock.MagicMock()\n \n         def fake_get_info(self, instance):\n@@ -22304,51 +22287,22 @@ def fake_to_xml(self, context, instance, network_info, disk_info,\n             f = open(libvirt_xml_path, 'w')\n             f.close()\n \n-            network_info = network_model.NetworkInfo(\n-                [network_model.VIF(id=uuids.normal_vif),\n-                 network_model.VIF(id=uuids.hybrid_vif,\n-                                   details={'ovs_hybrid_plug': True})])\n-            if migration.is_same_host():\n-                # Same host is all plug-time\n-                self.events_passed_to_fake_create = [\n-                    ('network-vif-plugged', uuids.normal_vif),\n-                    ('network-vif-plugged', uuids.hybrid_vif)]\n-            else:\n-                # For different host migration only non-hybrid plug\n-                # (\"normal\") VIFs \"emit\" plug-time events.\n-                self.events_passed_to_fake_create = [\n-                    ('network-vif-plugged', uuids.normal_vif)]\n-\n             with mock.patch.object(\n                 self.drvr, '_get_all_assigned_mediated_devices',\n                 return_value={}\n             ) as mock_get_a_mdevs:\n                 self.drvr.finish_revert_migration(\n-                    self.context, instance, network_info, migration,\n-                    power_on=power_on)\n+                    self.context, instance, network_model.NetworkInfo(),\n+                        objects.Migration(), power_on=power_on)\n \n             self.assertTrue(self.fake_create_guest_called)\n             mock_get_a_mdevs.assert_called_once_with(mock.ANY)\n \n     def test_finish_revert_migration_power_on(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n+        self._test_finish_revert_migration(True)\n \n     def test_finish_revert_migration_power_off(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=False, migration=migration)\n-\n-    def test_finish_revert_migration_same_host(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host',\n-                                      dest_compute='fake-host')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n-\n-    def test_finish_revert_migration_diff_host(self):\n-        migration = objects.Migration(id=42, source_compute='fake-host1',\n-                                      dest_compute='fake-host2')\n-        self._test_finish_revert_migration(power_on=True, migration=migration)\n+        self._test_finish_revert_migration(False)\n \n     def _test_finish_revert_migration_after_crash(self, backup_made=True,\n                                                   del_inst_failed=False):"
},
{
"sha":"2ea493d4521179424eb2ed18bcf96ba443f6109f",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":1,
"deletions":10,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/0b0f40d1b308b29da537859b72080488560c23d4/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/0b0f40d1b308b29da537859b72080488560c23d4/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=0b0f40d1b308b29da537859b72080488560c23d4",
"patch":"@@ -11278,18 +11278,9 @@ def finish_revert_migration(\n                                   instance.image_meta,\n                                   block_device_info=block_device_info,\n                                   mdevs=mdevs)\n-        # NOTE(artom) In some Neutron or port configurations we've already\n-        # waited for vif-plugged events in the compute manager's\n-        # _finish_revert_resize_network_migrate_finish(), right after updating\n-        # the port binding. For any ports not covered by those \"bind-time\"\n-        # events, we wait for \"plug-time\" events here.\n-        events = network_info.get_plug_time_events(migration)\n-        if events:\n-            LOG.debug('Instance is using plug-time events: %s', events,\n-                      instance=instance)\n         self._create_guest_with_network(\n             context, xml, instance, network_info, block_device_info,\n-            power_on=power_on, external_events=events)\n+            power_on=power_on)\n \n         if power_on:\n             timer = loopingcall.FixedIntervalLoopingCall("
}
]
},
{
"commit_sha":"ded6168ad729e747fc976ca3cdb8baf971fbc31a",
"commit_node_id":"C_kwDOAAwOD9oAKGRlZDYxNjhhZDcyOWU3NDdmYzk3NmNhM2NkYjhiYWY5NzFmYmMzMWE",
"commit_html_url":"https://github.com/openstack/nova/commit/ded6168ad729e747fc976ca3cdb8baf971fbc31a",
"commit_date":"2021-11-09T20:14:57Z",
"files":[
{
"sha":"74658ed1a905d39035082c0eb92682b2ed3b82b6",
"filename":".zuul.yaml",
"status":"modified",
"additions":62,
"deletions":0,
"changes":62,
"blob_url":"https://github.com/openstack/nova/blob/ded6168ad729e747fc976ca3cdb8baf971fbc31a/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/ded6168ad729e747fc976ca3cdb8baf971fbc31a/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=ded6168ad729e747fc976ca3cdb8baf971fbc31a",
"patch":"@@ -121,6 +121,66 @@\n               block_migrate_cinder_iscsi: false\n     post-run: playbooks/nova-live-migration/post-run.yaml\n \n+- job:\n+    name: nova-ovs-hybrid-plug\n+    parent: tempest-multinode-full-py3\n+    description: |\n+      Run move operations, reboot, and evacuation (via the same post-run hook\n+      as the nova-live-migration job) tests with the OVS network backend and\n+      the \"iptables_hybrid\" securitygroup firewall driver, aka \"hybrid plug\".\n+      The external events interactions between Nova and Neutron in these\n+      situations has historically been fragile. This job exercises them.\n+    irrelevant-files: *nova-base-irrelevant-files\n+    vars:\n+      tox_envlist: all\n+      tempest_test_regex: (^tempest\\..*compute\\..*(migration|resize|reboot).*)\n+      devstack_localrc:\n+        Q_AGENT: openvswitch\n+        Q_ML2_TENANT_NETWORK_TYPE: vxlan\n+        Q_ML2_PLUGIN_MECHANISM_DRIVERS: openvswitch,linuxbridge\n+        ML2_L3_PLUGIN: router\n+      devstack_services:\n+        # Disable OVN services\n+        br-ex-tcpdump: false\n+        br-int-flows: false\n+        ovn-controller: false\n+        ovn-northd: false\n+        q-ovn-metadata-agent: false\n+        # Neutron services\n+        q-agt: true\n+        q-dhcp: true\n+        q-l3: true\n+        q-meta: true\n+      devstack_local_conf:\n+        post-config:\n+          \"/$NEUTRON_CORE_PLUGIN_CONF\":\n+            securitygroup:\n+              firewall_driver: iptables_hybrid\n+    group-vars:\n+      subnode:\n+        devstack_localrc:\n+          Q_AGENT: openvswitch\n+          Q_ML2_TENANT_NETWORK_TYPE: vxlan\n+          Q_ML2_PLUGIN_MECHANISM_DRIVERS: openvswitch,linuxbridge\n+          ML2_L3_PLUGIN: router\n+        devstack_services:\n+          # Disable OVN services\n+          br-ex-tcpdump: false\n+          br-int-flows: false\n+          ovn-controller: false\n+          ovn-northd: false\n+          ovs-vswitchd: false\n+          ovsdb-server: false\n+          q-ovn-metadata-agent: false\n+          # Neutron services\n+          q-agt: true\n+        devstack_local_conf:\n+          post-config:\n+            \"/$NEUTRON_CORE_PLUGIN_CONF\":\n+              securitygroup:\n+                firewall_driver: iptables_hybrid\n+    post-run: playbooks/nova-live-migration/post-run.yaml\n+\n - job:\n     name: nova-live-migration-ceph\n     parent: devstack-plugin-ceph-multinode-tempest-py3\n@@ -545,6 +605,8 @@\n         - nova-lvm\n         - nova-multi-cell\n         - nova-next\n+        - nova-ovs-hybrid-plug:\n+            voting: false\n         - nova-tox-validate-backport:\n             voting: false\n         - nova-tox-functional-centos8-py36"
}
]
},
{
"commit_sha":"4b2aa93158940890a28e9e8c1a94ad93abbecb93",
"commit_node_id":"C_kwDOAAwOD9oAKDRiMmFhOTMxNTg5NDA4OTBhMjhlOWU4YzFhOTRhZDkzYWJiZWNiOTM",
"commit_html_url":"https://github.com/openstack/nova/commit/4b2aa93158940890a28e9e8c1a94ad93abbecb93",
"commit_date":"2021-12-22T17:18:19Z",
"files":[
{
"sha":"2875f3374adb04f9d628104eaa4afdc3563610c5",
"filename":"tox.ini",
"status":"modified",
"additions":30,
"deletions":1,
"changes":31,
"blob_url":"https://github.com/openstack/nova/blob/4b2aa93158940890a28e9e8c1a94ad93abbecb93/tox.ini",
"raw_url":"https://github.com/openstack/nova/raw/4b2aa93158940890a28e9e8c1a94ad93abbecb93/tox.ini",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/tox.ini?ref=4b2aa93158940890a28e9e8c1a94ad93abbecb93",
"patch":"@@ -29,6 +29,11 @@ deps =\n   -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}\n   -r{toxinidir}/requirements.txt\n   -r{toxinidir}/test-requirements.txt\n+extras =\n+  powervm\n+  zvm\n+  hyperv\n+  vmware\n passenv =\n   OS_DEBUG GENERATE_HASHES\n # there is also secret magic in subunit-trace which lets you run in a fail only\n@@ -42,16 +47,17 @@ commands =\n description =\n   Run type checks.\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   bash tools/mypywrap.sh {posargs}\n \n [testenv:pep8]\n description =\n   Run style checks.\n-envdir = {toxworkdir}/shared\n deps =\n   {[testenv]deps}\n   autopep8\n+extras =\n commands =\n   {[testenv:mypy]commands}\n   # check if autopep8 would alter the formatting but don't actually change it\n@@ -68,6 +74,7 @@ commands =\n   bash -c '! find doc/ -type f -name *.json | xargs -t -n1 python -m json.tool 2>&1 > /dev/null | grep -B1 -v ^python'\n \n [testenv:autopep8]\n+extras =\n deps = autopep8\n commands =\n   autopep8 --exit-code --max-line-length=79 --in-place -r nova doc setup.py\n@@ -76,6 +83,7 @@ commands =\n description =\n   Run style checks on the changes made since HEAD~. For a full run including docs, use 'pep8'\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   bash tools/flake8wrap.sh -HEAD\n \n@@ -84,6 +92,7 @@ description =\n   Determine whether a backport is ready to be merged by checking whether it has\n   already been merged to master or more recent stable branches.\n deps =\n+extras =\n skipsdist = true\n commands =\n   bash tools/check-cherry-picks.sh\n@@ -108,6 +117,7 @@ description =\n deps =\n   {[testenv]deps}\n   openstack-placement>=1.0.0\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional run {posargs}\n   stestr slowest\n@@ -116,20 +126,23 @@ commands =\n description =\n   Run functional tests using python3.6.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n [testenv:functional-py37]\n description =\n   Run functional tests using python3.7.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n [testenv:functional-py38]\n description =\n   Run functional tests using python3.8.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n@@ -140,13 +153,15 @@ description =\n   placement-nova-tox-functional-py38 job which is defined and\n   run in placement.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional run --exclude-regex '((?:api|notification)_sample_tests|functional\\.db\\.)' {posargs}\n \n [testenv:functional-py39]\n description =\n   Run functional tests using python3.9.\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   {[testenv:functional]commands}\n \n@@ -157,17 +172,20 @@ setenv =\n   GENERATE_SAMPLES=True\n   PYTHONHASHSEED=0\n deps = {[testenv:functional]deps}\n+extras =\n commands =\n   stestr --test-path=./nova/tests/functional/api_sample_tests run {posargs}\n   stestr slowest\n \n [testenv:genconfig]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslo-config-generator --config-file=etc/nova/nova-config-generator.conf\n \n [testenv:genpolicy]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslopolicy-sample-generator --config-file=etc/nova/nova-policy-generator.conf\n \n@@ -180,6 +198,7 @@ envdir = {toxworkdir}/shared\n setenv =\n   {[testenv]setenv}\n   PYTHON=coverage run --source nova --parallel-mode\n+extras =\n commands =\n   coverage erase\n   stestr run {posargs}\n@@ -190,13 +209,15 @@ commands =\n \n [testenv:debug]\n envdir = {toxworkdir}/shared\n+extras =\n commands =\n   oslo_debug_helper {posargs}\n \n [testenv:venv]\n deps =\n   {[testenv]deps}\n   -r{toxinidir}/doc/requirements.txt\n+extras =\n commands =\n   {posargs}\n \n@@ -208,6 +229,7 @@ description =\n deps =\n   -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}\n   -r{toxinidir}/doc/requirements.txt\n+extras =\n commands =\n   rm -rf doc/build/html doc/build/doctrees\n   sphinx-build -W --keep-going -b html -j auto doc/source doc/build/html\n@@ -219,6 +241,7 @@ description =\n   Build PDF documentation.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf doc/build/pdf\n   sphinx-build -W --keep-going -b latex -j auto doc/source doc/build/pdf\n@@ -229,6 +252,7 @@ description =\n   Generate the API guide. Called from CI scripts to test and publish to docs.openstack.org.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf api-guide/build\n   sphinx-build -W --keep-going -b html -j auto api-guide/source api-guide/build/html\n@@ -238,6 +262,7 @@ description =\n   Generate the API ref. Called from CI scripts to test and publish to docs.openstack.org.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf api-ref/build\n   sphinx-build -W --keep-going -b html -j auto api-ref/source api-ref/build/html\n@@ -247,6 +272,7 @@ description =\n   Generate release notes.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   rm -rf releasenotes/build\n   sphinx-build -W --keep-going -b html -j auto releasenotes/source releasenotes/build/html\n@@ -256,6 +282,7 @@ description =\n   Build all documentation including API guides and refs.\n envdir = {toxworkdir}/docs\n deps = {[testenv:docs]deps}\n+extras =\n commands =\n   {[testenv:docs]commands}\n   {[testenv:api-guide]commands}\n@@ -266,6 +293,7 @@ commands =\n # NOTE(browne): This is required for the integration test job of the bandit\n # project. Please do not remove.\n envdir = {toxworkdir}/shared\n+extras =\n commands = bandit -r nova -x tests -n 5 -ll\n \n [flake8]\n@@ -358,6 +386,7 @@ paths =\n # explicitly to avoid unnecessarily installing the checked-out repo too\n usedevelop = False\n deps = bindep\n+extras =\n commands =\n   bindep test\n "
}
]
},
{
"commit_sha":"86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"commit_node_id":"C_kwDOAAwOD9oAKDg2ZDg3YmU4ZGI1ODhjYzMxMjVkNTNjZDkyZTI3MWZiNDViMWEzYWE",
"commit_html_url":"https://github.com/openstack/nova/commit/86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"commit_date":"2021-12-22T16:25:19Z",
"files":[
{
"sha":"2190f0570ff8974ef7bb3bc582f72743d98f809b",
"filename":"nova/tests/unit/virt/hyperv/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/hyperv/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/hyperv/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/hyperv/__init__.py?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import os_win  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'os-win' dependency is not installed.\"\n+    )"
},
{
"sha":"3f8ef7b1671790fb92010ac7f089bb1b44b4fc25",
"filename":"nova/tests/unit/virt/powervm/__init__.py",
"status":"modified",
"additions":10,
"deletions":1,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/powervm/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/powervm/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/powervm/__init__.py?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -11,13 +11,22 @@\n #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n #    License for the specific language governing permissions and limitations\n #    under the License.\n-#\n+\n+import unittest\n+\n from oslo_utils.fixture import uuidsentinel\n \n from nova.compute import power_state\n from nova.compute import vm_states\n from nova import objects\n \n+try:\n+    import powervm  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'pypowervm' dependency is not installed.\"\n+    )\n+\n \n TEST_FLAVOR = objects.flavor.Flavor(\n     memory_mb=2048,"
},
{
"sha":"206b60cb8fedb175233c423089f0d45d1e7c4d8c",
"filename":"nova/tests/unit/virt/vmwareapi/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/vmwareapi/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/vmwareapi/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/vmwareapi/__init__.py?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import oslo_vmware  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'oslo.vmware' dependency is not installed.\"\n+    )"
},
{
"sha":"a93e19e1be56ea0e5b494376d9b8ee1cacbdec19",
"filename":"nova/tests/unit/virt/zvm/__init__.py",
"status":"modified",
"additions":20,
"deletions":0,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/zvm/__init__.py",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/nova/tests/unit/virt/zvm/__init__.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/zvm/__init__.py?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -0,0 +1,20 @@\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import unittest\n+\n+try:\n+    import zvmconnector  # noqa: F401\n+except ImportError:\n+    raise unittest.SkipTest(\n+        \"The 'zVMCloudConnector' dependency is not installed.\"\n+    )"
},
{
"sha":"c053e1e2202e0382d59d8cc23ae109385f9a2487",
"filename":"requirements.txt",
"status":"modified",
"additions":0,
"deletions":5,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -8,8 +8,6 @@ lxml>=4.5.0 # BSD\n Routes>=2.3.1 # MIT\n cryptography>=2.7 # BSD/Apache-2.0\n WebOb>=1.8.2 # MIT\n-# NOTE(mriedem): greenlet 0.4.14 does not work with older versions of gcc on\n-# ppc64le systems, see https://github.com/python-greenlet/greenlet/issues/136.\n greenlet>=0.4.15 # MIT\n PasteDeploy>=1.5.0 # MIT\n Paste>=2.0.2 # MIT\n@@ -52,17 +50,14 @@ os-brick>=4.3.1 # Apache-2.0\n os-resource-classes>=1.1.0 # Apache-2.0\n os-traits>=2.5.0 # Apache-2.0\n os-vif>=1.15.2 # Apache-2.0\n-os-win>=5.4.0 # Apache-2.0\n castellan>=0.16.0 # Apache-2.0\n microversion-parse>=0.2.1 # Apache-2.0\n tooz>=1.58.0 # Apache-2.0\n cursive>=0.2.1 # Apache-2.0\n-pypowervm>=1.1.15 # Apache-2.0\n retrying>=1.3.3,!=1.3.0 # Apache-2.0\n os-service-types>=1.7.0 # Apache-2.0\n taskflow>=3.8.0 # Apache-2.0\n python-dateutil>=2.7.0 # BSD\n-zVMCloudConnector>=1.3.0;sys_platform!='win32'  # Apache 2.0 License\n futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License"
},
{
"sha":"99d7cdaf104dad07bd7e6c2c1a7409f59eaa7b6a",
"filename":"setup.cfg",
"status":"modified",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/setup.cfg",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/setup.cfg",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/setup.cfg?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -30,6 +30,14 @@ classifiers =\n [extras]\n osprofiler =\n     osprofiler>=1.4.0 # Apache-2.0\n+powervm =\n+    pypowervm>=1.1.15 # Apache-2.0\n+zvm =\n+    zVMCloudConnector>=1.3.0;sys_platform!='win32'  # Apache 2.0 License\n+hyperv =\n+    os-win>=5.4.0 # Apache-2.0\n+vmware =\n+    oslo.vmware>=3.6.0 # Apache-2.0\n \n [files]\n data_files ="
},
{
"sha":"3194e9dd66376277760c1404b32c48c281ffa3eb",
"filename":"test-requirements.txt",
"status":"modified",
"additions":0,
"deletions":3,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/86d87be8db588cc3125d53cd92e271fb45b1a3aa/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/86d87be8db588cc3125d53cd92e271fb45b1a3aa/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=86d87be8db588cc3125d53cd92e271fb45b1a3aa",
"patch":"@@ -23,6 +23,3 @@ testtools>=2.5.0 # MIT\n bandit>=1.1.0 # Apache-2.0\n gabbi>=1.35.0 # Apache-2.0\n wsgi-intercept>=1.7.0 # MIT License\n-\n-# vmwareapi driver specific dependencies\n-oslo.vmware>=3.6.0 # Apache-2.0"
}
]
},
{
"commit_sha":"ff1dbb5eb4525a5e63fb04daae1297e770688862",
"commit_node_id":"C_kwDOAAwOD9oAKGZmMWRiYjVlYjQ1MjVhNWU2M2ZiMDRkYWFlMTI5N2U3NzA2ODg4NjI",
"commit_html_url":"https://github.com/openstack/nova/commit/ff1dbb5eb4525a5e63fb04daae1297e770688862",
"commit_date":"2021-12-23T10:34:07Z",
"files":[
{
"sha":"f4640c6e52d732ab05a5f72fd5fe1580552e17f9",
"filename":"lower-constraints.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/ff1dbb5eb4525a5e63fb04daae1297e770688862/lower-constraints.txt",
"raw_url":"https://github.com/openstack/nova/raw/ff1dbb5eb4525a5e63fb04daae1297e770688862/lower-constraints.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/lower-constraints.txt?ref=ff1dbb5eb4525a5e63fb04daae1297e770688862",
"patch":"@@ -149,7 +149,7 @@ tenacity==6.3.1\n testrepository==0.0.20\n testresources==2.0.0\n testscenarios==0.4\n-testtools==2.2.0\n+testtools==2.5.0\n tooz==1.58.0\n traceback2==1.4.0\n types-paramiko==0.1.3"
},
{
"sha":"3f3c1c0cb5e6e104fb13494ccd7cf6317aebf17a",
"filename":"test-requirements.txt",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/ff1dbb5eb4525a5e63fb04daae1297e770688862/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/ff1dbb5eb4525a5e63fb04daae1297e770688862/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=ff1dbb5eb4525a5e63fb04daae1297e770688862",
"patch":"@@ -19,7 +19,7 @@ stestr>=2.0.0 # Apache-2.0\n osprofiler>=1.4.0 # Apache-2.0\n testresources>=2.0.0 # Apache-2.0/BSD\n testscenarios>=0.4 # Apache-2.0/BSD\n-testtools>=2.2.0 # MIT\n+testtools>=2.5.0 # MIT\n bandit>=1.1.0 # Apache-2.0\n gabbi>=1.35.0 # Apache-2.0\n wsgi-intercept>=1.7.0 # MIT License"
}
]
},
{
"commit_sha":"452913a284a57a6d347c1e09c1a973faae9bccf2",
"commit_node_id":"C_kwDOAAwOD9oAKDQ1MjkxM2EyODRhNTdhNmQzNDdjMWUwOWMxYTk3M2ZhYWU5YmNjZjI",
"commit_html_url":"https://github.com/openstack/nova/commit/452913a284a57a6d347c1e09c1a973faae9bccf2",
"commit_date":"2021-12-22T17:01:28Z",
"files":[
{
"sha":"80511ffad6947ca0565a446e0b73e93fca6d2f54",
"filename":"nova/scheduler/host_manager.py",
"status":"modified",
"additions":1,
"deletions":6,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/452913a284a57a6d347c1e09c1a973faae9bccf2/nova/scheduler/host_manager.py",
"raw_url":"https://github.com/openstack/nova/raw/452913a284a57a6d347c1e09c1a973faae9bccf2/nova/scheduler/host_manager.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/scheduler/host_manager.py?ref=452913a284a57a6d347c1e09c1a973faae9bccf2",
"patch":"@@ -20,11 +20,6 @@\n import collections\n import functools\n import time\n-try:\n-    from collections import UserDict as IterableUserDict   # Python 3\n-except ImportError:\n-    from UserDict import IterableUserDict                  # Python 2\n-\n \n import iso8601\n from oslo_log import log as logging\n@@ -47,7 +42,7 @@\n HOST_INSTANCE_SEMAPHORE = \"host_instance\"\n \n \n-class ReadOnlyDict(IterableUserDict):\n+class ReadOnlyDict(collections.UserDict):\n     \"\"\"A read-only dict.\"\"\"\n \n     def __init__(self, source=None):"
},
{
"sha":"630cb54418883d31e234989bb3a04e32d0520dcb",
"filename":"nova/tests/unit/test_metadata.py",
"status":"modified",
"additions":1,
"deletions":5,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/452913a284a57a6d347c1e09c1a973faae9bccf2/nova/tests/unit/test_metadata.py",
"raw_url":"https://github.com/openstack/nova/raw/452913a284a57a6d347c1e09c1a973faae9bccf2/nova/tests/unit/test_metadata.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/test_metadata.py?ref=452913a284a57a6d347c1e09c1a973faae9bccf2",
"patch":"@@ -20,13 +20,9 @@\n import hashlib\n import hmac\n import os\n+import pickle\n import re\n \n-try:  # python 2\n-    import pickle\n-except ImportError:  # python 3\n-    import cPickle as pickle\n-\n from keystoneauth1 import exceptions as ks_exceptions\n from keystoneauth1 import session\n import mock"
}
]
},
{
"commit_sha":"0396bba4ccfeed74e684da5355fcd17ce997218e",
"commit_node_id":"C_kwDOAAwOD9oAKDAzOTZiYmE0Y2NmZWVkNzRlNjg0ZGE1MzU1ZmNkMTdjZTk5NzIxOGU",
"commit_html_url":"https://github.com/openstack/nova/commit/0396bba4ccfeed74e684da5355fcd17ce997218e",
"commit_date":"2021-12-22T16:29:39Z",
"files":[
{
"sha":"c01169ad8b69a07166dc0ac6551e5193e6ede2ca",
"filename":"lower-constraints.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/0396bba4ccfeed74e684da5355fcd17ce997218e/lower-constraints.txt",
"raw_url":"https://github.com/openstack/nova/raw/0396bba4ccfeed74e684da5355fcd17ce997218e/lower-constraints.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/lower-constraints.txt?ref=0396bba4ccfeed74e684da5355fcd17ce997218e",
"patch":"@@ -65,7 +65,6 @@ os-service-types==1.7.0\n os-traits==2.5.0\n os-vif==1.15.2\n os-win==5.4.0\n-os-xenapi==0.3.4\n osc-lib==1.10.0\n oslo.cache==1.26.0\n oslo.concurrency==4.4.0"
},
{
"sha":"46a611b1debb8544874b5038cb501cb478b23db2",
"filename":"requirements.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/0396bba4ccfeed74e684da5355fcd17ce997218e/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/0396bba4ccfeed74e684da5355fcd17ce997218e/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=0396bba4ccfeed74e684da5355fcd17ce997218e",
"patch":"@@ -55,7 +55,6 @@ os-vif>=1.15.2 # Apache-2.0\n os-win>=5.4.0 # Apache-2.0\n castellan>=0.16.0 # Apache-2.0\n microversion-parse>=0.2.1 # Apache-2.0\n-os-xenapi>=0.3.4 # Apache-2.0\n tooz>=1.58.0 # Apache-2.0\n cursive>=0.2.1 # Apache-2.0\n pypowervm>=1.1.15 # Apache-2.0"
}
]
},
{
"commit_sha":"125a8530ccd42dd1fd11cb883ac088acdd3af062",
"commit_node_id":"C_kwDOAAwOD9oAKDEyNWE4NTMwY2NkNDJkZDFmZDExY2I4ODNhYzA4OGFjZGQzYWYwNjI",
"commit_html_url":"https://github.com/openstack/nova/commit/125a8530ccd42dd1fd11cb883ac088acdd3af062",
"commit_date":"2022-01-25T15:12:32Z",
"files":[
{
"sha":"80f42da3d9c48c5a27a2db356161a596e8279585",
"filename":"nova/tests/unit/virt/libvirt/test_driver.py",
"status":"modified",
"additions":12,
"deletions":4,
"changes":16,
"blob_url":"https://github.com/openstack/nova/blob/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/tests/unit/virt/libvirt/test_driver.py",
"raw_url":"https://github.com/openstack/nova/raw/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/tests/unit/virt/libvirt/test_driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_driver.py?ref=125a8530ccd42dd1fd11cb883ac088acdd3af062",
"patch":"@@ -13616,7 +13616,7 @@ def fake_copy_image(src, dest, **kwargs):\n \n         mock_utime.assert_called()\n         mock_create_cow_image.assert_called_once_with(\n-            backfile_path, '/fake/instance/dir/disk_path')\n+            backfile_path, '/fake/instance/dir/disk_path', virt_disk_size)\n \n     @mock.patch('nova.virt.libvirt.utils.create_image',\n                 new=mock.NonCallableMock())\n@@ -13700,9 +13700,17 @@ def test_create_images_and_backing_ephemeral_gets_created(\n \n             # TODO(efried): Should these be disk_info[path]??\n             mock_create_cow_image.assert_has_calls([\n-                mock.call(root_backing, CONF.instances_path + '/disk'),\n-                mock.call(ephemeral_backing,\n-                          CONF.instances_path + '/disk.local')])\n+                mock.call(\n+                    root_backing,\n+                    CONF.instances_path + '/disk',\n+                    disk_info_byname['disk']['virt_disk_size']\n+                ),\n+                mock.call(\n+                    ephemeral_backing,\n+                    CONF.instances_path + '/disk.local',\n+                    disk_info_byname['disk.local']['virt_disk_size']\n+                ),\n+            ])\n \n     def test_create_images_and_backing_disk_info_none(self):\n         instance = objects.Instance(**self.test_instance)"
},
{
"sha":"decb27f98249356e0dca32f3a94485b82501642b",
"filename":"nova/tests/unit/virt/libvirt/test_imagebackend.py",
"status":"modified",
"additions":5,
"deletions":25,
"changes":30,
"blob_url":"https://github.com/openstack/nova/blob/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/tests/unit/virt/libvirt/test_imagebackend.py",
"raw_url":"https://github.com/openstack/nova/raw/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/tests/unit/virt/libvirt/test_imagebackend.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/libvirt/test_imagebackend.py?ref=125a8530ccd42dd1fd11cb883ac088acdd3af062",
"patch":"@@ -524,30 +524,12 @@ def test_cache_template_exists(self, mock_exists):\n \n     @mock.patch.object(imagebackend.utils, 'synchronized')\n     @mock.patch('nova.virt.libvirt.utils.create_cow_image')\n-    @mock.patch.object(imagebackend.disk, 'extend')\n-    @mock.patch('nova.privsep.path.utime')\n-    def test_create_image(self, mock_utime, mock_extend, mock_create,\n-                          mock_sync):\n-        mock_sync.side_effect = lambda *a, **kw: self._fake_deco\n-        fn = mock.MagicMock()\n-        image = self.image_class(self.INSTANCE, self.NAME)\n-\n-        image.create_image(fn, self.TEMPLATE_PATH, None)\n-\n-        mock_create.assert_called_once_with(self.TEMPLATE_PATH, self.PATH)\n-        fn.assert_called_once_with(target=self.TEMPLATE_PATH)\n-        self.assertTrue(mock_sync.called)\n-        self.assertFalse(mock_extend.called)\n-        mock_utime.assert_called()\n-\n-    @mock.patch.object(imagebackend.utils, 'synchronized')\n-    @mock.patch('nova.virt.libvirt.utils.create_cow_image')\n-    @mock.patch.object(imagebackend.disk, 'extend')\n     @mock.patch.object(os.path, 'exists', side_effect=[])\n     @mock.patch.object(imagebackend.Image, 'verify_base_size')\n     @mock.patch('nova.privsep.path.utime')\n-    def test_create_image_with_size(self, mock_utime, mock_verify, mock_exist,\n-                                    mock_extend, mock_create, mock_sync):\n+    def test_create_image(\n+        self, mock_utime, mock_verify, mock_exist, mock_create, mock_sync\n+    ):\n         mock_sync.side_effect = lambda *a, **kw: self._fake_deco\n         fn = mock.MagicMock()\n         mock_exist.side_effect = [False, True, False, False, False]\n@@ -561,10 +543,8 @@ def test_create_image_with_size(self, mock_utime, mock_verify, mock_exist,\n         image.create_image(fn, self.TEMPLATE_PATH, self.SIZE)\n \n         mock_verify.assert_called_once_with(self.TEMPLATE_PATH, self.SIZE)\n-        mock_create.assert_called_once_with(self.TEMPLATE_PATH, self.PATH)\n-        mock_extend.assert_called_once_with(\n-            imgmodel.LocalFileImage(self.PATH, imgmodel.FORMAT_QCOW2),\n-            self.SIZE)\n+        mock_create.assert_called_once_with(\n+            self.TEMPLATE_PATH, self.PATH, self.SIZE)\n         fn.assert_called_once_with(target=self.TEMPLATE_PATH)\n         mock_exist.assert_has_calls(exist_calls)\n         self.assertTrue(mock_sync.called)"
},
{
"sha":"08bad69489376b1b2e8da81cb0dfe91d59fd8bb7",
"filename":"nova/virt/libvirt/imagebackend.py",
"status":"modified",
"additions":3,
"deletions":9,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/virt/libvirt/imagebackend.py",
"raw_url":"https://github.com/openstack/nova/raw/125a8530ccd42dd1fd11cb883ac088acdd3af062/nova/virt/libvirt/imagebackend.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/imagebackend.py?ref=125a8530ccd42dd1fd11cb883ac088acdd3af062",
"patch":"@@ -624,14 +624,8 @@ def create_image(self, prepare_template, base, size, *args, **kwargs):\n         filename = self._get_lock_name(base)\n \n         @utils.synchronized(filename, external=True, lock_path=self.lock_path)\n-        def copy_qcow2_image(base, target, size):\n-            # TODO(pbrady): Consider copying the cow image here\n-            # with preallocation=metadata set for performance reasons.\n-            # This would be keyed on a 'preallocate_images' setting.\n-            libvirt_utils.create_cow_image(base, target)\n-            if size:\n-                image = imgmodel.LocalFileImage(target, imgmodel.FORMAT_QCOW2)\n-                disk.extend(image, size)\n+        def create_qcow2_image(base, target, size):\n+            libvirt_utils.create_cow_image(base, target, size)\n \n         # Download the unmodified base image unless we already have a copy.\n         if not os.path.exists(base):\n@@ -670,7 +664,7 @@ def copy_qcow2_image(base, target, size):\n \n         if not os.path.exists(self.path):\n             with fileutils.remove_path_on_error(self.path):\n-                copy_qcow2_image(base, self.path, size)\n+                create_qcow2_image(base, self.path, size)\n \n     def resize_image(self, size):\n         image = imgmodel.LocalFileImage(self.path, imgmodel.FORMAT_QCOW2)"
}
]
},
{
"commit_sha":"f87a63a46e9ebae260d9ff8cb140d2c93bed4e1e",
"commit_node_id":"C_kwDOAAwOD9oAKGY4N2E2M2E0NmU5ZWJhZTI2MGQ5ZmY4Y2IxNDBkMmM5M2JlZDRlMWU",
"commit_html_url":"https://github.com/openstack/nova/commit/f87a63a46e9ebae260d9ff8cb140d2c93bed4e1e",
"commit_date":"2022-01-25T01:34:55Z",
"files":[
{
"sha":"7a8ee61911cc44438069f65b1a386b92a36766c5",
"filename":".zuul.yaml",
"status":"modified",
"additions":3,
"deletions":0,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/f87a63a46e9ebae260d9ff8cb140d2c93bed4e1e/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/f87a63a46e9ebae260d9ff8cb140d2c93bed4e1e/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=f87a63a46e9ebae260d9ff8cb140d2c93bed4e1e",
"patch":"@@ -583,6 +583,9 @@\n             voting: false\n         - tempest-integrated-compute-centos-8-stream:\n             irrelevant-files: *nova-base-irrelevant-files\n+        - tempest-centos8-stream-fips:\n+            irrelevant-files: *nova-base-irrelevant-files\n+            voting: false\n     gate:\n       jobs:\n         - nova-live-migration"
}
]
},
{
"commit_sha":"555d859be763fde2c51a900ca416d23d34f10492",
"commit_node_id":"C_kwDOAAwOD9oAKDU1NWQ4NTliZTc2M2ZkZTJjNTFhOTAwY2E0MTZkMjNkMzRmMTA0OTI",
"commit_html_url":"https://github.com/openstack/nova/commit/555d859be763fde2c51a900ca416d23d34f10492",
"commit_date":"2022-01-25T00:48:05Z",
"files":[
{
"sha":"3ef432ae5eb001d41355210dcd8e9e435893e452",
"filename":"nova/tests/functional/regressions/test_bug_1937084.py",
"status":"modified",
"additions":5,
"deletions":23,
"changes":28,
"blob_url":"https://github.com/openstack/nova/blob/555d859be763fde2c51a900ca416d23d34f10492/nova/tests/functional/regressions/test_bug_1937084.py",
"raw_url":"https://github.com/openstack/nova/raw/555d859be763fde2c51a900ca416d23d34f10492/nova/tests/functional/regressions/test_bug_1937084.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/regressions/test_bug_1937084.py?ref=555d859be763fde2c51a900ca416d23d34f10492",
"patch":"@@ -17,7 +17,6 @@\n from nova import context\n from nova import exception\n from nova import objects\n-from nova.tests.functional.api import client\n from nova.tests.functional import integrated_helpers\n \n \n@@ -64,32 +63,15 @@ def test_delete_attachment_volume_not_found(self):\n         ):\n             # DELETE /servers/{server_id}/os-volume_attachments/{volume_id} is\n             # async but as we are using CastAsCall it's sync in our func tests\n-            ex = self.assertRaises(\n-                client.OpenStackApiException,\n-                self.api.delete_server_volume,\n+            self.api.delete_server_volume(\n                 server_id,\n                 self.cinder.IMAGE_BACKED_VOL)\n-            self.assertEqual(500, ex.response.status_code)\n             mock_attachment_delete.assert_called_once()\n \n-        # FIXME(lyarwood): This is the Nova portion of bug #1937084 where\n-        # the original caller hasn't polled os-volume_attachments and sent\n-        # a seperate DELETE request to c-api for the volume as soon as it\n-        # has become available but before n-cpu has finished the original\n-        # call. This leads to the sync request to c-api to delete the\n-        # attachment returning a 404 that Nova translates into\n-        # VolumeAttachmentNotFound.\n-        #\n-        # Replace this with the following once the exception is ignored:\n-        #\n-        #  self.assertRaises(\n-        #      exception.VolumeBDMNotFound,\n-        #      objects.BlockDeviceMapping.get_by_volume_and_instance,\n-        #      context.get_admin_context(),\n-        #      self.cinder.IMAGE_BACKED_VOL,\n-        #      server_id)\n-        #\n-        bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(\n+        # Assert that the volume attachment is still removed in Nova\n+        self.assertRaises(\n+            exception.VolumeBDMNotFound,\n+            objects.BlockDeviceMapping.get_by_volume_and_instance,\n             context.get_admin_context(),\n             self.cinder.IMAGE_BACKED_VOL,\n             server_id)"
},
{
"sha":"aff6c5ef199ed3644f4825c4213e35b59a3501de",
"filename":"nova/tests/unit/virt/test_block_device.py",
"status":"modified",
"additions":13,
"deletions":1,
"changes":14,
"blob_url":"https://github.com/openstack/nova/blob/555d859be763fde2c51a900ca416d23d34f10492/nova/tests/unit/virt/test_block_device.py",
"raw_url":"https://github.com/openstack/nova/raw/555d859be763fde2c51a900ca416d23d34f10492/nova/tests/unit/virt/test_block_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/virt/test_block_device.py?ref=555d859be763fde2c51a900ca416d23d34f10492",
"patch":"@@ -461,7 +461,11 @@ def test_call_wait_delete_volume_fail(self):\n     def test_call_wait_no_delete_volume(self):\n         self._test_call_wait_func(False)\n \n-    def test_volume_delete_attachment(self, include_shared_targets=False):\n+    def test_volume_delete_attachment(\n+        self,\n+        include_shared_targets=False,\n+        delete_attachment_raises=None\n+    ):\n         attachment_id = uuids.attachment\n         driver_bdm = self.driver_classes['volume'](self.volume_bdm)\n         driver_bdm['attachment_id'] = attachment_id\n@@ -488,6 +492,9 @@ def test_volume_delete_attachment(self, include_shared_targets=False):\n         ) as (mock_get_volume, mock_get_connector, mock_guard,\n               vapi_attach_del):\n \n+            if delete_attachment_raises:\n+                vapi_attach_del.side_effect = delete_attachment_raises\n+\n             driver_bdm.detach(elevated_context, instance,\n                               self.volume_api, self.virt_driver,\n                               attachment_id=attachment_id)\n@@ -499,6 +506,11 @@ def test_volume_delete_attachment(self, include_shared_targets=False):\n     def test_volume_delete_attachment_with_shared_targets(self):\n         self.test_volume_delete_attachment(include_shared_targets=True)\n \n+    def test_volume_delete_attachment_raises_attachment_not_found(self):\n+        self.test_volume_delete_attachment(\n+            delete_attachment_raises=exception.VolumeAttachmentNotFound(\n+                attachment_id=uuids.attachment_id))\n+\n     @mock.patch.object(encryptors, 'get_encryption_metadata')\n     @mock.patch.object(objects.BlockDeviceMapping, 'save')\n     def _test_volume_attach(self, driver_bdm, bdm_dict,"
},
{
"sha":"4a4170317462c0a19a1675ba6b46f4ee62035f86",
"filename":"nova/virt/block_device.py",
"status":"modified",
"additions":12,
"deletions":1,
"changes":13,
"blob_url":"https://github.com/openstack/nova/blob/555d859be763fde2c51a900ca416d23d34f10492/nova/virt/block_device.py",
"raw_url":"https://github.com/openstack/nova/raw/555d859be763fde2c51a900ca416d23d34f10492/nova/virt/block_device.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/block_device.py?ref=555d859be763fde2c51a900ca416d23d34f10492",
"patch":"@@ -450,7 +450,18 @@ def _do_detach(self, context, instance, volume_api, virt_driver,\n             volume_api.detach(context.elevated(), volume_id, instance.uuid,\n                               attachment_id)\n         else:\n-            volume_api.attachment_delete(context, self['attachment_id'])\n+            try:\n+                volume_api.attachment_delete(context, self['attachment_id'])\n+            except exception.VolumeAttachmentNotFound:\n+                LOG.info(\n+                    \"Ignoring a volume attachment deletion failure as the \"\n+                    \"volume %(volume_id)s or the volume attachment \"\n+                    \"%(attachment_id)s disappeared during the request.\",\n+                    {\n+                        'volume_id': volume_id,\n+                        'attachment_id': self['attachment_id']\n+                    }\n+                )\n \n     def detach(self, context, instance, volume_api, virt_driver,\n                attachment_id=None, destroy_bdm=False):"
}
]
},
{
"commit_sha":"b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"commit_node_id":"C_kwDOAAwOD9oAKGI5YjFiNGZhNjU3YjIwZjRjZGU4MGM2ZTRkNTYxN2ZjOTU5Mzk1OTA",
"commit_html_url":"https://github.com/openstack/nova/commit/b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"commit_date":"2022-01-25T00:37:20Z",
"files":[
{
"sha":"d60069ce844f91a3f68626e02873f7e74ce11622",
"filename":"nova/api/openstack/wsgi_app.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/api/openstack/wsgi_app.py",
"raw_url":"https://github.com/openstack/nova/raw/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/api/openstack/wsgi_app.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/wsgi_app.py?ref=b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"patch":"@@ -47,7 +47,13 @@ def _get_config_files(env=None):\n \n \n def _setup_service(host, name):\n-    utils.raise_if_old_compute()\n+    try:\n+        utils.raise_if_old_compute()\n+    except exception.TooOldComputeService as e:\n+        if CONF.workarounds.disable_compute_service_check_for_ffu:\n+            LOG.warning(str(e))\n+        else:\n+            raise\n \n     binary = name if name.startswith('nova-') else \"nova-%s\" % name\n "
},
{
"sha":"6d6e1d0adf243357a06988f206c8a13ccdd29fb1",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"patch":"@@ -369,6 +369,16 @@\n Related options:\n \n * :oslo.config:option:`DEFAULT.compute_driver` (libvirt)\n+\"\"\"),\n+    cfg.BoolOpt('disable_compute_service_check_for_ffu',\n+                default=False,\n+                help=\"\"\"\n+If this is set, the normal safety check for old compute services will be\n+treated as a warning instead of an error. This is only to be enabled to\n+facilitate a Fast-Forward upgrade where new control services are being started\n+before compute nodes have been able to update their service record. In an FFU,\n+the service records in the database will be more than one version old until\n+the compute nodes start up, but control services need to be online first.\n \"\"\"),\n ]\n "
},
{
"sha":"2c10224926a3220813e1da124303ee796d1d94cb",
"filename":"nova/service.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/service.py",
"raw_url":"https://github.com/openstack/nova/raw/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/service.py?ref=b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"patch":"@@ -261,7 +261,13 @@ def create(cls, host=None, binary=None, topic=None, manager=None,\n         # up before it allows the service to be created. The\n         # raise_if_old_compute() depends on the RPC to be up and does not\n         # implement its own retry mechanism to connect to the conductor.\n-        utils.raise_if_old_compute()\n+        try:\n+            utils.raise_if_old_compute()\n+        except exception.TooOldComputeService as e:\n+            if CONF.workarounds.disable_compute_service_check_for_ffu:\n+                LOG.warning(str(e))\n+            else:\n+                raise\n \n         return service_obj\n "
},
{
"sha":"247886b9ddfca20f8a4f24ea77ab489ca1cfba46",
"filename":"nova/tests/unit/api/openstack/test_wsgi_app.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/tests/unit/api/openstack/test_wsgi_app.py",
"raw_url":"https://github.com/openstack/nova/raw/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/tests/unit/api/openstack/test_wsgi_app.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/api/openstack/test_wsgi_app.py?ref=b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"patch":"@@ -18,6 +18,7 @@\n from oslotest import base\n \n from nova.api.openstack import wsgi_app\n+from nova import exception\n from nova import test\n from nova.tests import fixtures as nova_fixtures\n \n@@ -87,3 +88,19 @@ def test_init_application_called_twice(\n         wsgi_app.init_application('nova-api')\n         self.assertIn('Global data already initialized, not re-initializing.',\n                       self.stdlog.logger.output)\n+\n+    @mock.patch('nova.objects.Service.get_by_host_and_binary')\n+    @mock.patch('nova.utils.raise_if_old_compute')\n+    def test_setup_service_version_workaround(self, mock_check_old, mock_get):\n+        mock_check_old.side_effect = exception.TooOldComputeService(\n+            oldest_supported_version='2',\n+            scope='scope',\n+            min_service_level=2,\n+            oldest_supported_service=1)\n+\n+        self.assertRaises(exception.TooOldComputeService,\n+                          wsgi_app._setup_service, 'myhost', 'api')\n+        wsgi_app.CONF.set_override(\n+            'disable_compute_service_check_for_ffu', True,\n+            group='workarounds')\n+        wsgi_app._setup_service('myhost', 'api')"
},
{
"sha":"b5721696db8bdab6160a020fffc5098606a8453d",
"filename":"nova/tests/unit/test_service.py",
"status":"modified",
"additions":23,
"deletions":0,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/tests/unit/test_service.py",
"raw_url":"https://github.com/openstack/nova/raw/b9b1b4fa657b20f4cde80c6e4d5617fc95939590/nova/tests/unit/test_service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/test_service.py?ref=b9b1b4fa657b20f4cde80c6e4d5617fc95939590",
"patch":"@@ -287,6 +287,29 @@ def fake_wait(*args, **kwargs):\n         mock_check_old.assert_called_once_with()\n         mock_wait.assert_called_once_with(mock.ANY)\n \n+    @mock.patch('nova.utils.raise_if_old_compute')\n+    def test_old_compute_version_check_workaround(\n+            self, mock_check_old):\n+\n+        mock_check_old.side_effect = exception.TooOldComputeService(\n+            oldest_supported_version='2',\n+            scope='scope',\n+            min_service_level=2,\n+            oldest_supported_service=1)\n+\n+        self.assertRaises(exception.TooOldComputeService,\n+                          service.Service.create,\n+                          self.host, 'nova-conductor', self.topic,\n+                          'nova.tests.unit.test_service.FakeManager')\n+\n+        CONF.set_override('disable_compute_service_check_for_ffu', True,\n+                          group='workarounds')\n+\n+        service.Service.create(self.host, 'nova-conductor', self.topic,\n+                               'nova.tests.unit.test_service.FakeManager')\n+\n+        mock_check_old.assert_has_calls([mock.call(), mock.call()])\n+\n \n class TestWSGIService(test.NoDBTestCase):\n "
}
]
},
{
"commit_sha":"7d2e4815892ddd523c21bf1785cc113981871998",
"commit_node_id":"C_kwDOAAwOD9oAKDdkMmU0ODE1ODkyZGRkNTIzYzIxYmYxNzg1Y2MxMTM5ODE4NzE5OTg",
"commit_html_url":"https://github.com/openstack/nova/commit/7d2e4815892ddd523c21bf1785cc113981871998",
"commit_date":"2022-01-21T20:51:35Z",
"files":[
{
"sha":"d60069ce844f91a3f68626e02873f7e74ce11622",
"filename":"nova/api/openstack/wsgi_app.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/7d2e4815892ddd523c21bf1785cc113981871998/nova/api/openstack/wsgi_app.py",
"raw_url":"https://github.com/openstack/nova/raw/7d2e4815892ddd523c21bf1785cc113981871998/nova/api/openstack/wsgi_app.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/api/openstack/wsgi_app.py?ref=7d2e4815892ddd523c21bf1785cc113981871998",
"patch":"@@ -47,7 +47,13 @@ def _get_config_files(env=None):\n \n \n def _setup_service(host, name):\n-    utils.raise_if_old_compute()\n+    try:\n+        utils.raise_if_old_compute()\n+    except exception.TooOldComputeService as e:\n+        if CONF.workarounds.disable_compute_service_check_for_ffu:\n+            LOG.warning(str(e))\n+        else:\n+            raise\n \n     binary = name if name.startswith('nova-') else \"nova-%s\" % name\n "
},
{
"sha":"6d6e1d0adf243357a06988f206c8a13ccdd29fb1",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/7d2e4815892ddd523c21bf1785cc113981871998/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/7d2e4815892ddd523c21bf1785cc113981871998/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=7d2e4815892ddd523c21bf1785cc113981871998",
"patch":"@@ -369,6 +369,16 @@\n Related options:\n \n * :oslo.config:option:`DEFAULT.compute_driver` (libvirt)\n+\"\"\"),\n+    cfg.BoolOpt('disable_compute_service_check_for_ffu',\n+                default=False,\n+                help=\"\"\"\n+If this is set, the normal safety check for old compute services will be\n+treated as a warning instead of an error. This is only to be enabled to\n+facilitate a Fast-Forward upgrade where new control services are being started\n+before compute nodes have been able to update their service record. In an FFU,\n+the service records in the database will be more than one version old until\n+the compute nodes start up, but control services need to be online first.\n \"\"\"),\n ]\n "
},
{
"sha":"2c10224926a3220813e1da124303ee796d1d94cb",
"filename":"nova/service.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/7d2e4815892ddd523c21bf1785cc113981871998/nova/service.py",
"raw_url":"https://github.com/openstack/nova/raw/7d2e4815892ddd523c21bf1785cc113981871998/nova/service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/service.py?ref=7d2e4815892ddd523c21bf1785cc113981871998",
"patch":"@@ -261,7 +261,13 @@ def create(cls, host=None, binary=None, topic=None, manager=None,\n         # up before it allows the service to be created. The\n         # raise_if_old_compute() depends on the RPC to be up and does not\n         # implement its own retry mechanism to connect to the conductor.\n-        utils.raise_if_old_compute()\n+        try:\n+            utils.raise_if_old_compute()\n+        except exception.TooOldComputeService as e:\n+            if CONF.workarounds.disable_compute_service_check_for_ffu:\n+                LOG.warning(str(e))\n+            else:\n+                raise\n \n         return service_obj\n "
},
{
"sha":"247886b9ddfca20f8a4f24ea77ab489ca1cfba46",
"filename":"nova/tests/unit/api/openstack/test_wsgi_app.py",
"status":"modified",
"additions":17,
"deletions":0,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/7d2e4815892ddd523c21bf1785cc113981871998/nova/tests/unit/api/openstack/test_wsgi_app.py",
"raw_url":"https://github.com/openstack/nova/raw/7d2e4815892ddd523c21bf1785cc113981871998/nova/tests/unit/api/openstack/test_wsgi_app.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/api/openstack/test_wsgi_app.py?ref=7d2e4815892ddd523c21bf1785cc113981871998",
"patch":"@@ -18,6 +18,7 @@\n from oslotest import base\n \n from nova.api.openstack import wsgi_app\n+from nova import exception\n from nova import test\n from nova.tests import fixtures as nova_fixtures\n \n@@ -87,3 +88,19 @@ def test_init_application_called_twice(\n         wsgi_app.init_application('nova-api')\n         self.assertIn('Global data already initialized, not re-initializing.',\n                       self.stdlog.logger.output)\n+\n+    @mock.patch('nova.objects.Service.get_by_host_and_binary')\n+    @mock.patch('nova.utils.raise_if_old_compute')\n+    def test_setup_service_version_workaround(self, mock_check_old, mock_get):\n+        mock_check_old.side_effect = exception.TooOldComputeService(\n+            oldest_supported_version='2',\n+            scope='scope',\n+            min_service_level=2,\n+            oldest_supported_service=1)\n+\n+        self.assertRaises(exception.TooOldComputeService,\n+                          wsgi_app._setup_service, 'myhost', 'api')\n+        wsgi_app.CONF.set_override(\n+            'disable_compute_service_check_for_ffu', True,\n+            group='workarounds')\n+        wsgi_app._setup_service('myhost', 'api')"
},
{
"sha":"b5721696db8bdab6160a020fffc5098606a8453d",
"filename":"nova/tests/unit/test_service.py",
"status":"modified",
"additions":23,
"deletions":0,
"changes":23,
"blob_url":"https://github.com/openstack/nova/blob/7d2e4815892ddd523c21bf1785cc113981871998/nova/tests/unit/test_service.py",
"raw_url":"https://github.com/openstack/nova/raw/7d2e4815892ddd523c21bf1785cc113981871998/nova/tests/unit/test_service.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/test_service.py?ref=7d2e4815892ddd523c21bf1785cc113981871998",
"patch":"@@ -287,6 +287,29 @@ def fake_wait(*args, **kwargs):\n         mock_check_old.assert_called_once_with()\n         mock_wait.assert_called_once_with(mock.ANY)\n \n+    @mock.patch('nova.utils.raise_if_old_compute')\n+    def test_old_compute_version_check_workaround(\n+            self, mock_check_old):\n+\n+        mock_check_old.side_effect = exception.TooOldComputeService(\n+            oldest_supported_version='2',\n+            scope='scope',\n+            min_service_level=2,\n+            oldest_supported_service=1)\n+\n+        self.assertRaises(exception.TooOldComputeService,\n+                          service.Service.create,\n+                          self.host, 'nova-conductor', self.topic,\n+                          'nova.tests.unit.test_service.FakeManager')\n+\n+        CONF.set_override('disable_compute_service_check_for_ffu', True,\n+                          group='workarounds')\n+\n+        service.Service.create(self.host, 'nova-conductor', self.topic,\n+                               'nova.tests.unit.test_service.FakeManager')\n+\n+        mock_check_old.assert_has_calls([mock.call(), mock.call()])\n+\n \n class TestWSGIService(test.NoDBTestCase):\n "
}
]
},
{
"commit_sha":"96731a499a43ecec6744e9b047338b967374baed",
"commit_node_id":"C_kwDOAAwOD9oAKDk2NzMxYTQ5OWE0M2VjZWM2NzQ0ZTliMDQ3MzM4Yjk2NzM3NGJhZWQ",
"commit_html_url":"https://github.com/openstack/nova/commit/96731a499a43ecec6744e9b047338b967374baed",
"commit_date":"2022-01-23T03:58:10Z",
"files":[
{
"sha":"71ce48ff90e8c8c1b6c18513abcf95c87ea7c31b",
"filename":"nova/conf/cinder.py",
"status":"modified",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/96731a499a43ecec6744e9b047338b967374baed/nova/conf/cinder.py",
"raw_url":"https://github.com/openstack/nova/raw/96731a499a43ecec6744e9b047338b967374baed/nova/conf/cinder.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/cinder.py?ref=96731a499a43ecec6744e9b047338b967374baed",
"patch":"@@ -103,6 +103,12 @@\n Related options:\n \n * ``[DEFAULT]/default_schedule_zone``\n+\"\"\"),\n+    cfg.BoolOpt('debug',\n+        default=False,\n+        help=\"\"\"\n+Enable DEBUG logging with cinderclient and os_brick independently of the rest\n+of Nova.\n \"\"\"),\n ]\n "
},
{
"sha":"545fc5714591da851aaf25278473674368f0ccf3",
"filename":"nova/config.py",
"status":"modified",
"additions":5,
"deletions":0,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/96731a499a43ecec6744e9b047338b967374baed/nova/config.py",
"raw_url":"https://github.com/openstack/nova/raw/96731a499a43ecec6744e9b047338b967374baed/nova/config.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/config.py?ref=96731a499a43ecec6744e9b047338b967374baed",
"patch":"@@ -70,6 +70,11 @@ def set_log_defaults():\n         extra_default_log_levels = ['glanceclient=DEBUG']\n     else:\n         extra_default_log_levels = ['glanceclient=WARN']\n+\n+    # Allow cinderclient and os_brick to log at DEBUG without Nova\n+    if CONF.cinder.debug:\n+        extra_default_log_levels += ['cinderclient=DEBUG', 'os_brick=DEBUG']\n+\n     # NOTE(danms): DEBUG logging in privsep will result in some large\n     # and potentially sensitive things being logged.\n     extra_default_log_levels.append('oslo.privsep.daemon=INFO')"
},
{
"sha":"5eb8a764251051e298328bf72aa121fe190a2e9a",
"filename":"releasenotes/notes/cinder-debug-c522618d82987971.yaml",
"status":"added",
"additions":6,
"deletions":0,
"changes":6,
"blob_url":"https://github.com/openstack/nova/blob/96731a499a43ecec6744e9b047338b967374baed/releasenotes/notes/cinder-debug-c522618d82987971.yaml",
"raw_url":"https://github.com/openstack/nova/raw/96731a499a43ecec6744e9b047338b967374baed/releasenotes/notes/cinder-debug-c522618d82987971.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/cinder-debug-c522618d82987971.yaml?ref=96731a499a43ecec6744e9b047338b967374baed",
"patch":"@@ -0,0 +1,6 @@\n+---\n+features:\n+  - |\n+    A new ``[cinder]/debug`` configurable has been introduced to enable DEBUG\n+    logging for both the ``python-cinderclient`` and ``os-brick`` libraries\n+    independently to the rest of Nova."
}
]
},
{
"commit_sha":"ae779740c55424699948a1d05609fd7684fe0f22",
"commit_node_id":"C_kwDOAAwOD9oAKGFlNzc5NzQwYzU1NDI0Njk5OTQ4YTFkMDU2MDlmZDc2ODRmZTBmMjI",
"commit_html_url":"https://github.com/openstack/nova/commit/ae779740c55424699948a1d05609fd7684fe0f22",
"commit_date":"2022-01-22T02:18:09Z",
"files":[
{
"sha":"f33ce0a5fac02399c24efbb6ea6316f5741c6674",
"filename":".zuul.yaml",
"status":"modified",
"additions":7,
"deletions":0,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/ae779740c55424699948a1d05609fd7684fe0f22/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/ae779740c55424699948a1d05609fd7684fe0f22/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=ae779740c55424699948a1d05609fd7684fe0f22",
"patch":"@@ -214,10 +214,13 @@\n       Starting in Train, the job enabled counting quota usage from placement.\n       Starting in Ussuri, the job was changed to multinode.\n       Starting in Wallaby, the job defaults to the q35 machine type.\n+      Starting in Yoga, the job tests noVNC from source.\n       Runs all tempest compute API and most scenario tests concurrently.\n     irrelevant-files: *nova-base-irrelevant-files\n     # Run post-tempest tests like for nova-manage commands.\n     post-run: playbooks/nova-next/post.yaml\n+    required-projects:\n+        - novnc/novnc\n     vars:\n       # We use the \"all\" environment for tempest_test_regex and\n       # tempest_exclude_regex.\n@@ -290,6 +293,8 @@\n         ENABLE_VOLUME_MULTIATTACH: True\n         # Added in Ussuri.\n         FORCE_CONFIG_DRIVE: True\n+        # Added in Yoga.\n+        NOVNC_FROM_PACKAGE: False\n       devstack_services:\n         # Disable OVN services\n         br-ex-tcpdump: false\n@@ -322,6 +327,8 @@\n           NOVA_USE_SERVICE_TOKEN: True\n           NOVA_CONSOLE_PROXY_COMPUTE_TLS: True\n           FORCE_CONFIG_DRIVE: True\n+          # Added in Yoga.\n+          NOVNC_FROM_PACKAGE: False\n         devstack_services:\n           # Disable OVN services\n           br-ex-tcpdump: false"
}
]
},
{
"commit_sha":"5ad0d0cdbe86c9d714628ea4e4e08cf9a03ad93d",
"commit_node_id":"C_kwDOAAwOD9oAKDVhZDBkMGNkYmU4NmM5ZDcxNDYyOGVhNGU0ZTA4Y2Y5YTAzYWQ5M2Q",
"commit_html_url":"https://github.com/openstack/nova/commit/5ad0d0cdbe86c9d714628ea4e4e08cf9a03ad93d",
"commit_date":"2022-01-21T21:08:48Z",
"files":[
{
"sha":"f714a5f04300870022842049f2926bc20c34e5c2",
"filename":"nova/tests/functional/libvirt/test_live_migration.py",
"status":"added",
"additions":117,
"deletions":0,
"changes":117,
"blob_url":"https://github.com/openstack/nova/blob/5ad0d0cdbe86c9d714628ea4e4e08cf9a03ad93d/nova/tests/functional/libvirt/test_live_migration.py",
"raw_url":"https://github.com/openstack/nova/raw/5ad0d0cdbe86c9d714628ea4e4e08cf9a03ad93d/nova/tests/functional/libvirt/test_live_migration.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/libvirt/test_live_migration.py?ref=5ad0d0cdbe86c9d714628ea4e4e08cf9a03ad93d",
"patch":"@@ -0,0 +1,117 @@\n+# Copyright 2021 Red Hat, Inc.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import threading\n+\n+from lxml import etree\n+from nova.tests.functional import integrated_helpers\n+from nova.tests.functional.libvirt import base as libvirt_base\n+\n+\n+class LiveMigrationQueuedAbortTest(\n+    libvirt_base.LibvirtMigrationMixin,\n+    libvirt_base.ServersTestBase,\n+    integrated_helpers.InstanceHelperMixin\n+):\n+    \"\"\"Functional test for bug 1949808.\n+\n+    This test is used to confirm that VM's state is reverted properly\n+    when queued Live migration is aborted.\n+    \"\"\"\n+\n+    api_major_version = 'v2.1'\n+    microversion = '2.74'\n+    ADMIN_API = True\n+\n+    def setUp(self):\n+        super().setUp()\n+\n+        # We will allow only one live migration to be processed at any\n+        # given period of time\n+        self.flags(max_concurrent_live_migrations='1')\n+        self.src_hostname = self.start_compute(hostname='src')\n+        self.dest_hostname = self.start_compute(hostname='dest')\n+\n+        self.src = self.computes[self.src_hostname]\n+        self.dest = self.computes[self.dest_hostname]\n+\n+        # Live migration's execution could be locked if needed\n+        self.lock_live_migration = threading.Lock()\n+\n+    def _migrate_stub(self, domain, destination, params, flags):\n+        # Execute only if live migration is not locked\n+        with self.lock_live_migration:\n+            self.dest.driver._host.get_connection().createXML(\n+                params['destination_xml'],\n+                'fake-createXML-doesnt-care-about-flags')\n+            conn = self.src.driver._host.get_connection()\n+\n+            # Because migrateToURI3 is spawned in a background thread,\n+            # this method does not block the upper nova layers. Because\n+            # we don't want nova to think the live migration has\n+            # finished until this method is done, the last thing we do\n+            # is make fakelibvirt's Domain.jobStats() return\n+            # VIR_DOMAIN_JOB_COMPLETED.\n+            server = etree.fromstring(\n+                params['destination_xml']\n+            ).find('./uuid').text\n+            dom = conn.lookupByUUIDString(server)\n+            dom.complete_job()\n+\n+    def test_queued_live_migration_abort(self):\n+        # Lock live migrations\n+        self.lock_live_migration.acquire()\n+\n+        # Start instances: first one would be used to occupy\n+        # executor's live migration queue, second one would be used\n+        # to actually confirm that queued live migrations are\n+        # aborted properly.\n+        self.server_a = self._create_server(\n+            host=self.src_hostname, networks='none')\n+        self.server_b = self._create_server(\n+            host=self.src_hostname, networks='none')\n+        # Issue live migration requests for both servers. We expect that\n+        # server_a live migration would be running, but locked by\n+        # self.lock_live_migration and server_b live migration would be\n+        # queued.\n+        self._live_migrate(\n+            self.server_a,\n+            migration_expected_state='running',\n+            server_expected_state='MIGRATING'\n+        )\n+        self._live_migrate(\n+            self.server_b,\n+            migration_expected_state='queued',\n+            server_expected_state='MIGRATING'\n+        )\n+\n+        # Abort live migration for server_b\n+        serverb_migration = self.api.api_get(\n+            '/os-migrations?instance_uuid=%s' % self.server_b['id']\n+        ).body['migrations'].pop()\n+\n+        self.api.api_delete(\n+            '/servers/%s/migrations/%s' % (self.server_b['id'],\n+                                           serverb_migration['id']))\n+        self._wait_for_migration_status(self.server_b, ['cancelled'])\n+        # Unlock live migrations and confirm that server_a becomes\n+        # active again after successful live migration\n+        self.lock_live_migration.release()\n+        self._wait_for_state_change(self.server_a, 'ACTIVE')\n+\n+        # FIXME(artom) Assert the server_b never comes out of 'MIGRATING'\n+        self.assertRaises(\n+            AssertionError,\n+            self._wait_for_state_change, self.server_b, 'ACTIVE')\n+        self._wait_for_state_change(self.server_b, 'MIGRATING')"
}
]
},
{
"commit_sha":"34f841333b367ac0ca999d60fa31b048b5abd4c4",
"commit_node_id":"C_kwDOAAwOD9oAKDM0Zjg0MTMzM2IzNjdhYzBjYTk5OWQ2MGZhMzFiMDQ4YjVhYmQ0YzQ",
"commit_html_url":"https://github.com/openstack/nova/commit/34f841333b367ac0ca999d60fa31b048b5abd4c4",
"commit_date":"2022-01-21T21:08:39Z",
"files":[
{
"sha":"4238365135bf23b524d5d4a54befcf14d37a44da",
"filename":".zuul.yaml",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/34f841333b367ac0ca999d60fa31b048b5abd4c4/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/34f841333b367ac0ca999d60fa31b048b5abd4c4/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=34f841333b367ac0ca999d60fa31b048b5abd4c4",
"patch":"@@ -4,7 +4,7 @@\n - job:\n     name: nova-tox-functional-centos8-py36\n     parent: openstack-tox-functional-py36\n-    nodeset: devstack-single-node-centos-8\n+    nodeset: devstack-single-node-centos-8-stream\n     description: |\n       Run tox-based functional tests for the OpenStack Nova project\n       under cPython version 3.6 with Nova specific irrelevant-files list."
}
]
},
{
"commit_sha":"52b974acb715e1c7896125a90df39fba887f052a",
"commit_node_id":"C_kwDOAAwOD9oAKDUyYjk3NGFjYjcxNWUxYzc4OTYxMjVhOTBkZjM5ZmJhODg3ZjA1MmE",
"commit_html_url":"https://github.com/openstack/nova/commit/52b974acb715e1c7896125a90df39fba887f052a",
"commit_date":"2022-01-21T13:44:48Z",
"files":[
{
"sha":"ef873f6654a6f333e4085fbcacd09b6686e32644",
"filename":"nova/tests/fixtures/nova.py",
"status":"modified",
"additions":0,
"deletions":12,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/52b974acb715e1c7896125a90df39fba887f052a/nova/tests/fixtures/nova.py",
"raw_url":"https://github.com/openstack/nova/raw/52b974acb715e1c7896125a90df39fba887f052a/nova/tests/fixtures/nova.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/nova.py?ref=52b974acb715e1c7896125a90df39fba887f052a",
"patch":"@@ -836,12 +836,6 @@ def setUp(self):\n         # ...but filter everything out until we get around to fixing them\n         # TODO(stephenfin): Fix all of these\n \n-        warnings.filterwarnings(\n-            'ignore',\n-            module='nova',\n-            message=r'The Engine.execute\\(\\) method is considered legacy',\n-            category=sqla_exc.SADeprecationWarning)\n-\n         warnings.filterwarnings(\n             'ignore',\n             module='nova',\n@@ -854,12 +848,6 @@ def setUp(self):\n             message=r'The Column.copy\\(\\) method is deprecated .*',\n             category=sqla_exc.SADeprecationWarning)\n \n-        warnings.filterwarnings(\n-            'ignore',\n-            module='nova',\n-            message=r'The .close\\(\\) method on a so-called .*',\n-            category=sqla_exc.SADeprecationWarning)\n-\n         warnings.filterwarnings(\n             'ignore',\n             module='nova',"
}
]
},
{
"commit_sha":"5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"commit_node_id":"C_kwDOAAwOD9oAKDVjN2ZhNmQxMzkzOGEyZWM0M2RkMjMyOTkzNTUwZmQwZWU2YjkxNjU",
"commit_html_url":"https://github.com/openstack/nova/commit/5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"commit_date":"2022-01-21T13:44:40Z",
"files":[
{
"sha":"6b82b17e4b202cc9e2edab27275f0f6aed1fb745",
"filename":"nova/db/api/legacy_migrations/versions/067_train.py",
"status":"modified",
"additions":3,
"deletions":0,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/api/legacy_migrations/versions/067_train.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/api/legacy_migrations/versions/067_train.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/db/api/legacy_migrations/versions/067_train.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -27,6 +27,9 @@ def InetSmall():\n \n def upgrade(migrate_engine):\n     meta = sa.MetaData()\n+    # NOTE(stephenfin): This is not compatible with SQLAlchemy 2.0 but neither\n+    # is sqlalchemy-migrate which requires this. We'll remove these migrations\n+    # when dropping SQLAlchemy < 2.x support\n     meta.bind = migrate_engine\n \n     cell_mappings = sa.Table('cell_mappings', meta,"
},
{
"sha":"4c40be905ef7cd8a82f1af2ebb1ce586e71bc3e4",
"filename":"nova/db/main/api.py",
"status":"modified",
"additions":9,
"deletions":8,
"changes":17,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/api.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/db/main/api.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -4233,8 +4233,9 @@ def _get_fk_stmts(metadata, conn, table, column, records):\n     return inserts, deletes\n \n \n-def _archive_deleted_rows_for_table(metadata, tablename, max_rows, before,\n-                                    task_log):\n+def _archive_deleted_rows_for_table(\n+    metadata, engine, tablename, max_rows, before, task_log,\n+):\n     \"\"\"Move up to max_rows rows from one tables to the corresponding\n     shadow table.\n \n@@ -4249,7 +4250,7 @@ def _archive_deleted_rows_for_table(metadata, tablename, max_rows, before,\n         - number of extra rows archived (due to FK constraints)\n           dict of {tablename: rows_archived}\n     \"\"\"\n-    conn = metadata.bind.connect()\n+    conn = engine.connect()\n     # NOTE(tdurakov): table metadata should be received\n     # from models, not db tables. Default value specified by SoftDeleteMixin\n     # is known only by models, not DB layer.\n@@ -4382,8 +4383,9 @@ def archive_deleted_rows(context=None, max_rows=None, before=None,\n     table_to_rows_archived = collections.defaultdict(int)\n     deleted_instance_uuids = []\n     total_rows_archived = 0\n-    meta = sa.MetaData(get_engine(use_slave=True, context=context))\n-    meta.reflect()\n+    meta = sa.MetaData()\n+    engine = get_engine(use_slave=True, context=context)\n+    meta.reflect(bind=engine)\n     # Get the sorted list of tables in order of foreign key dependency.\n     # Process the parent tables and find their dependent records in order to\n     # archive the related records in a single database transactions. The goal\n@@ -4409,7 +4411,7 @@ def archive_deleted_rows(context=None, max_rows=None, before=None,\n \n         rows_archived, _deleted_instance_uuids, extras = (\n             _archive_deleted_rows_for_table(\n-                meta, tablename,\n+                meta, engine, tablename,\n                 max_rows=max_rows - total_rows_archived,\n                 before=before,\n                 task_log=task_log))\n@@ -4437,8 +4439,7 @@ def purge_shadow_tables(context, before_date, status_fn=None):\n     engine = get_engine(context=context)\n     conn = engine.connect()\n     metadata = sa.MetaData()\n-    metadata.bind = engine\n-    metadata.reflect()\n+    metadata.reflect(bind=engine)\n     total_deleted = 0\n \n     if status_fn is None:"
},
{
"sha":"ad6e65d011d9ce602c7b445c6118835c28ea2ae1",
"filename":"nova/db/main/legacy_migrations/versions/402_train.py",
"status":"modified",
"additions":7,
"deletions":1,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/legacy_migrations/versions/402_train.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/legacy_migrations/versions/402_train.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/db/main/legacy_migrations/versions/402_train.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -45,10 +45,13 @@ def process(element, compiler, **kw):\n \n \n def _create_shadow_tables(migrate_engine):\n-    meta = sa.MetaData(migrate_engine)\n+    meta = sa.MetaData()\n     meta.reflect(migrate_engine)\n     table_names = list(meta.tables.keys())\n \n+    # NOTE(stephenfin): This is not compatible with SQLAlchemy 2.0 but neither\n+    # is sqlalchemy-migrate which requires this. We'll remove these migrations\n+    # when dropping SQLAlchemy < 2.x support\n     meta.bind = migrate_engine\n \n     for table_name in table_names:\n@@ -184,6 +187,9 @@ def _create_shadow_tables(migrate_engine):\n \n def upgrade(migrate_engine):\n     meta = sa.MetaData()\n+    # NOTE(stephenfin): This is not compatible with SQLAlchemy 2.0 but neither\n+    # is sqlalchemy-migrate which requires this. We'll remove these migrations\n+    # when dropping SQLAlchemy < 2.x support\n     meta.bind = migrate_engine\n \n     agent_builds = sa.Table('agent_builds', meta,"
},
{
"sha":"33bd840f2500b0db8c889efc114931d9dd258b67",
"filename":"nova/db/main/migrations/versions/8f2f1571d55b_initial_version.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/migrations/versions/8f2f1571d55b_initial_version.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/db/main/migrations/versions/8f2f1571d55b_initial_version.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/db/main/migrations/versions/8f2f1571d55b_initial_version.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -53,8 +53,8 @@ def process(element, compiler, **kw):\n \n \n def _create_shadow_tables(connection):\n-    meta = sa.MetaData(connection)\n-    meta.reflect(connection)\n+    meta = sa.MetaData()\n+    meta.reflect(bind=connection)\n     table_names = list(meta.tables.keys())\n \n     for table_name in table_names:"
},
{
"sha":"705cc350b8b6120436f16dc5131c2a9999f93c2b",
"filename":"nova/tests/fixtures/nova.py",
"status":"modified",
"additions":0,
"deletions":12,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/fixtures/nova.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/fixtures/nova.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/nova.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -848,18 +848,6 @@ def setUp(self):\n             message=r'The current statement is being autocommitted .*',\n             category=sqla_exc.SADeprecationWarning)\n \n-        warnings.filterwarnings(\n-            'ignore',\n-            module='nova',\n-            message=r'The MetaData.bind argument is deprecated .*',\n-            category=sqla_exc.SADeprecationWarning)\n-\n-        warnings.filterwarnings(\n-            'ignore',\n-            module='nova',\n-            message=r'The ``bind`` argument for schema methods .*',\n-            category=sqla_exc.SADeprecationWarning)\n-\n         warnings.filterwarnings(\n             'ignore',\n             module='nova',"
},
{
"sha":"4a813d10a7c6709206a3048384e36988b89755d8",
"filename":"nova/tests/functional/db/test_archive.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/functional/db/test_archive.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/functional/db/test_archive.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/db/test_archive.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -177,8 +177,8 @@ def test_archive_deleted_rows_incomplete(self):\n     def _get_table_counts(self):\n         engine = db.get_engine()\n         conn = engine.connect()\n-        meta = sa.MetaData(engine)\n-        meta.reflect()\n+        meta = sa.MetaData()\n+        meta.reflect(bind=engine)\n         shadow_tables = db._purgeable_tables(meta)\n         results = {}\n         for table in shadow_tables:"
},
{
"sha":"c9a9e83154ac952089515e702369d9eac42c037b",
"filename":"nova/tests/unit/db/main/test_api.py",
"status":"modified",
"additions":21,
"deletions":14,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/unit/db/main/test_api.py",
"raw_url":"https://github.com/openstack/nova/raw/5c7fa6d13938a2ec43dd232993550fd0ee6b9165/nova/tests/unit/db/main/test_api.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/db/main/test_api.py?ref=5c7fa6d13938a2ec43dd232993550fd0ee6b9165",
"patch":"@@ -5652,7 +5652,7 @@ class ArchiveTestCase(test.TestCase, ModelsObjectComparatorMixin):\n     def setUp(self):\n         super(ArchiveTestCase, self).setUp()\n         self.engine = db.get_engine()\n-        self.metadata = sa.MetaData(self.engine)\n+        self.metadata = sa.MetaData()\n         self.conn = self.engine.connect()\n         self.instance_id_mappings = models.InstanceIdMapping.__table__\n         self.shadow_instance_id_mappings = sqlalchemyutils.get_table(\n@@ -5684,8 +5684,8 @@ def _assert_shadow_tables_empty_except(self, *exceptions):\n         except for specificially named exceptions, are empty. This\n         makes sure that archiving isn't moving unexpected content.\n         \"\"\"\n-        metadata = sa.MetaData(bind=self.engine)\n-        metadata.reflect()\n+        metadata = sa.MetaData()\n+        metadata.reflect(bind=self.engine)\n         for table in metadata.tables:\n             if table.startswith(\"shadow_\") and table not in exceptions:\n                 rows = self.conn.exec_driver_sql(\n@@ -5698,8 +5698,8 @@ def test_shadow_tables(self):\n \n         Shadow tables should have an identical schema to the main table.\n         \"\"\"\n-        metadata = sa.MetaData(bind=self.engine)\n-        metadata.reflect()\n+        metadata = sa.MetaData()\n+        metadata.reflect(bind=self.engine)\n         for table_name in metadata.tables:\n             # some tables don't have shadow tables so skip these\n             if table_name in [\n@@ -5942,7 +5942,9 @@ def _test_archive_deleted_rows_for_one_uuid_table(self, tablename):\n         self.assertEqual(len(rows), 0)\n         # Archive 2 rows\n         db._archive_deleted_rows_for_table(\n-            self.metadata, tablename, max_rows=2, before=None, task_log=False)\n+            self.metadata, self.engine, tablename, max_rows=2, before=None,\n+            task_log=False,\n+        )\n         # Verify we have 4 left in main\n         rows = self.conn.execute(qmt).fetchall()\n         self.assertEqual(len(rows), 4)\n@@ -5951,7 +5953,9 @@ def _test_archive_deleted_rows_for_one_uuid_table(self, tablename):\n         self.assertEqual(len(rows), 2)\n         # Archive 2 more rows\n         db._archive_deleted_rows_for_table(\n-            self.metadata, tablename, max_rows=2, before=None, task_log=False)\n+            self.metadata, self.engine, tablename, max_rows=2, before=None,\n+            task_log=False,\n+        )\n         # Verify we have 2 left in main\n         rows = self.conn.execute(qmt).fetchall()\n         self.assertEqual(len(rows), 2)\n@@ -5960,7 +5964,9 @@ def _test_archive_deleted_rows_for_one_uuid_table(self, tablename):\n         self.assertEqual(len(rows), 4)\n         # Try to archive more, but there are no deleted rows left.\n         db._archive_deleted_rows_for_table(\n-            self.metadata, tablename, max_rows=2, before=None, task_log=False)\n+            self.metadata, self.engine, tablename, max_rows=2, before=None,\n+            task_log=False,\n+        )\n         # Verify we still have 2 left in main\n         rows = self.conn.execute(qmt).fetchall()\n         self.assertEqual(len(rows), 2)\n@@ -6019,8 +6025,8 @@ def test_archive_deleted_rows_for_migrations(self):\n         # Archiving instances should result in migrations related to the\n         # instances also being archived.\n         num = db._archive_deleted_rows_for_table(\n-            self.metadata, \"instances\", max_rows=None, before=None,\n-            task_log=False)\n+            self.metadata, self.engine, \"instances\", max_rows=None,\n+            before=None, task_log=False)\n         self.assertEqual(1, num[0])\n         self._assert_shadow_tables_empty_except(\n             'shadow_instances',\n@@ -6386,7 +6392,8 @@ def call_api(*args, **kwargs):\n \n \n class TestSqlalchemyTypesRepr(\n-        test_fixtures.OpportunisticDBTestMixin, test.NoDBTestCase):\n+    test_fixtures.OpportunisticDBTestMixin, test.NoDBTestCase,\n+):\n \n     def setUp(self):\n         # NOTE(sdague): the oslo_db base test case completely\n@@ -6397,15 +6404,15 @@ def setUp(self):\n \n         super(TestSqlalchemyTypesRepr, self).setUp()\n         self.engine = enginefacade.writer.get_engine()\n-        meta = sa.MetaData(bind=self.engine)\n+        meta = sa.MetaData()\n         self.table = sa.Table(\n             'cidr_tbl',\n             meta,\n             sa.Column('id', sa.Integer, primary_key=True),\n             sa.Column('addr', col_types.CIDR())\n         )\n-        self.table.create()\n-        self.addCleanup(meta.drop_all)\n+        meta.create_all(self.engine)\n+        self.addCleanup(meta.drop_all, self.engine)\n \n     def test_cidr_repr(self):\n         addrs = [('192.168.3.0/24', '192.168.3.0/24'),"
}
]
},
{
"commit_sha":"bb2984b9c772d6eb9e594e90fc3a0a864d583d2d",
"commit_node_id":"C_kwDOAAwOD9oAKGJiMjk4NGI5Yzc3MmQ2ZWI5ZTU5NGU5MGZjM2EwYTg2NGQ1ODNkMmQ",
"commit_html_url":"https://github.com/openstack/nova/commit/bb2984b9c772d6eb9e594e90fc3a0a864d583d2d",
"commit_date":"2022-01-20T17:05:49Z",
"files":[
{
"sha":"2ee2e2fa6f793bc96841bf7bce5a1c8f259dd7cb",
"filename":"doc/source/contributor/process.rst",
"status":"modified",
"additions":23,
"deletions":14,
"changes":37,
"blob_url":"https://github.com/openstack/nova/blob/bb2984b9c772d6eb9e594e90fc3a0a864d583d2d/doc/source/contributor/process.rst",
"raw_url":"https://github.com/openstack/nova/raw/bb2984b9c772d6eb9e594e90fc3a0a864d583d2d/doc/source/contributor/process.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/contributor/process.rst?ref=bb2984b9c772d6eb9e594e90fc3a0a864d583d2d",
"patch":"@@ -697,34 +697,46 @@ Our experience was:\n    review time on the patches in the slots. Such commitment is hard to get or\n    follow up on without being aggressive.\n \n+3) Non-cores were not able to tell they were happy with reviewing some change\n+\n So the aim of the new review priority process is to be as decentralized amongst\n cores as possible. We trust cores that when they mark something as priority\n then they also themselves commit to review the patch. We also assume that if a\n core reviewed a patch then that core should easily find another core as a\n-second reviewer when needed.\n+second reviewer when needed. We also want contributors to be able to \"ping\"\n+cores asynchronously by asking them to review some changes they saw.\n \n-Note that this process does not want to change how a patch is discovered to be\n-ready for review. The patch authors free to you any existing forums and ways to\n-get review attention.\n+That said, this process doesn't explain how a patch is discovered to be\n+ready for review. While previously The patch authors were able to\n+asynchronously beg for reviews by adding their changes to the etherpad, now\n+they need to find ways to get review attention. For this, we need to understand\n+first whether this is a problem for contributors or not, so let us know please\n+if you have issues for asking to get reviews by going to the nova meeting.\n \n Therefore we use the Review-Priority label in Gerrit in the following way:\n \n-* Review-Priority is a label with 0 or +1 values, that can be set by the\n-  members of the core team\n+* Review-Priority is a label with 0, +1 or +2 values.\n+\n+* A contributor can set the Review-Priority flag to +1 to indicate they will\n+  want cores to review the patch.\n \n-* A core sets the Review-Priority flag to +1 to indicate that they will help\n+* A core sets the Review-Priority flag to +2 to indicate that they will help\n   the author to get the patch merged.\n \n-* We expect that the cores will limit the number of patches marked with +1\n+* We expect the contributors setting +1 for a patch that they will continue\n+  to look at the patch even if a core reviews it so they can then provide\n+  their own comments or replies.\n+\n+* We expect that the cores will limit the number of patches marked with +2\n   Review-Priority based on their actual review bandwidth\n \n * We expect that cores will check the list of reviews already having\n-  Review-Priority +1 set by other cores before they mark a new one as such to\n+  Review-Priority +2 set by other cores before they mark a new one as such to\n   see where they can help first by being the second core.\n \n * There will be a regular agenda point on the weekly meeting where the team\n-  look at the list of patches with +1 mark to keep an overall view what is\n-  happening in nova.\n+  look at the list of patches with +1 or +2 mark to keep an overall view what\n+  is happening in nova.\n \n Pros:\n \n@@ -742,9 +754,6 @@ Cons:\n * No externally enforced limit on how many things can be a priority at any\n   given time.\n \n-* Does not (want to) solve the problem of discovering reviews that are ready to\n-  core review\n-\n Process Evolution Ideas\n =======================\n "
}
]
},
{
"commit_sha":"7bb21723171c59b93e28f5d508c2b6df39220f13",
"commit_node_id":"C_kwDOAAwOD9oAKDdiYjIxNzIzMTcxYzU5YjkzZTI4ZjVkNTA4YzJiNmRmMzkyMjBmMTM",
"commit_html_url":"https://github.com/openstack/nova/commit/7bb21723171c59b93e28f5d508c2b6df39220f13",
"commit_date":"2022-01-18T22:45:59Z",
"files":[
{
"sha":"d9f5e0a7a6853bcd24708a1ccf5d791c8f99ccfa",
"filename":"nova/conf/vnc.py",
"status":"modified",
"additions":0,
"deletions":9,
"changes":9,
"blob_url":"https://github.com/openstack/nova/blob/7bb21723171c59b93e28f5d508c2b6df39220f13/nova/conf/vnc.py",
"raw_url":"https://github.com/openstack/nova/raw/7bb21723171c59b93e28f5d508c2b6df39220f13/nova/conf/vnc.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/vnc.py?ref=7bb21723171c59b93e28f5d508c2b6df39220f13",
"patch":"@@ -39,10 +39,6 @@\n     cfg.HostAddressOpt(\n         'server_listen',\n         default='127.0.0.1',\n-        deprecated_opts=[\n-            cfg.DeprecatedOpt('vncserver_listen', group='DEFAULT'),\n-            cfg.DeprecatedOpt('vncserver_listen', group='vnc'),\n-        ],\n         help=\"\"\"\n The IP address or hostname on which an instance should listen to for\n incoming VNC connection requests on this node.\n@@ -51,11 +47,6 @@\n     cfg.HostAddressOpt(\n         'server_proxyclient_address',\n         default='127.0.0.1',\n-        deprecated_opts=[\n-            cfg.DeprecatedOpt('vncserver_proxyclient_address',\n-                              group='DEFAULT'),\n-            cfg.DeprecatedOpt('vncserver_proxyclient_address', group='vnc'),\n-        ],\n         help=\"\"\"\n Private, internal IP address or hostname of VNC console proxy.\n "
},
{
"sha":"36d2660bae7460b35e97da3d89408981f04eb7e9",
"filename":"releasenotes/notes/remove-deprecated-vnc-opts-c2bbcbf0fb777593.yaml",
"status":"added",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/7bb21723171c59b93e28f5d508c2b6df39220f13/releasenotes/notes/remove-deprecated-vnc-opts-c2bbcbf0fb777593.yaml",
"raw_url":"https://github.com/openstack/nova/raw/7bb21723171c59b93e28f5d508c2b6df39220f13/releasenotes/notes/remove-deprecated-vnc-opts-c2bbcbf0fb777593.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/remove-deprecated-vnc-opts-c2bbcbf0fb777593.yaml?ref=7bb21723171c59b93e28f5d508c2b6df39220f13",
"patch":"@@ -0,0 +1,10 @@\n+---\n+upgrade:\n+  - |\n+    vnc-related config options were deprecated in Pike release and now has been\n+    removed:\n+\n+    - ``vncserver_listen`` opt removed, now we use only server_listen to bind\n+      vnc address opt.\n+    - ``vncserver_proxyclient_address`` opt removed, now we use only\n+      server_proxyclient_address opt."
}
]
},
{
"commit_sha":"59c3a468871e7213bb425d7ca2ddec8637aa398b",
"commit_node_id":"C_kwDOAAwOD9oAKDU5YzNhNDY4ODcxZTcyMTNiYjQyNWQ3Y2EyZGRlYzg2MzdhYTM5OGI",
"commit_html_url":"https://github.com/openstack/nova/commit/59c3a468871e7213bb425d7ca2ddec8637aa398b",
"commit_date":"2022-01-18T20:03:47Z",
"files":[
{
"sha":"6fe0dd9b8f318d250b24030bfa6d537908cbaf67",
"filename":"nova/conf/workarounds.py",
"status":"modified",
"additions":11,
"deletions":0,
"changes":11,
"blob_url":"https://github.com/openstack/nova/blob/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/conf/workarounds.py",
"raw_url":"https://github.com/openstack/nova/raw/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/conf/workarounds.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/conf/workarounds.py?ref=59c3a468871e7213bb425d7ca2ddec8637aa398b",
"patch":"@@ -358,6 +358,17 @@\n Related options:\n \n * :oslo.config:option:`DEFAULT.vif_plugging_timeout`\n+\"\"\"),\n+    cfg.BoolOpt('enable_qemu_monitor_announce_self',\n+                default=False,\n+                help=\"\"\"\n+If it is set to True the libvirt driver will  try as a best effort to send\n+the announce-self command to the QEMU monitor so that it generates RARP frames\n+to update network switches in the post live migration phase on the destination.\n+\n+Related options:\n+\n+* :oslo.config:option:`DEFAULT.compute_driver` (libvirt)\n \"\"\"),\n ]\n "
},
{
"sha":"e88d9068c6de42ed025f982ccefde3aed73b79f4",
"filename":"nova/virt/libvirt/driver.py",
"status":"modified",
"additions":21,
"deletions":0,
"changes":21,
"blob_url":"https://github.com/openstack/nova/blob/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/virt/libvirt/driver.py",
"raw_url":"https://github.com/openstack/nova/raw/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/virt/libvirt/driver.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/driver.py?ref=59c3a468871e7213bb425d7ca2ddec8637aa398b",
"patch":"@@ -10550,6 +10550,26 @@ def post_live_migration_at_source(self, context, instance, network_info):\n         \"\"\"\n         self.unplug_vifs(instance, network_info)\n \n+    def _qemu_monitor_announce_self(self, instance):\n+        \"\"\"Send announce_self command to QEMU monitor.\n+\n+        This is to trigger generation of broadcast RARP frames to\n+        update network switches. This is best effort.\n+        \"\"\"\n+        if not CONF.workarounds.enable_qemu_monitor_announce_self:\n+            return\n+\n+        LOG.info('Sending announce-self command to QEMU monitor',\n+                 instance=instance)\n+\n+        try:\n+            guest = self._host.get_guest(instance)\n+            guest.announce_self()\n+        except Exception:\n+            LOG.warning('Failed to send announce-self command to QEMU monitor',\n+                        instance=instance)\n+            LOG.exception()\n+\n     def post_live_migration_at_destination(self, context,\n                                            instance,\n                                            network_info,\n@@ -10565,6 +10585,7 @@ def post_live_migration_at_destination(self, context,\n         :param block_migration: if true, post operation of block_migration.\n         \"\"\"\n         self._reattach_instance_vifs(context, instance, network_info)\n+        self._qemu_monitor_announce_self(instance)\n \n     def _get_instance_disk_info_from_config(self, guest_config,\n                                             block_device_info):"
},
{
"sha":"53080e41f0b4a885b265902ab3432ac4e893906c",
"filename":"nova/virt/libvirt/guest.py",
"status":"modified",
"additions":10,
"deletions":0,
"changes":10,
"blob_url":"https://github.com/openstack/nova/blob/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/virt/libvirt/guest.py",
"raw_url":"https://github.com/openstack/nova/raw/59c3a468871e7213bb425d7ca2ddec8637aa398b/nova/virt/libvirt/guest.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/guest.py?ref=59c3a468871e7213bb425d7ca2ddec8637aa398b",
"patch":"@@ -48,6 +48,12 @@\n else:\n     libvirt = None\n \n+try:\n+    import libvirtmod_qemu\n+except ImportError:\n+    libvirtmod_qemu = None\n+\n+\n LOG = logging.getLogger(__name__)\n \n VIR_DOMAIN_NOSTATE = 0\n@@ -632,6 +638,10 @@ def migrate_start_postcopy(self):\n         \"\"\"Switch running live migration to post-copy mode\"\"\"\n         self._domain.migrateStartPostCopy()\n \n+    def announce_self(self):\n+        libvirtmod_qemu.virDomainQemuMonitorCommand(\n+            self._domain._o, 'announce_self', 1)\n+\n     def get_job_info(self):\n         \"\"\"Get job info for the domain\n "
},
{
"sha":"f0ec39f196bdac7e33e3ff514d9f3f837ce40d41",
"filename":"releasenotes/notes/announce-self-post-live-migration-936721b1ab887514.yaml",
"status":"added",
"additions":8,
"deletions":0,
"changes":8,
"blob_url":"https://github.com/openstack/nova/blob/59c3a468871e7213bb425d7ca2ddec8637aa398b/releasenotes/notes/announce-self-post-live-migration-936721b1ab887514.yaml",
"raw_url":"https://github.com/openstack/nova/raw/59c3a468871e7213bb425d7ca2ddec8637aa398b/releasenotes/notes/announce-self-post-live-migration-936721b1ab887514.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/releasenotes/notes/announce-self-post-live-migration-936721b1ab887514.yaml?ref=59c3a468871e7213bb425d7ca2ddec8637aa398b",
"patch":"@@ -0,0 +1,8 @@\n+---\n+features:\n+  - |\n+    Added a new configuration option ``[workarounds]/enable_qemu_monitor_announce_self``\n+    that when enabled causes the Libvirt driver to send a announce_self QEMU\n+    monitor command post live-migration. Please see `bug 1815989 <https://bugs.launchpad.net/nova/+bug/1815989>`_\n+    for more details. Please note that this causes the domain to be considered\n+    tainted by libvirt."
}
]
},
{
"commit_sha":"82c91e8cd8e7ebc2d6d0b49fa22bdf6a1660a5bc",
"commit_node_id":"C_kwDOAAwOD9oAKDgyYzkxZThjZDhlN2ViYzJkNmQwYjQ5ZmEyMmJkZjZhMTY2MGE1YmM",
"commit_html_url":"https://github.com/openstack/nova/commit/82c91e8cd8e7ebc2d6d0b49fa22bdf6a1660a5bc",
"commit_date":"2021-05-10T20:23:42Z",
"files":[
{
"sha":"66808b31d471a9c71f878d7e8a660e077be3ff65",
"filename":".zuul.yaml",
"status":"modified",
"additions":3,
"deletions":0,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/82c91e8cd8e7ebc2d6d0b49fa22bdf6a1660a5bc/.zuul.yaml",
"raw_url":"https://github.com/openstack/nova/raw/82c91e8cd8e7ebc2d6d0b49fa22bdf6a1660a5bc/.zuul.yaml",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/.zuul.yaml?ref=82c91e8cd8e7ebc2d6d0b49fa22bdf6a1660a5bc",
"patch":"@@ -550,6 +550,9 @@\n             voting: false\n         - tempest-integrated-compute-centos-8-stream:\n             irrelevant-files: *nova-base-irrelevant-files\n+        - tempest-centos8-stream-fips:\n+            irrelevant-files: *nova-base-irrelevant-files\n+            voting: false\n     gate:\n       jobs:\n         - nova-live-migration"
}
]
},
{
"commit_sha":"63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"commit_node_id":"C_kwDOAAwOD9oAKDYzYmU0YzZmYzNmOGUzZTM3ZjNkMjc4NzAwMDFmMTUyNTZjMzVhYWE",
"commit_html_url":"https://github.com/openstack/nova/commit/63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"commit_date":"2022-01-18T06:26:58Z",
"files":[
{
"sha":"f415e7f84d003c0021c7ef11c32186da8f83225b",
"filename":"nova/tests/fixtures/nova.py",
"status":"modified",
"additions":37,
"deletions":1,
"changes":38,
"blob_url":"https://github.com/openstack/nova/blob/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/nova/tests/fixtures/nova.py",
"raw_url":"https://github.com/openstack/nova/raw/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/nova/tests/fixtures/nova.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/nova.py?ref=63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"patch":"@@ -17,6 +17,7 @@\n \"\"\"Fixtures for Nova tests.\"\"\"\n \n import collections\n+import contextlib\n from contextlib import contextmanager\n import functools\n import logging as std_logging\n@@ -28,6 +29,7 @@\n import futurist\n import mock\n from openstack import service_description\n+from oslo_concurrency import lockutils\n from oslo_config import cfg\n from oslo_db import exception as db_exc\n from oslo_db.sqlalchemy import enginefacade\n@@ -405,7 +407,7 @@ def __init__(self):\n         # to point to a cell, we need to take an exclusive lock to\n         # prevent any other calls to get_context_manager() until we\n         # reset to the default.\n-        self._cell_lock = utils.ReaderWriterLock()\n+        self._cell_lock = ReaderWriterLock()\n \n     def _cache_schema(self, connection_str):\n         # NOTE(melwitt): See the regular Database fixture for why\n@@ -1721,3 +1723,37 @@ def test_case_id_wrapper(*args, **kwargs):\n         # our initialization to the child eventlet\n         self.useFixture(\n             fixtures.MonkeyPatch('nova.utils.spawn_n', wrapped_spawn_n))\n+\n+\n+class ReaderWriterLock(lockutils.ReaderWriterLock):\n+    \"\"\"Wrap oslo.concurrency lockutils.ReaderWriterLock to support eventlet.\n+\n+    As of fasteners >= 0.15, the workaround code to use eventlet.getcurrent()\n+    if eventlet patching is detected has been removed and\n+    threading.current_thread is being used instead. Although we are running in\n+    a greenlet in our test environment, we are not running in a greenlet of\n+    type GreenThread. A GreenThread is created by calling eventlet.spawn() and\n+    spawn() is not used to run our tests. At the time of this writing, the\n+    eventlet patched threading.current_thread() method falls back to the\n+    original unpatched current_thread() method if it is not called from a\n+    GreenThead [1] and that breaks our tests involving this fixture.\n+\n+    We can work around this by patching threading.current_thread() with\n+    eventlet.getcurrent() during creation of the lock object, if we detect we\n+    are eventlet patched. If we are not eventlet patched, we use a no-op\n+    context manager.\n+\n+    Note: this wrapper should be used for any ReaderWriterLock because any lock\n+    may possibly be running inside a plain greenlet created by spawn_n().\n+\n+    See https://github.com/eventlet/eventlet/issues/731 for details.\n+\n+    [1] https://github.com/eventlet/eventlet/blob/v0.32.0/eventlet/green/threading.py#L128  # noqa\n+    \"\"\"\n+\n+    def __init__(self, *a, **kw):\n+        eventlet_patched = eventlet.patcher.is_monkey_patched('thread')\n+        mpatch = fixtures.MonkeyPatch(\n+            'threading.current_thread', eventlet.getcurrent)\n+        with mpatch if eventlet_patched else contextlib.ExitStack():\n+            super().__init__(*a, **kw)"
},
{
"sha":"ec5e6c92480631c48a3ae160368cc887d43bf1d1",
"filename":"nova/utils.py",
"status":"modified",
"additions":0,
"deletions":35,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/nova/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/nova/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/utils.py?ref=63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"patch":"@@ -29,7 +29,6 @@\n import tempfile\n \n import eventlet\n-import fixtures\n from keystoneauth1 import loading as ks_loading\n import netaddr\n from openstack import connection\n@@ -1144,37 +1143,3 @@ def reset(wrapper, *args, **kwargs):\n         wrapper.reset = functools.partial(reset, wrapper)\n         return wrapper\n     return outer_wrapper\n-\n-\n-class ReaderWriterLock(lockutils.ReaderWriterLock):\n-    \"\"\"Wrap oslo.concurrency lockutils.ReaderWriterLock to support eventlet.\n-\n-    As of fasteners >= 0.15, the workaround code to use eventlet.getcurrent()\n-    if eventlet patching is detected has been removed and\n-    threading.current_thread is being used instead. Although we are running in\n-    a greenlet in our test environment, we are not running in a greenlet of\n-    type GreenThread. A GreenThread is created by calling eventlet.spawn() and\n-    spawn() is not used to run our tests. At the time of this writing, the\n-    eventlet patched threading.current_thread() method falls back to the\n-    original unpatched current_thread() method if it is not called from a\n-    GreenThead [1] and that breaks our tests involving this fixture.\n-\n-    We can work around this by patching threading.current_thread() with\n-    eventlet.getcurrent() during creation of the lock object, if we detect we\n-    are eventlet patched. If we are not eventlet patched, we use a no-op\n-    context manager.\n-\n-    Note: this wrapper should be used for any ReaderWriterLock because any lock\n-    may possibly be running inside a plain greenlet created by spawn_n().\n-\n-    See https://github.com/eventlet/eventlet/issues/731 for details.\n-\n-    [1] https://github.com/eventlet/eventlet/blob/v0.32.0/eventlet/green/threading.py#L128  # noqa\n-    \"\"\"\n-\n-    def __init__(self, *a, **kw):\n-        eventlet_patched = eventlet.patcher.is_monkey_patched('thread')\n-        mpatch = fixtures.MonkeyPatch(\n-            'threading.current_thread', eventlet.getcurrent)\n-        with mpatch if eventlet_patched else contextlib.ExitStack():\n-            return super().__init__(*a, **kw)"
},
{
"sha":"a8bed744fba2b1a8b5f6ba1834c90b6700a32752",
"filename":"requirements.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"patch":"@@ -68,4 +68,3 @@ futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License\n PyYAML>=5.1 # MIT\n-fixtures>=3.0.0 # Apache-2.0/BSD"
},
{
"sha":"44cb2bacf79d5bc43ed14cea5d4321939c3eca89",
"filename":"test-requirements.txt",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/63be4c6fc3f8e3e37f3d27870001f15256c35aaa/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=63be4c6fc3f8e3e37f3d27870001f15256c35aaa",
"patch":"@@ -7,6 +7,7 @@ mypy>=0.761 # MIT\n types-paramiko>=0.1.3 # Apache-2.0\n coverage!=4.4,>=4.0 # Apache-2.0\n ddt>=1.2.1 # MIT\n+fixtures>=3.0.0 # Apache-2.0/BSD\n mock>=3.0.0 # BSD\n psycopg2-binary>=2.8 # LGPL/ZPL\n PyMySQL>=0.8.0 # MIT License"
}
]
},
{
"commit_sha":"c2e50299f221daeee52171aa4c3a28932202b122",
"commit_node_id":"C_kwDOAAwOD9oAKGMyZTUwMjk5ZjIyMWRhZWVlNTIxNzFhYTRjM2EyODkzMjIwMmIxMjI",
"commit_html_url":"https://github.com/openstack/nova/commit/c2e50299f221daeee52171aa4c3a28932202b122",
"commit_date":"2022-01-17T18:17:21Z",
"files":[
{
"sha":"8dfb3455782b897ca771f76891273acd8f8e426d",
"filename":"nova/tests/functional/test_aggregates.py",
"status":"modified",
"additions":115,
"deletions":6,
"changes":121,
"blob_url":"https://github.com/openstack/nova/blob/c2e50299f221daeee52171aa4c3a28932202b122/nova/tests/functional/test_aggregates.py",
"raw_url":"https://github.com/openstack/nova/raw/c2e50299f221daeee52171aa4c3a28932202b122/nova/tests/functional/test_aggregates.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/test_aggregates.py?ref=c2e50299f221daeee52171aa4c3a28932202b122",
"patch":"@@ -197,14 +197,24 @@ def _add_host_to_aggregate(self, agg, host):\n         agg = self.aggregates[agg]\n         self.admin_api.add_host_to_aggregate(agg['id'], host)\n \n-    def _boot_server(self, az=None, flavor_id=None, image_id=None,\n-                     end_status='ACTIVE'):\n+    def _remove_host_from_aggregate(self, agg, host):\n+        \"\"\"Remove a compute host from both nova and placement aggregates.\n+\n+        :param agg: Name of the nova aggregate\n+        :param host: Name of the compute host\n+        \"\"\"\n+        agg = self.aggregates[agg]\n+        self.admin_api.remove_host_from_aggregate(agg['id'], host)\n+\n+    def _boot_server(\n+        self, az=None, host=None, flavor_id=None, image_id=None,\n+        end_status='ACTIVE',\n+    ):\n         flavor_id = flavor_id or self.flavors[0]['id']\n         image_uuid = image_id or '155d900f-4e14-4e4c-a73d-069cbf4541e6'\n         server_req = self._build_server(\n-            image_uuid=image_uuid,\n-            flavor_id=flavor_id,\n-            networks='none', az=az)\n+            image_uuid=image_uuid, flavor_id=flavor_id,\n+            networks='none', az=az, host=host)\n \n         created_server = self.api.post_server({'server': server_req})\n         server = self._wait_for_state_change(created_server, end_status)\n@@ -284,7 +294,7 @@ def _set_traits_on_aggregate(self, agg, traits):\n \n class AggregatePostTest(AggregateRequestFiltersTest):\n \n-    def test_set_az_for_aggreate_no_instances(self):\n+    def test_set_az_for_aggregate_no_instances(self):\n         \"\"\"Should be possible to update AZ for an empty aggregate.\n \n         Check you can change the AZ name of an aggregate when it does\n@@ -343,6 +353,105 @@ def test_cannot_delete_az(self):\n         self.assertEqual(az, agg['availability_zone'])\n \n \n+class AggregateHostMoveTestCase(AggregateRequestFiltersTest):\n+\n+    def setUp(self):\n+        super().setUp()\n+        # keep it separate from the parent class' setup\n+        self.host = 'host3'\n+        az = 'custom-az'\n+        self._start_compute(self.host)\n+        self._create_aggregate('ag1-no-az')\n+        self._create_aggregate('ag2-no-az')\n+        self._create_aggregate('ag3-custom-az')\n+        self._set_az_aggregate('ag3-custom-az', az)\n+        self._create_aggregate('ag4-custom-az')\n+        self._set_az_aggregate('ag4-custom-az', az)\n+\n+    def test_add_host_with_instances_default_az_doesnt_change(self):\n+        # server will be in default AZ\n+        self._boot_server(host=self.host)\n+\n+        # the AZ of the server does not change as the aggregate is also in\n+        # the default AZ.\n+        self._add_host_to_aggregate('ag1-no-az', self.host)\n+\n+    def test_add_host_with_instances_custom_az_doesnt_change(self):\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+        # server will be in custom AZ\n+        self._boot_server(host=self.host)\n+\n+        # as the new aggregate also in the custom-az this does not need the\n+        # server to move between AZs, so this is OK.\n+        self._add_host_to_aggregate('ag4-custom-az', self.host)\n+\n+    def test_cannot_add_host_with_instances_default_az_then_custom_az(self):\n+        # server will be in default AZ\n+        self._boot_server(host=self.host)\n+\n+        # FIXME(stephenfin): This is bug #1907775, where we should reject the\n+        # request to add a host to an aggregate when and instance would need\n+        # to move between AZs\n+\n+        # The server would need to move from default AZ to custom AZ, that\n+        # is not OK\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+\n+    def test_add_host_with_instances_custom_az_then_default(self):\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+        # server will be in custom AZ\n+        self._boot_server(host=self.host)\n+\n+        # The server is still in the custom AZ and that is OK as the host is\n+        # also in that AZ even after added to an aggregate without AZ.\n+        self._add_host_to_aggregate('ag1-no-az', self.host)\n+\n+    def test_remove_host_with_instances_default_az_doesnt_change(self):\n+        self._add_host_to_aggregate('ag1-no-az', self.host)\n+        self._add_host_to_aggregate('ag2-no-az', self.host)\n+        # server will be in default AZ\n+        self._boot_server(host=self.host)\n+\n+        # The server still remains in default AZ so no AZ change, this is OK\n+        self._remove_host_from_aggregate('ag1-no-az', self.host)\n+        # still OK as the host not in any aggregate means instance is in\n+        # default AZ.\n+        self._remove_host_from_aggregate('ag2-no-az', self.host)\n+\n+    def test_remove_host_with_instances_custom_az_doesnt_change(self):\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+        self._add_host_to_aggregate('ag4-custom-az', self.host)\n+        # server will be in custom AZ\n+        self._boot_server(host=self.host)\n+\n+        # The server still remains in custom AZ so no AZ change, it is OK.\n+        self._remove_host_from_aggregate('ag3-custom-az', self.host)\n+\n+    def test_cannot_remove_host_with_instances_custom_az_to_default(self):\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+        # server will be in custom AZ\n+        self._boot_server(host=self.host)\n+\n+        # FIXME(stephenfin): This is bug #1907775, where we should reject the\n+        # request to remove a host from the aggregate when there are instances\n+        # on said host\n+\n+        # The server would need to move to the default AZ, that is not OK.\n+        self._remove_host_from_aggregate('ag3-custom-az', self.host)\n+\n+    def test_moving_host_around_az_without_instances(self):\n+        # host moving from default to custom AZ\n+        self._add_host_to_aggregate('ag3-custom-az', self.host)\n+        # host still in custom AZ\n+        self._add_host_to_aggregate('ag1-no-az', self.host)\n+        # host moves from custom to default AZ\n+        self._remove_host_from_aggregate('ag3-custom-az', self.host)\n+        # host still in default AZ\n+        self._remove_host_from_aggregate('ag1-no-az', self.host)\n+        # host still in default AZ\n+        self._add_host_to_aggregate('ag1-no-az', self.host)\n+\n+\n # NOTE: this test case has the same test methods as AggregatePostTest\n # but for the AZ update it uses PUT /os-aggregates/{aggregate_id} method\n class AggregatePutTest(AggregatePostTest):"
}
]
},
{
"commit_sha":"58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"commit_node_id":"C_kwDOAAwOD9oAKDU4ZmRhMmVhZDVhNmRiNjY4NGRlZWY1ZjM5ZmJmNjZjMTBlMGJjY2Q",
"commit_html_url":"https://github.com/openstack/nova/commit/58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"commit_date":"2022-01-17T17:39:15Z",
"files":[
{
"sha":"b50db3aa1c0c6246e9644f9dccdba7680c076e07",
"filename":"nova/virt/libvirt/volume/fibrechannel.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/fibrechannel.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/fibrechannel.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/fibrechannel.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -50,9 +50,9 @@ def get_config(self, connection_info, disk_info):\n     def connect_volume(self, connection_info, instance):\n         \"\"\"Attach the volume to instance_name.\"\"\"\n \n-        LOG.debug(\"Calling os-brick to attach FC Volume\")\n+        LOG.debug(\"Calling os-brick to attach FC Volume\", instance=instance)\n         device_info = self.connector.connect_volume(connection_info['data'])\n-        LOG.debug(\"Attached FC volume %s\", device_info)\n+        LOG.debug(\"Attached FC volume %s\", device_info, instance=instance)\n \n         connection_info['data']['device_path'] = device_info['path']\n         if 'multipath_id' in device_info:"
},
{
"sha":"564bac14cc7e74ae5e21445c39f6c5c90035fdb0",
"filename":"nova/virt/libvirt/volume/iscsi.py",
"status":"modified",
"additions":2,
"deletions":2,
"changes":4,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/iscsi.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/iscsi.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/iscsi.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -60,9 +60,9 @@ def get_config(self, connection_info, disk_info):\n     def connect_volume(self, connection_info, instance):\n         \"\"\"Attach the volume to instance_name.\"\"\"\n \n-        LOG.debug(\"Calling os-brick to attach iSCSI Volume\")\n+        LOG.debug(\"Calling os-brick to attach iSCSI Volume\", instance=instance)\n         device_info = self.connector.connect_volume(connection_info['data'])\n-        LOG.debug(\"Attached iSCSI volume %s\", device_info)\n+        LOG.debug(\"Attached iSCSI volume %s\", device_info, instance=instance)\n \n         connection_info['data']['device_path'] = device_info['path']\n "
},
{
"sha":"d85ac8aa48187191c927b92061f211459c9dd655",
"filename":"nova/virt/libvirt/volume/mount.py",
"status":"modified",
"additions":14,
"deletions":11,
"changes":25,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/mount.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/mount.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/mount.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -290,15 +290,17 @@ def mount(self, fstype, export, vol_name, mountpoint, instance, options):\n                   'options=%(options)s) generation %(gen)s',\n                   {'fstype': fstype, 'export': export, 'vol_name': vol_name,\n                    'mountpoint': mountpoint, 'options': options,\n-                   'gen': self.generation})\n+                   'gen': self.generation}, instance=instance)\n         with self._get_locked(mountpoint) as mount:\n             if os.path.ismount(mountpoint):\n                 LOG.debug(('Mounting %(mountpoint)s generation %(gen)s, '\n                            'mountpoint already mounted'),\n-                          {'mountpoint': mountpoint, 'gen': self.generation})\n+                          {'mountpoint': mountpoint, 'gen': self.generation},\n+                          instance=instance)\n             else:\n                 LOG.debug('Mounting %(mountpoint)s generation %(gen)s',\n-                          {'mountpoint': mountpoint, 'gen': self.generation})\n+                          {'mountpoint': mountpoint, 'gen': self.generation},\n+                          instance=instance)\n \n                 fileutils.ensure_tree(mountpoint)\n \n@@ -316,7 +318,7 @@ def mount(self, fstype, export, vol_name, mountpoint, instance, options):\n                             '%(mountpoint)s. Continuing because mountpount is '\n                             'mounted despite this.',\n                             {'fstype': fstype, 'export': export,\n-                             'mountpoint': mountpoint})\n+                             'mountpoint': mountpoint}, instance=instance)\n                     else:\n                         # If the mount failed there's no reason for us to keep\n                         # a record of it. It will be created again if the\n@@ -331,7 +333,8 @@ def mount(self, fstype, export, vol_name, mountpoint, instance, options):\n \n         LOG.debug('_HostMountState.mount() for %(mountpoint)s '\n                   'generation %(gen)s completed successfully',\n-                  {'mountpoint': mountpoint, 'gen': self.generation})\n+                  {'mountpoint': mountpoint, 'gen': self.generation},\n+                  instance=instance)\n \n     def umount(self, vol_name, mountpoint, instance):\n         \"\"\"Mark an attachment as no longer in use, and unmount its mountpoint\n@@ -345,16 +348,15 @@ def umount(self, vol_name, mountpoint, instance):\n         LOG.debug('_HostMountState.umount(vol_name=%(vol_name)s, '\n                   'mountpoint=%(mountpoint)s) generation %(gen)s',\n                   {'vol_name': vol_name, 'mountpoint': mountpoint,\n-                   'gen': self.generation})\n+                   'gen': self.generation}, instance=instance)\n         with self._get_locked(mountpoint) as mount:\n             try:\n                 mount.remove_attachment(vol_name, instance.uuid)\n             except KeyError:\n-                LOG.warning(\"Request to remove attachment \"\n-                            \"(%(vol_name)s, %(instance)s) from \"\n+                LOG.warning(\"Request to remove attachment (%(vol_name)s from \"\n                             \"%(mountpoint)s, but we don't think it's in use.\",\n-                            {'vol_name': vol_name, 'instance': instance.uuid,\n-                             'mountpoint': mountpoint})\n+                            {'vol_name': vol_name, 'mountpoint': mountpoint},\n+                            instance=instance)\n \n             if not mount.in_use():\n                 mounted = os.path.ismount(mountpoint)\n@@ -368,7 +370,8 @@ def umount(self, vol_name, mountpoint, instance):\n \n             LOG.debug('_HostMountState.umount() for %(mountpoint)s '\n                       'generation %(gen)s completed successfully',\n-                      {'mountpoint': mountpoint, 'gen': self.generation})\n+                      {'mountpoint': mountpoint, 'gen': self.generation},\n+                      instance=instance)\n \n     def _real_umount(self, mountpoint):\n         # Unmount and delete a mountpoint."
},
{
"sha":"fefaaf434de2abe0961e5dca0223289f17af7e4e",
"filename":"nova/virt/libvirt/volume/nvme.py",
"status":"modified",
"additions":3,
"deletions":4,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/nvme.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/nvme.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/nvme.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -39,15 +39,14 @@ def connect_volume(self, connection_info, instance):\n \n         device_info = self.connector.connect_volume(\n             connection_info['data'])\n-        LOG.debug(\n-            \"Connecting NVMe volume with device_info %s\",\n-            device_info)\n+        LOG.debug(\"Connecting NVMe volume with device_info %s\",\n+                  device_info, instance=instance)\n \n         connection_info['data']['device_path'] = device_info['path']\n \n     def disconnect_volume(self, connection_info, instance):\n         \"\"\"Detach the volume from the instance.\"\"\"\n-        LOG.debug(\"Disconnecting NVMe disk\")\n+        LOG.debug(\"Disconnecting NVMe disk\", instance=instance)\n         self.connector.disconnect_volume(\n             connection_info['data'], None)\n         super(LibvirtNVMEVolumeDriver,"
},
{
"sha":"bb7a770e57ea69a0dada1c82b3d2d9f338a9c82b",
"filename":"nova/virt/libvirt/volume/quobyte.py",
"status":"modified",
"additions":7,
"deletions":5,
"changes":12,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/quobyte.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/quobyte.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/quobyte.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -158,9 +158,9 @@ def get_config(self, connection_info, disk_info):\n     def connect_volume(self, connection_info, instance):\n         \"\"\"Connect the volume.\"\"\"\n         if is_systemd():\n-            LOG.debug(\"systemd detected.\")\n+            LOG.debug(\"systemd detected.\", instance=instance)\n         else:\n-            LOG.debug(\"No systemd detected.\")\n+            LOG.debug(\"No systemd detected.\", instance=instance)\n \n         data = connection_info['data']\n         quobyte_volume = self._normalize_export(data['export'])\n@@ -171,7 +171,7 @@ def connect_volume(self, connection_info, instance):\n         except nova_exception.StaleVolumeMount:\n             mounted = False\n             LOG.info('Fixing previous mount %s which was not '\n-                     'unmounted correctly.', mount_path)\n+                     'unmounted correctly.', mount_path, instance=instance)\n             umount_volume(mount_path)\n         except nova_exception.InvalidVolume:\n             mounted = False\n@@ -185,7 +185,8 @@ def connect_volume(self, connection_info, instance):\n             validate_volume(mount_path)\n         except (nova_exception.InvalidVolume,\n                 nova_exception.StaleVolumeMount) as nex:\n-            LOG.error(\"Could not mount Quobyte volume: %s\", nex)\n+            LOG.error(\"Could not mount Quobyte volume: %s\", nex,\n+                      instance=instance)\n \n     @utils.synchronized('connect_qb_volume')\n     def disconnect_volume(self, connection_info, instance):\n@@ -196,7 +197,8 @@ def disconnect_volume(self, connection_info, instance):\n             validate_volume(mount_path)\n         except (nova_exception.InvalidVolume,\n                 nova_exception.StaleVolumeMount) as exc:\n-            LOG.warning(\"Could not disconnect Quobyte volume mount: %s\", exc)\n+            LOG.warning(\"Could not disconnect Quobyte volume mount: %s\", exc,\n+                        instance=instance)\n         else:\n             umount_volume(mount_path)\n "
},
{
"sha":"7c414c2870fc0b021e1a8ad37d468e305682a393",
"filename":"nova/virt/libvirt/volume/scaleio.py",
"status":"modified",
"additions":2,
"deletions":1,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/scaleio.py",
"raw_url":"https://github.com/openstack/nova/raw/58fda2ead5a6db6684deef5f39fbf66c10e0bccd/nova/virt/libvirt/volume/scaleio.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/virt/libvirt/volume/scaleio.py?ref=58fda2ead5a6db6684deef5f39fbf66c10e0bccd",
"patch":"@@ -53,7 +53,8 @@ def get_config(self, connection_info, disk_info):\n \n     def connect_volume(self, connection_info, instance):\n         device_info = self.connector.connect_volume(connection_info['data'])\n-        LOG.debug(\"Attached ScaleIO volume %s.\", device_info)\n+        LOG.debug(\"Attached ScaleIO volume %s.\", device_info,\n+                  instance=instance)\n         connection_info['data']['device_path'] = device_info['path']\n \n     def disconnect_volume(self, connection_info, instance):"
}
]
},
{
"commit_sha":"e6f9d1f43275e6b6c7acf65c86367da8901919e9",
"commit_node_id":"C_kwDOAAwOD9oAKGU2ZjlkMWY0MzI3NWU2YjZjN2FjZjY1Yzg2MzY3ZGE4OTAxOTE5ZTk",
"commit_html_url":"https://github.com/openstack/nova/commit/e6f9d1f43275e6b6c7acf65c86367da8901919e9",
"commit_date":"2022-01-17T16:15:52Z",
"files":[
{
"sha":"a6e5dbbe07c9f710ebc1ebd8b2c20fc4895cb59e",
"filename":"nova/tests/functional/api_samples_test_base.py",
"status":"modified",
"additions":5,
"deletions":2,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/e6f9d1f43275e6b6c7acf65c86367da8901919e9/nova/tests/functional/api_samples_test_base.py",
"raw_url":"https://github.com/openstack/nova/raw/e6f9d1f43275e6b6c7acf65c86367da8901919e9/nova/tests/functional/api_samples_test_base.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/api_samples_test_base.py?ref=e6f9d1f43275e6b6c7acf65c86367da8901919e9",
"patch":"@@ -135,8 +135,11 @@ def _write_template(self, name, data):\n             outf.write(data)\n \n     def _write_sample(self, name, data):\n-        with open(self._get_sample(\n-            name, self.microversion), 'w') as outf:\n+        sample_file = self._get_sample(name, self.microversion)\n+\n+        os.makedirs(os.path.dirname(sample_file), exist_ok = True)\n+\n+        with open(sample_file, 'w') as outf:\n             outf.write(data)\n \n     def _compare_result(self, expected, result, result_str):"
}
]
},
{
"commit_sha":"a341851f15060efc2e6e30717339c47c015ed0b7",
"commit_node_id":"C_kwDOAAwOD9oAKGEzNDE4NTFmMTUwNjBlZmMyZTZlMzA3MTczMzljNDdjMDE1ZWQwYjc",
"commit_html_url":"https://github.com/openstack/nova/commit/a341851f15060efc2e6e30717339c47c015ed0b7",
"commit_date":"2022-01-17T12:29:35Z",
"files":[
{
"sha":"f415e7f84d003c0021c7ef11c32186da8f83225b",
"filename":"nova/tests/fixtures/nova.py",
"status":"modified",
"additions":37,
"deletions":1,
"changes":38,
"blob_url":"https://github.com/openstack/nova/blob/a341851f15060efc2e6e30717339c47c015ed0b7/nova/tests/fixtures/nova.py",
"raw_url":"https://github.com/openstack/nova/raw/a341851f15060efc2e6e30717339c47c015ed0b7/nova/tests/fixtures/nova.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/nova.py?ref=a341851f15060efc2e6e30717339c47c015ed0b7",
"patch":"@@ -17,6 +17,7 @@\n \"\"\"Fixtures for Nova tests.\"\"\"\n \n import collections\n+import contextlib\n from contextlib import contextmanager\n import functools\n import logging as std_logging\n@@ -28,6 +29,7 @@\n import futurist\n import mock\n from openstack import service_description\n+from oslo_concurrency import lockutils\n from oslo_config import cfg\n from oslo_db import exception as db_exc\n from oslo_db.sqlalchemy import enginefacade\n@@ -405,7 +407,7 @@ def __init__(self):\n         # to point to a cell, we need to take an exclusive lock to\n         # prevent any other calls to get_context_manager() until we\n         # reset to the default.\n-        self._cell_lock = utils.ReaderWriterLock()\n+        self._cell_lock = ReaderWriterLock()\n \n     def _cache_schema(self, connection_str):\n         # NOTE(melwitt): See the regular Database fixture for why\n@@ -1721,3 +1723,37 @@ def test_case_id_wrapper(*args, **kwargs):\n         # our initialization to the child eventlet\n         self.useFixture(\n             fixtures.MonkeyPatch('nova.utils.spawn_n', wrapped_spawn_n))\n+\n+\n+class ReaderWriterLock(lockutils.ReaderWriterLock):\n+    \"\"\"Wrap oslo.concurrency lockutils.ReaderWriterLock to support eventlet.\n+\n+    As of fasteners >= 0.15, the workaround code to use eventlet.getcurrent()\n+    if eventlet patching is detected has been removed and\n+    threading.current_thread is being used instead. Although we are running in\n+    a greenlet in our test environment, we are not running in a greenlet of\n+    type GreenThread. A GreenThread is created by calling eventlet.spawn() and\n+    spawn() is not used to run our tests. At the time of this writing, the\n+    eventlet patched threading.current_thread() method falls back to the\n+    original unpatched current_thread() method if it is not called from a\n+    GreenThead [1] and that breaks our tests involving this fixture.\n+\n+    We can work around this by patching threading.current_thread() with\n+    eventlet.getcurrent() during creation of the lock object, if we detect we\n+    are eventlet patched. If we are not eventlet patched, we use a no-op\n+    context manager.\n+\n+    Note: this wrapper should be used for any ReaderWriterLock because any lock\n+    may possibly be running inside a plain greenlet created by spawn_n().\n+\n+    See https://github.com/eventlet/eventlet/issues/731 for details.\n+\n+    [1] https://github.com/eventlet/eventlet/blob/v0.32.0/eventlet/green/threading.py#L128  # noqa\n+    \"\"\"\n+\n+    def __init__(self, *a, **kw):\n+        eventlet_patched = eventlet.patcher.is_monkey_patched('thread')\n+        mpatch = fixtures.MonkeyPatch(\n+            'threading.current_thread', eventlet.getcurrent)\n+        with mpatch if eventlet_patched else contextlib.ExitStack():\n+            super().__init__(*a, **kw)"
},
{
"sha":"ec5e6c92480631c48a3ae160368cc887d43bf1d1",
"filename":"nova/utils.py",
"status":"modified",
"additions":0,
"deletions":35,
"changes":35,
"blob_url":"https://github.com/openstack/nova/blob/a341851f15060efc2e6e30717339c47c015ed0b7/nova/utils.py",
"raw_url":"https://github.com/openstack/nova/raw/a341851f15060efc2e6e30717339c47c015ed0b7/nova/utils.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/utils.py?ref=a341851f15060efc2e6e30717339c47c015ed0b7",
"patch":"@@ -29,7 +29,6 @@\n import tempfile\n \n import eventlet\n-import fixtures\n from keystoneauth1 import loading as ks_loading\n import netaddr\n from openstack import connection\n@@ -1144,37 +1143,3 @@ def reset(wrapper, *args, **kwargs):\n         wrapper.reset = functools.partial(reset, wrapper)\n         return wrapper\n     return outer_wrapper\n-\n-\n-class ReaderWriterLock(lockutils.ReaderWriterLock):\n-    \"\"\"Wrap oslo.concurrency lockutils.ReaderWriterLock to support eventlet.\n-\n-    As of fasteners >= 0.15, the workaround code to use eventlet.getcurrent()\n-    if eventlet patching is detected has been removed and\n-    threading.current_thread is being used instead. Although we are running in\n-    a greenlet in our test environment, we are not running in a greenlet of\n-    type GreenThread. A GreenThread is created by calling eventlet.spawn() and\n-    spawn() is not used to run our tests. At the time of this writing, the\n-    eventlet patched threading.current_thread() method falls back to the\n-    original unpatched current_thread() method if it is not called from a\n-    GreenThead [1] and that breaks our tests involving this fixture.\n-\n-    We can work around this by patching threading.current_thread() with\n-    eventlet.getcurrent() during creation of the lock object, if we detect we\n-    are eventlet patched. If we are not eventlet patched, we use a no-op\n-    context manager.\n-\n-    Note: this wrapper should be used for any ReaderWriterLock because any lock\n-    may possibly be running inside a plain greenlet created by spawn_n().\n-\n-    See https://github.com/eventlet/eventlet/issues/731 for details.\n-\n-    [1] https://github.com/eventlet/eventlet/blob/v0.32.0/eventlet/green/threading.py#L128  # noqa\n-    \"\"\"\n-\n-    def __init__(self, *a, **kw):\n-        eventlet_patched = eventlet.patcher.is_monkey_patched('thread')\n-        mpatch = fixtures.MonkeyPatch(\n-            'threading.current_thread', eventlet.getcurrent)\n-        with mpatch if eventlet_patched else contextlib.ExitStack():\n-            return super().__init__(*a, **kw)"
},
{
"sha":"a8bed744fba2b1a8b5f6ba1834c90b6700a32752",
"filename":"requirements.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/a341851f15060efc2e6e30717339c47c015ed0b7/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/a341851f15060efc2e6e30717339c47c015ed0b7/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=a341851f15060efc2e6e30717339c47c015ed0b7",
"patch":"@@ -68,4 +68,3 @@ futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License\n PyYAML>=5.1 # MIT\n-fixtures>=3.0.0 # Apache-2.0/BSD"
},
{
"sha":"44cb2bacf79d5bc43ed14cea5d4321939c3eca89",
"filename":"test-requirements.txt",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/a341851f15060efc2e6e30717339c47c015ed0b7/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/a341851f15060efc2e6e30717339c47c015ed0b7/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=a341851f15060efc2e6e30717339c47c015ed0b7",
"patch":"@@ -7,6 +7,7 @@ mypy>=0.761 # MIT\n types-paramiko>=0.1.3 # Apache-2.0\n coverage!=4.4,>=4.0 # Apache-2.0\n ddt>=1.2.1 # MIT\n+fixtures>=3.0.0 # Apache-2.0/BSD\n mock>=3.0.0 # BSD\n psycopg2-binary>=2.8 # LGPL/ZPL\n PyMySQL>=0.8.0 # MIT License"
}
]
},
{
"commit_sha":"1ddb8f83adef964a8ca050994a43adc6175994f1",
"commit_node_id":"C_kwDOAAwOD9oAKDFkZGI4ZjgzYWRlZjk2NGE4Y2EwNTA5OTRhNDNhZGM2MTc1OTk0ZjE",
"commit_html_url":"https://github.com/openstack/nova/commit/1ddb8f83adef964a8ca050994a43adc6175994f1",
"commit_date":"2022-01-17T11:14:52Z",
"files":[
{
"sha":"95f468abb47da61117bffb720b1eab2814b7d280",
"filename":"requirements.txt",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/1ddb8f83adef964a8ca050994a43adc6175994f1/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/1ddb8f83adef964a8ca050994a43adc6175994f1/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=1ddb8f83adef964a8ca050994a43adc6175994f1",
"patch":"@@ -68,3 +68,4 @@ futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License\n PyYAML>=5.1 # MIT\n+fixtures>=3.0.0 # Apache-2.0/BSD"
},
{
"sha":"80104c298f80a5dd4ec1acc7a40f8b13b41ea529",
"filename":"test-requirements.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/1ddb8f83adef964a8ca050994a43adc6175994f1/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/1ddb8f83adef964a8ca050994a43adc6175994f1/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=1ddb8f83adef964a8ca050994a43adc6175994f1",
"patch":"@@ -7,7 +7,6 @@ mypy>=0.761 # MIT\n types-paramiko>=0.1.3 # Apache-2.0\n coverage!=4.4,>=4.0 # Apache-2.0\n ddt>=1.2.1 # MIT\n-fixtures>=3.0.0 # Apache-2.0/BSD\n mock>=3.0.0 # BSD\n psycopg2-binary>=2.8 # LGPL/ZPL\n PyMySQL>=0.8.0 # MIT License"
}
]
},
{
"commit_sha":"3d411cad6031b76a033f1e3aeb029959cc865e36",
"commit_node_id":"C_kwDOAAwOD9oAKDNkNDExY2FkNjAzMWI3NmEwMzNmMWUzYWViMDI5OTU5Y2M4NjVlMzY",
"commit_html_url":"https://github.com/openstack/nova/commit/3d411cad6031b76a033f1e3aeb029959cc865e36",
"commit_date":"2022-01-17T10:31:21Z",
"files":[
{
"sha":"0ceb3b4b8fe2ee0d0d56daeeed7c8f1795e23a9b",
"filename":"nova/image/glance.py",
"status":"modified",
"additions":11,
"deletions":9,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/3d411cad6031b76a033f1e3aeb029959cc865e36/nova/image/glance.py",
"raw_url":"https://github.com/openstack/nova/raw/3d411cad6031b76a033f1e3aeb029959cc865e36/nova/image/glance.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/image/glance.py?ref=3d411cad6031b76a033f1e3aeb029959cc865e36",
"patch":"@@ -419,17 +419,17 @@ def _verify_and_write(self, context, image_id, trusted_certs,\n         if data is None:\n             write_image = False\n \n-        # Retrieve properties for verification of Glance image signature\n-        verifier = self._get_verifier(context, image_id, trusted_certs)\n+        try:\n+            # Retrieve properties for verification of Glance image signature\n+            verifier = self._get_verifier(context, image_id, trusted_certs)\n \n-        # Exit early if we do not need write nor verify\n-        if verifier is None and write_image is False:\n-            if data is None:\n-                return image_chunks\n-            else:\n-                return\n+            # Exit early if we do not need write nor verify\n+            if verifier is None and write_image is False:\n+                if data is None:\n+                    return image_chunks\n+                else:\n+                    return\n \n-        try:\n             for chunk in image_chunks:\n                 if verifier:\n                     verifier.update(chunk)\n@@ -463,6 +463,8 @@ def _verify_and_write(self, context, image_id, trusted_certs,\n                 data.flush()\n                 self._safe_fsync(data)\n                 data.close()\n+            if isinstance(image_chunks, glance_utils.IterableWithLength):\n+                image_chunks.iterable.close()\n \n         if data is None:\n             return image_chunks"
},
{
"sha":"4f35f060e414432c3ce8ebe9ff7761db42b5d5cb",
"filename":"nova/tests/unit/image/test_glance.py",
"status":"modified",
"additions":37,
"deletions":5,
"changes":42,
"blob_url":"https://github.com/openstack/nova/blob/3d411cad6031b76a033f1e3aeb029959cc865e36/nova/tests/unit/image/test_glance.py",
"raw_url":"https://github.com/openstack/nova/raw/3d411cad6031b76a033f1e3aeb029959cc865e36/nova/tests/unit/image/test_glance.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/unit/image/test_glance.py?ref=3d411cad6031b76a033f1e3aeb029959cc865e36",
"patch":"@@ -16,12 +16,14 @@\n \n import copy\n import datetime\n+import io\n from io import StringIO\n import urllib.parse as urlparse\n \n import cryptography\n from cursive import exception as cursive_exception\n import ddt\n+import glanceclient.common.utils\n import glanceclient.exc\n from glanceclient.v1 import images\n from glanceclient.v2 import schemas\n@@ -701,16 +703,15 @@ def test_download_no_returned_image_data_v2(\n         with testtools.ExpectedException(exception.ImageUnacceptable):\n             service.download(ctx, mock.sentinel.image_id)\n \n-    @mock.patch('glanceclient.common.utils.IterableWithLength')\n-    @mock.patch('os.path.getsize', return_value=1)\n+    @mock.patch('os.path.getsize')\n     @mock.patch('builtins.open')\n     @mock.patch('nova.image.glance.LOG')\n     @mock.patch('nova.image.glance.GlanceImageServiceV2._get_verifier')\n     @mock.patch('nova.image.glance.GlanceImageServiceV2._get_transfer_method')\n     @mock.patch('nova.image.glance.GlanceImageServiceV2.show')\n     def test_download_direct_rbd_uri_v2(\n             self, show_mock, get_tran_mock, get_verifier_mock, log_mock,\n-            open_mock, getsize_mock, iterable_with_length_mock):\n+            open_mock, getsize_mock):\n         self.flags(enable_rbd_download=True, group='glance')\n         show_mock.return_value = {\n             'locations': [\n@@ -724,9 +725,13 @@ def test_download_direct_rbd_uri_v2(\n         get_tran_mock.return_value = tran_mod\n         client = mock.MagicMock()\n         ctx = mock.sentinel.ctx\n+        image_content = [\"rbd1\", \"rbd2\"]\n+        getsize_mock.return_value = len(image_content)\n+        file_object = mock.MagicMock(spec=io.BytesIO)\n+        file_object.__iter__.return_value = image_content\n         writer = mock.MagicMock()\n+        writer.__enter__.return_value = file_object\n         open_mock.return_value = writer\n-        iterable_with_length_mock.return_value = [\"rbd1\", \"rbd2\"]\n         service = glance.GlanceImageServiceV2(client)\n \n         verifier = mock.MagicMock()\n@@ -994,7 +999,7 @@ def test_download_with_get_verifier_failure_v2(self,\n                           service.download,\n                           context=None, image_id=None,\n                           data=None, dst_path=None)\n-        mock_log.error.assert_called_once_with(mock.ANY, mock.ANY)\n+        self.assertEqual(mock_log.error.call_count, 2)\n \n     @mock.patch('nova.image.glance.LOG')\n     @mock.patch('nova.image.glance.GlanceImageServiceV2.show')\n@@ -1052,6 +1057,33 @@ def test_download_dst_path_signature_fail_v2(self, mock_fsync,\n         mock_dest.truncate.assert_called_once_with(0)\n         self.assertTrue(mock_dest.close.called)\n \n+    @mock.patch('builtins.open')\n+    @mock.patch('cursive.signature_utils.get_verifier')\n+    @mock.patch('nova.image.glance.GlanceImageServiceV2.show')\n+    @mock.patch('nova.image.glance.GlanceImageServiceV2._safe_fsync')\n+    def test_download_dst_path_with_invalid_signature_v2(\n+            self, mock_fsync, mock_show, mock_get_verifier, mock_open):\n+        glance_iterable = mock.MagicMock(spec=io.BytesIO)\n+        glance_iterable.__iter__.return_value = self.fake_img_data\n+        self.client.call.return_value = fake_glance_response(\n+            glanceclient.common.utils.IterableWithLength(\n+                iterable=glance_iterable, length=len(self.fake_img_data)))\n+        service = glance.GlanceImageServiceV2(self.client)\n+        mock_get_verifier.side_effect = \\\n+            cursive_exception.SignatureVerificationError\n+        mock_dest = mock.MagicMock()\n+        mock_open.return_value = mock_dest\n+        mock_show.return_value = self.fake_img_props\n+        fake_path = 'FAKE_PATH'\n+        self.assertRaises(cursive_exception.SignatureVerificationError,\n+                          service.download,\n+                          context=None, image_id=None,\n+                          data=None, dst_path=fake_path)\n+        mock_open.assert_called_once_with(fake_path, 'wb')\n+        mock_fsync.assert_called_once_with(mock_dest)\n+        mock_dest.close.assert_called()\n+        glance_iterable.close.assert_called()\n+\n \n class TestDownloadCertificateValidation(test.NoDBTestCase):\n     \"\"\"Tests the download method of the GlanceImageServiceV2 when"
}
]
},
{
"commit_sha":"24e02f1a9caf3cfbc4deb86066a05e1b60043446",
"commit_node_id":"C_kwDOAAwOD9oAKDI0ZTAyZjFhOWNhZjNjZmJjNGRlYjg2MDY2YTA1ZTFiNjAwNDM0NDY",
"commit_html_url":"https://github.com/openstack/nova/commit/24e02f1a9caf3cfbc4deb86066a05e1b60043446",
"commit_date":"2022-01-17T04:25:51Z",
"files":[
{
"sha":"c0f25bd260bba16268b56431a1137265332a2b7f",
"filename":"nova/exception.py",
"status":"modified",
"additions":3,
"deletions":2,
"changes":5,
"blob_url":"https://github.com/openstack/nova/blob/24e02f1a9caf3cfbc4deb86066a05e1b60043446/nova/exception.py",
"raw_url":"https://github.com/openstack/nova/raw/24e02f1a9caf3cfbc4deb86066a05e1b60043446/nova/exception.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/exception.py?ref=24e02f1a9caf3cfbc4deb86066a05e1b60043446",
"patch":"@@ -2362,8 +2362,9 @@ class AcceleratorRequestOpFailed(NovaException):\n class AcceleratorRequestBindingFailed(NovaException):\n     msg_fmt = _(\"Failed to bind accelerator requests: %(msg)s\")\n \n-    def __init__(self, arqs, **kwargs):\n-        super().__init__(message=self.msg_fmt, **kwargs)\n+    def __init__(self, message=None, arqs=None, **kwargs):\n+        super(AcceleratorRequestBindingFailed, self).__init__(\n+            message=message, **kwargs)\n         self.arqs = arqs or []\n \n "
}
]
},
{
"commit_sha":"33bc5c09f576680d150435fb7ad435b23e778316",
"commit_node_id":"C_kwDOAAwOD9oAKDMzYmM1YzA5ZjU3NjY4MGQxNTA0MzVmYjdhZDQzNWIyM2U3NzgzMTY",
"commit_html_url":"https://github.com/openstack/nova/commit/33bc5c09f576680d150435fb7ad435b23e778316",
"commit_date":"2022-01-16T14:30:41Z",
"files":[
{
"sha":"95f468abb47da61117bffb720b1eab2814b7d280",
"filename":"requirements.txt",
"status":"modified",
"additions":1,
"deletions":0,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/33bc5c09f576680d150435fb7ad435b23e778316/requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/33bc5c09f576680d150435fb7ad435b23e778316/requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/requirements.txt?ref=33bc5c09f576680d150435fb7ad435b23e778316",
"patch":"@@ -68,3 +68,4 @@ futurist>=1.8.0 # Apache-2.0\n openstacksdk>=0.35.0 # Apache-2.0\n dataclasses>=0.7;python_version=='3.6'  # Apache 2.0 License\n PyYAML>=5.1 # MIT\n+fixtures>=3.0.0 # Apache-2.0/BSD"
},
{
"sha":"80104c298f80a5dd4ec1acc7a40f8b13b41ea529",
"filename":"test-requirements.txt",
"status":"modified",
"additions":0,
"deletions":1,
"changes":1,
"blob_url":"https://github.com/openstack/nova/blob/33bc5c09f576680d150435fb7ad435b23e778316/test-requirements.txt",
"raw_url":"https://github.com/openstack/nova/raw/33bc5c09f576680d150435fb7ad435b23e778316/test-requirements.txt",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/test-requirements.txt?ref=33bc5c09f576680d150435fb7ad435b23e778316",
"patch":"@@ -7,7 +7,6 @@ mypy>=0.761 # MIT\n types-paramiko>=0.1.3 # Apache-2.0\n coverage!=4.4,>=4.0 # Apache-2.0\n ddt>=1.2.1 # MIT\n-fixtures>=3.0.0 # Apache-2.0/BSD\n mock>=3.0.0 # BSD\n psycopg2-binary>=2.8 # LGPL/ZPL\n PyMySQL>=0.8.0 # MIT License"
}
]
},
{
"commit_sha":"d5b6412ef52b1e5ad797a49850c9c6701b0405db",
"commit_node_id":"C_kwDOAAwOD9oAKGQ1YjY0MTJlZjUyYjFlNWFkNzk3YTQ5ODUwYzljNjcwMWIwNDA1ZGI",
"commit_html_url":"https://github.com/openstack/nova/commit/d5b6412ef52b1e5ad797a49850c9c6701b0405db",
"commit_date":"2022-01-14T22:28:02Z",
"files":[
{
"sha":"f480403a4065b374a01d6e12cfe2b43c829e3020",
"filename":"api-ref/source/servers-actions.inc",
"status":"modified",
"additions":2,
"deletions":1,
"changes":3,
"blob_url":"https://github.com/openstack/nova/blob/d5b6412ef52b1e5ad797a49850c9c6701b0405db/api-ref/source/servers-actions.inc",
"raw_url":"https://github.com/openstack/nova/raw/d5b6412ef52b1e5ad797a49850c9c6701b0405db/api-ref/source/servers-actions.inc",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/api-ref/source/servers-actions.inc?ref=d5b6412ef52b1e5ad797a49850c9c6701b0405db",
"patch":"@@ -755,7 +755,8 @@ Rescue Server (rescue Action)\n \n Puts a server in rescue mode and changes its status to ``RESCUE``.\n \n-.. note:: This API is not supported for volume-backed instances.\n+.. note:: Until microversion 2.87, this API is not supported for volume-backed\n+          instances.\n \n Specify the ``rescue`` action in the request body.\n "
}
]
},
{
"commit_sha":"a17b67ab2a83df97116d0767978b80d37035ce91",
"commit_node_id":"C_kwDOAAwOD9oAKGExN2I2N2FiMmE4M2RmOTcxMTZkMDc2Nzk3OGI4MGQzNzAzNWNlOTE",
"commit_html_url":"https://github.com/openstack/nova/commit/a17b67ab2a83df97116d0767978b80d37035ce91",
"commit_date":"2022-01-14T22:27:56Z",
"files":[
{
"sha":"248d9f11c2065db622f0cbd8233cd15b66aafee9",
"filename":"doc/source/contributor/testing.rst",
"status":"modified",
"additions":4,
"deletions":3,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/a17b67ab2a83df97116d0767978b80d37035ce91/doc/source/contributor/testing.rst",
"raw_url":"https://github.com/openstack/nova/raw/a17b67ab2a83df97116d0767978b80d37035ce91/doc/source/contributor/testing.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/contributor/testing.rst?ref=a17b67ab2a83df97116d0767978b80d37035ce91",
"patch":"@@ -121,6 +121,7 @@ services and a database, with minimal stubbing of nova internals.\n Interoperability tests\n -----------------------\n \n-The DefCore committee maintains a list that contains a subset of Tempest tests.\n-These are used to verify if a particular Nova deployment's API responds as\n-expected. For more details, see: https://opendev.org/osf/interop\n+The Interop Working Group maintains a list that contains a subset of Tempest\n+tests. These are used to verify if a particular Nova deployment's API responds\n+as expected. For more details, see:\n+https://docs.opendev.org/openinfra/interop/latest/"
},
{
"sha":"0ed6d9d050cf488fcf1646cadc783fb2a23ec521",
"filename":"doc/source/user/feature-classification.rst",
"status":"modified",
"additions":1,
"deletions":1,
"changes":2,
"blob_url":"https://github.com/openstack/nova/blob/a17b67ab2a83df97116d0767978b80d37035ce91/doc/source/user/feature-classification.rst",
"raw_url":"https://github.com/openstack/nova/raw/a17b67ab2a83df97116d0767978b80d37035ce91/doc/source/user/feature-classification.rst",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/doc/source/user/feature-classification.rst?ref=a17b67ab2a83df97116d0767978b80d37035ce91",
"patch":"@@ -139,7 +139,7 @@ rating for each feature group.\n .. note::\n \n    Although having some similarities, this list is not directly related\n-   to the DefCore effort.\n+   to the Interop effort.\n \n **Feature Group ratings:**\n "
}
]
},
{
"commit_sha":"51821373673e2fce0f6230bb2d2e2fb4170d5ff3",
"commit_node_id":"C_kwDOAAwOD9oAKDUxODIxMzczNjczZTJmY2UwZjYyMzBiYjJkMmUyZmI0MTcwZDVmZjM",
"commit_html_url":"https://github.com/openstack/nova/commit/51821373673e2fce0f6230bb2d2e2fb4170d5ff3",
"commit_date":"2022-01-14T21:02:28Z",
"files":[
{
"sha":"322cc7bedf09328caaa39545d59c0ec7d63ec25b",
"filename":"nova/tests/fixtures/nova.py",
"status":"modified",
"additions":17,
"deletions":3,
"changes":20,
"blob_url":"https://github.com/openstack/nova/blob/51821373673e2fce0f6230bb2d2e2fb4170d5ff3/nova/tests/fixtures/nova.py",
"raw_url":"https://github.com/openstack/nova/raw/51821373673e2fce0f6230bb2d2e2fb4170d5ff3/nova/tests/fixtures/nova.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/fixtures/nova.py?ref=51821373673e2fce0f6230bb2d2e2fb4170d5ff3",
"patch":"@@ -958,6 +958,11 @@ class OSAPIFixture(fixtures.Fixture):\n     - resp.content - the body of the response\n     - resp.headers - dictionary of HTTP headers returned\n \n+    This fixture also has the following clients with various differences:\n+\n+        self.admin_api - Project user with is_admin=True and the \"admin\" role\n+        self.reader_api - Project user with only the \"reader\" role\n+        self.other_api - Project user with only the \"other\" role\n     \"\"\"\n \n     def __init__(\n@@ -1021,9 +1026,17 @@ def setUp(self):\n             base_url += '/' + self.project_id\n \n         self.api = client.TestOpenStackClient(\n-            'fake', base_url, project_id=self.project_id)\n+            'fake', base_url, project_id=self.project_id,\n+            roles=['reader', 'member'])\n         self.admin_api = client.TestOpenStackClient(\n-            'admin', base_url, project_id=self.project_id)\n+            'admin', base_url, project_id=self.project_id,\n+            roles=['reader', 'member', 'admin'])\n+        self.reader_api = client.TestOpenStackClient(\n+            'reader', base_url, project_id=self.project_id,\n+            roles=['reader'])\n+        self.other_api = client.TestOpenStackClient(\n+            'other', base_url, project_id=self.project_id,\n+            roles=['other'])\n         # Provide a way to access the wsgi application to tests using\n         # the fixture.\n         self.app = app\n@@ -1040,8 +1053,9 @@ def fake_ctx(env, **kwargs):\n             user_id = env['HTTP_X_AUTH_USER']\n             project_id = env['HTTP_X_AUTH_PROJECT_ID']\n             is_admin = user_id == 'admin'\n+            roles = env['HTTP_X_ROLES'].split(',')\n             return context.RequestContext(\n-                user_id, project_id, is_admin=is_admin, **kwargs)\n+                user_id, project_id, is_admin=is_admin, roles=roles, **kwargs)\n \n         self.useFixture(fixtures.MonkeyPatch(\n             'nova.api.auth.NovaKeystoneContext._create_context', fake_ctx))"
},
{
"sha":"801ca4df7e46dacd98f0fc7a89271bc387d9aaa0",
"filename":"nova/tests/functional/api/client.py",
"status":"modified",
"additions":6,
"deletions":1,
"changes":7,
"blob_url":"https://github.com/openstack/nova/blob/51821373673e2fce0f6230bb2d2e2fb4170d5ff3/nova/tests/functional/api/client.py",
"raw_url":"https://github.com/openstack/nova/raw/51821373673e2fce0f6230bb2d2e2fb4170d5ff3/nova/tests/functional/api/client.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/api/client.py?ref=51821373673e2fce0f6230bb2d2e2fb4170d5ff3",
"patch":"@@ -123,9 +123,12 @@ class TestOpenStackClient(object):\n     This is a really basic OpenStack API client that is under our control,\n     so we can make changes / insert hooks for testing\n \n+    By default, no roles are implied and must be passed like\n+    roles=['reader', 'member'] in order for the user to have\n+    privileges on the project, just like in a real deployment.\n     \"\"\"\n \n-    def __init__(self, auth_user, base_url, project_id=None):\n+    def __init__(self, auth_user, base_url, project_id=None, roles=None):\n         super(TestOpenStackClient, self).__init__()\n         self.auth_user = auth_user\n         self.base_url = base_url\n@@ -134,6 +137,7 @@ def __init__(self, auth_user, base_url, project_id=None):\n         else:\n             self.project_id = project_id\n         self.microversion = None\n+        self.roles = roles or []\n \n     def request(self, url, method='GET', body=None, headers=None):\n         _headers = {'Content-Type': 'application/json'}\n@@ -169,6 +173,7 @@ def api_request(self, relative_uri, check_response_status=None,\n         headers.setdefault('X-Auth-User', self.auth_user)\n         headers.setdefault('X-User-Id', self.auth_user)\n         headers.setdefault('X-Auth-Project-Id', self.project_id)\n+        headers.setdefault('X-Roles', ','.join(self.roles))\n \n         response = self.request(full_uri, **kwargs)\n "
}
]
},
{
"commit_sha":"ca1efb52f1596401262c28d09229fb5625c2351c",
"commit_node_id":"C_kwDOAAwOD9oAKGNhMWVmYjUyZjE1OTY0MDEyNjJjMjhkMDkyMjlmYjU2MjVjMjM1MWM",
"commit_html_url":"https://github.com/openstack/nova/commit/ca1efb52f1596401262c28d09229fb5625c2351c",
"commit_date":"2022-01-14T18:34:43Z",
"files":[
{
"sha":"e0543a5fd995cac0a1ae2317450eeba8343459be",
"filename":"nova/tests/functional/regressions/test_bug_1937084.py",
"status":"added",
"additions":95,
"deletions":0,
"changes":95,
"blob_url":"https://github.com/openstack/nova/blob/ca1efb52f1596401262c28d09229fb5625c2351c/nova/tests/functional/regressions/test_bug_1937084.py",
"raw_url":"https://github.com/openstack/nova/raw/ca1efb52f1596401262c28d09229fb5625c2351c/nova/tests/functional/regressions/test_bug_1937084.py",
"contents_url":"https://api.github.com/repos/openstack/nova/contents/nova/tests/functional/regressions/test_bug_1937084.py?ref=ca1efb52f1596401262c28d09229fb5625c2351c",
"patch":"@@ -0,0 +1,95 @@\n+# Copyright 2021, Red Hat, Inc. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n+# not use this file except in compliance with the License. You may obtain\n+# a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+# License for the specific language governing permissions and limitations\n+# under the License.\n+\n+import mock\n+\n+from nova import context\n+from nova import exception\n+from nova import objects\n+from nova.tests.functional.api import client\n+from nova.tests.functional import integrated_helpers\n+\n+\n+class TestDetachAttachmentNotFound(integrated_helpers._IntegratedTestBase):\n+    \"\"\"Regression test for the Nova portion of bug 1937084\n+\n+    This regression test asserts the behaviour of Nova when Cinder raises a 404\n+    during a DELETE request against an attachment.\n+\n+    In the context of bug 1937084 this could happen if a caller attempted to\n+    DELETE a volume attachment through Nova's os-volume_attachments API and\n+    then made a separate DELETE request against the underlying volume in Cinder\n+    when it was marked as available.\n+    \"\"\"\n+\n+    microversion = 'latest'\n+\n+    def test_delete_attachment_volume_not_found(self):\n+        # Create a server and attach a single volume\n+        server = self._create_server(networks='none')\n+        server_id = server['id']\n+        self.api.post_server_volume(\n+            server_id,\n+            {\n+                'volumeAttachment': {\n+                    'volumeId': self.cinder.IMAGE_BACKED_VOL\n+                }\n+            }\n+        )\n+        self._wait_for_volume_attach(server_id, self.cinder.IMAGE_BACKED_VOL)\n+\n+        # Assert that we have an active bdm for the attachment before we detach\n+        bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(\n+            context.get_admin_context(),\n+            self.cinder.IMAGE_BACKED_VOL,\n+            server_id)\n+\n+        with mock.patch(\n+            'nova.volume.cinder.API.attachment_delete',\n+            side_effect=exception.VolumeAttachmentNotFound(\n+                attachment_id=bdm.attachment_id)\n+        ) as (\n+            mock_attachment_delete\n+        ):\n+            # DELETE /servers/{server_id}/os-volume_attachments/{volume_id} is\n+            # async but as we are using CastAsCall it's sync in our func tests\n+            ex = self.assertRaises(\n+                client.OpenStackApiException,\n+                self.api.delete_server_volume,\n+                server_id,\n+                self.cinder.IMAGE_BACKED_VOL)\n+            self.assertEqual(500, ex.response.status_code)\n+            mock_attachment_delete.assert_called_once()\n+\n+        # FIXME(lyarwood): This is the Nova portion of bug #1937084 where\n+        # the original caller hasn't polled os-volume_attachments and sent\n+        # a seperate DELETE request to c-api for the volume as soon as it\n+        # has become available but before n-cpu has finished the original\n+        # call. This leads to the sync request to c-api to delete the\n+        # attachment returning a 404 that Nova translates into\n+        # VolumeAttachmentNotFound.\n+        #\n+        # Replace this with the following once the exception is ignored:\n+        #\n+        #  self.assertRaises(\n+        #      exception.VolumeBDMNotFound,\n+        #      objects.BlockDeviceMapping.get_by_volume_and_instance,\n+        #      context.get_admin_context(),\n+        #      self.cinder.IMAGE_BACKED_VOL,\n+        #      server_id)\n+        #\n+        bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(\n+            context.get_admin_context(),\n+            self.cinder.IMAGE_BACKED_VOL,\n+            server_id)"
}
]
}
]